source,domain,url,created_utc,title,text,query
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/desktop-wallpaper-calendars-february-2026/,1769850000,"Short Month, Big Ideas (February 2026 Wallpapers Edition)","Short Month, Big Ideas (February 2026 Wallpapers Edition)

Letâ€™s make the most of the shortest month of the year with a new collection of desktop wallpapers that are sure to bring a smile to your face â€” and maybe spark your creativity, too. All of them were designed with love by the community for the community and can be downloaded for free. Happy February!",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/practical-use-ai-coding-tools-responsible-developer/,1769778000,Practical Use Of AI Coding Tools For The Responsible Developer,"Practical Use Of AI Coding Tools For The Responsible Developer

AI coding tools like agents can be valuable allies in everyday development work. They help handle time-consuming grunt work, guide you through large legacy codebases, and offer low-risk ways to implement features in previously unfamiliar programming languages. Here are practical, easy-to-apply techniques to help you use these tools to improve your workflow.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/unstacking-css-stacking-contexts/,1769508000,Unstacking CSS Stacking Contexts,"Unstacking CSS Stacking Contexts

In CSS, we can create â€œstacking contextsâ€ where elements are visually placed one on top of the next in a three-dimensional sense that creates the perception of depth. Stacking contexts are incredibly useful, but theyâ€™re also widely misunderstood and often mistakenly created, leading to a slew of layout issues that can be tricky to solve.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking â€œPixel Perfectâ€ Web Design,"Rethinking â€œPixel Perfectâ€ Web Design

Amit Sheen takes a hard look at the â€œPixel Perfectâ€ legacy concept, explaining why itâ€™s failing us and redefining what â€œperfectionâ€ actually looks like in a multi-device, fluid world.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designerâ€™s Career Paths In 2026,"UX And Product Designerâ€™s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI thatâ€™s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,PivotingÂ Your Career Without Starting From Scratch,"PivotingÂ Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, â€œIs this still what I want to be doing?â€ This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as youâ€™re reading this or youâ€™re still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? Weâ€™ve got you covered.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/giving-users-voice-virtual-personas/,1766484000,Giving Users A Voice Through Virtual Personas,"Giving Users A Voice Through Virtual Personas

Turn scattered user research into AI-powered personas that give anyone consolidated multi-perspective feedback from a single question.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/,1766138400,How To Measure The Impact Of Features,"How To Measure The Impact Of Features

Meet TARS â€” a simple, repeatable, and meaningful UX metric designed specifically to track the performance of product features. Upcoming part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today).",
rss,uxdesign.cc,https://uxdesign.cc/gemini-vs-chatgpt-5-cloud-dancing-with-data-color-schemes-c32658205a65?source=rss----138adf9c44c---4,1769949085,Gemini vs ChatGPT-5: cloud dancing with data color schemes.,"Gemini vs ChatGPT-5: cloud dancing with data color schemes.

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/gemini-vs-chatgpt-5-cloud-dancing-with-data-color-schemes-c32658205a65?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1952/1*Xj5r0mGdlP1V8_nc2jYhbw.png"" width=""1952"" /></a></p><p class=""medium-feed-snippet"">Applying the 2026 Pantone Color of the Year to data visualization.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/gemini-vs-chatgpt-5-cloud-dancing-with-data-color-schemes-c32658205a65?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/lost-for-words-why-text-in-ai-images-still-goes-wrong-b5232c39bd11?source=rss----138adf9c44c---4,1769949004,Lost for words: why text in AI images still goes wrong,"Lost for words: why text in AI images still goes wrong

<h4>AI can conjure photorealistic faces and dreamy landscapes in seconds, but ask it to write â€œHappy Birthdayâ€ on a cake and things get weird fast. The culprit is how these models learn to read, and the solution is trickier than itÂ seems.</h4><p>Imagine youâ€™ve just prompted your chosen AI image generator to create a stunning fashion advertisement for a major platform. The colours are gorgeous, the composition is beautifully balanced, and the lighting would make any photographer jealous. Thereâ€™s just one small problem: the text reads â€œSHOP NUG.â€ Close, but notÂ quite.</p><figure><img alt=""Four identical fashion ads with increasingly garbled AI-generated text, showing errors like â€˜SHUP NOY,â€™ â€˜DISGVER YUR SFYLE,â€™ and â€˜SUMMILER COLLECIONâ€™ instead of proper words."" src=""https://cdn-images-1.medium.com/max/1024/1*JpH8f3y4pOZpYh5Mlbg1iQ.png"" /><figcaption>Image byÂ author</figcaption></figure><p>If this sounds familiar, youâ€™re certainly not alone. Despite remarkable leaps in AI-generated imagery over the past few years, text rendering remains the Achillesâ€™ heel of even the most sophisticated models. And hereâ€™s the kicker: whilst generation has been steadily improving, <em>editing</em> that garbled text after the fact is proving to be an even thornier challenge.</p><p>So, whatÂ gives?</p><h3><strong>The fundamental mismatch</strong></h3><p>The truth is, AI image generators donâ€™t actually â€œreadâ€ text. At all. When you ask <a href=""https://openai.com/index/dall-e-3/"">DALL-E</a> or <a href=""https://www.midjourney.com/"">Midjourney</a> to include words in an image, the model isnâ€™t processing language. Itâ€™s simply pattern-matching shapes it has seen before in trainingÂ data.</p><p>Traditional text-to-image models like Stable Diffusion perceive text as a collection of pixels and visual elements to composite into the scene, not as meaning-conveying strings of characters. The model has seen millions of images containing billboards, book covers, and street signs, but it was never explicitly taught what those squiggles <em>mean</em> or how they follow strict rules of spelling andÂ grammar.</p><p>This creates a fundamental mismatch. Text is precise and unforgiving: one wrong letter changes everything (â€œSTOPâ€ versus â€œST0Pâ€, anyone?). Images, by contrast, are fluid and interpretive. A face can be slightly asymmetrical and still look human. A landscape can have unusual lighting and still feel real. But misspell a single word? The illusion shatters.</p><h3><strong>How diffusion actually works (in broadÂ strokes)</strong></h3><p>To understand why text is such a headache, it helps to peek behind the curtain at how these models generate images in the firstÂ place.</p><p>Most modern AI image generators use something called <a href=""https://stable-diffusion-art.com/how-stable-diffusion-work/"">diffusion models</a>. The basic idea is surprisingly elegant. During training, the model learns to gradually add noise to images until they become pure static, then reverses this process by removing noise step-by-step to recover coherent pictures.</p><p>When you type a prompt, it gets processed through a text encoder (typically <a href=""https://openai.com/index/clip/"">CLIP</a>) that converts your words into numerical representations. These embeddings then guide the denoising process, steering the random noise towards something resembling your description.</p><figure><img alt=""Diagram showing AI image generation workflow in five steps: 1) Prompt (text input), 2) Encode (AI processes text), 3) Denoise (removes visual noise shown as dots), 4) Refine (improves image composition), 5) Output (final image). Illustrated with simple icons connected by arrows flowing left to right."" src=""https://cdn-images-1.medium.com/max/1024/1*Q2BzL8FhuLaDKns0UbFJ5g.png"" /><figcaption>Image byÂ author</figcaption></figure><p>The problem? Fine details like individual letters are treated as low-priority during the early denoising steps. Errors get â€œbaked inâ€ early and become <a href=""https://dev.to/tracywhodoesnot/why-ai-struggles-with-text-in-image-generation-n69"">incredibly difficult to correct later in the process</a>. The model is essentially guessing letter shapes with no feedback loop to verify whether its guess makes any linguistic sense.</p><p>Thereâ€™s also the tokenisation issue. When CLIP processes text, it splits words into tokens, and sometimes those splits break apart the very concepts itâ€™s trying to understand. â€œDeep focus,â€ for instance, gets tokenised into separate pieces, losing the photographic meaning entirely. The same fragmentation happens with the text <em>in</em> your images, making coherent words harder to reconstruct.</p><h3><strong>Generation is getting betterâ€Šâ€”â€Šediting, not soÂ much</strong></h3><p>Now for some good news: text generation in AI images has improved dramatically. Newer models are making genuine strides, and the gap between â€œabsolutely wrongâ€ and â€œactually usableâ€ has narrowed considerably over the past year orÂ so.</p><p>The improvement isnâ€™t accidental. Companies have specifically invested in solving this problem, recognising that text accuracy is a dealbreaker for commercial applications. After all, nobody wants to hand a client an otherwise perfect AI-generated mockup with â€œBSET PRCIESâ€ plastered acrossÂ it.</p><p><a href=""https://ideogram.ai/"">Ideogram</a>, a platform built specifically with typography in mind, is said to be achieving now roughly <a href=""https://pxz.ai/blog/ideogram-vs-midjourney-2026"">95% accuracy on text prompts</a>, a remarkable leap compared to Midjourneyâ€™s approximately 40%. The company claims its latest model reduces text error rates by <a href=""https://the-decoder.com/ideogram-1-0-outshines-midjourney-and-dall-e-3-with-impressive-text-rendering/"">nearly half compared to DALL-E 3</a>. For designers who need readable words on posters, logos, and social media graphics, this could be genuinely transformative.</p><p>But does it really stand up to scrutiny? In the first example below, I asked it to generate a bookshelf with popular titles on product design, with the text clearly visible. The results showed significant errors (â€œDonâ€™t Make Me Thinkâ€ became â€œDONâ€™T MAKE ME M THINK THINK,â€) and other titles were similarly garbled. Next, I provided a specific list of books and authors. The outcome? Still riddled with text errors, suggesting that Ideogramâ€™s touted 95% accuracy claim falls short in actual use cases that require heavy text generation. It may fare better with simpler, single-text prompts, but complex scenarios remain problematic.</p><figure><img alt=""Two AI-generated images of design book bookshelves side by side. Left image shows books with text errors including â€˜DONâ€™T MAKE ME M THINK THINKâ€™ and garbled versions of titles like â€˜The Design of Everyday Things,â€™ â€˜About Face,â€™ â€˜Lean UX,â€™ and â€˜Atomic Design.â€™ Right image shows even more severely garbled text with â€˜DO ONâ€™ OK ME THIK,â€™ â€˜ROOK LE,â€™ â€˜DEUNNEWE UMBI BOULE,â€™ and â€˜LEZCEDRâ€™ demonstrating AIâ€™s failure to render accurate book spine text."" src=""https://cdn-images-1.medium.com/max/1024/1*_ieWpXulhkEfhTa5bjnVPw.png"" /><figcaption>Image byÂ author</figcaption></figure><p><a href=""https://www.recraft.ai/blog/comparing-popular-and-high-performing-text-to-image-models-and-providers"">Recraft V3</a>, another newcomer, has also positioned itself as a leader in accurate text rendering, claiming â€œflawless results with every prompt.â€ A bold assertion, but the benchmarks suggest itâ€™s not farÂ off.</p><p>So if generation is improving, why is editing still such aÂ mess?</p><h3><strong>The short answer: context preservation</strong></h3><p>When generating an image from scratch, the model has complete creative freedom. It can place text wherever it likes, choose fonts that play nicely with its capabilities, and build the entire composition around what it knows it can renderÂ well.</p><p>Editing is a different beast entirely. When you ask an AI to fix garbled text on an existing image (through inpainting or other techniques) the model must preserve everything <em>around</em> the text whilst only modifying the specific region youâ€™ve highlighted. This is where things get complicated.</p><p><a href=""https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1614608/full"">Research on latent diffusion models for inpainting</a> shows that when applied to large or irregular regions, these models â€œtend to generate blurry or contextually ambiguous reconstructions.â€ The model fills in details based on surrounding context and learned patterns, which simply isnâ€™t precise enough for the exact letter shapes that text requires.</p><p>In practical terms? The AI might successfully remove your gibberish text, but when it tries to paint new letters into that space, it struggles to match the exact style, lighting, and perspective of the original image. The result often looks patched rather than seamless.</p><h3><strong>Why youâ€™re not imagining things</strong></h3><p>If editing feels harder than generating, the data backs you up. A <a href=""https://www.mdpi.com/2076-3417/15/5/2274"">2025 benchmark study published in MDPI</a> evaluated multiple AI models across text accuracy metrics and found that all major platforms (including DALL-E 3, Ideogram, and Stable Diffusion) face â€œsignificant challenges with text accuracyâ€ across domains like code, chemical diagrams, and multi-line text.</p><p>The scores are telling. For code-related text, Stable Diffusion scored just 1.25 out of 5 for text accuracy. Even Ideogram, the supposed text champion, managed only 1.75 in the same category. When it comes to complex, structured text requiring precise formatting, all models struggle.</p><p>Platform comparisons in 2025 reflect this reality. <a href=""https://apatero.com/blog/image-to-image-ai-transformation-comparison-2025"">Image-to-image tools vary significantly</a>, with Midjourney notably lacking â€œtrue inpainting and transformation controls.â€ For users who do heavy editing work, local Stable Diffusion with ControlNet remains the go-to option. However, that requires technical expertise most casual users might simply notÂ have.</p><h3><strong>The workarounds (forÂ now)</strong></h3><p>Until AI cracks this particular nut, whatâ€™s a designer to do? A few strategies have emerged, each with their own trade-offs.</p><p><strong>Use text-first generators.</strong> If you know youâ€™ll need accurate typography, start with <a href=""https://ideogram.ai/"">Ideogram</a> or similar text-focused tools rather than trying to force words into Midjourneyâ€™s artistic outputs. Itâ€™s a case of picking the right tool for the job; you wouldnâ€™t edit a feature film in PowerPoint.</p><figure><img alt=""Dual monitor setup showing AI workflow: left screen displays AI-generated coffee shop interior without text, right screen shows the same image in Photoshop with â€˜Daily Brew Co.â€™ text overlay being added. Design tool logos (Photoshop, Figma, Canva, Affinity Designer) surround the monitors on the right side."" src=""https://cdn-images-1.medium.com/max/1024/1*_KEoHpKYJ9mBavQCGm33XA.png"" /><figcaption>Image byÂ author</figcaption></figure><p><strong>Generate first, add text later.</strong> Many professionals now create their AI imagery text-free, then overlay typography using traditional design tools like Photoshop, Canva, or Figma. Itâ€™s an extra step, but the results are far more reliable. This approach also gives you complete control over font selection, kerning, and placement; things AI still handles clumsily atÂ best.</p><p><strong>Try dedicated fix-it tools.</strong> Platforms like <a href=""https://www.makeuseof.com/how-to-fix-gibberish-text-in-ai-generated-images/"">Storia Labâ€™s Textify</a> or Canvaâ€™s Grab Text tool can identify gibberish text and attempt to replace it. Results vary (patience is required) but for simple corrections, they can save considerable headaches. Just donâ€™t expect miracles with complex multi-line text or heavily stylised typography.</p><p><strong>Embrace the hybrid workflow.</strong> As one industry comparison put it, â€œmany professionals use both platforms,â€ generating artistic foundations in Midjourney, then handling typography in Ideogram. Itâ€™s not elegant, and it requires subscriptions to multiple services, but it works. Think of it as assembling a toolkit rather than searching for a single magicÂ wand.</p><p><strong>Keep expectations realistic.</strong> Perhaps the most important strategy is simply managing client and stakeholder expectations. AI-generated imagery is powerful, but it has clear limitations. Flagging potential text issues upfront saves awkward conversations down theÂ line.</p><h3><strong>What this means for designers and UX professionals</strong></h3><p>Beyond the technical challenges, thereâ€™s a broader conversation here about workflow and expectations. As AI tools become more embedded in creative processes, understanding their limitations isnâ€™t just nice-to-have knowledge; itâ€™s essential professional competence.</p><p>For UX writers and content designers, this has particular relevance. If youâ€™re working with teams that use AI-generated imagery, you need to factor text limitations into your content strategy. That punchy headline might look great in a mockup, but will it survive the AI rendering process intact? Sometimes the answer is simply: maybeÂ not.</p><p>And letâ€™s be honest, thereâ€™s something almost poetic about AI mastering the creation of human faces whilst fumbling with human writing. Itâ€™s a reminder that these tools, however impressive, arenâ€™t magic. Theyâ€™re sophisticated pattern-matching systems with specific strengths and equally specific blindÂ spots.</p><h3><strong>Whatâ€™s on theÂ horizon?</strong></h3><p>The research community hasnâ€™t given up. Several promising approaches are in development:</p><ul><li><strong>Hybrid AI systems</strong> that generate a base image through one model, then overlay text using a separate, specialist module designed specifically for accurate placement. Think of it as mimicking how human designers work: creating the visual first, then adding captions as a finalÂ step.</li><li><strong>Better training data.</strong> Most current datasets lack properly labelled, structured text within images. Training on annotated text data could help models understand not just where text appears, but what it actually says and how words are properlyÂ formed.</li><li><strong>Vector-based rendering.</strong> Some teams are exploring ways to separate text from raster imagery entirely, treating typography as a discrete, editable layer rather than baking it into pixels. This would fundamentally change how text is handled, moving from pattern-matching to something closer to actual typesetting.</li><li><strong>OCR feedback loops.</strong> Imagine a model that generates text, runs optical character recognition to check its own work, and iterates until the spelling is correct. This kind of self-correction mechanism could dramatically reduce errors, though it would add computational overhead.</li></ul><h3><strong>Spelling itÂ out</strong></h3><p>AI image generation has come a long way in a remarkably short time. Photorealistic faces, impossible architecture, dreamlike landscapesâ€Šâ€”â€Šall conjured from a few words typed into a prompt box. But text, that most human of visual elements, remains stubbornly resistant.</p><p>The core issue isnâ€™t laziness or neglect. Itâ€™s architectural. Diffusion models were designed to see images holistically, not to parse the precise, rule-bound structures that make written language work. Generation is improving because researchers are training dedicated models for the task. Editing lags behind because preserving context whilst fixing details is a fundamentally harderÂ problem.</p><p>For now, the practical advice is straightforward: plan for text limitations, use the right tool for the job, and donâ€™t be afraid to bring in traditional design software for the finishing touches. AI is brilliant at many things. Fixing spelling errors in images just isnâ€™t one of themâ€¦Â yet.</p><blockquote><strong><em>Thanks for reading!Â ğŸ“–</em></strong></blockquote><blockquote><em>If you liked this post, </em><a href=""https://medium.com/@doracee""><em>follow me on Medium</em></a><em> forÂ more!</em></blockquote><h3><strong>References &amp;Â Credits:</strong></h3><ul><li><a href=""https://www.mdpi.com/2076-3417/15/5/2274"">(2025). Challenges in Generating Accurate Text in Images: A Benchmark for Text-to-Image Models on Specialized Content</a></li><li><a href=""https://stable-diffusion-art.com/how-stable-diffusion-work/"">Stable Diffusion Art. (2024). How Does Stable Diffusion Work?</a></li><li><a href=""https://dev.to/tracywhodoesnot/why-ai-struggles-with-text-in-image-generation-n69"">Why AI Still Struggles with Text in Image Generation</a></li><li><a href=""https://the-decoder.com/ideogram-1-0-outshines-midjourney-and-dall-e-3-with-impressive-text-rendering/"">THE DECODER. (2024). Ideogram 1.0 outshines Midjourney and DALL-E 3 with impressive text rendering</a></li><li><a href=""https://pxz.ai/blog/ideogram-vs-midjourney-2026"">(2026). Ideogram vs Midjourney: 50+ HoursÂ Testing</a></li><li><a href=""https://www.recraft.ai/blog/comparing-popular-and-high-performing-text-to-image-models-and-providers"">(2025). Comparing Text to Image Models and Providers</a></li><li><a href=""https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1614608/full"">Frontiers in AI. (2025). High-resolution image inpainting using a probabilistic framework</a></li><li><a href=""https://apatero.com/blog/image-to-image-ai-transformation-comparison-2025"">(2025). Image-to-Image AI Comparison 2025</a></li><li><a href=""https://www.makeuseof.com/how-to-fix-gibberish-text-in-ai-generated-images/"">(2024). I Tested 4 Tools to Fix Gibberish Text in AI-Generated Images</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b5232c39bd11"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/lost-for-words-why-text-in-ai-images-still-goes-wrong-b5232c39bd11"">Lost for words: why text in AI images still goes wrong</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/data-tables-need-to-be-accessible-too-6a13533a6fde?source=rss----138adf9c44c---4,1769948938,"Data tables need to be accessible, too","Data tables need to be accessible, too

<h4><em>Why data tables are an accessibility blind-spot (and how WCAGÂ helps)</em></h4><p>Data tables are used in many different products and contexts. They are used in dashboards, product comparisons, or even internal finance reports. They help users make decisions, spot data patterns, and take action whereÂ needed.</p><p><strong>But when it comes to accessibility, data tables are often skipped.</strong> Theyâ€™re assumed to be handled by default HTML or put off until the development stage.</p><p>Visually, the tables look easy to read with clear columns and rows, as well as distinct headers. But for many users (like those using screen readers or keyboard navigation), these tables can become confusing or even unusable.</p><figure><img alt=""Example data tables from IBM Carbon and Salesforce Lightning design systems"" src=""https://cdn-images-1.medium.com/max/1024/1*V2pdiWu3IGVeuqcTJI_yRw.png"" /><figcaption><em>Many open-source data tables are available via </em><a href=""https://react.carbondesignsystem.com/?path=/docs/components-datatable-basic--overview""><em>IBM Carbon</em></a><em> and </em><a href=""https://sds-site-docs-1fea39e7763a.herokuapp.com/index.html?path=/story/components-data-table--base""><em>Salesforce Lightning</em></a></figcaption></figure><p><strong>Just to be clear; WCAG doesnâ€™t prohibit data tables, it just requires that the tableâ€™s information, relationships, and functionality are available to all users.</strong> Not only that, you donâ€™t need complex solutions to have both data tables and WCAG-compliant designs.</p><p>Letâ€™s break down why data tables are frequently overlooked, what WCAG requires of them, and how designers and product teams can create accessible dataÂ tables.</p><h3>Why are tables an accessibility blind-spot?</h3><p>To be fair, data tables sit in an awkward spot between design and development. They feel too technical to be a pure design problem, but also feel too visual to be treated as just code. As a result, accessibility issues slip through theÂ cracks.</p><p>But what specific issues come from neither design or dev taking full ownership ofÂ tables?</p><h4>Tables lack semantic structure</h4><p>Visually, most tables appear easy to scan with aligned column headers and distinguished rows. But when this same structure isnâ€™t communicated properly in the code, assistive technologies lose the context that sighted users get visually.</p><p><strong>Without proper header associations, a screen reader (like Voiceover or NVDA) may announce a value without indicating which column or row it belongsÂ to.</strong></p><p>For instance, letâ€™s say there is a data table depicting the concerts you attended last year. A sighted user can easily understand when and where each concert was, but a screen reader announces â€œ12 Februaryâ€ without the associated concert it corresponds to.</p><figure><img alt=""Data table example with header cells named Date, Event, Venue in the top row"" src=""https://cdn-images-1.medium.com/max/1024/1*m6eIsbk0X6ngwuwkpiQeAQ.png"" /><figcaption><em>Data table example with header cells in the top row via </em><a href=""https://www.w3.org/WAI/tutorials/tables/one-header/#table-with-header-cells-in-the-top-row-only""><em>W3 WAI tutorials</em></a></figcaption></figure><pre>&lt;table&gt;<br />  &lt;tr&gt;<br />    &lt;th&gt;Date&lt;/th&gt;<br />    &lt;th&gt;Event&lt;/th&gt;<br />    &lt;th&gt;Venue&lt;/th&gt;<br />  &lt;/tr&gt;<br />  &lt;tr&gt;<br />    &lt;td&gt;12 February&lt;/td&gt;<br />    &lt;td&gt;Waltz with Strauss&lt;/td&gt;<br />    &lt;td&gt;Main Hall&lt;/td&gt;<br />  &lt;/tr&gt;<br />  [â€¦]<br />&lt;/table&gt;</pre><h4>Design Systems with information gaps</h4><p><strong>Many Design Systems include a table component, but sometimes they donâ€™t clarify how the component should be used in the wild.</strong> The guidance leaves open questions about accessibility, like:</p><ul><li>When should a table be used instead of aÂ list?</li><li>How should sortingÂ behave?</li><li>What happens when data is empty, truncated, orÂ loading?</li></ul><p>Without explicit standards, tables used by different teams behave differently, and accessibility becomes inconsistent.</p><h4>Added interactions without accessibility</h4><p>Modern tables are typically dynamic with sortable columns, selectable rows, and inline actions. But these interaction patterns are layered on top of the table without clear guidance on keyboard behavior, focus order, or screen reader announcements.</p><p><strong>When accessibility is addressed late in development, teams might add impromptu ARIA attributes instead of designing inclusively from the start.</strong> This results in a table that â€œfunctions,â€ but feels unpredictable or exhausting to navigate with only a keyboard.</p><figure><img alt=""Data table with batch actions as an example from IBM Carbon Storybook"" src=""https://cdn-images-1.medium.com/max/1024/1*gxIqfbG4PyAO04wG_Sk3WA.png"" /><figcaption><em>Data table with batch actions via </em><a href=""https://react.carbondesignsystem.com/?path=/story/components-datatable-batch-actions--default""><em>IBM Carbon Storybook</em></a></figcaption></figure><h3>Anatomy of an accessible dataÂ table</h3><h4>Overall structure</h4><ul><li>Rows and columns reflect the dataâ€™s relationships (not just visual alignment)</li><li>Headers clearly describe the content they correspond to</li><li>Reading order matches how the data is meant to be understood</li></ul><figure><img alt=""Tables create inherent visual structure using columns and row"" src=""https://cdn-images-1.medium.com/max/1024/1*Okr49IcRO2jl9hwhoNUSdA.png"" /><figcaption><em>Tables create inherent visual structure using columns and row; via </em><a href=""https://docs.google.com/spreadsheets/u/0/""><em>GoogleÂ Sheets</em></a></figcaption></figure><h4>Data relationships</h4><ul><li>Individual values connect to both their column and their row headers (even in multi-dimensional tables)</li><li>Context is communicated through programmatic associations (not only by visual means like spacing or alignment)</li><li>Users navigate cell by cell and understand the data as aÂ whole</li></ul><h4>Predictable navigation</h4><ul><li>Filters, column headers, and actions have clearÂ labels</li><li>Keyboard focus is always visible on the dataÂ table</li><li>Focus (tab) order aligns with the visual and logical layout of theÂ table</li></ul><figure><img alt=""Dellâ€™s Design System includes proper keyboard interactions for their table component"" src=""https://cdn-images-1.medium.com/max/1024/1*CEFgqCp5UFOJYITDRfLxJg.gif"" /><figcaption><a href=""https://react.delldesignsystem.com/2.21.0/index.html?path=/story/components-table--bulk-actions""><em>Dellâ€™s Design System</em></a><em> includes proper keyboard interactions for their table component</em></figcaption></figure><h4>Proper interactions</h4><ul><li>Interactive tables have clear affordances, accessible labels, and visibleÂ states</li><li>Users know when a column is sortable and which direction itâ€™s sortedÂ in</li><li>Users know what happens when they activate a control with a keyboard orÂ mouse</li></ul><blockquote><strong>Note</strong><em>: This anatomy allows assistive technologies to answer basic questions like: What column am I in? What does this value represent? Without it, users are forced toÂ guess.</em></blockquote><h3>WCAG criteria that matter most for dataÂ tables</h3><p>WCAG doesnâ€™t treat data tables as a special case. Thereâ€™s no guideline that says â€œmake tables accessible.â€ Instead, WCAG is more concerned with whether users can perceive relationships, operate functionality, and understand content within theÂ table.</p><p><strong>WCAG provides a framework, but itâ€™s up to designers and teams to meet the expectations.</strong></p><h4><a href=""https://www.w3.org/WAI/WCAG21/Understanding/info-and-relationships.html#brief"">SC 1.3.1 Info and Relationships (LevelÂ A)</a></h4><p>This criteria asks that all users can understand how headers relate to data cells, regardless of how the table looks visually. When header relationships are missing, assistive technologies canâ€™t provide meaningful context.</p><p><strong>Example techniques toÂ pass:</strong></p><ul><li>Use table markup to present tabular information (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/html/H51"">Technique H51</a>)</li><li>Use caption elements to associate the data tableâ€™s title or heading with the table (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/html/H39"">Technique H39</a>)</li><li>Use the scope attribute to associate header cells with cells in data tables (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/html/H63"">Technique H63</a>)</li><li>Use id and headers attributes to associate cells with header cells in data tables (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/html/H43"">Technique H43</a>)</li></ul><a href=""https://medium.com/media/338e43f81349ebc2a12841deaf0dd258/href"">https://medium.com/media/338e43f81349ebc2a12841deaf0dd258/href</a><h4><a href=""https://www.w3.org/WAI/WCAG21/Understanding/keyboard"">SC 2.1.1 Keyboard (LevelÂ A)</a></h4><p>Any interaction included in a table must be operable using only a keyboard. This includes not only navigating the table itself, but also using features like filtering, pagination, and row-level actions.</p><p><strong>Example techniques toÂ pass:</strong></p><ul><li>Ensure keyboard control for all functionality (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/general/G202"">Technique G202</a>)</li><li>Provide keyboard-triggered event handlers (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/general/G90"">Technique G90</a>)</li></ul><h4><a href=""https://www.w3.org/WAI/WCAG21/Understanding/focus-order#brief"">SC 2.4.3 Focus Order (LevelÂ A)</a></h4><p>Users navigating with a keyboard need to know where they are at all times. WCAG requires visible focus indicators and clear communication of stateÂ changes.</p><p><strong>Example techniques toÂ pass:</strong></p><ul><li>Place the interactive elements in an order that follows sequences and relationships within the content (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/general/G59"">Technique G59</a>)</li><li>Make the DOM order match the visual order (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/css/C27"">Technique C27</a>)</li></ul><h4><a href=""https://www.w3.org/WAI/WCAG21/Understanding/headings-and-labels"">SC 2.4.6 Headings and Labels (LevelÂ AA)</a></h4><p>WCAG requires that controls and content have clear, descriptive labels. In data tables, this applies to the tableâ€™s title, column headers, and its interactive controls.</p><p><strong>Example techniques toÂ pass:</strong></p><ul><li>Provide descriptive headings (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/general/G130"">Technique G130</a>)</li><li>Provide descriptive labels (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/general/G131"">Technique G131</a>)</li></ul><a href=""https://medium.com/media/64748825f9b314ce382b355646219ca9/href"">https://medium.com/media/64748825f9b314ce382b355646219ca9/href</a><h4><a href=""https://www.w3.org/WAI/WCAG21/Understanding/name-role-value#brief"">SC 4.1.2 Name, Role, Value (LevelÂ A)</a></h4><p>WCAG requires that content work reliably with assistive technologies now and in the future. For data tables, this means relying on semantic structure and predictable behavior rather than visually driven solutions.</p><p>Example techniques toÂ pass:</p><ul><li>Use aria-label to provide an accessible name where a visible label cannot be used (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/aria/ARIA14"">Technique ARIA14</a>)</li><li>Use aria-labelledby to provide a name for user interface controls (<a href=""https://www.w3.org/WAI/WCAG21/Techniques/aria/ARIA16"">Technique ARIA16</a>)</li></ul><h3>What designers should do before dev touchesÂ code</h3><p>Accessible data tables start with design decisions. Designers are responsible for preventing accessibility issues long before a developer ever starts coding. This includes defining design decisions like table structure, interactions, and data complexity.</p><h4>Use real structure, not justÂ layout</h4><p>Before thinking about visual styling, designers should answer the following:</p><ul><li>What are theÂ rows?</li><li>What are theÂ columns?</li><li>What relationships matterÂ most?</li></ul><p>If these answers arenâ€™t obvious in the design, they wonâ€™t be obvious to assistive technologies. You need clear column headers, meaningful row labels, and consistent data structure.</p><h4>Have intentional interactions</h4><p>Not every table needs sorting, filtering, or inline actions. Each interaction adds cognitive load and accessibility complexity. When interactions are necessary, designers shouldÂ define:</p><ul><li>Which columns areÂ sortable</li><li>What happens when sorting isÂ applied</li><li>How users move between table content andÂ controls</li><li>If actions apply to a row, a cell, or the entireÂ table</li></ul><figure><img alt=""Atlassianâ€™s Design System includes interactions when it makes sense with the data relationships"" src=""https://cdn-images-1.medium.com/max/1024/1*pplXXuqgTPxTXbCCSO0EqA.png"" /><figcaption><a href=""https://atlassian.design/components/dynamic-table/examples#uncontrolled""><em>Atlassianâ€™s Design System</em></a><em> includes interactions, like sorting, when it makes sense with the data relationships</em></figcaption></figure><h4>Design for keyboardÂ users</h4><p>Using a keyboard is a primary input method for many users. Designers need to ensure that tables can be navigated in a logical, predictable order byÂ asking:</p><ul><li>Can every interactive element be reached without a mouse/ trackpad?</li><li>Does keyboard focus move in a way that matches the tableâ€™s structure?</li><li>Are hover-only actions also doable via keyboard?</li></ul><h4>Consider various screenÂ sizes</h4><p>Designers need to explicitly define how table structure and relationships are preserved across breakpoints. As the screen size shrinks, itâ€™s simple to collapse and hide content, but designers should document:</p><ul><li>How labels remain associated with theirÂ values</li><li>How users can navigate between theÂ data</li><li>How accessible interactions are maintained</li></ul><figure><img alt=""Lightning Design Systemâ€™s data table responding to mobile screen size"" src=""https://cdn-images-1.medium.com/max/1024/1*8s-b_ImlOvrMbOwmyYkvvg.png"" /><figcaption>Data tables need to respond when presented on mobile devices; via <a href=""https://sds-site-docs-1fea39e7763a.herokuapp.com/index.html?path=/story/components-data-table--with-sorting"">Lightning DesignÂ System</a></figcaption></figure><h4>Document table expectations in DesignÂ Systems</h4><p>Data tables scale and remain consistent when theyâ€™re a shared standard. Documenting how tables behave is just as important as documenting how theyÂ look.</p><p>Helpful documentation includes:</p><ul><li>When to use a table (and when to other components like aÂ list)</li><li>Required semantics with structure, headers, andÂ labels</li><li>Keyboard and interaction behavior (like focus and pagination)</li><li>Interaction states and edge cases (like empty, loading, or errorÂ states)</li><li>Any known accessibility considerations or constraints</li></ul><p>Data tables are treated as containers for information, but theyâ€™re some of the most complex elements users interact with. Without incorporating accessibility into tables, users lose context, navigation becomes frustrating, and critical data becomes hard to understand.</p><p><strong>Complying with WCAG criteria helps all users no matter their ability.</strong> Accessible tables are easier to scan, more predictable to navigate, and clearly communicate meaning. They benefit screen reader users, keyboard users, and anyone working with dense data. When tables are designed with the same care as any other interface, accessibility follows naturally.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6a13533a6fde"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/data-tables-need-to-be-accessible-too-6a13533a6fde"">Data tables need to be accessible, too</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/beyond-the-double-diamond-integrating-leavitts-diamond-into-ux-e581b6d0a799?source=rss----138adf9c44c---4,1769862107,Beyond the Double Diamond: Integrating Leavittâ€™s Diamond into UX,"Beyond the Double Diamond: Integrating Leavittâ€™s Diamond into UX

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/beyond-the-double-diamond-integrating-leavitts-diamond-into-ux-e581b6d0a799?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1200/0*YQon5D-87jYUit6M.png"" width=""1200"" /></a></p><p class=""medium-feed-snippet"">Moving from &#x201c;feature factories&#x201d; to systems architecture</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/beyond-the-double-diamond-integrating-leavitts-diamond-into-ux-e581b6d0a799?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/when-design-stops-asking-why-and-starts-asking-can-ai-do-it-625c9a5d9c68?source=rss----138adf9c44c---4,1769862102,When design stops asking why and starts asking â€œcan AI do it?â€,"When design stops asking why and starts asking â€œcan AI do it?â€

<h3>When design stops asking why and starts asking, â€œCan AI doÂ it?â€</h3><h4>This advice is why designers are quietly losing strategic influence. We optimized AI interfaces for confidence. Organizations learned that confidence replaces judgment.</h4><figure><img alt=""Illustration of a fictional team chat where a product leader pushes for an AI-generated solution to a business problem before design investigation."" src=""https://cdn-images-1.medium.com/max/1024/1*oypi566Pl6vxkzJGk69RQw.png"" /><figcaption>Image Credit:Â Author.</figcaption></figure><p>The question dropped into the Slack channel before the user research summary. Before the problem was clearly defined. Before anyone asked if users actually needed thisÂ feature.</p><p>Your product manager already generated three interface options in ChatGPT. Now theyâ€™re asking which one to build. Not <em>whether</em> to build. Not <em>why</em> to build.Â <em>Which.</em></p><p>And when you slow the conversation down to ask those questions, youâ€™re about to discover that strategic thinking now reads as bottleneck behavior.</p><p>This isnâ€™t an accident. We designed the system that taught teams to trust AI outputs over design judgment.</p><p><a href=""https://www.figma.com/blog/figma-2025-ai-report-perspectives/"">Figmaâ€™s 2025 AI Report</a> surveyed 2,500 designers and developers and found that 78% agree AI significantly enhances work efficiency. Only 32% say they can actually rely on theÂ output.</p><figure><img alt=""Copy of Figmaâ€™s 2025 AI Report"" src=""https://cdn-images-1.medium.com/max/1024/1*IFEBoa0VZjExIekRqsQWkQ.png"" /><figcaption><a href=""https://www.figma.com/reports/ai-2025/"">Copy of Figmaâ€™s 2025 AIÂ Report.</a></figcaption></figure><p>That gap isnâ€™t a quality problem. Itâ€™s a powerÂ shift.</p><p>22% designers now use AI to create first drafts of interfaces. 33% use it to generate design assets. The time from concept to visible prototype collapsed from days toÂ minutes.</p><p>But something shifted that nobody warned you about: <strong>â€œCan AI do this?â€ started showing up at the beginning of product discussions.</strong> Not after user needs are validated. Not after strategic intent is clarified. It arrivesÂ first.</p><p>And when you slow teams down to ask strategic questions, youâ€™re increasingly seen as friction rather than guidance.</p><p>We built this pattern. Now itâ€™s being used againstÂ us.</p><h3>We taught teams that polish means correctness</h3><p>For years, UX designers optimized AI interfaces to hide uncertainty. <a href=""https://medium.com/core-ai/why-ai-sounds-confident-even-when-its-wrong-4c0683a6f61e"">Chatbots</a> that sounded certain even when guessing. Loading states that implied thoughtfulness without revealing computational doubt. Systems that presented single recommendations with high visual confidence rather than surfacing alternatives with calibrated uncertainty.</p><p>We did this because <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC3240751/"">research told us</a> users trust confident systems. Smooth experiences read as competent. Hesitation feels like failure. As Erika Hall noted in her <a href=""https://picovoice.ai/blog/conversation-design-tips-from-Hall/"">conversation with John Maeda</a>, â€œthe level of visual polish can lead designers and decision-makers to think that the concepts underneath are stronger than theyÂ are.â€</p><p>The concepts underneath are what matter. But we wrapped them in interfaces that signaled completion rather than exploration.</p><p>Those design decisions didnâ€™t stay contained. They taught organizations how to relate to AI outputs: <strong>polish became synonymous with correctness</strong>. Generation became synonymous with judgment. â€œAI created thisâ€ became implicit validation rather than a signal requiring verification.</p><p>We optimized for adoption. We got replacement.</p><h3>The data exposes the disconnect</h3><p>Figmaâ€™s survey of 2,500 designers and developers reveals the mechanic driving designâ€™s strategic erosion:</p><ul><li><strong>78% agree AI significantly enhances work efficiency</strong></li><li><strong>Only 32% say they can rely on AIÂ output</strong></li><li><strong>68% of developers report AI improves their workÂ quality</strong></li><li><strong>Only 40% of designers say theÂ same</strong></li></ul><p>The gap isnâ€™t about AI capability. Itâ€™s about what organizations value. When engineers can generate functional code, theyâ€™re delivering tangible output. When designers generate questions about whether this serves users, theyâ€™re deliveringâ€¦ friction.</p><figure><img alt=""Copy from Figmaâ€™s AI Report."" src=""https://cdn-images-1.medium.com/max/428/1*RnkBrXncSK__OSsyVRdAow.png"" /><figcaption><a href=""https://www.figma.com/reports/ai-2025/"">https://www.figma.com/reports/ai-2025/</a></figcaption></figure><p><a href=""https://medium.com/@msjuliabraimova/the-rise-of-ai-in-ux-ui-design-how-artificial-intelligence-is-reshaping-digital-experiences-7639bee841c7"">Julie Zhuo observed</a>: â€œAI is redefining how we prototype. What once took days can now be done in hours, allowing designers to iterate and test more rapidly.â€ True. But iteration without interrogation isnâ€™t strategic designâ€Šâ€”â€Šitâ€™s production atÂ scale.</p><p><a href=""https://banotes.org/administrative-thinkers/bounded-rationality-satisficing-decision-making-simon/"">Herbert Simonâ€™s research on bounded rationality</a> explains why this matters: under time pressure and cognitive constraints, people accept solutions that appear â€œgood enoughâ€ rather than optimal. AI doesnâ€™t create this behaviorâ€Šâ€”â€Šit accelerates it by making â€œgood enoughâ€ arrive so quickly that deeper evaluation feels wasteful.</p><p>When creation is cheap, <strong>teams learn to mistake speed for strategy</strong>.</p><h3>What actually changed: Decision orderÂ flipped</h3><p>Product teams used to follow a sequence: understand user problems â†’ clarify strategic intent â†’ explore solutions â†’ generate artifacts. This ordering wasnâ€™t arbitraryâ€Šâ€”â€Šit created space for judgment.</p><p>AI disrupted that sequence not by replacing designers but by making execution nearly instantaneous. When something can be generated in seconds, the act of creation no longer signals commitment. It signals possibility.</p><p>But teams donâ€™t always treat it thatÂ way.</p><p>Once a generated interface existsâ€Šâ€”â€Ševen provisionallyâ€Šâ€”â€Šit reshapes the conversation. The artifact becomes gravitational. Feedback clusters around it. Critique becomes incremental. The deeper question (<em>why this at all</em>) arrives late, if it arrives atÂ all.</p><p><a href=""https://designintech.report/2024/03/12/design-against-ai-2024/"">John Maedaâ€™s 2024 Design in Tech Report</a> distinguishes between â€œmakersâ€ (designers and developers who create) and â€œtalkersâ€ (product managers who drive revenue). AI made it easier for makers to make. But it made it <em>better</em> for talkers to talkâ€Šâ€”â€Šbecause AI outputs give them tangible artifacts to discuss without waiting for design judgment.</p><figure><img alt=""Abstract architectural forms in teal, gold, and black showing stacked geometric shapes representing organizational hierarchy transformation and power redistribution between different roles"" src=""https://cdn-images-1.medium.com/max/1024/1*EivrjbF7gUjc8D0uhCv67Q.png"" /><figcaption>The organizational power shift: When AI made artifacts instant, strategic influence moved from makers to talkers. Generated With Midjourney.</figcaption></figure><p>When stakeholders see â€œworkingâ€ prototypes in first meetings, the implicit question becomes: <em>What do we need designers for?</em></p><p>The answer used to be: <strong>Strategic thinking. User advocacy. The discipline to ask why beforeÂ how.</strong></p><p>But when generation speed becomes the primary value signal, those skills read as obstruction.</p><h3>The confidence problem weÂ created</h3><p>Most AI design tools are optimized for decisiveness. They generate singular recommendations with confident presentation. This makes sense from a UX perspectiveâ€Šâ€”â€Šconfidence reads as competence, smoothness reads as quality. As <a href=""https://www.studioubique.com/ai-ux-design/"">design best practices emphasize</a>, AI interfaces should â€œset honest expectationsâ€ and â€œshow confidence.â€</p><p>But between honest expectations and confident presentation, most products chose confidence.</p><p>This creates cascading problems. When AI presents one interface design with high visual polish, teams treat it as <em>the</em> answer rather than <em>an</em> exploration. Alternative approaches arenâ€™t surfaced. Edge cases arenâ€™t flagged. Uncertainty is smoothedÂ over.</p><p><a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC3240751/"">Research on automation bias</a> has demonstrated this dynamic for decades: people are significantly more likely to accept system output even when it conflicts with their own judgment, particularly when that output is presented confidently. The effect strengthens as systems appear more capable and authoritative.</p><p><a href=""https://interactions.acm.org/archive/view/july-august-2019/toward-human-centered-ai"">Human-centered AI research</a> has long advocated that systems should â€œsupport human judgment rather than replace itâ€â€Šâ€”â€Šsurfacing uncertainty, presenting multiple options, enabling override. But velocity pressures push teams toward tools that minimize friction, not maximize judgment.</p><p><strong>We designed the experience that trained organizations to trust confident outputs over strategic questioning.</strong></p><h3>What stopped gettingÂ asked</h3><p>As generation becomes easier, certain questions surface less often in product discussions:</p><p><strong>Why this approach instead of alternatives?</strong> When AI produces one polished solution quickly, exploring other directions feels wasteful. The existence of a â€œworkingâ€ prototype creates psychological commitment before strategic evaluation happens.</p><p><strong>What assumptions are embedded in this output?</strong> AI training data encodes countless decisions about what â€œgood designâ€ looks like, what user problems matter, what solutions are appropriate. These assumptions remain invisible unless teams actively interrogate them.</p><p><strong>Who does this work well forâ€Šâ€”â€Šand who does it exclude?</strong> Rapid generation optimizes for median cases in training data. Edge cases, accessibility considerations, users who donâ€™t match demographic norms get systematically overlooked.</p><p>As <a href=""https://www.muledesign.com/"">Mike Monteiro and Erika Hall have argued</a> for years, designâ€™s ethical responsibility is interrogating these questions <em>before</em> building. But when â€œCan AI do this?â€ shows up first, those questions get framed as barriers to velocity rather than essential judgment.</p><h3>The strategic ground designers areÂ losing</h3><p><strong>1 in 3 Figma users shipped an AI-powered product in 2025</strong>â€Šâ€”â€Ša 50% increase from 2024. Only 9% cited revenue growth as the primary goal. Instead, <strong>35% said â€˜experiment with AIâ€™ and 41% said â€˜enhance customer experienceâ€™</strong>â€Šâ€”â€Šgoals that struggle to define measurable success.</p><figure><img alt=""Fractured architectural platform with city lights glowing on top while ocean waves erode the breaking edges, representing diminishing strategic territory and crumbling foundation beneath ongoing work"" src=""https://cdn-images-1.medium.com/max/1024/1*dfkLKul12MDKLvxYSyVw3A.png"" /><figcaption>The strategic erosion: Design work continues on the surface while foundational influence fragments beneath. Generated With Midjourney.</figcaption></figure><p>Translation: teams are building because they can, not because theyâ€™ve clarified what problem requiresÂ solving.</p><p>This isnâ€™t speculation. <a href=""https://www.nngroup.com/articles/state-of-ux-2026/"">Nielsen Norman Groupâ€™s State of UX in 2026</a> names the existential tension directly: â€œAvailable roles will increasingly demand breadth and judgment, not just artifactsâ€¦ The practitioners who thrive will be adaptable generalists who treat UX as strategic problem solving, rather than focusing on producing deliverables.â€</p><p>But when artifacts arrive instantly via AI, organizations donâ€™t value judgment that questions whether those artifacts should exist. They value judgment that makes those artifacts shipÂ faster.</p><p><a href=""https://maven.com/centercentre/uxai"">Jared Spool notes</a>: â€œAI gives us an unprecedented ability to anticipate user needs. The challenge is balancing automation with human empathy in design.â€ The challenge isnâ€™t technical. Itâ€™s organizational. When teams measure progress in shipped features rather than solved problems, empathy reads as slowdown.</p><p><strong>68% of developers say AI improves work quality. Only 40% of designers agree.</strong> The gap reveals whoâ€™s winning the value argument. Engineers deliver code. Designers deliver questions. In velocity-obsessed cultures, questions donâ€™tÂ ship.</p><h3>What separates successful teams from everyoneÂ else</h3><p>Figmaâ€™s data on successful versus unsuccessful AI product teams reveals the pattern: <strong>60% of successful teams explored multiple design or technical approaches</strong>, compared to only <strong>39% of unsuccessful ones</strong>.</p><p>The differentiator wasnâ€™t AI capability. It was judgment discipline.</p><blockquote>Successful teams donâ€™t slow down generation. They slow down after generation.</blockquote><p>They treat AI output as a starting point requiring validation, not a conclusion requiring execution. They assume speed increases the risk of unexamined assumptions, not decreases it.</p><p>This aligns with <a href=""https://www.muledesign.com/"">principles Erika Hall has advocated</a> for years: â€œ80% of your job should be talking to peopleâ€¦ The concepts underneath are the most important part.â€ But talking takes time. In cultures optimized for generation speed, time feels expensive.</p><p><a href=""https://designbetterpodcast.com/p/brad-frost"">Brad Frostâ€™s work on design systems</a> emphasizes that sustainable systems require â€œhuman relationshipsâ€ and collaborative judgment, not just component libraries. But when AI can generate components in seconds, the relationship part getsÂ skipped.</p><h3>The uncomfortable truth about designâ€™s complicity</h3><p>Hereâ€™s what makes this particularly painful: <strong>UX designers built thisÂ problem</strong>.</p><p>We spent years optimizing AI interfaces for confident presentation over calibrated uncertainty. We designed chatbots to sound certain even when guessing. We created loading states that implied thoughtfulness without revealing doubt. We built systems that hid alternatives behind single recommendations.</p><p>We did this because users wanted smooth experiences. Because confident systems get adopted. Because our job was removing friction.</p><p>Those design decisions didnâ€™t stay contained. They taught organizations that <strong>AI outputs deserve trust by default</strong>. That polish equals correctness. That questioning generated work slows teamsÂ down.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*Alv38Wim_CfOCyWKzwudig.png"" /><figcaption>We optimized for smooth experiences. We didnâ€™t see what we were hiding underneath. Generated with Midjourney.</figcaption></figure><p>As <a href=""https://johnmaeda.medium.com/autodesigners-on-autopilot-88c5b07609b9"">John Maedaâ€™s 2025 Design in Tech Report</a> notes: â€œComputational thinking is invaluableâ€¦ Work transformation is coming FAST.â€ We focused on making tools smooth. We didnâ€™t prepare for how smooth tools would reshape what organizations value about designers.</p><h3>What happensÂ next</h3><p>The real risk isnâ€™t that AI will design for us. AI already designs <em>with</em> us, and that collaboration produces real value when guided by strategic judgment.</p><p>The risk is that organizations will stop rewarding the judgmentÂ part.</p><p>When â€œAI can do this fasterâ€ becomes sufficient reason to build something, design stops being about solving meaningful problems and becomes about demonstrating AI capability. User needs become secondary to technical possibility. Strategic clarity becomes friction to be eliminated.</p><p>As noted, teams cite â€˜experiment with AIâ€™ and â€˜enhance customer experienceâ€™ as goals rather than measurable outcomes. Theyâ€™re building because they can, iterating because itâ€™s fast, shipping because velocity signals progressâ€Šâ€”â€Šall without the designers who used to ask whether any of this serves anyone beyond the teamâ€™s desire to ship AI features.</p><h3>The choice that hasnâ€™t disappeared yet</h3><p>Design has always been about judgment. Not just making things usable or attractive, but deciding what deserves to exist in the firstÂ place.</p><p>AI changes how quickly we arrive at form. It doesnâ€™t change the need forÂ intent.</p><p>When creation is cheap, judgment becomes the most valuable part of the process. When generation is instant, the ability to say â€œthis solves the wrong problemâ€ becomes rare enough to be strategically important. When teams can build anything, knowing what <em>not</em> to build becomes the differentiator.</p><figure><img alt=""An image of Speed vs Quality from article Finding the balance: Speed vs Quality."" src=""https://cdn-images-1.medium.com/max/1024/1*XaAPOgfsnuGydQH2fiNwqg.png"" /><figcaption>Article Source: <a href=""https://medium.com/design-bootcamp/finding-the-balance-speed-vs-quality-1955d42da6bf"">Finding the balance: Speed vsÂ Quality</a></figcaption></figure><p>But Nielsen Norman Group is clear: â€œAdaptability, strategy, and discernment are the skills that will serve us best in the futureâ€¦ If youâ€™re just slapping together components from a design system, youâ€™re already replaceable by AI. What isnâ€™t easy to automate? Curated taste, research-informed contextual understanding, critical thinking, and careful judgment.â€</p><p>The question isnâ€™t whether designers can prompt AIÂ tools.</p><p>The question is whether organizations will still value designers who slow down to ask <em>why</em>â€Šâ€”â€Ševen when AI has already answeredÂ <em>how</em>.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=625c9a5d9c68"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/when-design-stops-asking-why-and-starts-asking-can-ai-do-it-625c9a5d9c68"">When design stops asking why and starts asking â€œcan AI do it?â€</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/going-analog-in-2026-64a007180d4c?source=rss----138adf9c44c---4,1769862084,Going analog in 2026,"Going analog in 2026

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/going-analog-in-2026-64a007180d4c?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*L6qGRoRcrICrf4eKfwiWxw.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">Can UX coexist with analog living?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/going-analog-in-2026-64a007180d4c?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4,1769775212,Thinking clearly while everything speeds up,"Thinking clearly while everything speeds up

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*9ODCVnUP3kLQO6hYu_ePiQ.jpeg"" width=""5712"" /></a></p><p class=""medium-feed-snippet"">It&#x2019;s a crazy time to be alive, let alone be a UX designer.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/beyond-the-waterfall-state-why-missions-need-a-different-decision-making-architecture-d81fadb93106?source=rss----138adf9c44c---4,1769729047,Beyond the waterfall state: why missions need a different decision-making architecture,"Beyond the waterfall state: why missions need a different decision-making architecture

<h4>Why government keeps forcing uncertainty through systems designed for stabilityâ€Šâ€”â€Šand what an alternative might lookÂ like</h4><p>In a previous article, I argued that<a href=""https://civicworks.substack.com/p/unfit-for-uncertainty-rethinking""> the UK government is structurally unfit for uncertainty</a>â€Šâ€”â€Štaking 21st-century challenges, evaluating them with 20th-century tools, and responding within 19th-century institutionsâ€Šâ€”â€Šbuilt for a different time, and for different kinds of problems. And, if Labourâ€™s<a href=""https://labour.org.uk/change/mission-driven-government/""> mission-driven government</a> is to mean anything in reality, the civil service needs a new grammar of everyday decision-making: one that treats uncertainty as navigable, frames choices in terms of <em>risk and opportunity</em> rather than cost and control, and builds learning into how problems are defined and actedÂ upon.</p><p>This piece starts where that argument ends, asking what a <em>different architecture for decision-making</em> might look like when uncertainty is highâ€Šâ€”â€Šand stability still matters. To answer it, this article explores why existing innovation efforts repeatedly collapse back into business-as-usual routines, before setting out an alternative, <em>overlaying</em> architecture for decision-making under uncertainty: one built on the premise of strength without weight and dynamic learning at itsÂ core.</p><h3>Beyond the waterfall state</h3><p>To be clear, the answer is not to burn everything down and start again. It points in a very different direction from the chainsaw, scorched-earth approach of the Elon Musks of the world. As<a href=""https://apolitical.co/communities/reimagining-public-institutions/8d06fbe0-ceab-11f0-8080-8001537bea73#1cf87f8c-d7ad-408c-a626-0640c5768499""> Andy Knight reminded me</a>, most of what government does is stewardshipâ€Šâ€”â€Šand that function is indispensable. It depends on stable, convergent, waterfall prediction policymaking. It is what keeps the lights on. Literally.</p><p>But the architecture that underpins stability is not the architecture that enables transformative change. Keeping the lights on today mattersâ€Šâ€”â€Šbut so does ensuring they stay on in the future. Missions, systems change, and early-stage sense-making require something different: space for divergent creativity, structured exploration, and collective judgement. This is the foundation for a state that is able to work with uncertainty rather than suppress itâ€Šâ€”â€Šwhat Kattel, Drechsler, and Karo describe as<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/final_innovation_bureaucracies_20_dec.pdf""> agile stability</a>: the capacity to generate new directions while maintaining long-term institutional coherence.</p><p>The problem is that we continue to run all forms of decision-makingâ€Šâ€”â€Šcertain <em>and</em> uncertainâ€Šâ€”â€Šthrough the same architecture inherited from a New Public Management era, an architecture built on the assumption that if you press a button, you know something will happenâ€Šâ€”â€Šas if governing were<a href=""https://plato.stanford.edu/entries/bounded-rationality/""> a computational task with bounded rationality</a> rather than a socio-technical one. While this logic may work tolerably well for stewarding stable systems, organisationsâ€Šâ€”â€Šand the world around themâ€Šâ€”â€Šare not computers. When uncertainty is high and judgement, learning, and creativity matter most, this type of computational â€œbounded rationalityâ€ repeatedly fails (See:<a href=""https://www.ucl.ac.uk/bartlett/publications/2024/may/mission-critical-statecraft-21st-century""> Statecraft for the 21st Century</a>) leaving us with a hollowed-out version of what Charles Lindblom once described as<a href=""https://academic.oup.com/policyandsociety/article/30/1/1/6422222""> â€œmuddling throughâ€</a>: not pragmatic adaptation, but institutional drift in the face of uncertainty.</p><p>James Plunkett has suggested that this<a href=""https://medium.com/@jamestplunkett/what-if-government-is-stuck-in-a-local-maximum-b54ad3f9dd0d""> traps government in a kind of â€œlocal maximum</a>â€ able to improve what it can already see, but unable to perceive or reach a wider landscape of possibility. Sophia Parker<a href=""https://sophiaparker-241.medium.com/a-larger-reality-how-governments-can-escape-the-local-maximum-d62018ec3949""> extends this argument</a>, noting that when institutions are caught â€œbetween worlds,â€ the familiar tools of optimisation cannot open up a larger realityâ€Šâ€”â€Šthey only make us better at navigating the statusÂ quo.</p><blockquote><em>â€œA local maximum is a place where everything you try seems to make things a bit better, but nothing you try can make things fundamentally differentâ€â€Šâ€”â€ŠJamesÂ Plunkett</em></blockquote><p>This is precisely why the re-emergence of mission-oriented and responsible approaches to policymakingâ€Šâ€”â€Šused here as an umbrella for systems thinking, futures thinking, user-centred design, agile methods and other exploratory practicesâ€Šâ€”â€Šhas put the limits of the administrative system in the spotlight. Instead of becoming a routinised way of organising systemic change, missionsâ€Šâ€”â€Šand the transformative methods attached to themâ€Šâ€”â€Šrepeatedly collapse back into incrementalism and business-as-usual routines when they are forced through an architecture built for stability.</p><blockquote>See<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/mission_oriented_innovation_policies_in_europe_from_normative_to_epistemic_turn.pdf""> Kattel &amp; Mazzucato</a> on why missions struggle to make an epistemic turn within existing bureaucratic logics, Demos Helsinkiâ€™s â€œ<a href=""https://demoshelsinki.fi/wp-content/uploads/2022/10/Missions-for-Governance-Demos-Helsinki.pdf"">Missions for Governance</a>â€ on how missions constrained by current mechanisms tend to produce only incremental improvements.</blockquote><p>So, if the architecture is the limit, the question becomes not how to replace the existing system (we rely on its stability more than we admit), but how to create an overlaying architecture that can be activated when uncertainty is high and when public value depends on exploration. Geoff Mulgan refers to this type of bureaucracy as having â€œ<a href=""https://substack.com/home/post/p-158372382"">strength without weight</a>,â€ the ability to use institutional power without the bureaucratic drag that stifles learningâ€Šâ€”â€Šenabling decision-making supported by intelligence, curiosity and adaptability, rather than the machinery of implementation andÂ control.</p><h3>The capabilities the state needs to work under uncertainty</h3><p>Any discussion of a second, more agile organisational architecture for navigating uncertainty and producing public value must begin with capability. Not whether an organisation has the <em>right structures</em> on paper, but whether it can learn, coordinate, and adjust as conditions change. Working under uncertaintyâ€Šâ€”â€Šand delivering any form of transformative, systemic changeâ€Šâ€”â€Šrequires a different way of thinking about both public value and the organisational capabilities that sustainÂ it.</p><p>First, public value cannot be treated only as an outcome delivered at the end of a policy process, or as a means-to-an-end justified through appraisal. As<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government""> Mark Moore argues</a>, it is both an outcome and something produced through the policy process itself. Under conditions of uncertainty, the quality of these processes is not incidental;<a href=""https://www.gov.uk/government/publications/the-public-design-evidence-review/public-design-evidence-review-literature-review-paper-2-public-value-html#how-to-define-public-value""> it is constitutive of public value</a>, shaped across an organisationâ€™s mission, sources of legitimacy and operational capacity. Treating value as both an outcome and a process provides a practical way to judge whether particular actions are improving a situation and are worth theirÂ costs.</p><p>This shifts attention to the dynamic capabilities embedded within public organisations: the capacities that allow institutions to sense change, coordinate across boundaries and deliberately reshape resources and priorities as the environment shifts. These are not specialist innovation skills or isolated tools, but foundational capabilitiesâ€Š<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government"">â€”â€Šcentral to public value management</a>â€Šâ€”â€Šthat determine whether an alternative decision-making architecture can function atÂ all.</p><p>This aligns closely with work on<a href=""https://www.humanlearning.systems/""> <em>Human Learning Systems</em></a>, which frames outcomes as emergent properties of complex systems and treats learning, adaptation and relationship-building not as phases of reform, but as the core work of public management under complexity.</p><p>This is where the Institute of Innovation and Public Purposeâ€™s<a href=""https://www.ucl.ac.uk/bartlett/publications/2022/mar/dynamic-capabilities-public-sector-towards-new-synthesis""> work on dynamic capabilities</a> is particularly useful. For this discussion, it helps clarify both what decision-making under uncertainty requires and why so many innovation efforts struggle to influence practice. Three dynamic capabilities are especially relevantÂ here:</p><ul><li><strong>Sense-making:</strong> the ability to scan an environment, surface weak signals, and develop shared interpretations of what is happening and why. This is not about better forecasting or more data, but about collective orientation when evidence is partial, contested, or evolving.</li><li><strong>Connecting:</strong> the capacity to coordinate across organisational, disciplinary, and sectoral boundaries. Under uncertainty, no single team or function holds the full picture. Effective decision-making depends on integrating different forms of knowledge and negotiating trade-offs across silos that were never designed toÂ meet.</li><li><strong>Shaping:</strong> the ability to reconfigure priorities, resources, and routines in response to what is being learned. Without this capability, insight accumulates but decisions remain locked inâ€Šâ€”â€Šlearning exists, but it has no leverage.</li></ul><p>Taken together, these capabilities frame public value as something produced <em>through</em> decision-making itself (or<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government""> â€œstrategic managementâ€</a> if you would rather). How problems are framed, whose knowledge is included, when commitments are made, and whether learning is allowed to alter direction all shape whether public value is createdâ€Šâ€”â€Šor quietlyÂ eroded.</p><h3>Why innovation efforts collapse back into business asÂ usual</h3><p>The difficulty is not a lack of innovation activity, itâ€™s where that activity sits relative to how decisions are actually made. Uncertainty demands dynamic capabilities such as sense-making, connecting, and shaping. Yet, most public-sector decision-making architectures are designed to steward stable systems, not to navigate contested, evolving or genuinely new ones. This creates a structural mismatch where even when teams attempt to work differentlyâ€Šâ€”â€Šthrough experimentation, design or mission-led approachesâ€Šâ€”â€Šthe surrounding architecture pulls decision-making back towards certainty.</p><p>Public Digitalâ€™s<a href=""https://public.digital/the-radical-how""> The Radical How</a> illustrates this issue. In the dominant waterfall model of policymaking, the most consequential decisions are made upfrontâ€Šâ€”â€Šprecisely when uncertainty is highestâ€Šâ€”â€Šwhile learning arrives later, once direction has already been fixed. The process follows a familiar pattern: <strong><em>Write policy â†’ guess requirements â†’ procure IT systems â†’ Inflict on users at scale â†’ operate indefinitely.</em></strong></p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*eFXc3Zpnftr_W-NR.png"" /><figcaption>Waterfall-style programmes start with many risky assumptions (<a href=""https://d1rnadml6vbx0i.cloudfront.net/Public-Digital_The-Radical-How.pdf"">The Radical How</a>,Â 2024)</figcaption></figure><p>Seen through this lens, learning is systematically pushed downstream, when its capacity to shape outcomes is weakest. Innovation efforts are not failing because they lack ambition or quality, but because they are layered <em>onto</em> an architecture that is structurally hostile to uncertainty.</p><p>This pattern repeats across governments. New methods are introduced, capabilities are developed, and insights are generatedâ€Šâ€”â€Šbut only <em>after</em> the moments when direction is set, resources committed, and alternatives foreclosed. The result is activity without leverage: innovation that is visible and energetic, but ultimately powerless.</p><p>Three examples help bring this structural mismatch toÂ life.</p><ol><li><strong>Policy Labs</strong></li></ol><p>Policy labs are among the most significant attempts to embed learning into policymaking through user-centred and systems perspectives. They are designed to intercept policy ideas early and improve decision quality (see<a href=""https://www.tandfonline.com/doi/full/10.1080/25741292.2021.1883834""> Anna Whicher</a> on the evolution of Policy Labs in the UK). In capability terms, labs are particularly strong at sensemaking in many ways. A large part of my own work is surfacing lived experiences, identifying risks and challenging the assumptions of policy teams while at the same time bringing together multidisciplinary actors who would not normally work together and creating relational infrastructure across policy and deliveryÂ siloes.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*n1BImJe4q3SJUECH.png"" /><figcaption>Policy Labs embed agile learning after decisions have beenÂ made</figcaption></figure><p>The problem, however, is not <em>what</em> labs do, but <em>when</em> they are able to do it. Within the existing decision-making architecture, the moments when assumptions can genuinely be challenged are tightly constrained. Policy labs rarely control the decision gates where commitments are made, budgets locked in or political capital spent. Their insights enter policy processes already moving toward closure. Learning exists, but it arrives downstream ofÂ power.</p><p>As a result, insight is absorbed rather than acted uponâ€Šâ€”â€Šoften filed away in the proverbial â€œpolicy drawerâ€ while assumptions remain untested. Labs generate understanding, but without authority to reopen decisions, that understanding struggles to shape outcomes.</p><p><strong>2. Technology-centric or challenge-driven funding</strong></p><p>Technology programmes and challenge-driven funds apply shaping pressure differently. They create momentum around emerging technologies and capabilities, directing attention, investment, and experimentation towards what <em>might</em> be possible. In doing so, they generate valuable insight into technical feasibility and future optionsâ€Šâ€”â€Šoften through pilots, prototypes, and partnerships that test new approaches in practice.</p><p>This activity frequently supports sense-making as wellâ€Šâ€”â€Šimagining new uses of AI, automation, or data at scale, and expanding the perceived solutionÂ space.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*KvUr5gH0dFZJEfMh.png"" /><figcaption>Technology and challenge-driven funds struggle to diffuse into the decision-making system</figcaption></figure><p>The problem is not the quality of this learning, but its <strong>position</strong> in the decision-making system and who it involves. Insights generated through challenge funds rarely travel upstream into everyday policy work. Policy teams struggle to access or apply what has been learnedâ€Šâ€”â€Šnot through resistance or lack of interest, but because there are few institutional pathways for the diffusion of knowledge.</p><p>As a result, innovation happens <em>around</em> the policy system rather than <em>within</em> itâ€Šâ€”â€Šshaping the environment without reshaping the decisions that govern it. Insight accumulates, but without leverage where it matters most (see my note on the frustration of AI pilots<a href=""https://substack.com/@jackstrachan/note/c-164601193"">Â here</a>).</p><p><strong>3. Generalist training, hackathons and experimentation initiatives</strong></p><p>Perhaps the most compressed illustration of the problem comes from generalist training programmes, hackathons, and short-term experimentation initiatives. These are designed to introduce brief moments of learning and collaborationâ€Šâ€”â€Šshort bursts of sense-making and connectingâ€Šâ€”â€Šoften framed as ways of normalising experimental decision-making.</p><p>Yet, in practice, they frequently do the opposite. Because these initiatives are time-bound, performative and disconnected from approval, commissioning and resource-allocation processes, their outputs struggle to survive contact with existing governance routines. What is learned rarely reshapes decisions; instead, participants return to an architecture that rewards certainty, compliance, and delivery over adaptation. It is often theatre over substance.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*zYFSfCbZgnPcu8j5.png"" /><figcaption>Generalist training, hackathons and sandboxes are often isolated occasions ofÂ theatre</figcaption></figure><p>Viewed in isolation, these initiatives can appear valuable. Participants report insight, energy, and motivation. But because they sit outside the moments where commitments are made, they offer no sustained pathway for learning to translate into publicÂ value.</p><p>This is not a failure of individuals or intent. It reflects a deeper structural issue. When learning is experienced as an exception rather than a condition of everyday decision-making, it is easily dismissed as â€œinteresting but unrealistic.â€ Without repeated, consequential exposure to uncertaintyâ€Šâ€”â€Šwhere learning genuinely alters directionâ€Šâ€”â€Šcounter-intuitive ways of working struggle toÂ stick.</p><p><strong>Across each of these examples, the same patternÂ repeats.</strong></p><p>Learning happens, but too late. Insight accumulates, but without leverage. Innovation is active, but powerless.</p><p>Seen through the waterfall architecture, this is not surprising. These mechanisms are attempting to introduce uncertainty, exploration, and adaptation into a system designed to eliminate them as early as possible. This is why mission-oriented approaches, design methods, and experimental practices so often collapse back into incrementalism: they are forced to operate <em>after</em> direction is set, resources committed, and alternatives foreclosed.</p><p>This is not a capability problem. It is an architectural one. Until the conditions exist for sense-making, connecting, and shaping to influence decisions <em>when they matter most</em>, innovation efforts will remain episodic and low-impact. Which leads to the next question: what would an alternativeâ€Šâ€”â€Š<em>complementaryâ€Šâ€”â€Š</em>decision-making architecture need to lookÂ like?</p><h3>An alternative (mission-driven) decision-making architecture</h3><p>Rather than replacing existing policymaking systems, this section sets out an overlaying decision-making architecture designed for moments of uncertainty. Drawing on Vinnovaâ€™s<a href=""https://www.vinnova.se/en/publications/mission-oriented-innovation---a-handbook-from-vinnova/""> mission-design framework</a>â€Šâ€”â€Šand learning from the UK Government Digital Serviceâ€™s<a href=""https://gds.blog.gov.uk/2014/04/01/a-year-in-the-making-the-digital-by-default-service-standard/""> agile delivery model for digital services</a>â€Šâ€”â€Šthe model below translates these insights into a participatory decision-making architecture for moments of uncertainty. Its purpose is not to generate <em>better</em> analysis, but to change how <em>direction, commitment, and resourcing decisions are formed</em> by deliberately activating the dynamic capabilities discussed earlier: sense-making, connecting, andÂ shaping.</p><p>Put simply, this architecture embeds learning <em>throughout</em> the policy design and delivery process, rather than treating it as something that arrives after key decisions have already beenÂ made.</p><p>This architecture rests on four principles.</p><ol><li><strong>Conditional, not universal: </strong>It is activated only where uncertainty is high and stakes are systemicâ€Šâ€”â€Šnot as a default mode of governance.</li><li><strong>Triggered by uncertainty, not default:</strong> It complements, rather than competes with, existing stewardship systems.</li><li><strong>Relational and procedural, not structural:</strong> it works through roles, practices and decision rights, not new hierarchies. This means a focus on making stakeholders active participants of the designÂ process.</li><li><strong>Time-bound and reversible:</strong> Its purpose is to resolve uncertainty, not institutionalise exploration indefinitely. ResultsÂ matter.</li></ol><p>Critically, it also depends on what Dan Hill describes as<a href=""https://medium.com/dark-matter-and-trojan-horses/the-city-is-my-homescreen-317673e0f57a""> <em>â€œsoft eyesâ€</em></a>: the capacity to observe and work with the dark matter of bureaucracyâ€Šâ€”â€Šthe informal relationships, tacit norms and interdependencies that sit between teams, directorates and policy domains. Without this, attempts to engage uncertainty are either blocked by premature certainty or absorbed back into business-as-usual routines before they can influence decisions.</p><p>This is not an abstract sensibility either. Variants of this capability have been articulated over the past decade through relational practices such as<a href=""https://www.linkedin.com/pulse/what-do-we-mean-relational-services-dennis-vergne-fq9he/?trackingId=ovP%2BQ3INid7UUUDxmYDavQ%3D%3D""> Relational Service Design</a>,<a href=""https://www.humanlearning.systems/""> Human Learning Systems</a>, Dark Matter Labâ€™s<a href=""https://freight.cargo.site/m/Q2581255008246565147592803666662/Governing-Together-MASTER-DECK-September-2025-v6.pdf""> Governing Together</a>, and the<a href=""https://www.strategy-business.com/article/00344""> TEAL movement</a>, which foreground trust, continuity, and institutional relationships as core operating conditions rather than delivery-side effects. The challenge is not their absence, but their marginal position relative to where decisions are actuallyÂ made.</p><p>What follows sets out how this overlaying architecture works in practice: the stages it moves through, the capabilities it embeds, and how it interfaces with the stateâ€™s existing delivery and stewardship machinery.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*LSRj1lPPAt4Y84RE.png"" /><figcaption>An overlaying decision-making architecture</figcaption></figure><p>At a high level, the architecture is organised around four overlapping learning loops. These are not phases or stage gates. They are modes of work that structure how learning, judgement, and commitment evolve under uncertainty. What distinguishes this model from familiar innovation or design frameworks is not the loops themselves, but where decision authority and resource commitment sit withinÂ them.</p><p>The flow follows Vinnovaâ€™s mission-design framework, moving from <strong>Angles â†’ Missions â†’ Prototypes â†’ Demonstrators</strong>, progressively reducing uncertainty while keeping direction open for as long as possible.</p><h3>A. Angles: orienting theÂ system</h3><p>The Angles loop focuses on collectively developing an initial view of the system: identifying where uncertainty lies, what matters, and where intervention might be possible.</p><p>Rather than jumping to solutions, this loop brings a core group together to surface <em>different ways of seeing the problem space</em>. It deliberately draws together a trans-disciplinary team of policy, operational, user, technical, and political perspectives to build a shared orientation to the system as it is experienced, not just described.</p><p>The emphasis here is on sense-making and connecting. The output is not a strategy or recommendation, but a set of <em>plausible directions</em>â€Šâ€”â€Šangles of intervention worth exploring further.</p><h3>B. Missions: committing to direction</h3><p>The Missions loop translates the most promising angles into statements of intent and design principles. These articulate <em>what kind of change is being pursued and why</em>, without prematurely specifying how it will be delivered. Design principles matter because they act as decision constraints under uncertaintyâ€Šâ€”â€Ša function<a href=""https://gds.blog.gov.uk/2025/12/10/designing-public-services-that-work-for-everyone/""> GDS has long used to align teams</a> without over-specifying solutions.</p><p>At this point, connecting remains centralâ€Šâ€”â€Šaligning actors around a shared purposeâ€Šâ€”â€Šwhile shaping begins to matter more. Missions create directionality by setting boundaries, clarifying intent, and establishing criteria for learning in the nextÂ stages.</p><p>Crucially, missions are treated as provisional commitments. They are strong enough to mobilise action, but flexible enough to adapt as learning accumulates. Their role is not to close down debate, but to focus itâ€Šâ€”â€Šsimilar to<a href=""https://futurestatedesign.co/futurestate-design""> futurestate strategy</a> or<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/stakeholder_engagement_for_policy_design_planning.pdf""> strategic foresight practices</a>.</p><h3>C. Prototypes: learning through tangible commitments</h3><p>The Prototypes loop explores missions through a portfolio of concrete experimentsâ€Šâ€”â€Špolicy, service, regulatory, or organisationalâ€Šâ€”â€Šdesigned to test assumptions and surface consequences.</p><p>Prototypes are decision-shaping commitments: deliberately designed to inform judgement about whether, how, and where to scale. Multiple prototypes ask different questions, reducing uncertainty through comparison rather than consensus. Vinnovaâ€™s<a href=""https://arkdes.se/en/projects/street-moves/""> <em>Street Moves</em></a> programme is a good example: place-based experiments used not as pilots, but as learningÂ devices.</p><p>Here, connecting and shaping are tightly coupled. Prototypes act as boundary objects, aligning actors, mobilising resources and enabling learning through doing. The emphasis is not speed for its own sake, but efficiency: learning as much as possible for the least irreversible cost. Or, in Public Digitalâ€™s â€œ<a href=""https://d1rnadml6vbx0i.cloudfront.net/Public-Digital_The-Radical-How.pdf"">The Radical Howâ€</a> terms: doing whatever it takes to speed up the loop of testing the things that matter the most and learning from theÂ results.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/966/0*pj4BbouEHOw6rmkz.png"" /><figcaption>Agile learning. The Radical How,Â 2024.</figcaption></figure><h3>D. Demonstrators: integrating learning atÂ scale</h3><p>The Demonstrators loop brings together insights from multiple prototypes into large-scale system demonstrations. These are not end states; they are decision-shaping devices. Their purpose is to determine whether uncertainty has been reduced <em>enough</em> to re-enter the stateâ€™s core delivery and stewardship architecture.</p><p>Here, sense-making resurfaces, alongside continued connecting and shaping, as priorities and resources are adjusted in response to what has been learned. Demonstrators help decision-makers see how interventions interact at scale before irreversible commitments are made. At this point, work can deliberately transition from exploratory modes into more stable delivery pathwaysâ€Šâ€”â€Šmoving from adaptive learning to reliable execution.</p><h3>Switching modes</h3><p>At this point, I want to stress that this proposed second architecture is conditional, not universal. It is activated only when uncertainty is highâ€Šâ€”â€Šwhen outcomes cannot be reliably predicted, causal pathways are contested, and early lock-in would be costly or irreversible. Itâ€™s about introducing a dynamic learning process so that the state can <em>return</em> to its stable delivery architecture once uncertainty has beenÂ reduced.</p><p>When activated, several conditions matter:</p><ul><li>decision authority must sit close to theÂ work</li><li>learning must have formal routes into commitment and resourcing</li><li>participation must include those affected, not only those accountable</li><li>exit conditions must beÂ explicit</li></ul><p>The intent is not to weaken the stateâ€™s capacity for delivery, but to protect it by ensuring that stability is not achieved at the cost of learning, and that exploration does not become detached from power. In other words, this is not about replacing the machinery that keeps the lights on. It is about creating the conditions under which the state can <em>decide differently when it needs to</em>â€Šâ€”â€Šand then return, deliberately, to what it already doesÂ well.</p><h3>Preparing the ground: agile team models when working under uncertainty</h3><p>Transformative change starts by <em>preparing the ground</em>: creating the conditions for a small, multidisciplinary team to work differently, with political cover, protected space, and the authority to bypass routine constraints long enough to prove what is possible. This was true of the early Government Digital Service in 2011, and it remains true of any attempt to change how the state decides under uncertainty.</p><p>Fundamentally, if we expect teams to sense, connect, and shape under uncertainty, we cannot treat them as interchangeable delivery units. Different phases of decision-making require different, malleable team purposes and archetypes that evolve as uncertainty reduces.</p><p>Kate Tarlingâ€™s work on<a href=""https://www.theserviceorg.com/""> service organisations</a> is useful here. Rather than assuming static â€œagile teams,â€ she shows how teams shift over time: from exploratory, functional groupings with hand-offs, towards whole teams responsible for delivering and improving joined-up services. She stresses that hand-offs are not inherently problematic but they are often necessary early onâ€Šâ€”â€Šwith problems arising when teams are <em>locked</em> into a structure that no longer matches the nature of the work and are forced into incompatible handovers.</p><p>It is therefore more helpful to think in terms of complementary team types, rather than a single ideal form. Drawing loosely on team typologies developed by<a href=""https://teamtopologies.com/book""> Skelton and Pais</a> (and Tarling), a mission-driven architecture typically relies on a portfolio of teams with distinctÂ roles:</p><ul><li><strong>Service teams</strong> are responsible for delivering and improving outcomes for users and operations.</li><li><strong>Depth teams</strong>, which explore complex issues, generate insight and reduce uncertainty on behalf ofÂ others.</li><li><strong>Common-capability teams</strong>, which build shared tools, platforms, and processes that make learning and deliveryÂ easier.</li><li><strong>Enabling teams</strong>, which unblock, coach, and support other teams to adopt new ways ofÂ working.</li><li><strong>Coordinating teams</strong>, which align activity across services or missions when interdependencies areÂ high.</li><li><strong>Operational teams</strong>, which steward stable systems and deliver continuity overÂ time.</li></ul><p>Crucially, these teams do not all operate in the same way, nor at the same time. Early in the lifecycle of a missionâ€Šâ€”â€Šwhen uncertainty is highestâ€Šâ€”â€Šdepth, enabling, and coordinating teams play a larger role in sense-making and connecting. As direction stabilises and uncertainty reduces, service and operational teams take on greater responsibility for shaping and delivery.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*Mue1QZS_TrhSJKpp.png"" /><figcaption>Different types of decision-making demand different types ofÂ teams</figcaption></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*12rV9jFOQ7-1YVOL.png"" /><figcaption>Team types, roles and sizes are malleable to the context of theÂ decision</figcaption></figure><p>Seen this way, team models are not an implementation detail, but a core part of the decision-making architecture. Without the right mix of teamsâ€Šâ€”â€Šand the ability for them to change as conditions changeâ€Šâ€”â€Ševen well-designed missions will struggle to move from exploration toÂ impact.</p><h3>Conclusion</h3><p>The world is not a machine where, if you pull a policy lever, something will happen. Reconnecting policymaking with this reality means moving beyond top-down, disconnected approaches and towards a decision-making architecture that treats uncertainty as something to be worked with, not engineered away. One that embeds learning, judgement, and adaptation into how direction is setâ€Šâ€”â€Šwithout sacrificing the stability the state depends on. Whatâ€™s required is <em>strength without weight.</em> The ability to do the hard things well, while remaining flexible enough to change when conditions demandÂ it.</p><p>I want to be clear about what this piece isâ€Šâ€”â€Šand is not. Itâ€™s not a story of pessimism, nor a claim that the government lacks innovation or intent. Quite the opposite. There is a great deal of thoughtful, committed work happening across UK government and beyond (See:<a href=""https://academic.oup.com/pa/article/77/4/837/7729221?login=false""> The state of British policymaking: How can UK government become more effective</a>). This is an attempt to frame those effortsâ€Šâ€”â€Šthrough theory and lived experienceâ€Šâ€”â€Šin a way that surfaces a deeper constraint: not ambition or capability, but the architectures through which decisions areÂ made.</p><p>This article is not <em>the</em> answer either. The critique, and the model that follows it, could easily be read as two-dimensional: one person diagnosing a system and proposing a cleaner alternative. That reading misses the point. The issue is not a shortage of models for change. Itâ€™s that institutionsâ€Š<a href=""https://demos.co.uk/research/the-human-handbrake-how-whitehall-culture-holds-back-public-service-reform/"">â€”â€ŠWhitehall included</a>â€Šâ€”â€Šoften convince themselves they are uniquely resistant to new ways of doing, while continuing to route uncertainty through systems designed to suppressÂ it.</p><p>This is as much a cultural challenge as a structural one. Work on systems change reminds us that transformation rarely follows linear cause-and-effect pathways. It emerges through overlapping activity, partial learning and shifting coalitions over time. For those of us working inside the government, that means holding multiple perspectives at once: staying curious, working across boundaries, and treating thinking itself as a form of actionâ€Šâ€”â€Šsomething that shapes what becomes possibleÂ next.</p><p>Much of what Iâ€™ve drawn on here builds on existing ground: the early work of Government Digital Service, mission-oriented innovation frameworks, action-based approaches to social change, and emerging practices around Human Learning Systems and other relational practices. The open questions, for me, are less about invention than application. How do these principles actually reshape decision-making at scale? What role does digital playâ€Šâ€”â€Šnot as infrastructure alone, but as an enabler of learning, coordination and judgement? Have we laid the horizontal foundations for a third era of digital governance, or are we still struggling to move beyond enterprise-era assumptions?</p><p>Those are questions for anotherÂ time.</p><h3>Next stepsâ€¦</h3><p>As with most of my writing on substack, this is thinking-as-writing rather than a finished argument. Itâ€™s an attempt to synthesise lived experience wrestle with the ideas and practices Iâ€™ve been immersed in over the past few years, to see whether they hold together. Itâ€™s written as self-provocations, loose ends, tensions and partial conclusionsâ€Šâ€”â€Šthatâ€™s part of the point forÂ me.</p><p>For now though, this thinking is feeding directly into my own work at HM Revenue &amp; Customs where Iâ€™m currently leading a review of our internal <em>Budget Policy Starter</em> technology-impacting process by working with policymakers, solution architects, cost engineers and user-centred designers to better bridge stable and agile ways of workingâ€Šâ€”â€Šand, in doing so, improve how policy decisions are shaped upstream so they serve citizens more effectively downstream.</p><p><em>This post is part of </em><a href=""https://civicworks.substack.com/""><em>CIVICWORKS</em></a><em>; a publication on (re)thinking civic bureaucracy, institutional reform, dynamic capabilities, policymaking and technology.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d81fadb93106"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/beyond-the-waterfall-state-why-missions-need-a-different-decision-making-architecture-d81fadb93106"">Beyond the waterfall state: why missions need a different decision-making architecture</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4,1769728943,Vibe prototyping is a double-edged sword,"Vibe prototyping is a double-edged sword

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*Ez3xrHNO1FxfTH0By1-Ekg.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">Vibe coding prototypes is so fun we forget what prototypes are for</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4,1769623657,The rise of the Orchestrated User Interface (OUI),"The rise of the Orchestrated User Interface (OUI)

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2452/1*WyC312mkKkITB1eOo56HrA.jpeg"" width=""2452"" /></a></p><p class=""medium-feed-snippet"">Designing for intent in a brave new world.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiugFBVV95cUxQQTl0TzRHem5wU2ZLUDV1S2R3SjliZWRfVTctVjdjTnFIV0ExeFFBdkFlaFk4bjZOUExsZmZxSjN0ZGo1VGljXzh0UDdPWXF2Z2xhNUMyZ2dBYXoyQzR5MTMwREk3cnZXc0RvNThOdXcwNTgtb1ZVYXg3bm0tbVFGNkRTbGZHWDM3eDVmY2x3eWgzbm1Sbkd6NzhHS29DNnpfdk1ZNlhOZVJ4X0hIUHk5ODhGVUllTGFia3c?oc=5,1769499900,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMid0FVX3lxTE84WklhdnlBcTZkRy1PSjNSd0tDQUEwSDRlNVEwWGdNZGFBQ1BuVEVKbFVlX1FPZkROY2cxN0NjdS0yQkx0SVZqU0JQQU5CSTluVnpnVG5uQm1nb2dMNEVCQzh4VGt5d2pzTjdBdWQzRVJUNnhQMG9R?oc=5,1767686400,Future of Graphic Design: Trends & Predictions - Business.com,Future of Graphic Design: Trends & Predictions - Business.com,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMickFVX3lxTE9WcHZJUFRiREJ4OUl1dzlrRW9uMVlZUmppbnhNaEwxaVY5YUZtbERGWFRxdXBlMkpBQ3hIYkxVMF9qUFI3aE1UeHRZQ3lfNFFDcE1UcVM1YUlfYzZpcm96VDVIa2k5dFFqb0JXWjA1QVBSQQ?oc=5,1768896000,10 Interior Design Trends That Are on Their Way Out in 2026 - The Everygirl,10 Interior Design Trends That Are on Their Way Out in 2026 - The Everygirl,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMikgFBVV95cUxQMEEwdDNWUy1naGo2Q1JqRlp3R3VpLUdSTDFJcFhRRE04NWRiOEVIY2xuSEFDcmRDZkFHcUdRaWw3cFM5MGJWbVVpU29uT0lxcFl3T2hEb3dlWTE5a1hXenduLV93b3ljc3hmNUdRc0ZNZmZaRlVtOVZLUERzZHRPdm8yTHFtQnc3Ykw4STRWYkdwZw?oc=5,1768377600,"Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor","Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor",graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiV0FVX3lxTE9wU1dmbVZMREZQc3dULTA3OHdoZXdhOGEyemJ2c2xMNGFGZHpQajFEaE1GaU40RExnYzNSS3JvY1RJN05WeHBPUXBhb05na0JaclhRMVdyMA?oc=5,1768223466,Forward Thinking - It's Nice That,Forward Thinking - It's Nice That,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipwFBVV95cUxOODlDdWw5R3FrNlpnNS1uZTliQmx6MUdiTG1wUUNiLTR6Z2dKTWNpS0ZIYUpJMnMtTlNVVzNISkZYMzBRUTdJTnRId1lfSHhsZDF1NGVjU2doTnktbGxKU0lCdXl0N0g4LVJjVzc1UHZCdG9hWUxfLUFiNWZUQU00TW9Ra25abGV0YjgxbTE3NU01QVZmVzlENjRhQXlKd0oyV2hUMGtrOA?oc=5,1767254400,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMivwFBVV95cUxNYVV3emxXZ2dCWmdRcXp0OFQzWW9oRDRodUJOWUFPSUh2NnR6aWRKWVZTamIwLUtueElFYUlPTUl4aHp3RmNDbHJaOFgySFhLb3RBV2NOemV6WVpKektLaUgtcm92b1lrZjdWa25kcjhxeDUzRGthU0V3d21Uc3o3N1NhOUR1bVVfWXpGQ3h6QnN0dW9CYVBLbTZyMmVvajZSV1ZZN0JabWdWbnE4bUJOTzV3cWg4N3J5c3VYN2FBSQ?oc=5,1766736000,"Messy, meaningful and made by humans: the biggest illustration trends for 2026 - Creative Bloq","Messy, meaningful and made by humans: the biggest illustration trends for 2026 - Creative Bloq",graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMilAFBVV95cUxNMTc2SGFDU2h0OEVINzhWMVlTRy1Cb1BOd1FCZDdKbHRTYjdfTHpuMzNUNDRiRUF6THhkYXF4UDYyRnFSbTk2R0VkamU0bmx4d0J3c0tSZV80ak5wZGVhU1FiTGZvVjVfV2x0azhNMmRlMDBjTGJPWVBOMWJ5WGRNMVFocFdxbnI1WC1vaHpJeEFsbjll?oc=5,1766908800,Canva's 2026 trend predictions have filled me with hope - Creative Bloq,Canva's 2026 trend predictions have filled me with hope - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiZkFVX3lxTE95aEtIbVRhclRrS3hxMzhUQXgwRzlJOUdvZjg3VlZCTlc5XzdmTTZ1OFVucjNiRjNjZGdFT3M3dUkyQjhOMGVUVWc3ZzNpOFdMb3lweE92S1pZX3MxUE80a2pNYkVvdw?oc=5,1767513600,Graphic design trends in 2026 - The Morning,Graphic design trends in 2026 - The Morning,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMilAFBVV95cUxNVVZGRDlFUF95aHhVSmJQcV9pTmk2Qjhyel9YeGx0VGRDcXpOVWo1RFhjZXhmUzVWMEJaVXhlWVFYU3R4M0wwem1xbVZnNl94Y1IxcTR1emdHRDZSVk9ia3lCejZ2djdkekRabkJ1M2JOUWlJT0xmSGJ6ZmN3cWxyenA1SndfaGQ4UWNQMlJaMHdxY1Ut?oc=5,1769719656,Custom Web Development Trends Shaping Business Growth In 2026 - Geek Vibes Nation,Custom Web Development Trends Shaping Business Growth In 2026 - Geek Vibes Nation,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiWkFVX3lxTE40UU00VzlvX0tPdGx1bVBJbG9iNFl6b05JUXRabjZuc21KVTN3NHlhX2YwUTFPQWpwWlJaQXcwRks2UHM2azg4YTNybEsyVk1EaFNoRGVGVHZvZw?oc=5,1768809600,Duotone â€“ Fresh Trend in Website Design - Designmodo,Duotone â€“ Fresh Trend in Website Design - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMikwFBVV95cUxPRzlkRnZUUFI1bjhNUDBEVDQ5Z3MxYnJ2amlnTWgzd2ptRHNVaVdXM1hyLVpqU3NiNVE1RmFxak9uVW11ZjRpLXNxWHA4UkhZQzcwTFdfSnFVNWVROFBYMFdBN2dIa3huWUlYUUpyLVloOHZaZ0xlTlkyXzFrQWhyQ0NGaUNPY2RSaXAwMHdhZmQ4TlE?oc=5,1767081600,These logo design trends will define 2026 - Creative Bloq,These logo design trends will define 2026 - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiT0FVX3lxTE1HV2ppY1oySC1FZEM0S1h3QXkzMlUxYS1KV2JrVTNnZ0RlcEw4QjQ5YThRZFkyc0hBdDhRU280a3k0b182bndjZXFvMUlVQkk?oc=5,1768809600,Tabbed Widgets in Web Design: UI Examples & Free Plugins - Designmodo,Tabbed Widgets in Web Design: UI Examples & Free Plugins - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipwFBVV95cUxOODlDdWw5R3FrNlpnNS1uZTliQmx6MUdiTG1wUUNiLTR6Z2dKTWNpS0ZIYUpJMnMtTlNVVzNISkZYMzBRUTdJTnRId1lfSHhsZDF1NGVjU2doTnktbGxKU0lCdXl0N0g4LVJjVzc1UHZCdG9hWUxfLUFiNWZUQU00TW9Ra25abGV0YjgxbTE3NU01QVZmVzlENjRhQXlKd0oyV2hUMGtrOA?oc=5,1767254400,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,typography trend
youtube,,https://www.youtube.com/watch?v=D6yksnapzqY,1769961963,Abstract Design in Adobe Illustrator #graphicdesign #adobe #illustrator #adobeillustrator #abstract,Abstract Design In Adobe Illustrator âœ“ Graphic Designers âœ“ Abstract Art Lovers âœ“ Illustrator Creators Illustrator Beginners ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=hXarXPIxm-4,1769953571,Modern logo design tutorial in Canva gradient logo design,"In this video We will show you Modern logo design tutorial in Canva gradient logo design. logo design tutorial, Canva logo design, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=22YK2eQfvlQ,1769952620,Create a Pro-Level Product Poster Design in Canva | Full Tutorial ğŸ”¥,"Create a Pro-Level Product Poster Design in Canva | Full Tutorial This video shows the full poster design process in Canva, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=YSqgQPfz988,1769931447,Bradbury Thompson Graphic Designer,Born in 1911. Changed graphic design forever. Not with trends. With typography. He believed type was the message. At Westvaco ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=XgxPG1smgxY,1769931301,Rudolph De Harak - Graphic Designer,Most people don't know his name. But you've seen his influence everywhere. Rudolph de Harak wasn't loud. He was precise.,graphic design trends
youtube,,https://www.youtube.com/watch?v=EA4-3Hhe3kw,1769930327,23 Theme (From &quot;AA23&quot;),"Provided to YouTube by The Orchard Enterprises 23 Theme (From ""AA23"") Â· Anirudh Ravichander Â· Hector Salamanca ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=Hz0jshq9Ix4,1769929215,"youtube chanel setup,Graphic Design Tutorials, Trends &amp; Jobs | Learn Canva, Illustrator &amp; AI Design","youtube chanel setup,Graphic Design Tutorials, Trends & Jobs | Learn Canva, Illustrator & AI Design Welcome to my Graphic ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=OnsA6E0_kGY,1769928804,Social Media Poster Design   âœ¨ğŸ”¥ #shorts #posterdesigner,Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=G8iC-dBkSlY,1769919594,Logo design trends #trendingshorts #corporatedesign#designtrends #designtrends,,graphic design trends
youtube,,https://www.youtube.com/watch?v=0Z8qHiXkqVY,1769916118,3 Crazy Websites Every Designer NEEDS To Know About NOW,"3 Crazy Websites Every Designer NEEDS To Know About NOW hidden design tools, graphic design secrets, secret websites for ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=Tn4cR9crcMM,1769877437,AI Logo Design!,"need a logo, ai logo design, looka ai tutorial, logo design with ai, create logo online, branding with ai, ai design tools, professional ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=ekuUi1Hana0,1769871778,PS Tutorial HD | Nuevo Truco para Cambiar Color de Ropa | Photoshop Editing | CC + BP Drop #ps N.D ,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Q1OQd9hMUaU,1769871417,Graphic design trends per il 2026,,graphic design trends
youtube,,https://www.youtube.com/watch?v=O5Y98yFPTM4,1769865309,Master New Graphic Design Tricks &amp; Modern Trends | Ahsan Sabri Tutorials,"Dear Viewers, In this CorelDraw Tutorial, You will learn about Any Advertising Design. By following this one, you'll able to learn ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=oHemK52TOzM,1769860094,Heels Poster Design   âœ¨ğŸ”¥ #shorts #posterdesigner,Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Pc4zWste9pU,1769848224,The EASIEST way to deliver a ROYAL Save the Date Wedding Invite! ğŸ‘‘ğŸ¨,"TAGS: E-Invites, Digital Invitations, Custom E-Invites, Online Invitations, Graphic Design, E-Invite Design, Digital Invitation Design, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=dSkOf2YUD1g,1769810444,La tendance du Maximalist Design en design graphique en 2026,"DÃ©couvrez la dixiÃ¨me grande tendance design de 2026 : le design maximaliste. Couleurs intenses, typographies audacieuses, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=b76Lik6NhsE,1769792467,La tendance du Blueprint Design en design graphique en 2026,"DÃ©couvrez la neuviÃ¨me grande tendance design de 2026 : le Blueprint Design. Grilles visibles, lignes techniques et structures ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=QdWMSmUFxKU,1769789260,PS Tutorial HD | Efecto Aura de Atardecer | Photoshop Editing | CC + BP Drop #ps Netto Doch Yt ,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=PnE3HYlk-Ms,1769787026,Creating AMAZING Dotted Lines Backgrounds in Photoshop #photoshop #photoshoptutorial   #easy,Unlock your creativity in Photoshop with our ultimate guide to creating **AMAZING Dotted Lines Backgrounds**! âœ¨ In this ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=4UiqgLyFTmw,1769783405,CorelDRAW 2024 Impact Tool Full Tutorial in Hindi | Graphic Design Course | Class 21,CorelDRAW 2024 Impact Tool Full Tutorial in Hindi | Graphic Design Course | Class 21 About Vid: à¤‡à¤¸ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤®à¥‡à¤‚ à¤¹à¤® ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Wrq6ZvIILS4,1769780728,The house of Modern Logo design in Adobe  # #tipsforgraphicdesigner#tipsforbeginner#graphic@everyone,Subscribe the channel for more informative videos and comments about your favorite blog post. If you're interested please share ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=oN3xdOPmsP8,1769779768,Adobe Illustrator 2026 - Abstract Design #sylusskydesigns #graphicdesign #adobe #illustrator,Graphic Designers âœ“ Abstract Art Lovers âœ“ Illustrator Creators Illustrator Beginners Abstract Design Lovers adobe illustrator ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=KULsXr3ogLw,1769762257,Classmate Notebooks Design Discovery | 40 sec | English,"Every Classmate notebook design is colorful, creative, and made to reflect the trends and characters you love. Inspired by bold ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=BxeGIhSmdNs,1769758615,The Future of Interior Design (Trends &amp; Predictions),Discover the latest trends and predictions shaping the future of interior design. From sustainable materials to smart home ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=o2jCJtS91z0,1769974357,ğŸ”¥ Luxury Fashion Website Design ğŸ”¥ | Modern UI for Fashion Brands,Luxury Fashion House Website Design âœ¨ This modern and premium fashion website design is crafted to elevate brand identity ...,web design trends
youtube,,https://www.youtube.com/watch?v=YKnwtgjBaHQ,1769952561,6 UI Trends You Need to Know in 2026 ğŸ¨Glassmorphism vs. Liquid Glass (The Difference) ğŸ’§,Most designers get this wrong. There is a massive difference between Glassmorphism (Blur) and Liquid Glass (Refraction).,web design trends
youtube,,https://www.youtube.com/watch?v=NULayk9f08A,1769943758,The UX trends that actually move the needle in 2026!,The UX trends that actually move the needle in 2026 aren't about how things look. They're about how experiences influence ...,web design trends
youtube,,https://www.youtube.com/watch?v=0Z8qHiXkqVY,1769916118,3 Crazy Websites Every Designer NEEDS To Know About NOW,"3 Crazy Websites Every Designer NEEDS To Know About NOW hidden design tools, graphic design secrets, secret websites for ...",web design trends
youtube,,https://www.youtube.com/watch?v=vd6Aw0cOiMk,1769909459,The Future of Construction is Spider Silk,"The Incredible Speed of Spiderweb Creation is a fascinating topic that showcases the remarkable engineering skills of spiders, ...",web design trends
youtube,,https://www.youtube.com/watch?v=9JfYZy0-Nf8,1769817025,Why 3D and Immersive Design is taking Over Websites in 206,"Web design in 2026 is moving beyond flat layouts and into more immersive, interactive experiences. Subtle 3D elements, depth ...",web design trends
youtube,,https://www.youtube.com/watch?v=RtoZXB0fty0,1769814611,Human Scribbles and Nostalgia Web Design Trend,"Web design in 2026 is moving in the opposite directionâ€”back toward human, imperfect, and nostalgic elements. Hand-drawn ...",web design trends
youtube,,https://www.youtube.com/watch?v=eVAVOr1wmic,1769788046,Transform Your Website with Cinematic Scroll Effects,Websites in 2026 aren't just being viewedâ€”they're being experienced. Scroll storytelling and cinematic design techniques are ...,web design trends
youtube,,https://www.youtube.com/watch?v=fobQHXU5SHs,1769780377,3 Free Design Websites Every UI Designer Should Bookmark | Emcee IT Solutions,"If you're designing websites or UI screens and you want faster ideas without sacrificing quality, these 3 free resources are worth ...",web design trends
youtube,,https://www.youtube.com/watch?v=zT00cUinQN8,1769778258,ğŸ’» Login Form Design Using Glassmorphism #FrontendDeveloper #TechShorts #shorts #JavaScript #WebDev,"In this video, I have created a Modern Glassmorphism Login Form UI Design with an attractive Neon Glow effect âœ¨.",web design trends
youtube,,https://www.youtube.com/watch?v=FbpEcA8n3bU,1769755519,Ever wondered how websites looked before modern UI trends? ğŸ‘€#uxdesign #uidesign #webdesign,,web design trends
youtube,,https://www.youtube.com/watch?v=X4P2l5vvO1w,1769752835,9000+ Free 3D Icons for Designers (Better than FlatIcon) ğŸ”¥,Stop using boring 2D icons! Upgrade your design with these free 3D assets. The Website Link: Check the Link in my Bio ...,web design trends
youtube,,https://www.youtube.com/watch?v=vgV-bkcKjuk,1769749272,Cool Web Designs ğŸ¤¯ | Where Creativity Meets Functionality #Shorts #Viral #Creativity #Hacks #Html,"These cool web designs prove that creativity + functionality = From smooth animations to clean UI layouts, this is what modern ...",web design trends
youtube,,https://www.youtube.com/watch?v=eL2nOKEt2rk,1769728811,Why Bento Grid Layouts are Everywhere in 2026 Web Design,"Bento grid layouts are redefining how modern websites organize content. Inspired by modular design and editorial layouts, this ...",web design trends
youtube,,https://www.youtube.com/watch?v=QhGkZz9xGxg,1769721967,2026 Website Design Trends #colorpalette #webdesign2026,"Website color trends are evolving fast, and 2026 is bringing a new wave of design choices that balance personality, clarity, and ...",web design trends
youtube,,https://www.youtube.com/watch?v=vpZxGjX1TKM,1769707667,The invisible code Exploring generative AI&#39;s impact on web design trends #motivation #shorts,The invisible code Exploring generative AI's impact on web design trends #motivation #shorts.,web design trends
youtube,,https://www.youtube.com/watch?v=ryMmaHdEdM4,1769699706,WORST Interior Design Trends in 2026 (Some of them have to go!),"Not every trend is worth following. Some interior design trends look great onlineâ€”but fail badly in real homes. In this video, we ...",web design trends
youtube,,https://www.youtube.com/watch?v=W1x4iratmTs,1769698805,Learn the Latest Front-End Development &amp; UI / UX Design Trends at Pixel Pioneers 2026!,Pixel Pioneers Website: https://pixelpioneers.co/ --- Learn The Latest Front End Development and UI / UX Design Trends At Pixel ...,web design trends
youtube,,https://www.youtube.com/watch?v=ViuqiN2Hh7E,1769697000,2026 Web Design Trends to Easily Upgrade Your Site,"Want your website to look modern, engaging, and professional without spending a fortune? In this video, we break down the top ...",web design trends
youtube,,https://www.youtube.com/watch?v=0LkfTj2QVxY,1769696778,8 Web Design Trends That Are About to Change Everything in 2026,"In 2026, web design trends focus on creating faster, more intuitive, and visually dynamic experiences. From modular bento grid ...",web design trends
youtube,,https://www.youtube.com/watch?v=mPClFpP0ZT0,1769692266,How to Create a Professional Business Website in WordPress in 2026 â€” without any coding! ğŸš€,2026 mein apne business ke liye professional website kaise banaye? Is video mein maine step-by-step bataya hai ki kaise aap ...,web design trends
youtube,,https://www.youtube.com/watch?v=A6atF5TI5Yg,1769686581,Stop Following Website Design Trends in 2026. Do This Instead,"Every year, business owners are told to follow the latest website design trends. New fonts. New layouts. New styles. But 2026 is ...",web design trends
youtube,,https://www.youtube.com/watch?v=uw6C8Z1XieY,1769669248,Portfolio Websites Every Designer Should Study in 2026,Here are some the best Portfolio Websites for Web Designers to gain Inspiration in 2026. Made by some of the best award ...,web design trends
youtube,,https://www.youtube.com/watch?v=da4fScaoth0,1769654668,These 2026 Web Design Trends Will Change Everything,"Step into the future of web design! In 2026, websites are evolving to combine human-centered design, cutting-edge technology, ...",web design trends
youtube,,https://www.youtube.com/watch?v=pasM-XtMx8A,1769634359,2026 Graphic Design Trends You Need to Know,"What will graphic design look like in 2026? In this video, I break down the emerging design trends shaping branding, digital ...",web design trends
youtube,,https://www.youtube.com/watch?v=YwWW4Ry2OxE,1769867480,Design Trends 2026,Stop guessing what's next! ğŸ§ Our massive new report on the 10 Design Trends shaping typography and the visual landscape in ...,typography trends
youtube,,https://www.youtube.com/watch?v=6c6XBFoUU7M,1769841137,typography in one click #trending #viral #typhography,"Discover the power of typography in one click, where trending and viral designs come to life. Learn how to create stunning ...",typography trends
youtube,,https://www.youtube.com/watch?v=2x2ksjhzMLY,1769784674,Typography Trends 2026,The rules of typography are being rewritten. ğŸš€ We've just released our full Blog Post: Top 10 Typography Trends for 2026.,typography trends
youtube,,https://www.youtube.com/watch?v=3vQ00qHHGZU,1769584047,Ep.4 Parallel Obssrver.      #mindset #philosophy #trends #typography  #glitch #thinkdivine,Ep.4 Parallel Obssrver. #mindset #philosophy #trends #typography #motivation #glitch.,typography trends
youtube,,https://www.youtube.com/watch?v=CJgLYiSRO-s,1769461743,How To Made typography video|| Like this ğŸ’¸ğŸ“¸ #shortvideo #typography #shorts,What is Typography? Complete Guide for Beginners Typography Explained in Simple English History of Typography â€“ From ...,typography trends
youtube,,https://www.youtube.com/watch?v=lYOtZKah68o,1769339605,Display Fonts 2026: The ONE Change That Fixes Flat Designs,"Display Fonts 2026: The ONE Change That Fixes Flat Designs display fonts, display font tutorial, display font vs regular font, bold ...",typography trends
youtube,,https://www.youtube.com/watch?v=nrVojxqD68o,1769077385,How to add aesthetic fonts #shorts #tipsandtricks,Learn how to add aesthetic fonts to your graphic design projects with these simple tips and tricks. If you're a beginner in graphic ...,typography trends
youtube,,https://www.youtube.com/watch?v=qcnxiQQ_0Fc,1769031357,2026 Font Trends You Should Know About,Use These Fonts In Kittl: https://kit.tl/2026fonts ğŸ‘‰ Learn More About These Fonts: https://www.kittl.com/blogs/top-font-trends-dsi/ ...,typography trends
youtube,,https://www.youtube.com/watch?v=9_Da1xf_LF0,1768974240,What Are the Top School Leavers Top Trends Students Actually Love to Wear? | Colour Up Uniforms,What Are the Top School Leavers Top Trends Students Actually Love to Wear? | Colour Up Uniforms What Are the Top School ...,typography trends
youtube,,https://www.youtube.com/watch?v=cnTP2LuSFOw,1768636943,"ğŸ˜‚ WAIT FOR END ğŸ˜€Typography video, reel trends,",,typography trends
youtube,,https://www.youtube.com/watch?v=MTMIKSUFXEE,1768579770,ğŸ†•#ValeLaPenaVer ğŸ‡¨ğŸ‡´ | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseÃ±o 2026,"ValeLaPenaVer ğŸ‡¨ğŸ‡´ | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseÃ±o 2026, un anÃ¡lisis que ...",typography trends
youtube,,https://www.youtube.com/watch?v=iq7E1RBZgDY,1768570250,#handwriting #calligraphy #calligrphylearning #handlettering #artist #letter #typography#handwriting,"modern calligraphy tips, calligraphy for beginners, DIY calligraphy projects, calligraphy tutorials, calligraphy lettering styles, brush ...",typography trends
youtube,,https://www.youtube.com/watch?v=_jkyUunzs1I,1768538874,5 Best Websites to Download Free Fonts for Designers ğŸ”¥,"Looking for the best websites to download free fonts for your design projects? In this short video, I share 5 powerful font websites ...",typography trends
youtube,,https://www.youtube.com/watch?v=qErJzUWGgLQ,1768410089,Our font design predictions for 2026,"Want to boost your branding in 2026? Start with your fonts! Because when your typography feels like your voice, customers listen ...",typography trends
youtube,,https://www.youtube.com/watch?v=WHIGDDkIbz0,1768342928,8 fresh font trends for 2026,The font trends for 2026 reveal that personality and imperfection are standing out in a market flooded with overly polished ...,typography trends
youtube,,https://www.youtube.com/watch?v=HKprAtVk7TM,1768093232,Frontiers of Visual Language Emerging Trends in Graphic Design,"Explore the latest design trends shaping 2026, from AI workflows to immersive branding. Practical tips to elevate your next project.",typography trends
youtube,,https://www.youtube.com/watch?v=nN7IWFanI0M,1768052624,day 1 journey of my life #viral #typography #motivation #editing #trending #day1,Welcome to my channel! ğŸ˜Š In this video you'll see amazing **typography text animations** and **design inspiration** â€” perfect ...,typography trends
youtube,,https://www.youtube.com/watch?v=83wacmeqGd0,1768049484,design trends 2026 pt. 1ğŸ’ #Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ #Ğ±Ñ€ĞµĞ½Ğ¸Ğ½Ğ³ #Ğ±Ñ€ĞµĞ½Ğ´Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ #Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ñƒ,,typography trends
youtube,,https://www.youtube.com/watch?v=kRmT9kJ_E-E,1767981896,day 0 journey of my life    #viral #motivation #typography #day0 #editing,Welcome to my channel! ğŸ˜Š In this video you'll see amazing **typography text animations** and **design inspiration** â€” perfect ...,typography trends
youtube,,https://www.youtube.com/watch?v=uRK43kg05zI,1767918989,Typography Trends 2026 (Versi Tayo) ,Typography Trends 2026 Saya menemukan template mengagumkan ini di CapCut. Ketuk tautan untuk mencobanya!,typography trends
youtube,,https://www.youtube.com/watch?v=DCpoDKHct00,1767890799,These Bold Fonts Will Dominate 2026 &amp; Beyond!,"Looking for the best bold fonts for 2026 and beyond? In this video, we explore the bold typography trends that will dominate ...",typography trends
youtube,,https://www.youtube.com/watch?v=qeFr2L2Sjxs,1767790238,"days [4/7] Kala Tika, Safed Tikaâ€¦ Confusion Hi Confusion ğŸ˜Œ #typography #shorts","Kala Tika, Safed Tikaâ€¦ Confusion Hi Confusion ğŸ˜Œ #typography #shorts â€¢Disclaimer: This is Video made for entertainment ...",typography trends
youtube,,https://www.youtube.com/watch?v=MPbWoDrwzY0,1767711643,"Minimalist Fonts for a Fresh Start | Clean, Modern Typography  #canvahacks #businesstemplates","A new season is the perfect moment to refresh your design style. Clean typography creates clarity, calm, and focus â€” before ...",typography trends
youtube,,https://www.youtube.com/watch?v=yHs9-RVTwsA,1767704407,Graphic Design Trends 2026 â€” And How to Actually Use Them!,Discover the most important graphic design trends of 2026 and learn exactly how to use them the right way in your own work!,typography trends
youtube,,https://www.youtube.com/watch?v=RPnW-5FqgCk,1767676992,Typography #typographyart #banglatypography #starrynightvibes #artandcraft #trends #virals,,typography trends
