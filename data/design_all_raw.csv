source,domain,url,created_utc,title,text,query
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/smashing-animations-part-7-recreating-toon-text-css-svg/,1765965600,Smashing Animations Part 7: Recreating Toon Text With CSS And SVG,"Smashing Animations Part 7: Recreating Toon Text With CSS And SVG

In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk) shows his techniques for creating [Toon Text titles](https://stuffandnonsense.co.uk/toon-text/index.html) using modern CSS and SVG.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/accessible-ux-research-ebook-release/,1765296000,"Accessible UX Research, eBook Now Available For Download","Accessible UX Research, eBook Now Available For Download

Weâ€™ve got exciting news! eBook versions of â€œAccessible UX Research,â€ a new Smashing Book by Michele A. Williams, are now available for download! Which means soon the book will go to the printer. Order the eBook for instant download now or <a href=""https://www.smashingmagazine.com/printed-books/accessible-ux-research/"">reserve your print copy at the presale price.</a>",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/state-logic-native-power-css-wrapped-2025/,1765274400,"State, Logic, And Native Power: CSS Wrapped 2025","State, Logic, And Native Power: CSS Wrapped 2025

CSS Wrapped 2025 is out! Weâ€™re entering a world where CSS can increasingly handle logic, state, and complex interactions once reserved for JavaScript. Here is an unpacking of the standout highlights and how they connect to the bigger evolution of modern CSS.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-ux-professionals-can-lead-ai-strategy/,1765180800,How UX Professionals Can Lead AI Strategy,"How UX Professionals Can Lead AI Strategy

Lead your organizationâ€™s AI strategy before someone else defines it for you. A practical framework for UX professionals to shape AI implementation.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/beyond-black-box-practical-xai-ux-practitioners/,1764946800,Beyond The Black Box: Practical XAI For UX Practitioners,"Beyond The Black Box: Practical XAI For UX Practitioners

Explainable AI isnâ€™t just a challenge for data scientists. Itâ€™s also a design challenge and a core pillar of trustworthy, effective AI products. Victor Yocco offers practical guidance and design patterns for building explainability into real products.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/masonry-things-you-wont-need-library-anymore/,1764669600,Masonry: Things You Wonâ€™t Need A Library For Anymore,"Masonry: Things You Wonâ€™t Need A Library For Anymore

CSS Masonry is almost here! Patrick Brosset takes a deep dive into what this long-awaited feature means for web developers and how you could make use of it in your own work.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/desktop-wallpaper-calendars-december-2025/,1764493200,A Sparkle Of December Magic (2025 Wallpapers Edition),"A Sparkle Of December Magic (2025 Wallpapers Edition)

With December just around the corner, how about some new desktop wallpapers to welcome the last month of the year â€” and the holiday season, if youâ€™re celebrating? Our latest edition of monthly wallpapers has got you covered. Enjoy!",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/accessibility-problem-authentication-methods-captcha/,1764237600,The Accessibility Problem With Authentication Methods Like CAPTCHA,"The Accessibility Problem With Authentication Methods Like CAPTCHA

CAPTCHAs were meant to keep bots out, but too often, they lock people with disabilities out, too. From image classification to click-based tests, many â€œhuman checksâ€ are anything but inclusive. Thereâ€™s no universal solution, but understanding real user needs is where accessibility truly starts.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/design-system-culture/,1764093600,Design System Culture: What It Is And Why It Matters (Excerpt),"Design System Culture: What It Is And Why It Matters (Excerpt)

Weâ€™re so happy to announce that â€œMaturing Design Systemsâ€â€”a Smashing book by Ben Callahan &mdash; will soon be joining the Smashing Library! Benâ€™s insights and advice are so powerful, we thought you might like to read an excerpt from the book. <a href=""https://www.smashingmagazine.com/the-smashing-newsletter/"">Subscribe to our Smashing newsletter</a> to be notified when orders are open.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/designing-for-stress-emergency/,1763989200,Designing For Stress And Emergency,"Designing For Stress And Emergency

Practical guidelines on designing time-critical products that prevent errors and improve accuracy. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today). With a <a href=""https://smashingconf.com/online-workshops/workshops/vitaly-friedman-impact-design/"">live UX training</a> starting next week.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/keyframes-tokens-standardizing-animation-across-projects/,1763712000,Keyframes Tokens: Standardizing Animation Across Projects,"Keyframes Tokens: Standardizing Animation Across Projects

Animations can be one of the most joyful parts of building interfaces, but without structure, they can also become one of the biggest sources of frustration. By consolidating and standardizing keyframes, you take something that is usually messy and hard to manage and turn it into a clear, predictable system.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/simplifying-server-management-ai-automation/,1763460000,From Chaos To Clarity: Simplifying Server Management With AI And Automation,"From Chaos To Clarity: Simplifying Server Management With AI And Automation

Server chaos doesnâ€™t have to be the norm. AI-ready infrastructure and automation can bring clarity, performance, and focus back to your web work.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/css-gamepad-api-visual-debugging-css-layers/,1763125200,CSS Gamepad API Visual Debugging With CSS Layers,"CSS Gamepad API Visual Debugging With CSS Layers

Debugging controllers can be a real pain. Hereâ€™s a deep dive into how CSS helps clean it up and how to build a reusable visual debugger for your own projects.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/older-tech-browser-stack/,1763020800,Older Tech In The Browser Stack,"Older Tech In The Browser Stack

There are many existing web features and technologies in the wild that you may never touch directly in your day-to-day work. Perhaps youâ€™re fairly new to web development and are simply unaware of them because youâ€™re steeped in the abstraction of a specific framework that doesnâ€™t require you to know it deeply, or even at all. Bryan Rasmussen looks specifically at XPath and demonstrates how it can be used alongside CSS to query elements.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/effectively-monitoring-web-performance/,1762855200,Effectively Monitoring Web Performance,"Effectively Monitoring Web Performance

There are lots of tips for [improving your website performance](https://www.debugbear.com/blog/improve-website-performance?utm_campaign=sm-10). But even if you follow all of the advice, are you able to maintain an optimized site? And are you targeting the right pages? Matt Zeunert outlines an effective strategy for web performance optimization and explains the roles that different types of data play in it.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/smashing-animations-part-6-svgs-css-custom-properties/,1762527600,Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties,"Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties

SVG is one of those web technologies thatâ€™s both elegant and, at times, infuriating. In this article, pioneering author and web designer Andy Clarke explains his technique for animating SVG elements that are hidden in the Shadow DOM.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/practical-guide-ux-strategy/,1762347600,Six Key Components of UX Strategy,"Six Key Components of UX Strategy

Letâ€™s dive into the building blocks of UX strategy and see how it speaks the language of product and business strategy to create user value while achieving company goals. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today).",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/how-leverage-component-variants-penpot/,1762250400,How To Leverage Component Variants In Penpot,"How To Leverage Component Variants In Penpot

With component variants, design systems become more flexible, letting you reuse the same component while adapting its look or state with ease. In this article, Daniel Schwarz demonstrates how design tokens can be leveraged to manage components and their variations using <a href=""https://penpot.app?utm_source=SmashingMag&amp;utm_medium=Article&amp;utm_campaign=Variants"">Penpot</a>, the open-source tool built for scalable, consistent design.",
rss,uxdesign.cc,https://uxdesign.cc/keep-making-ai-will-not-save-you-402023b808fc?source=rss----138adf9c44c---4,1766060349,Keep making (AI will not save you),"Keep making (AI will not save you)

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/keep-making-ai-will-not-save-you-402023b808fc?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2388/1*4ZsibUXyomAMfufYXBeUgQ.png"" width=""2388"" /></a></p><p class=""medium-feed-snippet"">Why growing your conceptual abilities via sketching and idea generation will help you compete with AI and against AI.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/keep-making-ai-will-not-save-you-402023b808fc?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/3-color-contrast-mistakes-designers-still-make-68cc224735b3?source=rss----138adf9c44c---4,1765973643,3 color contrast mistakes designers still make,"3 color contrast mistakes designers still make

<h4><em>WCAG color contrast is more than justÂ text</em></h4><p>Most designers know the basics of web accessibility and color contrast. Weâ€™ve memorized that â€œnormal textâ€ (<a href=""https://www.w3.org/WAI/WCAG21/Understanding/contrast-minimum.html#dfn-large-scale"">24 CSS pixels and below</a>) needs to meet a 4.5:1 contrast ratio with its background, and â€œlarge textâ€ (greater than 24 CSS pixels) needs to meet a 3:1Â ratio.</p><p><strong>But WCAG (</strong><a href=""https://www.w3.org/WAI/WCAG21/Understanding/""><strong>Web Content Accessibility Guidelines</strong></a><strong>) color contrast requirements donâ€™t stop at text.</strong> There are lesser known WCAG success criteria (or â€œrulesâ€) that are still very important for inclusive design; these ensure interfaces are usable to users with low vision or color blindness.</p><figure><img alt=""Viewing YouTubeâ€™s homepage with different vision simulations, like red-green color blindness and sun-glare"" src=""https://cdn-images-1.medium.com/max/1024/1*-l5gevfqLDE88Ha5TisA6g.png"" /><figcaption>Viewing YouTubeâ€™s homepage with different vision simulations, like red-green color blindness</figcaption></figure><p>Some of these forgotten requirements circle around UI components, inline links, and data visualizations, which all have color contrast rules of their own. When these details are overlooked, users canâ€™t tell whatâ€™s interactive, whatâ€™s linked, or what the data is actually saying (even if all the text uses accessible colors).</p><p>And these accessibility gaps arenâ€™t edge cases. They show up in mature Design Systems, enterprise products, and well-intentioned designs because they live outside the accessibility standards designers tend to learn andÂ adopt.</p><p>To avoid these gaps for the future, letâ€™s go over 3 ongoing color contrast issues, how WCAG applies beyond text, and who exactly is impacted by color contrast.</p><blockquote><strong>Note</strong><em>: I reference WCAG 2.1, Level AA standards. If your product needs to comply with Level AAA, required color contrast ratios increase (i.e., </em><a href=""https://www.w3.org/WAI/WCAG21/Understanding/contrast-enhanced.html""><em>normal text needs a 7:1 ratio</em></a><em> with its background).</em></blockquote><h3>UI components that look accessible (butÂ arenâ€™t)</h3><p>WCAG criteria: <a href=""https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html"">SC 1.4.11: Non-Text Contrast (LevelÂ AA)</a></p><p>In plain english, this WCAG criteria requires that non-text UI elements that are interactive or communicate meaning have a <strong>minimum of 3:1 contrast ratio</strong> against adjacent colors (like the UI background).</p><p>But what is covered by â€œUI elementsâ€? Basically, anything that a user can interact with or needs to see to use; suchÂ as:</p><ul><li>Buttons and buttonÂ states</li><li>Form fields and theirÂ borders</li><li>Checkboxes, radio buttons, andÂ toggles</li><li>Focus indicators</li><li>Icons that convey meaning or affordance</li></ul><figure><img alt=""Spirit includes text fields that do not meet contrast requirements with a 1.6:1 ratio"" src=""https://cdn-images-1.medium.com/max/1024/1*mzlbjZWOHK27EOSS3N1QaQ.png"" /><figcaption><a href=""https://www.spirit.com/flight-status""><em>Spirit</em></a><em> includes text fields that do not meet contrast requirements with a 1.6:1 ratio; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><blockquote><strong>Important note</strong><em>: If color contrast fails WCAG standards from the Design System level, the failure is replicated across all product adopters; itâ€™s critical to check system UI componentâ€™s color contrast.</em></blockquote><h4>What designers miss and why itÂ matters</h4><p>This is where many designs that are intended to be accessible quietly fail. Since these UI elements donâ€™t contain text, theyâ€™re excluded from color contrast checks. And yes, text is very important to check, but so are the UI elements that provide any product its functionality.</p><p><strong>Common gaps within UI elementsÂ include:</strong></p><ul><li>Input borders that blend into the product background</li><li>Custom focus indicators that rely on subtle color shifts instead of high-contrast</li><li>Icon-only controls (like buttons) that donâ€™t meet contrast on theirÂ own</li></ul><p><strong>When UI elements lack minimum contrast, users canâ€™t reliably:</strong></p><ul><li>Identify whatâ€™s interactive or understand UI component states (likeÂ hover)</li><li>Navigate interfaces using only theirÂ keyboard</li><li>Complete forms without repetitive errors</li></ul><figure><img alt=""BBC includes a primary CTA that meets contrast requirements with a 4.58:1 ratio"" src=""https://cdn-images-1.medium.com/max/1024/1*9lBpa8t8UhfH8HfsgOkvOQ.png"" /><figcaption><a href=""https://www.bbc.com/""><em>BBC</em></a><em> includes a primary CTA that meets contrast requirements with a 4.58:1 ratio; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><h4>Who are the users impacted?</h4><p>Though low-contrast UI elements affect everyone at some capacity (you might have to do some squinting), they make products unusable to peopleÂ like:</p><ul><li>Users with low vision who need distinct visualÂ styling</li><li>Keyboard users who depend on focus indicators that stand-out on theÂ UI</li><li>Older users experiencing reduced contrast sensitivity</li><li>Users in low-contrast environments (i.e., sun-glare, small screens, fluorescent lights)</li></ul><blockquote><strong>Note</strong><em>: To check a UI componentâ€™s contrast (or any element that needs contrast), you can also use </em><a href=""https://chromewebstore.google.com/detail/web-disability-simulator/olioanlbgbpmdlgjnnampnnlohigkjla?hl=en&amp;pli=1""><em>Web Disability Simulator</em></a><em> on any web page to simulate how it looks for users with color-blindness or cognitive disabilities.</em></blockquote><figure><img alt=""Red-green color blind simulation on YouTube with the Web Disability Simulator Chrome extension"" src=""https://cdn-images-1.medium.com/max/1024/1*QWZyIWC5rf7neuUBx-RhKQ.png"" /><figcaption><em>Red-green color blind simulation on </em><a href=""https://www.youtube.com/""><em>YouTube</em></a><em> with the </em><a href=""https://chromewebstore.google.com/detail/web-disability-simulator/olioanlbgbpmdlgjnnampnnlohigkjla?hl=en&amp;pli=1""><em>Web Disability Simulator</em></a><em> Chrome extension</em></figcaption></figure><h3>Data visualizations with lowÂ contrast</h3><p>WCAG criteria: <a href=""https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html"">SC 1.4.11: Non-Text Contrast (LevelÂ AA)</a></p><p>This accessibility gap references the same WCAG standard as UI components from above. But though data visualizations (data viz) may not always be interactive, theyâ€™re communicating meaningful information. Because of this, data viz must be perceivable without relying only on color and must meet a <strong>minimum 3:1 contrast ratio</strong> against adjacentÂ colors.</p><p>This standard appliesÂ to:</p><ul><li>Chart lines, bars, andÂ segments</li><li>Data points andÂ markers</li><li>Axes, gridlines, or any reference lines that conveyÂ meaning</li><li>Legends or other visualÂ keys</li></ul><figure><img alt=""Datylon includes a pie chart example that does not meet contrast requirements with a 1:1 ratio"" src=""https://cdn-images-1.medium.com/max/1024/1*1OTh5HfA1C-vKeF7ZsJWag.png"" /><figcaption><a href=""https://www.datylon.com/resources/chart-library/pie-chart""><em>Datylon</em></a><em> includes a pie chart example that does not meet contrast requirements with a 1:1 ratio; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><h4>What designers miss and why itÂ matters</h4><p>Data viz is an already complex and complicated UI element, so itâ€™s even more difficult to bake in accessibility guidelines (especially if itâ€™s being retrofitted). But color contrast issues are frequently found in charts and heatmaps that use the brandâ€™s color palette rather than accessibility-tested colors.</p><p><strong>Common issues with data vizÂ include:</strong></p><ul><li>Chart colors that are distinguishable in isolation but fail 3:1 contrast when touching oneÂ another</li><li>Data series using colors that arenâ€™t distinguishable for color-blind users (i.e., red-green)</li><li>Thin gridlines with low contrast that disappear against the background</li><li>Charts that use multiple colors without secondary text indicators</li><li>Legends that depend on matching colors instead of labels orÂ patterns</li></ul><p><strong>When data viz lack contrast and use color alone, usersÂ canâ€™t:</strong></p><ul><li>Clearly and quickly understand trends in the dataÂ set</li><li>Confidently compare data without the feeling ofÂ guessing</li><li>Lose access to critical insights (especially when the data isnâ€™t provided in anotherÂ way)</li></ul><h4>Who are the users impacted?</h4><p>Again, all users are affected on some level by low contrast data viz. But other users need to be considered when designing the different types of charts so they can perceive and comprehend the same information as everyoneÂ else.</p><p>Some of these usersÂ include:</p><ul><li>Color-blind users (especially those with red-green color blindness)</li><li>Users with low vision who need high contrast for visual distinction</li><li>Users with cognitive disabilities who benefit from redundant cues</li><li>Users viewing charts on small screens or in poorÂ lighting</li></ul><figure><img alt=""IBM Carbon includes a pie chart example that meets contrast requirements with a 7.76:1 ratio"" src=""https://cdn-images-1.medium.com/max/1024/1*_Gsff7Yx_6gvh6DmjX7Djg.png"" /><figcaption><a href=""https://carbondesignsystem.com/data-visualization/simple-charts/#pie""><em>IBM Carbon</em></a><em> includes a pie chart example that meets contrast requirements with a 7.76:1 ratio; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><blockquote><strong>Note</strong><em>: Simply by adding a white border between data viz elements, the colors become more distinguishable and meet accessibility guidelines.</em></blockquote><h3>Inline links that rely on low contrastÂ color</h3><p>WCAG criteria: <a href=""https://www.w3.org/WAI/WCAG21/Understanding/use-of-color.html"">SC 1.4.1: Use of Color (LevelÂ A)</a></p><p>Color cannot be the only visual means used to indicate a link on a web page. But not only that, inline links also must have <strong>at least 3:1 contrast</strong> against surrounding body text to be distinguishable (especially when the link doesnâ€™t have an additional visual cue, <a href=""https://www.w3.org/TR/WCAG20-TECHS/F73.html"">like an underline or bold fontÂ weight</a>).</p><figure><img alt=""Atlantaâ€™s Department of Transportation includes inline links that do not meet contrast requirements with a 1.58:1 ratio"" src=""https://cdn-images-1.medium.com/max/1024/1*k_84e7wKBM0IOAXis1ljeA.png"" /><figcaption><a href=""https://atldot.atlantaga.gov/""><em>Atlantaâ€™s Department of Transportation</em></a><em> includes inline links that do not meet contrast requirements with a 1.58:1 ratio; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><h4>What designers miss and why itÂ matters</h4><p>Inline links are such simple and subtle UI components; itâ€™s easy to miss the checks needed to ensure accessibility. Designers typically think that since a paragraph of text meets the 4.5:1 color ratio requirement, any inline link using the same text color within the paragraph also passes. Since links are interactive elements, they have additional guidelines other than passing the color requirements forÂ text.</p><p><strong>Frequent issues with inline linksÂ include:</strong></p><ul><li>Links that are differentiated only by an underline when the link receive mouse hover or keyboardÂ focus</li><li>Link colors that meet contrast against the background, but not against adjacentÂ text</li><li>Underlines removed for aesthetic or simplicity reasons</li></ul><p><strong>When inline links arenâ€™t clearly distinguishable, usersÂ canâ€™t:</strong></p><ul><li>Easily comprehend whatâ€™s interactive (especially when hidden in bodyÂ copy)</li><li>Efficiently navigate a website or productÂ page</li><li>Find important actions or information they need to complete aÂ task</li></ul><h4>Who are the users impacted?</h4><p>Iâ€™ve said it before, and Iâ€™ll say it againâ€¦ this affects all users at some capacity. Inline links are not as recognizable to any user when the underline affordance or high contrast color is taken away. But for some users, it becomes impossible to identify links that could lead the user to information or product pages theyÂ need.</p><p>Users to consider when designing inline linksÂ include:</p><ul><li>Color-blind users who may not perceive color differences</li><li>Users with low vision who require visual affordances with highÂ contrast</li><li>Users with cognitive disabilities who benefit from consistent patterns</li><li>All users scanning contentÂ quickly</li></ul><blockquote><strong>Note</strong><em>: A simple rule of thumb is to make a link look like a link for optimal usability and accessibility.</em></blockquote><figure><img alt=""Gov.UK includes inline links that meets contrast requirements with a 3.81:1 ratio AND are underlined"" src=""https://cdn-images-1.medium.com/max/1024/1*3rOPtaAXaJBwGlfl3wKXcg.png"" /><figcaption><a href=""https://www.gov.uk/how-to-have-your-benefits-paid""><em>Gov.UK</em></a><em> includes inline links that meets contrast requirements with a 3.81:1 ratio AND are underlined; calculated with </em><a href=""https://webaim.org/resources/contrastchecker/""><em>WebAimâ€™s ContrastÂ Checker</em></a></figcaption></figure><p><strong>UI components, inline links, and data visualizations often fall outside the mental checklist of color contrast and accessible design.</strong> WCAG covers these elements, but itâ€™s often overlooked when focusing on adequate contrast for text. This leads to websites and interfaces that look high contrast, but are near impossible to use for some userÂ groups.</p><p>By spreading awareness to these accessibility gaps, we can expand how we define color contrast and better apply ideal accessibility practices. When these requirements are built into components, patterns, and Design Systems from the start, accessibility stops being a last-minute fix (or remediation plan) and becomes part of the designÂ process.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=68cc224735b3"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/3-color-contrast-mistakes-designers-still-make-68cc224735b3"">3 color contrast mistakes designers still make</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/designing-product-delighters-people-remember-and-share-d7efd29a0379?source=rss----138adf9c44c---4,1765926245,Designing product delighters people remember and share,"Designing product delighters people remember and share

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/designing-product-delighters-people-remember-and-share-d7efd29a0379?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2400/1*84iOQ9FdVgC9tWmJ8CFW3Q.png"" width=""2400"" /></a></p><p class=""medium-feed-snippet"">Why moments like Spotify Wrapped get shared everywhere, and how products like Figma and Duolingo design small delights</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/designing-product-delighters-people-remember-and-share-d7efd29a0379?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/your-users-dont-need-training-they-need-scaffolding-10acd8270022?source=rss----138adf9c44c---4,1765926230,Your users donâ€™t need training. They need scaffolding.,"Your users donâ€™t need training. They need scaffolding.

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/your-users-dont-need-training-they-need-scaffolding-10acd8270022?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/612/1*npJoMqO-8IJw23_qkfAdXQ.jpeg"" width=""612"" /></a></p><p class=""medium-feed-snippet"">Get new users doing instead of learning</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/your-users-dont-need-training-they-need-scaffolding-10acd8270022?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/why-cleaner-design-slides-arent-the-answer-to-getting-your-team-to-buy-in-1ccb203e29a0?source=rss----138adf9c44c---4,1765887256,Why cleaner design slides arenâ€™t the answer to getting your team to buy in,"Why cleaner design slides arenâ€™t the answer to getting your team to buy in

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-cleaner-design-slides-arent-the-answer-to-getting-your-team-to-buy-in-1ccb203e29a0?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*LLl1zhFwWMQQAivmOpIpoQ.jpeg"" width=""6000"" /></a></p><p class=""medium-feed-snippet"">Information is cheap, but attention is expensive: why design presentations fail</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-cleaner-design-slides-arent-the-answer-to-getting-your-team-to-buy-in-1ccb203e29a0?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/lower-the-surprise-applying-the-free-energy-principle-to-ux-0e557d122b81?source=rss----138adf9c44c---4,1765836432,Lower the surprise: Applying The free energy principle to UX,"Lower the surprise: Applying The free energy principle to UX

<h4>Our brain is a prediction machine that canâ€™t be stopped. No matter how hard we try, it will still build expectations.</h4><p>If youâ€™re reading this, youâ€™ve probably asked yourself the same question I always have: What exactly makes users subconsciously follow <a href=""https://www.researchgate.net/publication/279871278_Color-in-Context_Theory"">Color Psychology</a>, <a href=""https://www.interaction-design.org/literature/topics/gestalt-principles?srsltid=AfmBOopi3ws2HhTLq5t9k-4j8DcE9Ef_W6XddNvGAqidJSuDQZDW4XU4"">Gestalt principles</a>, and behavioral patterns like <a href=""https://lawsofux.com/hicks-law/"">Hickâ€™s law</a>? Why does all of this work? Is there a way to understand the true nature of our brain and not just how it reacts, but why it predicts, expects, and perceives the world the way itÂ does?</p><p>Now itâ€™s time to go one level deeperâ€Šâ€”â€Šinto the core of how our brain actually works. In this article, weâ€™ll touch on one of the fundamental theories that helps me personally answer these questions, and I would love to share it with you. Buckle up, weâ€™re shifting into nerdÂ gear!</p><h3>The Free Energy Principle</h3><p>In 2010, in his paper <a href=""https://www.nature.com/articles/nrn2787"">The free-energy principle: a unified brain theory?</a>, <a href=""https://en.wikipedia.org/wiki/Karl_J._Friston"">Karl Friston</a> formally introduced a theory stating that every system, including living organisms, strives to minimize free energy. Simple enough: we donâ€™t like surprises. But letâ€™s take a closer look at what that reallyÂ means.</p><figure><img alt=""Portrait of neuroscientist Karl Friston, author of the Free Energy Principle."" src=""https://cdn-images-1.medium.com/max/1024/0*SSE0hdbj4PtpTqh7.jpg"" /><figcaption>Karl Friston, Photo by Kate PetersÂ (<a href=""https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/"">WIRED</a>)</figcaption></figure><p>The brainâ€™s main task is to minimize the gap between expectation and reality. This gap is what the <a href=""https://en.wikipedia.org/wiki/Free_energy_principle"">Free Energy Principle</a> defines as free energy. When the brain encounters unpredictable input, its stress level rises. And itâ€™s crucial to understand: this isnâ€™t about you as a person or a â€œuserâ€, itâ€™s about your brain. Itâ€™s not something we consciously control, but itâ€™s something we canÂ use.</p><p>After all, as humans, we donâ€™t always chase predictability or comfort. Many people enjoy physical exercise, even though itâ€™s technically stress for the muscles. We love movies with unexpected plot twists, and even comedy works by placing us in a familiar setup and then adding an unpredictable punchline.</p><p>Thatâ€™s because weâ€™re more than just our brains. The human organism and our consciousness is a complex system of subsystems, including our hormonal system, which can reward the brain with the right chemistry under stress, or reinforce behavior when we act in line with its internal â€œprogram.â€</p><p>So, the Free Energy Principle is actually quite a complex theory, and there are different mathematical interpretations of it. But for simplicity and convenience, today weâ€™re going to look at a more accessible formula:</p><figure><img alt=""Diagram of the free energy equation with each variable labeled."" src=""https://cdn-images-1.medium.com/max/1024/1*OltXx93fAkWg9_8i2HvACw.png"" /></figure><p>We can break it down into several key variables:</p><ul><li><strong><em>F</em>â€Š</strong>â€”â€Švariational free energy: this is the result of our brainâ€™s calculations. For the brain (or any predictive system) to remain in a stable, low-stress state, F should approach zero. The higher the free energy, the greater the stress or uncertainty in the system. This idea directly connects to the concept of entropy, the natural tendency toward disorder which both we and our brains constantly try toÂ resist.</li><li><strong><em>s</em></strong>â€Šâ€”â€Šsensory input: everything we receive from the external worldâ€Šâ€”â€Šsounds, tactile sensations, visual images,Â etc.</li><li><strong><em>m</em></strong>â€Šâ€”â€Šinternal model: our internal representation of how the world works. Essentially, our expectations about external reality or specific aspects ofÂ it.</li><li><strong><em>P</em></strong><em>â€Š</em>â€”â€Šprobability: represents the likelihood of a certain sensory input given our internal model (itâ€™s defined by whatâ€™s in the parentheses but not part of the main operation). The result ranges from 0 to 1, since itâ€™s a probability.</li><li><strong>âˆ’ln</strong>â€Šâ€”â€Šnatural logarithm: this function converts probabilities (values between 0 and 1) into a scale from 0 to infinity, making the difference between expectation and reality mathematically measurable but notÂ limited.</li></ul><p>The higher the probability, the smaller the resulting value. In other words, our brain is â€œhappyâ€ when the probability of our expectations matching what we actually perceive equals 1 (maximum probability)â€Šâ€”â€Šin that case, F=0. The lower the probability (P), the greater the amount of free energy (F): 1 = 0; 0.5 = 0.69; 0.1 = 2.3; 0.01 =Â 4.6.</p><p>Letâ€™s look at an example. A user moves the cursor over something that looks like a button: text on a bright blue rectangle.</p><figure><img alt=""Interface example of a button with active cursor"" src=""https://cdn-images-1.medium.com/max/1024/1*idKF4TdvSkphrORSln-aGg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p>mâ€Šâ€”â€Šthe user expects that the button will somehow change its state, what we usually call a hoverÂ state.</p><p>sâ€Šâ€”â€Šnothing happens to the button itself, but the cursorÂ changes.</p><p>Technically, the userâ€™s expectations were violated. But since our internal models are more complex than a single visual reaction, the additional input (the cursor change) helped complete the picture. When the button eventually responds to a click, the user almost immediately forgets the odd interaction.</p><p>Their P might have dropped slightly, perhaps to 0.95, meaning the probability that their mental model still matches the incoming input remains very high. The amount of free energy is close to zero. The brain is calm, the user is satisfied, the product isÂ sold.</p><p>Now letâ€™s take a negative example. The user moves the cursor over the same button: the same text, the same blue rectangle. The user once again expects that clicking it will initiate a purchase, thatâ€™s our m (the internalÂ model).</p><p>But the response is nothing: no color change, no cursor change, not even an error message. The user clicks repeatedly. Their P (probability) that their mental model matches the actual input, drops close toÂ zero.</p><figure><img alt=""Interface example of a button with no hover feedback."" src=""https://cdn-images-1.medium.com/max/1024/1*SN8vFhrI6J4EoE0zb1jFCA.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p>The brain starts trying to reduce the growing amount of free energy, sending out emotional signals. In this case, the button, the site, the entire interaction become irritants. Almost unconsciously, the user begins performing a series of random actions, trying to fix theÂ problem.</p><p>And if weâ€™re lucky, they eventually scroll up and notice that the email field is outlined in red with a message saying itâ€™s required. They enter the email, click Buy again, and finallyÂ succeed.</p><p>Not as happy, but at least with a product on the way. All of this happened simply because the button had no disabled state, no visual communication that it couldnâ€™t yet be pressed, forcing the user to waste five tense seconds clicking intoÂ nothing.</p><p>This is a fairly simple example that directly illustrates the relationship between our expectations and our perception of reality. But there are many others that you, as designers, already knowÂ well.</p><p>Take the Gestalt principles, for instance. We donâ€™t just see a random collection of shapes but we instinctively try to group them and assign meaning. Itâ€™s something our brain does automatically, without conscious effort. Thatâ€™s exactly why, at the beginning of this section, I emphasized that this principle isnâ€™t about us as individuals. Itâ€™s about our brainÂ itself.</p><p>Our brain constantly relies on its internal model, comparing it with the incoming sensory input we receive. And when the amount of free energy becomes too high, the brain automatically tries to fix theÂ problem.</p><p>It starts to create new categories or groups, sending the necessary emotional signals to push us toward resolving the discrepancy. Sometimes, it adjusts the internal model itself, modifying m in the formula to reduce the gap between expectation and reality. Thatâ€™s actually how we learn something new and this, in fact, can explain the very nature of our neuroplasticity.</p><p>But the brain can also go the other way distorting perception, effectively altering s in the formula, the sensory input itself. And thatâ€™s where we enter the territory of cognitive biases and perceptual illusions, an entire field in itself, and one that truly deserves the attention of us designers.</p><h3>Abduction is the key toÂ humanity</h3><p>Iâ€™m confident in saying that almost every well-known principle we are using in design can ultimately be explained through the Free Energy Principle. But that doesnâ€™t mean we, as designers, need to consciously apply it in our daily work. Good and even excellent designers usually operate within the beginner and intermediate levels of design psychology, and thatâ€™s more than enough to create meaningful, functional products.</p><p>For me personally, it has always been and still is fascinating to understand why things, principles, and rules work the way they do. Thatâ€™s why I try to find explanations and new perspectives through different sciences. And psychology is one ofÂ them.</p><p>With this article, Iâ€™d like to invite you to look at the familiar design dogmas we follow from a slightly different angle and to try broadening our perspective.</p><p>In a world where AI already knows all these rules and can even create interfaces based on them, what may soon remain truly ours is our human curiosity, the desire to reach for truth, to question what we take for granted, and to look at problems from new angles, expanding the boundaries of any givenÂ task.</p><p>In the language of philosophy, specifically the branch of logic we, as humans and users, most often rely on deduction and induction.</p><p>Deduction is deriving consequences from established rules. When we build our hypotheses based on principles and patterns. All clickable elements should change their state on hover â†’ This button changes its state on hover â†’ Therefore, this button is a clickable element.</p><p>Induction is generalizing from experience. When we conduct direct user testing. Our user clicked 100 different buttons, and each time the button changed its state on hover â†’ The user now expects that all buttons should change their state when hoveredÂ over.</p><p>But we, as designers, are expected to bring new ideas into theÂ world.</p><p>So Iâ€™d like to invite you to look at another type of reasoningâ€Šâ€”â€Šabduction. It is the process of forming a hypothesis that could best explain an observation.</p><figure><img alt=""Triangular diagram showing the relation between abduction, deduction and induction with text descriptions."" src=""https://cdn-images-1.medium.com/max/850/1*cLJYu98iQ0ogbr6iNisEuw.png"" /><figcaption>The relation between abduction, deduction and induction. <a href=""https://www.researchgate.net/figure/Fig-A1-The-relation-between-abduction-deduction-and-induction-Several-alternative_fig1_48326326"">ImageÂ Source</a></figcaption></figure><p>We notice that users often close the payment page without clicking the button â†’ What if the problem isnâ€™t the buttonâ€™s state but the emotional contextâ€Šâ€”â€Šthe anxiety or distrust triggered by the act of payment? â†’ Letâ€™s change â€œPayâ€ to â€œSecure Paymentâ€ and add the logos of trusted payment providers below the button to increase confidence.</p><blockquote>Abduction is the process of forming explanatory hypotheses. It is the only logical operation which introduces any new idea.<br /><a href=""https://en.wikipedia.org/wiki/Charles_Sanders_Peirce""><em>Charles S. Peirce</em></a><em> in </em><a href=""https://isidore.co/misc/Res%20pro%20Deo/Peirce/Done/5.html""><em>Collected Papers, CPÂ 5.172</em></a></blockquote><figure><img alt=""Portrait of philosopher Charles S. Peirce, associated with the concept of abduction."" src=""https://cdn-images-1.medium.com/max/720/0*7FcbdkzlQAL20VNs.png"" /><figcaption>Charles Sanders Peirce. <a href=""https://en.wikipedia.org/wiki/Charles_Sanders_Peirce#/media/File:Charles_Sanders_Peirce.png"">ImageÂ Source</a></figcaption></figure><p>You could even say that by using abduction, we ourselves become prediction machines: the feeling of anticipation, building a hypothesis, is what has made us human for thousands of years. Itâ€™s how we were able to achieve such heights of science and technology out ofÂ nothing.</p><p>And this ability appeared in us precisely because our brain tries to get rid of free energy. Thatâ€™s why I believe this principle is important not only to try to explain user behavior, but it is fundamental for us, as creators, thinkers, and engineers.</p><h3>Final thoughts</h3><p>And as for the practical application of todayâ€™s topic, I suggest you the following approach as an experiment just for yourself: if youâ€™re facing a tough problem or one youâ€™ve solved a hundred times, try ignoring all design principles for a moment. Approach it as if you only had abduction to generate hypotheses and the Free Energy Principle to evaluateÂ them.</p><p>Take a specific user and the situation theyâ€™re in, then sketch several alternative solutions you can score with the formula F = âˆ’lnÂ P(sâˆ£m).</p><p>Fill in the variables: m (what the user expected) and s (what the user actually saw). Then estimate which solution â€œminimizes free energyâ€, meaning yields the highest probability that perception will match expectation. And thatâ€™s your leading candidate.</p><p>And remember, psychology gives us the lens, design provides the tools, but the final verdict always belongs to the human being whose subjective perception can overturn any formula. Thatâ€™s why theory is only valuable as long as it remains flexible, ready to yield to real observation, to the living unpredictable experience of the people we designÂ for.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0e557d122b81"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/lower-the-surprise-applying-the-free-energy-principle-to-ux-0e557d122b81"">Lower the surprise: Applying The free energy principle to UX</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/perplexity-and-notebooklm-dont-use-better-ai-they-use-better-intelligence-flow-architecture-ace59eeda531?source=rss----138adf9c44c---4,1765801565,Perplexity and NotebookLM donâ€™t use better AIâ€”they use better intelligence flow architecture,"Perplexity and NotebookLM donâ€™t use better AIâ€”they use better intelligence flow architecture

<h4><strong>What product designers can learn from how they design intelligence flows.</strong></h4><p>Everyone thinks Perplexity and NotebookLM succeed because they use â€œbetterÂ AI.â€</p><p>They donâ€™t. <strong>They use the same models as everyoneÂ else.</strong></p><p>I spent three months deconstructing bothâ€Šâ€”â€Šnot just as a user, but as an architect. I mapped where intelligence lives, traced where humans direct and where AI executes.</p><p><strong>Hereâ€™s what they actually did differently.</strong></p><p><strong>The answer isnâ€™t in the AI models. Itâ€™s in how they architect the flow of work between human andÂ AI.</strong></p><p>This is what I call <strong>Intelligence Flow Architecture</strong>â€Šâ€”â€Šthe design of HOW cognitive work flows between human and artificial intelligence. Not what the AI can do, but how the collaboration is structured. Where does intelligence live? Who does what work? How do they hand offÂ tasks?</p><p>This is a design discipline most product teams donâ€™t knowÂ exists.</p><figure><img alt=""The essence of Intelligence Flow Architecture: Same models, different flows, completely different results. Visualization created with Gemini AI."" src=""https://cdn-images-1.medium.com/max/1024/1*GQSkjlcqKfFq5LvOj0HyUA.png"" /><figcaption><em>The essence of Intelligence Flow Architecture: Same models, different flows, completely different results. Visualization created with GeminiÂ AI.</em></figcaption></figure><p><strong>What I mean by â€œarchitectureâ€:</strong> Iâ€™m not talking about software architecture (microservices, backend systems) or information architecture (navigation, content structure). Iâ€™m talking about <strong>architecting the â€œhowâ€</strong>â€Šâ€”â€Šthe flow of cognitive work between human and AI. Who does what? Where does intelligence live? How do they collaborate? This is the discipline of designing intelligent systems, not just intelligent features.</p><p>Let me show you exactly how Perplexity and NotebookLM do itâ€Šâ€”â€Šand what you can apply to your own products.</p><h3>The architecture difference</h3><p>Hereâ€™s what peopleÂ miss:</p><p>Both products run on the same foundationâ€Šâ€”â€Šlarge language models, vector embeddings, search APIs, retrieval-augmented generation.</p><p><strong>Same ingredients. Completely different results.</strong></p><p>Why? Because they architected different <strong>intelligence flows</strong>â€Šâ€”â€Šdifferent answers to these critical questions:</p><ul><li>WHERE does AI work autonomously?</li><li>WHERE does human provide direction?</li><li>HOW do they hand off work betweenÂ them?</li><li>WHAT intelligence lives in whichÂ layer?</li></ul><blockquote><strong><em>In his </em></strong><a href=""https://www.youtube.com/watch?v=LCEmiRjPEtQ""><strong><em>June 2025 keynote at Y Combinator</em></strong></a><strong><em>, Andrej Karpathyâ€Šâ€”â€Šformer director of AI at Tesla and OpenAI co-founderâ€Šâ€”â€Šdescribed this exact shift:</em></strong><em> </em>â€œLLMs arenâ€™t just tools anymore. Theyâ€™re becoming operating systems. The LLM is the CPU, the context window is the memory, and the real design work is architecting how this new computer orchestrates problem-solving.â€</blockquote><p>Thatâ€™s exactly what Perplexity and NotebookLM understood.</p><p><strong>Watch whatÂ happens:</strong></p><p>When you ask <a href=""https://www.perplexity.ai/"">Perplexity</a> a question, AI doesnâ€™t give you search results to click. It searches, synthesizes, answers, and cites sourcesâ€Šâ€”â€Šall autonomously.</p><p><strong>Flow:</strong> You direct â†’ AI discovers â†’ YouÂ evaluate</p><p>When you upload documents to <a href=""https://notebooklm.google.com/"">NotebookLM</a>, AI doesnâ€™t just â€œchat about your docs.â€ It analyzes, maps relationships, and generates insightsâ€Šâ€”â€Šwithout waiting for instructions.</p><p><strong>Flow:</strong> You curate sources â†’ AI orchestrates knowledge â†’ YouÂ explore</p><p>These are different architectures of collaboration.</p><p>Let me deconstruct bothâ€Šâ€”â€Šlayer byÂ layer.</p><h3>Perplexityâ€™s intelligence flow architecture: Real-time discovery</h3><p>What makes Perplexity feel different from Google isnâ€™t better search. Itâ€™s a different distribution of cognitive work.</p><h4><strong>THE DESIGN DECISIONS:</strong></h4><p>Someone architected this. SomeoneÂ decided:</p><ul><li>AI executes search autonomously (you donâ€™t click 10Â tabs)</li><li>AI synthesizes while streaming (you donâ€™t wait for batchÂ results)</li><li>AI handles citations in real-time (you donâ€™t copy-paste sources)</li><li>Human directs through conversation (you donâ€™t fill searchÂ forms)</li></ul><p><strong>Cognitive split: ~20% Human (direction + evaluation) / 80% AI (discovery + synthesis)</strong></p><p><strong>What this feels like to you as aÂ user:</strong></p><p>You ask a question. Seconds later, youâ€™re reading a synthesized answer with sourcesâ€Šâ€”â€Šwithout opening ten browser tabs. It feels like the system â€œjust knowsâ€ what you meant and found the answer forÂ you.</p><p>That feeling isnâ€™t magic. <strong>Itâ€™s architecture.</strong></p><p>The intelligence lives in the synthesis layer, orchestrating search and combining sources in real-time.</p><figure><img alt=""Perplexityâ€™s 5-layer architecture showing the 20% human / 80% AI cognitive split. Notice how AI handles the heavy autonomous work (Layers 2â€“3) while human provides direction and evaluation (Layers 1, 4â€“5)."" src=""https://cdn-images-1.medium.com/max/1024/1*3ixZ5MFq6BAS2S0kjHJqSw.png"" /><figcaption><em>Perplexityâ€™s 5-layer architecture showing the 20% human / 80% AI cognitive split. Notice how AI handles the heavy autonomous work (Layers 2â€“3) while human provides direction and evaluation (Layers 1, 4â€“5). </em>Visualization created with GeminiÂ AI.</figcaption></figure><h3>NotebookLMâ€™s intelligence flow architecture: Document orchestration</h3><p>NotebookLM made a completely different architectural choice.</p><p>Not web discovery. Document understanding.</p><h4><strong>THE DESIGN DECISIONS:</strong></h4><p>Someone architected this. SomeoneÂ decided:</p><ul><li>AI works only with YOUR documents (not the entireÂ web)</li><li>AI builds knowledge graph invisibly (you experience results, not structure)</li><li>AI generates multiple formats from same knowledge base</li><li>Human curates sources and exploration direction</li></ul><p><strong>Cognitive split: ~30% Human (curation + direction) / 70% AI (analysis + orchestration)</strong></p><p><strong>What this feels like to you as aÂ user:</strong></p><p>You upload research papers. Within seconds, the system â€œunderstandsâ€ themâ€Šâ€”â€Šnot just text search, but conceptual understanding. It finds connections you hadnâ€™t seen. It can explain your own documents back to you in different formats.</p><p>That feeling isnâ€™t magic. <strong>Itâ€™s architecture.</strong></p><p>The intelligence lives in the knowledge processing layer, building invisible structure that enables multiple interaction modes.</p><figure><img alt=""NotebookLMâ€™s 5-layer architecture showing the 30% human / 70% AI cognitive split. Note Layer 4â€™s gradientâ€Šâ€”â€Šitâ€™s collaborative, where human and AI work together in the interaction loop."" src=""https://cdn-images-1.medium.com/max/1024/1*n46VTbjYM-ykBfKFQdRAiw.png"" /><figcaption><em>NotebookLMâ€™s 5-layer architecture showing the 30% human / 70% AI cognitive split. Note Layer 4â€™s gradientâ€Šâ€”â€Šitâ€™s collaborative, where human and AI work together in the interaction loop. </em>Visualization created with GeminiÂ AI.</figcaption></figure><h4>The pattern they bothÂ reveal</h4><p>Both succeed because they architected intelligence flows with clear principles.</p><p>(If you look back at the hero infographic at the top, youâ€™ll see the contrast: Traditional AI = features bolted onto existing UIs. Intelligence Flow Architecture = intelligence embedded in the systemâ€™sÂ core.)</p><h4><strong>The four principles</strong></h4><h3>Principle 1: Design backward from autonomous execution</h3><p>Donâ€™t start with: <em>â€œWhat interface should weÂ show?â€</em></p><p>Start with: <em>â€œWhat will the system DO autonomously?â€</em></p><ul><li>Perplexity: Search + synthesize +Â cite</li><li>NotebookLM: Analyze + map + generateÂ formats</li></ul><p>Then design everything else to enable that autonomy.</p><p>This inverts traditional software design. Traditional products started with the interfaceâ€Šâ€”â€Šbuttons, menus, workflowsâ€Šâ€”â€Šthen built backend systems to support them. Intelligence-first architecture starts with autonomous execution and works backward.</p><blockquote><em>The shift is profound: from </em>â€œHow will users accomplish this task?â€ to â€œWhat can the system accomplish autonomously?â€ <em>As </em><a href=""https://www.youtube.com/watch?v=a_RjOhCkhvQ""><em>Satya Nadella</em></a><em> noted, weâ€™re moving business logic from the application tier to the intelligence tier. The execution layer defines your systemâ€™s valueâ€Šâ€”â€Ševerything else exists to enableÂ it.</em></blockquote><p>Without this inversion, you end up with â€œAI featuresâ€ bolted onto traditional interfaces. The intelligence feels like an add-on because it IS an add-on. True intelligence-first architecture means intelligence is embedded as fundamental structure, not added as features.</p><h3>Principle 2: Embed intelligence in specificÂ layers</h3><p>Donâ€™t bolt AI on as features.</p><p>Architect where intelligence lives:</p><ul><li>Perplexity: Intelligence in synthesis layer</li><li>NotebookLM: Intelligence in knowledge processing layer</li></ul><p>The intelligence isnâ€™t visible as â€œAI featureâ€â€Šâ€”â€Šitâ€™s structural.</p><p>The test for embedded intelligence: Can you remove the AI and still have a functional product? If yes, intelligence is bolted on. If no, itâ€™s embedded.</p><p>Perplexity without its synthesis intelligence doesnâ€™t existâ€Šâ€”â€Šitâ€™s not â€œGoogle with AI added,â€ itâ€™s a fundamentally different architecture where intelligence IS the product. NotebookLMâ€™s knowledge processing layer isnâ€™t a feature you can toggle off; itâ€™s the systemâ€™s foundation.</p><p>This architectural embedding happens in specific layers of your five-layer stack. Intelligence doesnâ€™t float everywhereâ€Šâ€”â€Šit concentrates where transformation occurs. In Perplexity, thatâ€™s Layer 2 (synthesis orchestration). In NotebookLM, itâ€™s Layer 2 (knowledge graph construction). Identify where YOUR systemâ€™s intelligence must live, then build everything to support thatÂ layer.</p><h3>Principle 3: Design clear human/AI boundaries</h3><p>Define precisely where AI works autonomously and where human provides direction:</p><ul><li>Perplexity: Human directs â†’ AI discovers â†’ Human evaluates</li><li>NotebookLM: Human curates â†’ AI orchestrates â†’ HumanÂ explores</li></ul><blockquote><strong><em>Think of this as creating control mapsâ€Šâ€”â€Šthe new journey maps for AI experiences.</em></strong><em> Instead of mapping what users do, you map who is in control (user, AI, or both) and when that control shifts. As </em><a href=""https://uxdesign.cc/from-journey-maps-to-control-maps-17aac58b9dd9""><em>Rob Chappell</em></a><em> notes, </em>â€œThe question is no longer â€˜What is the user trying to do?â€™ The more relevant question is: â€˜Who is in control at this moment, and how does thatÂ shift?â€™â€</blockquote><p>This is the evolution from traditional user journeys to human-AI collaboration flows.</p><p><strong>This pattern is becoming so clear that in June 2025, Karpathy dedicated his Y Combinator keynote to it.</strong> He calls it â€œpartial autonomyâ€â€Šâ€”â€Šsystems where AI generates and humans verify in a continuous loop.</p><p>The architectural insight: <strong>The fastest generation-verification loop wins. Not the most autonomous AI.</strong></p><p>Thatâ€™s why <a href=""https://cursor.com/"">Cursor</a> (coding), Perplexity (search), and NotebookLM (research) are succeedingâ€Šâ€”â€Šthey optimized the loop, not the autonomy.</p><h3>Principle 4: Optimize for cognitive distribution</h3><p>Not: â€œCan AI do thisÂ task?â€</p><p>But: â€œSHOULD AI do this, or SHOULDÂ human?â€</p><ul><li><strong>Human strengths:</strong> Goal definition, judgment, creative direction, evaluation</li><li><strong>AI strengths:</strong> Discovery, synthesis, pattern recognition, execution</li></ul><p>Both products make this mapping explicit in their architecture.</p><p>This requires mapping cognitive strengths systematically. From your Hybrid Cognition Map: Humans excel at goal definition, context understanding, judgment calls, ambiguity resolution, ethical decisions, creative direction, and stakeholder intuition. AI excels at information retrieval, pattern recognition, rapid iteration, consistency, tedious execution, multi-source synthesis, and 24/7 availability.</p><p>The magic happens at the intersectionâ€Šâ€”â€Šnot human OR AI, but human AND AI working in complementary strengths. Perplexity distributes: human defines information need (judgment), AI discovers and synthesizes (execution). NotebookLM distributes: human curates sources (context), AI processes and orchestrates (synthesis).</p><p>Poor cognitive distribution creates friction. If you ask humans to do what AI does better (tedious data processing), or ask AI to do what humans do better (strategic judgment), the collaboration fails. Design explicitly for strengths, not just capabilities.</p><figure><img alt=""The complete framework: Four principles that define how Perplexity and NotebookLM architect human-AI collaboration. Infographic created with Gemini AI."" src=""https://cdn-images-1.medium.com/max/1024/1*ce2n59g1mX33lzWrHmZWiQ.png"" /><figcaption><em>The complete framework: Four principles that define how Perplexity </em>and NotebookLM architect human-AI collaboration. Infographic created <em>with GeminiÂ AI.</em></figcaption></figure><p><strong>A few days ago, my daughter had an English exam.</strong> Sheâ€™d finished her practice exercises and wanted more. I took photos of the worksheet, showed them to an AI, and asked it to generate similar exercises. Seconds later: a new practice set, perfectly matched to herÂ level.</p><p>She finished it. Asked for another. I already had everything loadedâ€Šâ€”â€Šanother set appeared inÂ seconds.</p><p><strong>This wasnâ€™t impressive because the AI was smart.</strong> It was impressive because Iâ€™d designed the <strong>how</strong>: Photo â†’ Parse â†’ Generate â†’ Verify â†’ Iterate. A five-second intelligence flow that would have taken me 30 minutes manually.</p><p>Thatâ€™s Intelligence Flow Architecture in dailyÂ life.</p><p>Now letâ€™s make it actionable for yourÂ team.</p><h3>From analysis to application</h3><p>Youâ€™ve seen how Perplexity and NotebookLM architect intelligence flows.</p><p>Now letâ€™s make this actionable for yourÂ team.</p><p>The method works for any product workflowâ€Šâ€”â€Šfrom email to CRM to documentÂ editing.</p><p>Hereâ€™s the four-step process:</p><h3>How to apply intelligence flow architecture to yourÂ product</h3><h4><strong>STEP 1: Map your currentÂ workflow</strong></h4><p>Pick one core workflow. List every step users do manually.</p><h4><strong>STEP 2: Identify cognitive work</strong></h4><p>For each step,Â ask:</p><ul><li>Is this discovery work? (AI strength)</li><li>Is this synthesis? (AI strength)</li><li>Is this judgment? (Human strength)</li><li>Is this goal-setting? (Human strength)</li></ul><h4><strong>STEP 3: Design the intelligence flow</strong></h4><p>Redistribute work:</p><ul><li>What should AI do autonomously?</li><li>Where does humanÂ direct?</li><li>What are the handoffÂ points?</li></ul><h4><strong>STEP 4: Design backward from execution</strong></h4><ul><li>What will AI execute? (execution layer)</li><li>What intelligence enables that? (intelligence layer)</li><li>How do systems coordinate? (orchestration layer)</li><li>How does human express intention? (inputÂ layer)</li></ul><h4><strong>Example: Redesigning email with Intelligence Flow Architecture</strong></h4><p>Letâ€™s make this concrete. Hereâ€™s how Intelligence Flow Architecture transforms a common workflowâ€Šâ€”â€Šemail composition.</p><p>Traditional Gmail requires you to manually type, edit, format, and sendâ€Šâ€”â€Šroughly 5 minutes of writing every word. Intelligence Flow Architecture redesigns this as a 6-layer collaboration where AI handles autonomous execution while you provide direction and judgment.</p><p>The result: 30 seconds instead of 5 minutes. Directing instead ofÂ writing.</p><figure><img alt=""Email workflow transformation: Traditional Gmail requires 5 minutes of manual writing. Intelligence Flow Architecture reduces it to 30 seconds of AI-directed execution."" src=""https://cdn-images-1.medium.com/max/1024/1*eEIbDOOIZSTpnOPnVIddWQ.png"" /><figcaption><em>Email workflow transformation: Traditional Gmail requires 5 minutes of manual writing. Intelligence Flow Architecture reduces it to 30 seconds of AI-directed execution. </em>Visualization created with GeminiÂ AI.</figcaption></figure><h4><strong>The transformation:</strong></h4><ul><li><strong>Before:</strong> You spend time writing, formatting, editing</li><li><strong>After:</strong> You spend time on judgment and direction</li></ul><h4><strong>The architecture enablesÂ this:</strong></h4><ul><li>Intelligence Layer: Understands context, style, userâ€™s pastÂ patterns</li><li>Execution Layer: Drafts email autonomously</li><li>Input Layer: Natural language intention (â€œdecline politelyâ€)</li></ul><p>Thatâ€™s Intelligence Flow Architecture applied.</p><h3>Why not full autonomy? The TeslaÂ lesson</h3><p>Before we dive into what this means for product teams, letâ€™s address the obvious question: <strong>Why design for partial autonomy instead of full autonomous agents?</strong></p><p>In his June 2025 keynote, Karpathy shared a telling story from his five years building autonomous systems atÂ Tesla:</p><p>In 2013, he took a perfect self-driving ride in a Waymoâ€Šâ€”â€Šzero interventions, flawless. He thought: â€œSelf-driving is imminent.â€</p><p><strong>That was 12 years ago.</strong> Even now, <a href=""https://waymo.com/"">Waymo vehicles</a> that appear driverless still require significant human teleoperation and oversight.</p><blockquote><strong><em>His warning applies directly to product design:</em></strong><em> When AI generates massive outputsâ€Šâ€”â€Š10,000 lines of code, complete research reports, fully redesigned interfacesâ€Šâ€”â€Šyou havenâ€™t saved time if verification takes hours. </em>â€œWhen I see things like â€˜oh 2025 is the year of agents,â€™ I get very concerned. This is the <strong>decade</strong> ofÂ agents.â€</blockquote><blockquote><strong>â€œWe have to keep the AI on the leash,â€</strong> <em>Karpathy emphasized. Not because AI isnâ€™t capable, but because </em><strong><em>verification speed determines actual productivity.</em></strong></blockquote><p>This is why Intelligence Flow Architecture prioritizes the generation-verification loop over full autonomy. The goal isnâ€™t to remove humans from the loop. <strong>The goal is to make the loop spin as fast as possible.</strong></p><figure><img alt=""Karpathyâ€™s lesson from 12 years at Tesla: Fast generation-verification loops beat pursuing full autonomy. Loop speed determines productivity, not autonomy level."" src=""https://cdn-images-1.medium.com/max/1024/1*2OemyGgIYm1AjKuiQUmbuQ.png"" /><figcaption><em>Karpathyâ€™s lesson from 12 years at Tesla: Fast generation-verification </em>loops beat pursuing full autonomy. Loop speed determines productivity, <em>not autonomy level. </em>Visualization created with GeminiÂ AI.</figcaption></figure><p><strong>A note for designers:</strong> You might be thinking â€œIâ€™m not a system architect. Can I actually apply this?â€ Yes. Intelligence Flow Architecture isnâ€™t about backend engineeringâ€Šâ€”â€Šitâ€™s about design thinking applied to human-AI collaboration. Start small: Pick one workflow. Map where human directs vs where AI executes. Thatâ€™s architecting intelligence flows. Youâ€™re already doing this thinkingâ€Šâ€”â€Šnow you have language forÂ it.</p><h3>What this means for productÂ teams</h3><p>Hereâ€™s what changes when you adopt Intelligence Flow Architecture:</p><h4><strong>BEFORE (AI Features):</strong></h4><ul><li>PM says: â€œLetâ€™s add AI to this workflowâ€</li><li>Designer asks: â€œWhat should the AI button lookÂ like?â€</li><li>Engineer builds: API call to GPT â†’ showÂ response</li><li>Result: Feature that feels boltedÂ on</li></ul><h4><strong>AFTER (Intelligence Flow Architecture):</strong></h4><ul><li>PM asks: â€œWhat cognitive work should AI handle autonomously?â€</li><li>Designer maps: Human direction â†’ AI execution â†’ Human evaluation</li><li>Engineer architects: Intelligence layer + orchestration layer + execution layer</li><li>Result: System that feels intelligent</li></ul><h3><strong>The pattern</strong></h3><p>Perplexity and NotebookLM didnâ€™t ask â€œHow do we addÂ AI?â€</p><p>They asked: â€œHow do we architect collaboration between human and artificial intelligence?â€</p><p>Thatâ€™s the difference between an AI feature and an intelligent system.</p><p>Thatâ€™s Intelligence Flow Architecture.</p><p>And that frameworkâ€Šâ€”â€Šdeciding where intelligence lives, how work distributes, when systems execute autonomouslyâ€Šâ€”â€Š<strong>thatâ€™s intelligence-first architecture.</strong></p><p><strong>Same AI models.</strong><br /><strong>Different architecture.</strong><br /><strong>Completely different experience.</strong></p><p>Now you knowÂ why.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ace59eeda531"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/perplexity-and-notebooklm-dont-use-better-ai-they-use-better-intelligence-flow-architecture-ace59eeda531"">Perplexity and NotebookLM donâ€™t use better AIâ€”they use better intelligence flow architecture</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/so-your-ai-wants-a-personality-9cbb47e07dd7?source=rss----138adf9c44c---4,1765801516,So your AI wants a personality,"So your AI wants a personality

<h4>Emerging personality patterns that drive differentiation in AIÂ products</h4><figure><img alt=""Cover image depicting different AI products like Slack bot, Claude, Tolans and Moxie robot."" src=""https://cdn-images-1.medium.com/max/1024/1*r5Fda8lcau0bg7QYOs1FHw.jpeg"" /></figure><p>In 1966, MITâ€™s Joseph Weizenbaum created ELIZA, a conversational AI that mimicked a Rogerian therapist using simple pattern matching. Despite its limited design, many users felt understood and emotionally â€œseen,â€ attributing empathy and intent to the system, a phenomenon later called the <a href=""https://en.wikipedia.org/wiki/ELIZA_effect""><strong>â€œELIZA effect</strong></a><strong>â€. </strong>From the very start, people related to even basic conversational software as if it had a mind of itsÂ own.</p><p>Long before modern AI, product and brand design had already embraced personality as a differentiator. <a href=""https://imgs.search.brave.com/bGxPgSeNEiF9Eug7c4YNn_bgulI2vwDeCDJqyq_KKtU/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9kMmlq/ejZvNXhheTF4cS5j/bG91ZGZyb250Lm5l/dC9hY2NvdW50XzQ4/MS9TY3JlZW5zaG90/MjAxOC0xMS0wOGF0/MTFfMDRfMThBTV81/NDI1N2M0MTI4M2Mx/NWI0YTMxNTRiNjMz/ZDRlY2IxNV84MDAu/cG5n"">Mailchimpâ€™s playful feedback</a> or <a href=""https://medium.com/swlh/slack-copywriting-what-they-say-to-9-6-million-pageviews-every-month-4351888f1c2c"">Slackâ€™s quirky copywriting</a> showed how tone and character could give otherwise functional software a distinctive emotional presence. Design theory reinforces this! <a href=""https://en.wikipedia.org/wiki/Emotional_Design""><strong>Normanâ€™s emotional design theory</strong></a> shows that products which evoke emotion foster attachment and loyalty<strong>,</strong> while <a href=""https://en.wikipedia.org/wiki/Anthropomorphism""><strong>anthropomorphism</strong></a><strong> </strong>explains our instinct to assign human traits to machines.<strong> </strong>Sherry Turkleâ€™s research at MIT shows that people form <a href=""https://sts-program.mit.edu/book/alone-together-expect-technology-less-eachother/""><strong>â€œartificial intimacyâ€</strong></a> with conversational agents assigning them emotions, motives, and moral qualities as if they were caring entities rather thanÂ tools.</p><p>In modern AI systems, this projection becomes even more consequential. Anthropic, for example, shapes <a href=""https://www.youtube.com/watch?v=iyJj9RxSsBY""><strong>Claude</strong> around a deliberate character</a>â€Šâ€”â€Šthoughtful, principled, and balancedâ€Šâ€”â€Šby embedding values and ethical reasoning into how the model thinks and responds.</p><p>Thus<strong>, designing for personality shifts from a branding layer to a core interaction layer </strong>that shapes trust, adoption, and long-term habits.</p><h3>Emerging personality patterns in AIÂ products</h3><p>This framework draws from my work on a virtual pet at <a href=""https://www.ideo.com/"">IDEO</a>, a companion robot at <a href=""https://miko.ai/"">Miko.ai</a>, and most recently an AI tutor at <a href=""https://www.getsupernova.ai/new-home"">SuperNova AIâ€Š</a>â€”â€Šsupported by research (reference list in the end) across HCI, HRI, and narrative designÂ .</p><p>Personality in AI systems is shaped much like a human character with underlying internal traits that drive behavior and external expressive cues that make those traitsÂ visible.</p><ul><li><strong>Internal layer</strong> refers to the traits and personality cues like values, worldview, personality archetype, backstory and contextual intelligence.</li><li><strong>External layer</strong> expresses these traits through the surface with avatar, typography, tone of voice, motion, and other multi-modal feedbackÂ cues.</li></ul><figure><img alt=""A diagram showing an AI personality model with Internal Layer components on the left and External Layer components on the right, all pointing to a central AI icon. Internal elements include Purpose/Worldview/Values, Personality Archetype, Backstory, and Contextual Adaptation. External elements include Visual Identity, Communication Style &amp; Copy, and Multi-Modal Feedback."" src=""https://cdn-images-1.medium.com/max/1024/1*0JMf5NrH1dafeI4lMdwX0w.jpeg"" /></figure><p>The interplay between these layers and their individual elements determines an <strong>AI productâ€™s position on the personality spectrum from minimal to expressive to fully characterful</strong>â€Šâ€”â€Šand ultimately shapes how people perceive and engage withÂ it.</p><h3>1. Purpose, worldview andÂ values</h3><h4><strong>Purpose</strong></h4><p>Purpose is the starting point and shapes the AIâ€™s <em>relationship</em> to the user based on what it helps them accomplish. <br /><br />An AI built to <em>teach</em> will naturally behave differently from one designed to <em>co-create an app or automate commands</em>. <strong>Defining purpose guidesÂ â€”</strong></p><ul><li><em>What is this AI supposed to accomplish forÂ users?</em></li><li><em>What should be the nature of AI-human relation? Is the interaction like interacting with a tool help, a pet/ companion or a collaborator/ supervisor/ assistant?</em></li></ul><p>After purpose, worldview and values form the underlying belief system that makes the AIâ€™s behavior consistent and predictable across different situations.</p><h4><strong>Worldview</strong></h4><p>Defines <em>how the AI interprets problems and reasons under uncertainty, </em>whether it approaches tasks with caution, optimism, curiosity, or analytical detachment. <strong>Defining worldview guidesÂ â€”</strong></p><ul><li><em>How should user needs/ problems be approached?</em></li><li><em>What matters most in its interactions?</em></li></ul><h4><strong>Values</strong></h4><p>Define the AIâ€™s ethical boundaries and prioritiesâ€Šâ€”â€Šthe principles it wonâ€™t break. They influence not only <em>what</em> the AI refuses, but <em>how</em> it refuses, shaping the emotional tone of guardrails. <strong>Defining values guidesÂ â€”</strong></p><ul><li>What are the rules it shouldnâ€™t break?</li><li>How should it protect or guide theÂ user?</li></ul><figure><img alt=""A split-screen image explaining Purpose, Worldview, and Values using Claudeâ€™s system prompt. On the left, three labeled termsâ€Šâ€”â€ŠPurpose (â€œwhy the AI existsâ€), Worldview (â€œhow it interprets the worldâ€), and Values (â€œthe rules it wonâ€™t breakâ€)â€Šâ€”â€Šare shown with arrows connecting them. On the right, a screenshot of Amanda Askellâ€™s tweet highlights parts of Claude 3â€™s system prompt in color-coded boxes labeled Purpose, Worldview, and Values."" src=""https://cdn-images-1.medium.com/max/1024/1*EO0MpbmaiHlyA7ekC7eTLw.jpeg"" /></figure><p><a href=""https://x.com/AmandaAskell/status/1765207842993434880"">Amanda Askell tweet about Claudeâ€™s system prompt</a>, reveals how purpose, worldview, and values are explicitly programmed into AI personalityâ€Šâ€”â€Šdirectly shaping how millions of users experience Claude assistant.</p><h3>2. Archetypes</h3><p><a href=""https://en.wikipedia.org/wiki/Archetype#:~:text=An%20archetype%20can%20be%20any,,%20or%20%22merge%22%20into.""><strong>Brand archetypes</strong></a> are universal character prototypes drawn from Carl Jungâ€™s psychology. Brands adopt these familiar personas to evoke specific emotions and embody coreÂ values.</p><p>Selecting an archetype helps determine whether your AI feels like a playful entertainer (Jester), a wise advisor (Sage), an empathetic supporter (Caregiver) or any of the other twelve classic archetypes.</p><figure><img alt=""A brand-archetype wheel showing twelve archetypes (Creator, Innocent, Sage, Explorer, Outlaw, Magician, Hero, Lover, Jester, Everyman, Caregiver, Ruler). Various AI products and robots are placed around the wheel to match their archetypes: Moxie and Wysa near Caregiver, Alexa and Siri near Everyman, Miko and Lovots near Lover/Jester, Replika and Character.ai near Lover, Claude near Sage, Anki Cozmo near Explorer, Cursor near Hero, Pepper and Gemini near Creator"" src=""https://cdn-images-1.medium.com/max/1024/1*YV4ajRGbz6FDVgyPmzmTPQ.jpeg"" /></figure><p>Choosing an<strong> archetype layer guides</strong>Â â€”</p><ul><li><strong>How the AI presents itself visually</strong>â€Šâ€”â€Šavatar style, colors, motionÂ design</li><li><strong>How the AI communicates</strong>â€Šâ€”â€Štone of voice, phrasing, pacing, and conversational behavior.</li></ul><p>For example</p><ul><li><strong>Claude (Sage) </strong>embodies a wise, thoughtful assistant focused on clarity and balanced reasoning. Its warm, calm visual identity and starburst icon signal structure and trust, while its communication style stays gentle, honest, and reflective.</li><li><strong>Wysa (Jester + Coach)</strong> a compassionate, judgment-free companion focused on emotional support and guided healing. Its cute penguin mascot and playful tone signal approachability and warmth, while its communication style stays empathetic, encouraging, and grounded in evidence-based cognitive behavioral therapy.</li></ul><p>Archetypes resonate at a subconscious level guiding the design to maintain character consistency and thus strengthening user experience and engagement.</p><h3>3. Backstory</h3><p>In consumer-facing AI, where emotional connection is key, backstory adds coherence and emotional weight to the interaction. <a href=""https://en.wikipedia.org/wiki/Hamlet_on_the_Holodeck"">Janet Murrayâ€™s Hamlet on the Holodeck</a> shows that when virtual characters have defined roles and histories, it enriches user interaction and making the system feel more alive and intentional.</p><figure><img alt=""An image of the Miko robot on the left and a chat transcript on the right, where Miko answers questions about its name, age, abilities, and identity with playful personality. A caption explains that Miko robots have rich backstories users uncover through conversation."" src=""https://cdn-images-1.medium.com/max/1024/1*MXwMEzP9HuRskUPhuce0Bw.jpeg"" /></figure><p>Some successful consumer products which follow this pattern stronglyÂ are</p><ul><li><a href=""http://www.miko.ai""><strong>Miko</strong></a><strong>:</strong> The companion robot invites children to ask, <em>â€œWhere did you come from?â€, â€œWhatâ€™s your job?â€, â€œAre you a boy or a girl?â€</em>â€Šâ€”â€Šrevealing his backstory and personality through playful dialogue.</li><li><a href=""https://www.tolans.com/""><strong>Tolan</strong></a><strong>:</strong> General-purpose assistants take on the persona of friendly aliens from planet Portolah, each arriving with distinct personalities and quirks to befriend their human companions</li><li><a href=""https://character.ai/""><strong>Character.ai</strong></a><strong>:</strong> A massive platform where users chat with millions of AI characters, each with detailed backstories, personalities and fictional histories toÂ explore.</li></ul><h3>4. Context adaptation</h3><p>Contextual adaptation is the AIâ€™s ability to respond appropriately to a userâ€™s <strong>situational context or emotional state</strong> and shaping tone, language, and pacing to feel human and supportive.</p><p>This relies on techniques like <a href=""https://en.wikipedia.org/wiki/Emotion_recognition""><strong>emotional state recognition</strong></a> (detecting sentiment or tone), <a href=""https://www.emergentmind.com/topics/ai-mirroring-behaviors""><strong>conversational mirroring</strong></a> (reflecting the userâ€™s phrasing or energy), and <strong>contextual personality shifting</strong> (adjusting tone or style based on task complexity or user mood)Â .</p><ul><li><a href=""https://en.wikipedia.org/wiki/Amazon_Alexa""><strong>Alexa</strong></a>, though simpler, varies its vocal delivery: sounding excited when offering good news (â€œItâ€™s sunny all day!â€) or disappointed when reporting a loss, reinforcing its role as a helpful household companion.</li><li><a href=""https://answeringagent.com/blog/5-ways-ai-adapts-tone-for-customer-calls""><strong>T-Mobileâ€™s AI</strong> reduced customer complaints by 73%</a> through instant detection of negative sentiment and tone mirroring</li><li><a href=""https://play.google.com/store/apps/details?id=ai.replika.app&amp;hl=en_IN&amp;pli=1""><strong>Replika</strong></a>, performs deep, long-term mirroring. It learns a userâ€™s vocabulary, emotional patterns, and interaction style over many conversations, gradually shaping its own language, tone, and even â€œpersonalityâ€ to reflect the individual.</li></ul><h3>5. VisualÂ identity</h3><p>Visual identity is often the first layer through which users infer an AI productâ€™s personality. Design decisions around logo, avatar, color, type and even hardware shapesÂ cues.</p><figure><img alt=""Image showing Perplexityâ€™s geometric logo, Claudeâ€™s serif typography, and the Lovot robot. A caption notes that Claudeâ€™s serifs feel warm and credible, Perplexityâ€™s sans-serif feels modern and analytical, and Lovotâ€™s soft design conveys a companion-like personality."" src=""https://cdn-images-1.medium.com/max/1024/1*sQ7i9Nt3p9T041kdfEAYoQ.jpeg"" /></figure><ul><li><strong>Logo/ Avatar/ Embodied identity </strong>give an AI a recognizable â€œfaceâ€ and act as an immediate proxy for personality. For instance, <a href=""https://www.perplexity.ai/"">Perplexity</a>â€™s logo, is minimal, geometric, and abstract and it subtly animates during search to cue users that AI is creating an answer. On the other end of the spectrum, more expressive AI products like <a href=""https://lovot.life/en/"">Lovot</a> uses a physical body, large eyes, soft materials, and even personalised clothing to project warmth, affection, and a companion-like presence.</li><li><strong>Typography</strong> contributes to brand voice in chat interfaces. For example, <strong>Claudeâ€™s serif typography conveys</strong> warmth, maturity, and approachabilityâ€Šâ€”â€Šqualities that align with its thoughtful, privacy-first positioning. <strong>Perplexityâ€™s geometric sans-serif communicates</strong> modern technical clarity and reliability, reinforcing its role as a precise, research-oriented tool.</li><li><strong>Illustrations/ Imagery:</strong> Supports communicating information in a delightful way</li><li><strong>Motion and Animation: </strong>Motion guidelines define how elements animate, transition, and respond to user interaction.</li><li><strong>Color palette</strong> reinforce AI personality archetypes by leveraging emotional associations rooted in color psychology. For example. blue signals trust and calm (Alexa), bright green colours signal playfulness and growth (Duolingo, Miko) and muted tones as professionalism (NotionÂ AI).</li></ul><h3>6. Communication style &amp;Â copy</h3><p>Communication style and copy are also the most visible expressions of an AIâ€™s personality. Whether experienced through <strong>voice or text,</strong> elements like <strong>tone</strong>, <strong>phrasing</strong>, <strong>pacing</strong>, <strong>formality </strong>work together to communicate characterâ€™s personality and guide user experience.</p><figure><img alt=""Screenshot of Duolingoâ€™s writing guidelines page showing the section on â€˜Voiceâ€™. It describes how Duolingoâ€™s brand personality appears through words, supported by four voice qualitiesâ€Šâ€”â€Šexpressive, playful, embracing and worldlyâ€Šâ€”â€Šwith a sidebar menu on the left and an illustration on top"" src=""https://cdn-images-1.medium.com/max/1024/1*ZOGg6drhwqpcvegAtbKosw.jpeg"" /></figure><h4>Core elements shared across voice and chat interfaces</h4><ul><li><strong>Tone</strong> sets the emotional posture: formal tones (e.g., <em>Sage</em>, <em>Ruler</em>) project authority and professionalism, while informal tones (e.g., <em>Everyman</em>, <em>Jester</em>) build warmth and approachability. For example, <a href=""https://www.capitalone.com/digital/tools/eno/"">Capital Oneâ€™s Eno</a> uses â€œFirst things firstâ€ is perceived as friendlier than â€œHere is the first stepâ€ in user research.</li><li><strong>Phrasing and vocabulary</strong> reflect personality cues. For instance, a Caregiver might say â€œ<em>â€œLet me walk you through thisÂ , weâ€™ll figure it out together,â€</em>,â€ while Sage personas might use precise, technical terms (e.g., â€œ<em>â€œLet me explain the details step byÂ step</em>â€).</li><li><strong>Pacing and prosody</strong> (in voice), or <strong>structure and grammar</strong> (in text), shape rhythm and emphasis which is key to emotional delivery and comprehension. Models from <a href=""https://elevenlabs.io/docs/models"">ElevanLabs V3</a> and <a href=""https://cartesia.ai/sonic"">Cartesia</a> uses intentional pauses and inflection to simulate human-like and expressive speech generation.</li></ul><h4>Modality differences: Voice vs.Â Chat</h4><p>Voice-first interfaces (e.g., Alexa, Miko) rely heavily on <strong>prosody, timing, and conversational repair</strong>. Spoken interactions are adaptiveâ€Šâ€”â€Šusers naturally adjust tone, pacing, or emphasis when thereâ€™s confusion.</p><p>In contrast, chat-based interfaces (e.g., Claude, Perplexity) emphasize <strong>structural clarity, grammar, and concise phrasing</strong>. Because written responses canâ€™t be corrected mid-delivery, users expect a higher degree of accuracy andÂ polish.</p><h3>7. Multimodal feedback</h3><p><strong>Multimodal feedback</strong> refers to the way an AI system expresses its internal states such as listening, thinking, processing, or responding sometime called <a href=""https://www.ibm.com/think/topics/chain-of-thoughts""><strong>Chain-of-thought (CoT)</strong></a><strong> display </strong>through various visual design elements and multiple sensory channels. These channels can include <strong>visual cues</strong>, <strong>voice and sound design</strong>, <strong>micro-animations</strong>, <strong>LED lights</strong>, orÂ <strong>haptics</strong>.</p><p><strong>It allows users to <em>see</em>, <em>hear</em> or <em>feel</em> what the AI is doing</strong>, making the interaction more interpretable, human-like and trustworthy.</p><figure><img alt=""Four examples of AI systems showing how they express internal state: Replit panels with micro-animations for thinking steps; Alexa device with LED ring phasesâ€Šâ€”â€Šidle, listening, thinking, speaking; Duolingo voice call using animated character face; Moxie robot using voice, eyes, and body movement"" src=""https://cdn-images-1.medium.com/max/1024/1*2C-JnFqBHXrmlqKoxgfg-g.jpeg"" /></figure><p>Multimodal feedback varies across products depending on how much personality is intended for theÂ product.</p><ul><li><a href=""https://replit.com/ai"">Replit AI</a>, <a href=""https://www.perplexity.ai/"">Perplexity</a>, <a href=""https://claude.ai/"">Claude</a><strong> </strong>relies on <strong>icon animations</strong> and <strong>microcopy</strong> to communicates systemÂ states.</li><li>Alexa devices like <a href=""https://www.amazon.com/dp/B09B8V1LZ3?ref=amzdv_ucc_dp_lod__B09B8V1LZ3&amp;th=1"">Echo dot</a> uses <strong>LED lights</strong>, <strong>voice tone</strong> and <strong>sound effects</strong> to express internal states. The glowing ring is soft and household-friendly, reinforcing her calm, helpfulÂ persona.</li><li><a href=""https://www.instagram.com/moxierobot/"">Moxie</a> robot<strong> </strong>combines <strong>voice and non verbal cuesâ€Š</strong>â€”â€Šscreen animations, sound effects and hand and body movements<strong> </strong>to communicate states in a child-friendly, playful way consistent with its worldview of empathy and curiosity.</li></ul><h4><strong>Interaction rhythm andÂ timing</strong></h4><p>Interaction rhythm and timing are critical to how AI systems communicate through multimodal cues. Research in humanâ€“robot interaction (Michalowski et al., 2007; Hoffman &amp; Breazeal, 2007; Breazeal, 2003) shows when robots align their timing with humansâ€Šâ€”â€Špausing at the right moments, matching conversational pacing, or synchronizing gesture and gazeâ€Šâ€”<strong>â€Šinteractions feel more alive</strong>, more engaging<strong>, more lifelike, and more trustworthy</strong>.</p><p>Products like <strong>Tolans</strong> use coordinated animations, eye-gaze, and motion timing to signal attention and emotional states, making the characters feel alive. Voice agents like <strong>Alexa</strong> similarly use rhythmic cuesâ€Šâ€”â€Šbrief pauses, LED pulses, and vocal pacingâ€Šâ€”â€Što create a sense of responsiveness. In both cases, achieving the right timing transforms abstract AI behaviour into something that feels intentional, expressive, and sociallyÂ fluent.</p><h3>When does personality matter?</h3><p>The fundamental question to ask before designing for personality, if your product needs one and howÂ complex?</p><p>Not every AI system needs a quirky mascot or empathetic voice. The role of personality depends on what problem the product is solving and what users expect fromÂ AI<em>.</em></p><figure><img alt=""This chart provides a relative comparison of each product based on how many personality patterns it uses and the depth of their implementation. A more detailed scoring breakdown will be released in a separate article"" src=""https://cdn-images-1.medium.com/max/1024/1*MVIKD6P88sCcG2q5gd0IIQ.jpeg"" /></figure><p><strong>In enterprise, B2B SaaS, </strong>or high-utility applications<strong>, personality is kept limited </strong>like professional tone, clear explanations and minimal flair as seen in tools like Ema, Salesforce Einstein or Intercom where u<a href=""http://www.ijdesign.org/index.php/IJDesign/article/view/861/366"">sers value accuracy, compliance, and integration</a>.</p><p><strong>In</strong> <strong>consumer AI</strong>,<strong> personality is often the differentiator</strong> driving engagement, trust, and habit-building where functionality is commoditized. Duolingoâ€™s cheeky Duo, Mikoâ€™s playful child companion, Alexaâ€™s polite household voice, Claudeâ€™s thoughtful collaborator persona, and Lovableâ€™s friendly co-creative tone all show how personality, delights, stickiness, and emotional connection become as important as utilityÂ itself.</p><h3>References</h3><ul><li><a href=""https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input""><strong>Collective Constitutional AI</strong></a><strong>: </strong>Aligning a Language Model with Public Input by Anthropic</li><li><a href=""https://www.anthropic.com/news/introducing-claude""><strong>Introducing Claude</strong></a> (March 2023) by Anthropic</li><li><a href=""https://mitpress.mit.edu/9780262533485/hamlet-on-the-holodeck/""><strong>Hamlet on the Holodeck</strong></a>: The future of narrative in cyberspace. MIT Press. Murray, J. H.Â (1997).</li><li><a href=""https://www.media.mit.edu/publications/social-interactions-in-hri-the-robot-view-2/""><strong>Social interactions in HRI: The robot view.</strong></a>Â <strong>. </strong><em>IEEE Transactions on Systems, Man, and Cyberneticsâ€Šâ€”â€ŠPart C: Applications and Reviews</em>, 33(4),Â 550â€“560.</li><li><a href=""https://search.worldcat.org/title/1104049258""><strong>Humanâ€“robot interaction: An introduction</strong></a>. Cambridge University Press. Bartneck, C., Belpaeme, T., Damholdt, M., Jensen, B., &amp; Å abanoviÄ‡, S.Â (2020).</li><li><a href=""https://linkinghub.elsevier.com/retrieve/pii/S1071581903000181""><strong>Emotion and sociable humanoid robotsâ€Š</strong></a>â€”â€ŠBreazeal, C. (2003)International Journal of Human-Computer Studies, <strong>59</strong>(1â€“2),Â 119â€“155.</li><li><a href=""https://search.worldcat.org/title/1104049258""><strong>Effects of anticipatory action on humanâ€“robot teamworkâ€Š</strong></a><strong>â€”â€Š</strong>Hoffman, G., &amp; Breazeal, C. (2007). Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI),Â 1â€“8.</li><li><a href=""https://ieeexplore.ieee.org/document/4415107/""><strong>Robots in rhythmic interaction: Improvisation in embodied humanâ€“robot interaction</strong></a><strong>â€Šâ€”â€Š</strong>Michalowski, M. P., SabanoviÄ‡, S., &amp; Simmons, R. (2007). Proceedings of the IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 2007,Â 330â€“335.</li><li><a href=""https://f.hubspotusercontent40.net/hubfs/637744/Digital%20Assistants/AnswerLab%20-%20Successful%20Digital%20Assistants.pdf""><strong>Elements of a Successful Digital Assistant</strong></a><strong>â€Š</strong>â€”â€ŠAnswerLab (2018)<strong> </strong><br />UX research study exploring tone, persona, and assistant clarity.</li><li><a href=""https://medium.com/ibm-watson/best-practices-designing-a-persona-for-your-assistant-c2a58666f3c""><strong>Best practices: designing a persona for your assistant</strong></a>â€Šâ€”â€ŠJamesÂ Walsh</li><li><a href=""https://uxdesign.cc/should-your-ai-sound-human-or-like-you-what-to-know-before-designing-a-voice-agent-d00252496307""><strong>Should your AI sound humanâ€Šâ€”â€Šor like you?</strong></a><strong>â€Š</strong>â€”â€ŠErin Xie (2023)<br />Published on UX Collective, explores prosody, tone, and brand identity in voiceÂ AI.</li><li><a href=""https://design.duolingo.com/writing/brand-narrative#principles""><strong>Duolingo Brand Narrative guidelines </strong></a>â€”Duolingo</li><li><a href=""https://www.ibm.com/think/topics/chain-of-thoughts""><strong>What is chain of thought (CoT) prompting?</strong></a>â€Šâ€”â€ŠIBM</li><li><a href=""https://academic.oup.com/hcr/article/48/3/404/6572120""><strong>My AI Friend: How Users of a Social Chatbot Understand Their Human</strong></a>â€“AI Friendship</li><li><a href=""https://www.emerald.com/ejm/article-abstract/59/4/879/1245301/Serif-or-sans-serif-typefaces-The-effects-of?redirectedFrom=fulltext""><strong>Serif or sans serif typefaces?</strong></a>â€Šâ€”â€ŠThe effects of typefaces on consumersâ€™ perceptions of activity and potency of brand logos. <em>European Journal of Marketing</em>, <em>59</em>(4), 879â€“922.â€Šâ€”â€ŠZhang, M., Teng, L., Xie, C., Wang, X., &amp; Foti, L.Â (2025).</li><li><a href=""https://www.researchgate.net/publication/253236337_The_Marketers'_Prismatic_Palette_A_Review_of_Color_Research_and_Future_Directions""><strong>The Marketersâ€™ Prismatic Palette</strong></a>: A Review of Color Research and Future Directions.â€ <em>Psychology &amp; Marketing</em>, <em>30</em>(2), 187â€“202.<strong>-</strong> Labrecque, L. I., Patrick, V. M., &amp; Milne, G. R.Â (2013).</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9cbb47e07dd7"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/so-your-ai-wants-a-personality-9cbb47e07dd7"">So your AI wants a personality</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/developers-arent-the-enemy-ddf76b1593dd?source=rss----138adf9c44c---4,1765801484,Developers arenâ€™t the enemy,"Developers arenâ€™t the enemy

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/developers-arent-the-enemy-ddf76b1593dd?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/0*DUCI0VIQW0YwqSVC"" width=""7184"" /></a></p><p class=""medium-feed-snippet"">Don&#x2019;t demonize those that can help you provide more accessible content.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/developers-arent-the-enemy-ddf76b1593dd?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/why-feature-roadmaps-dont-work-for-early-stage-startups-9360d392758b?source=rss----138adf9c44c---4,1765801371,Why feature roadmaps donâ€™t work for early-stage startups,"Why feature roadmaps donâ€™t work for early-stage startups

<h4><strong>The comfort and the cost of knowing whatâ€™sÂ next.</strong></h4><figure><img alt=""A product roadmap displayed on a reddish-brown background. The timeline is divided into four sections: â€˜Now,â€™ â€˜Month 01,â€™ â€˜Month 02,â€™ â€˜Month 03â€Šâ€”â€ŠEarly Access,â€™ and â€˜Month 04â€Šâ€”â€ŠSoft Launch.â€™ Under â€˜Now,â€™ the items are Auth User Management and Object Management. Month 01 includes Receipt Scanner, Onboarding, and Homepage. Month 02 includes Grocery List, Auto-categorisation, AI, and Analytics. Month 03 includes Sharing and Permissions, Notifications, Export feature, Budgeting, Tags, and Search. Mo"" src=""https://cdn-images-1.medium.com/max/1024/1*6VG6wG73XifozBos5j4EPA.png"" /><figcaption>An example of a feature-based roadmap</figcaption></figure><blockquote><strong><em>Imagine this scenario:<br /></em></strong>You are working with a passionate founder. They want to build a product which they are super sure of; they have their pitch deck ready, investors are lined up, and they want to hit market in six months. All they need is a working product: an embodiment of their mission. As a product manager, you do the usual. In a short duration, you conjure up enough details to come up with a roadmap. A plan with all the required features to put the product in the hands of potential users. It is well-detailed, with release dates and launch timelines. You align the team and start development. <strong>What could goÂ wrong?</strong></blockquote><p>Working constantly with early-stage startups has taught me one thing: startups are a minefield of uncertainty. If a founder believes they have all their answers on <strong>day one, </strong>they pretty much have a dream to sell you. It might just say that on the pitchÂ deck.</p><p>In my experience, anything a startup builds in its early stages is a whole lot of assumptions wrapped around a concrete vision. When you start treating these assumptions as ground reality and planning features rather than outcomes, you create a recipe for trouble. A well-documented, timeline-based feature roadmap is often where the problemÂ starts.</p><p>These plans actually give founder and teams a false sense of security. However, teams very quickly realiseÂ that:</p><p><strong>Feature roadmaps limit exploration and discovery. </strong>If the boundaries of exploration are limited to a predefined feature set, you quickly find yourself boxed in. Instead of giving the team ample time to actually solve problems, you end up preparing for the next release cycle as the team focuses on building the current feature on theÂ list.</p><p><strong>Feature roadmaps leave little room for new information.</strong> These plans operate under the conviction that all underlying assumptions have been fully priced in, locking potential ideas, features, and deadlines inÂ advance.</p><p>However, as you start working on the product, the <strong><em>act of building</em></strong> itself brings significant clarity. New information either challenges or validates previously made assumptions. As a result, you are compelled to carve out a new shape for the productâ€Šâ€”â€Šone that reflects an evolved understanding, sometimes with a focus on revised outcomes.</p><p>This is where feature roadmaps fail to adapt. They are built for predictability, and any change often leads to delays or scope expansion. You then have to resist new ideas and information just to stay on track with previously set timelines.</p><p><strong>Feature roadmaps have a confidence bias. </strong>They inherently believe that the solution, from the outset, is already fit for the market in its current shape. What is supposed to be a strategic and continuous discovery turns into a scheduling exercise. In reality, just because you are solving the right problem doesnâ€™t mean the current shape of the product will perform well in theÂ market.</p><p><strong>Feature roadmaps underestimate the invisible work.</strong> Development teams often require a fair amount of time and effort to figure out the <em>right</em> way to build before dipping their hands into execution. This is difficult to plan for, as the paths of discovery are not always linear. Sometimes you have to spend more time delivering the same planned item. The timeline is affected not by new demands, but by a well-defined scope.</p><blockquote><em>A PM I know used to say â€˜</em><strong><em>Roadmaps are the glue that makes strategy stick to planningâ€™. </em></strong><em>Lately, I feel the longer they are planned for, the </em><strong><em>harder</em></strong><em> they set in, making things very difficult and </em><strong><em>costly</em></strong><em> to pullÂ away.</em></blockquote><p>Donâ€™t get me wrong. I am not saying they are a bad exercise. Early-stage startups <strong>need</strong> to have a vision and a pathway to get there, and roadmaps serve that purpose effectively. What I do take issue with is the way of thinking that propagates building â€˜all the things we thought were correct <strong>then</strong>â€™ at the cost of â€˜what we know <strong>nowâ€™,</strong> treating previous ideas as gospel truth. A product being built just for the sake of it. Itâ€™s a lose-lose situation for everyone.</p><p>So, whatâ€™s the alternative?</p><ol><li><strong>Building roadmaps around outcomes, not features. </strong>This gives your team the agility to adapt to one of the umpteen pathways that could be used to arrive at the desired outcome. Outcome-focused roadmaps also ensure that the team focuses on solving the problem at hand and not just checking stories off a to-doÂ list.</li><li><strong>Make clarity your top priority. </strong>Be it through initial research, alpha releases, or targeted experiments, your first three months should focus on validating your assumptions. These will help you plan a more robust roadmap, rather than building a product on ideas made ofÂ sand.</li><li><strong>Use the 666 method. </strong>A way of mapping horizons based on what your startup needs to focus on over the next <strong>6 years, 6 months, and 6Â weeks</strong>.</li></ol><ul><li><strong>Next 6 years. </strong>This is your north star, the teamâ€™s vision of the future six years from now. This will change and evolve as your team learns how your product is built, adopted, and integrated into your usersâ€™ lives. Please do not create a fixed plan for sixÂ years.</li><li><strong>Next 6 months. </strong>This is your pathway of putting the product in front of your users for the very first time. It is a culmination of all your current beliefs, learnings and insights. The team should assume that only 50â€“60% of this plan will actually get built. The rest will emerge based on what you discover along the way, creating a need to revisit and revise this plan every couple ofÂ months.</li><li><strong>Next 6 weeks. </strong>This is where a feature roadmap makes sense. Once your team is confident on what needs to be built next, create a small, focused plan. Once locked in, changes here should be minimal. Make sure you know what you want to learn from the outcome of these six weeks. <strong>This is the only horizon where going granular is appropriate.</strong></li></ul><p><em>Lastly, learn to </em><strong><em>balance</em></strong><em> and </em><strong><em>realign</em></strong><em>. Planning works best when delivery and discovery are mapped together, each informing and correcting theÂ other.</em></p><p>References:</p><ul><li>Yojji: Roadmap Startup Guide &amp; Examples: <a href=""https://yojji.io/blog/roadmap-startup-guide-examples"">https://yojji.io/blog/roadmap-startup-guide-examples</a></li><li>Clarify: The Art of Product Roadmapping for Early-Stage SaaS Founders: <a href=""https://www.clarify.ai/blog/the-art-of-product-roadmapping-for-early-stage-saas-founders"">https://www.clarify.ai/blog/the-art-of-product-roadmapping-for-early-stage-saas-founders</a></li><li>Product School: Nowâ€“Nextâ€“Later Roadmap Framework: <a href=""https://productschool.com/blog/product-strategy/now-next-later-roadmap"">https://productschool.com/blog/product-strategy/now-next-later-roadmap</a></li><li>Product plan: Product roadmaps for startups vs enterprises: <a href=""https://www.productplan.com/learn/product-roadmaps-startups-versus-enterprises/"">https://www.productplan.com/learn/product-roadmaps-startups-versus-enterprises/</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9360d392758b"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/why-feature-roadmaps-dont-work-for-early-stage-startups-9360d392758b"">Why feature roadmaps donâ€™t work for early-stage startups</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
gnews,news.google.com,https://news.google.com/rss/articles/CBMid0FVX3lxTE84WklhdnlBcTZkRy1PSjNSd0tDQUEwSDRlNVEwWGdNZGFBQ1BuVEVKbFVlX1FPZkROY2cxN0NjdS0yQkx0SVZqU0JQQU5CSTluVnpnVG5uQm1nb2dMNEVCQzh4VGt5d2pzTjdBdWQzRVJUNnhQMG9R?oc=5,1762243200,Future of Graphic Design: Trends & Predictions - Business.com,Future of Graphic Design: Trends & Predictions - Business.com,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMidEFVX3lxTFBGVVJ2cDZhaVlBVkhTeGRDSEVBaG00UTNZR0lNdjRUZHpiMDRWOElLa3dNek9mNW1KWDBCQ1l6Slo0VzlQMGpjT3Q2Q212R1UwSUNNbWtvTVR3SkEyZzJYQ1FTWmdHaTJyZWRkOGJrbTBoVk54?oc=5,1765905976,Which Visual Trend Needs to Die in 2026? - Little Black Book | LBBOnline,Which Visual Trend Needs to Die in 2026? - Little Black Book | LBBOnline,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMihwFBVV95cUxQRS15aDM5dnZfZjRFR3lBVGw4RWZ4UTBBMWl0ZDlTQTdlWmxiSmszVVU0aGNVMnRfdnY0N1RsNmJUWktXNVEyWmcwME1yVS14N2gyVkhKWVlNVkJVNXdYdFE5bE43SndJR0NNUXdKN1V4YlZEUHpVN2dMX04zajNHOG9pUDlmaVE?oc=5,1765353600,"Graphic design - 20th Century, Typography, Visual Communication - Britannica","Graphic design - 20th Century, Typography, Visual Communication - Britannica",graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiaEFVX3lxTE5XY0RHaHRyT2hIMG4yYVI0Q05MSDBHUDdUM0I1ZXQxMnBsRXRlV21Zb3RIeFdNN2o0TGltUUpBenhxVWNza09OTUJHVloxZFhENEF4UHRDekgxTTZoeVdKR3lad1FvZEVw?oc=5,1765353600,Graphic Design Trends : What's Hot [2026] - Simplilearn.com,Graphic Design Trends : What's Hot [2026] - Simplilearn.com,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiiwFBVV95cUxQc0VDN19Xa2R5Y0g5SWMyTE56Y2pGeU12anNYTi1oQ0pMM2R4NzBFOGhCTmlvUGlMTWJ0bEdnbkd5QmNhdkpSX3JRRXBsUjB0WWJWMmxsZXpLbF9DNWhxWmFoWWdBNmZ3SVg2dU9PQmZlcEkxNXBiSnBQc0FhNUE3cExNOVhwQUFNOXM4?oc=5,1763107200,Playful Design Is Trending: Hereâ€™s How to Get the Look - HGTV,Playful Design Is Trending: Hereâ€™s How to Get the Look - HGTV,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMifkFVX3lxTE9iT0dnQ2o3alBOUDlvT180S2dYbng5REJHSGF4V3pISzJqVWJPVHYwUFh3RnNHYTZmald0T00tVk45OVRqS1o0bDZ0c0dFSXF1T3FLMUNlUWFJRWt6RnctcV83eFZhT2JlMGM2SW0yQllXVTU2eW9SY1RCcGJKZw?oc=5,1765981080,91% of Users Demand Better UX: What Your Brand Must Do in 2026 - DesignRush,91% of Users Demand Better UX: What Your Brand Must Do in 2026 - DesignRush,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiUkFVX3lxTE1MZDF0dGdEUFFSLUxZRjF4QVNzWlF2RTBUaXlCdHp0N04zQWc4VmlKaktyVmdsRUV6eVBMZTFFTnhYa0lDTmZZanc3ZVpNc1NxNVE?oc=5,1763539200,How Card UI Patterns Dominate Web Design - Designmodo,How Card UI Patterns Dominate Web Design - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiWEFVX3lxTE9WbUM4MjM5dVlyWnZ1M3ZuemUwMVE3ckk3UnNYZmc0WUdCcW9uSzBhMmxla0FkU25RSVJlTlJCWnd4X2ZHSkhlMWRHQUhwSEE0RmNUN05zWHM?oc=5,1763366400,Top 10 Frontend Trends in 2025 - Netguru,Top 10 Frontend Trends in 2025 - Netguru,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiT0FVX3lxTE1HV2ppY1oySC1FZEM0S1h3QXkzMlUxYS1KV2JrVTNnZ0RlcEw4QjQ5YThRZFkyc0hBdDhRU280a3k0b182bndjZXFvMUlVQkk?oc=5,1763539200,Tabbed Widgets in Web Design: UI Examples & Free Plugins - Designmodo,Tabbed Widgets in Web Design: UI Examples & Free Plugins - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMidEFVX3lxTE5GelVQVGR6MEVYLXpCS3I3WmdrZy0ycUVyNXNDX21udUMyVjBGZzQ5TEFFODk3SlFzbmdOMVY1YmRxaEt6c00zbDhraVB3NVhDX05NWnVsb0FFOEw4QjVWN3FQVlVwM296cTVWMlJXemNXTzBf?oc=5,1762329600,Stunning parallax scrolling web designs that make you never want to stop scrolling - Creative Bloq,Stunning parallax scrolling web designs that make you never want to stop scrolling - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiSkFVX3lxTFBTb21zbzJmbWdrMk5YUlQ4YWlmc19BS2dPNWtrdU5iYUZNRmNLcVNNQ2ExMngtN25rNlBya2QycVBoQkIyX0JkSjdn?oc=5,1763539200,"Free Fonts Youâ€™ll Want to Use Now, Trends and Examples - Designmodo","Free Fonts Youâ€™ll Want to Use Now, Trends and Examples - Designmodo",typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMirgFBVV95cUxOXy1kaUdpX2JmMDBIY3BWU2xScjhOYjJPMTBnVmlERVJ3QThIcWZXd2NOLWFSaXZoYUZsNFczbmF1U2dheDBBckdCM3g0aVBhMXhDbTVmNkNBTmdmR05UdkNYcHduaE9KbG5MS09NSVBFR3dHNVBZOTE4UFU1S1Z6WWwwcjI1eXBXLV92dENUNW82MEsxcXUzODMycndsaDRWNnhrQVlfUXNVa01LT1E?oc=5,1763452800,"Is it just me, or is this font suddenly everywhere? - Creative Bloq","Is it just me, or is this font suddenly everywhere? - Creative Bloq",typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMi0AFBVV95cUxPZDVEM3c1R2xQX2dXOF9YV3dudWktV0ZKMUEySXhhamh1aXlaRm1NcGxFNjhKcHp0S1VOV0xtam5WR1NyMjZFWnVrTGc0dFYtSWRKSDZ1eHlrU3BPN0M2bHVqT2YtMTlnSUNhZHNsYU1KLVlZZG5kQjVSZ2dwdVZTSVNWdTZvdF9QZjRoTGtrbWNEdFM4M1JIbDB0WTN1VUx0TURHOWlkSmxzc3JmVlc5QnJreG1tMEd6QVhiOWM3VzhRM1VIMlVoRF9OUnY1ek5Q?oc=5,1765532751,"Envato forecasts 2026 creative trends across graphic design, fonts, advertising, photography - DesignTAXI Community","Envato forecasts 2026 creative trends across graphic design, fonts, advertising, photography - DesignTAXI Community",typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQZVNLQV9CbHlZSlhrNGJSSHEyQ1NxdElMc0drek83MHg2aHN0SFVOcXVDN0h4QVJfbmRjUFZQWHdrVkxQSUE0TzlJV1d0RGxRRG5JYnVUNWtCbnNGQkViRDlqM2ZpeFQxc3ZHZTFwUFVWcm13amVCc3lnemg4eFhFVW5EVEdtMjFzYjNtanlDeHIxX2RCd3REZmU5YmZaNFV3emltcWlid0xacnlXR1JKYmV5TkZqd9IBuwFBVV95cUxNSE1MSEhfd3N6Ym11a2hHMXRRdXl1YXlBaWptdi1oY3dYVVJZaVh0RnMwN3dyb245ZUxrLS1xU3FNU2hqdlBfN2dMeVV0T2JMc0hYNllBcW5rYmJxX01MOEdkb1U3MG1KNWJEd1dpem5ERmRueVBoZmthY0l6VGlLanhIbXJ5X3lUSXBPN3hlbjZLdWptVjB3TWptX1NnOVgwdEtWcGlwNVJIR3BQNWFsc1kwNDZrUTBhSUIw?oc=5,1765603235,"Lil Baby Claims Originality In Viral Font Trend, Fans React With Mixed Emotions - Celebrity Insider","Lil Baby Claims Originality In Viral Font Trend, Fans React With Mixed Emotions - Celebrity Insider",typography trend
youtube,,https://www.youtube.com/watch?v=DqUD5WRp39g,1766065743,PS Tutorial HD | Agregar Sombra Debajo del Objeto | Photoshop Editing | CC + BP Drop #ps Netto Doch ,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=QwQO05suMqg,1766059200,How Graphic Designers Can Upskill for Better Opportunities | Connecting North,How Graphic Designers Can Upskill for Better Opportunities | Connecting North Upskilling is essential for graphic designers who ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=2hi37ypzA7k,1766045607,Your business. Our strategy. #shortsvideo,MarkslinkSolutionInc Your business. Our strategy. # We craft high-impact social media ads and stunning graphics that turn ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Qko7_Ei5njw,1766033058,Art is in the details! #branddesign #makhana #graphicdesign packaging #packagingdesign,Ecare Packaging Design â€“ Creative Branding That Sells! Your product deserves packaging that doesn't just look good â€” it sells ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=sV_FlX5d8Sg,1766001654,Clients Buy Confidence,Some of the best projects fall apart because they're presented terribly. Presentation skills are one of the most important things a ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=sTJspKIOHvc,1765977174,KREA AI: Explore the Future of Design in 2026!,Welcome to the Future of Design! 2026 mein design kaise badlega? Aapko milne wala hai ek jhalak KREA AI ke saath!,graphic design trends
youtube,,https://www.youtube.com/watch?v=9IHUvkWiR8Q,1765976303,Difference between beginner and pro graphic designer #adobeillustrator #graphicdesign,Difference between beginner and pro graphic designer #adobeillustrator #graphicdesign Adobe Illustrator 2025 Tips ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=0g_-mG0vN0w,1765972884,Design Trends  2026,"Get ready to jump three years into the future! In this comprehensive deep dive, we're uncovering the *Design Trends 2026* that ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=qjkF2Ceg5iQ,1765968266,Top 8 Graphic Design Trends for 2026 #logo #shorts #design #tutorial #designer #graphicdesign,Top 8 Graphic Design Trends for 2026 #Top 8 Graphic Design Trends for 2026 #logo #shorts #design #tutorial #designer ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=KchRWDX1e38,1765966305,Graphic Designer Portfolio 2026 || Motion Graphics Showreel || Rifat Hasan.,Welcome to my Graphic Design Portfolio 2026 This video showcases my latest Motion Graphics Showreel and professional ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=d0kgkRivBdo,1765954828,Canva Design Trends 2026 You Canâ€™t Ignore ğŸš€|These Canva Trends Will Go Viral #youtubeshortsindia,Canva Design Trends 2026 You Can't Ignore |These Canva Trends Will Go Viral These Canva design trends will dominate ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=CJDcQWO081Y,1765949231,washing pouch designs âœ¨âœ¨ğŸ¨ #branddesign #productdesign #graphicdesign #brandidentity #packagingdesign,Ecare Packaging Design â€“ Creative Branding That Sells! Your product deserves packaging that doesn't just look good â€” it sells ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Dj_gvcwzJVc,1765948544,WEDDING HASHTAGS: EPISODE 14,"TAGS: E-Invites, Digital Invitations, Custom E-Invites, Online Invitations, Graphic Design, E-Invite Design, Digital Invitation Design, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=p6uKxGg9Tts,1765946198,What Graphic Designers Need to Know About LOGO Design Trends in 2025,"Hello Friends, U all are welcome in VCE If you like this video please Like ,Comment and Share Thank you. my another channel ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=08vOer1itFY,1765933201,New Wave design trends episode three,"An educational and entertaining dive into the latest graphic design trends with actionable tips. Each segment showcases tools, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=3UWabkr6TPg,1765931402,Canva Must-Try Christmas Trends: Design Like a Pro! ğŸ‰ğŸ„ #Teamobaid #canva #canvaforbeginner,canva #Teamobaid #graphicdesigners âœ¨ Canva Christmas Trends Alert! Design like a pro this festive season! From magical ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=t4W8zuAw6ac,1765914220,PS Tutorial HD 2025 | Efecto Halftone Elegante | Photoshop Editing | CC + BP Drop #ps Netto Doch YT,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=6yWyZCLlrC0,1765895423,11 Graphic Design Trends 2026,"Ready to discover the biggest Graphic Design Trends of 2026? In this video, I'll walk you through the styles, techniques, and ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=VVL6FSj9a_0,1765888422,Indian Maximalism Design Trend ğŸ”¥| Pinterest Moodboard | #pinterest #maximalism,"Indian Maximalism through a Pinterest lens, where vibrant patterns, rich textures, and fearless visuals come together. This short is ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=Oy8dPSflmJo,1765888200,Why is Design is Going Backwards?? | Graphic Design Trends ,"In this video, we look at why modern design trends are shifting and what this change says about the future of branding and visual ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=NkKZqvXV5rg,1765887066,How to make a beautiful  birthday tec card //Very  easy card  making,Suraiya crafts HD. Graphic design trends 2024 . Interior design trends . Border Designs / Border design for project / Project work ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=1-5NdTrkHZw,1765868403,Ğ¢Ñ€ĞµĞ½Ğ´Ñ‹ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° 2026 Ğ² Canva,"Ğ’ ÑÑ‚Ğ¾Ğ¼ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¼Ñ‹ Ñ€Ğ°Ğ·Ğ±ĞµÑ€Ñ‘Ğ¼ ÑĞ°Ğ¼Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ñ‹Ğµ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½-Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ 2026 Ğ³Ğ¾Ğ´Ğ° Ğ¿Ğ¾ Ğ²ĞµÑ€ÑĞ¸Ğ¸ Canva. Ğ“Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ, Ñ‡Ñ‚Ğ¾ Ğ¸Ñ… Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=0rl4ixbsJ3U,1765852253,Graphic design trends 2026: The future of design,"The rules of graphic design are shifting fast, and 2026 is rewriting the playbook. From AI-powered workflows to chaotic packaging, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=oIx1ffIlTCs,1765847375,Bold Minimalism Graphic Design Trend 2024 #shorts,"Graphic design in 2024? Bold minimalism. Big, bold fonts with minimal distractions. A clean, impactful look that cuts through the ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=_yNrZAFcjXs,1765846848,Quantized Color and Sonic Surfaces The New Multisensory Branding Playbook,"A practical dive into emerging design trends blending quantified color, responsive textures, and sonic visualizations.",graphic design trends
youtube,,https://www.youtube.com/watch?v=YcDLL9Te5sE,1766057847,LEC 18 M2R5 Web Designing&amp; Publishing ||CSS||#practical #webdesign #html #olevel #ngi #olevelexam,AGNI BATCH [ O LEVEL- NEW BATCH] AGNI BATCH à¤®à¥‡à¤‚ à¤œà¥à¤¡à¤¼à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤²à¤¿à¤‚à¤• à¤ªà¤° ...,web design trends
youtube,,https://www.youtube.com/watch?v=Lrkje3Sot7I,1766046630,Website trends for 2026,"Website trends for 2026 aren't about hype. They're about clarity, speed, and conversion. We broke down what will actually matter ...",web design trends
youtube,,https://www.youtube.com/watch?v=LzPwp-ZE_Pc,1766044170,How can I find the best web designing company in Khardah--- Xwebdigital,How can I find the best web designing company in Khardah--- Xwebdigital If you're wondering How can I find the best web ...,web design trends
youtube,,https://www.youtube.com/watch?v=cX5NpF1ThzA,1766042533,Where to find freelance web designers in Khardah for hire --- Xwebdigital,Where to find freelance web designers in Khardah for hire --- Xwebdigital Looking for answers to Where to find freelance web ...,web design trends
youtube,,https://www.youtube.com/watch?v=W9VuTqe7qWw,1765992622,LEC 16 M2R5 Web Designing&amp; Publishing ||CSS||#practical #webdesign #html #olevel #ngi #olevelexam,AGNI BATCH [ O LEVEL- NEW BATCH] AGNI BATCH à¤®à¥‡à¤‚ à¤œà¥à¤¡à¤¼à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤²à¤¿à¤‚à¤• à¤ªà¤° ...,web design trends
youtube,,https://www.youtube.com/watch?v=jAQZXZ2BGFQ,1765961818,LEC 17 M2R5 Web Designing&amp; Publishing ||CSS||#practical #webdesign #html #olevel #ngi #olevelexam,AGNI BATCH [ O LEVEL- NEW BATCH] AGNI BATCH à¤®à¥‡à¤‚ à¤œà¥à¤¡à¤¼à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤²à¤¿à¤‚à¤• à¤ªà¤° ...,web design trends
youtube,,https://www.youtube.com/watch?v=RgN7MOu6FM8,1765904668,LEC 15 M2R5 Web Designing&amp; Publishing ||CSS||#practical #webdesign #html #olevel #ngi #olevelexam,AGNI BATCH [ O LEVEL- NEW BATCH] AGNI BATCH à¤®à¥‡à¤‚ à¤œà¥à¤¡à¤¼à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤²à¤¿à¤‚à¤• à¤ªà¤° ...,web design trends
youtube,,https://www.youtube.com/watch?v=dsbCtrokyuM,1765896518,Tech News: New Global Web Development Trends for 2026,"The future of web development is being shaped by responsive design, Progressive Web Apps (PWAs), AI-backed developer tools, ...",web design trends
youtube,,https://www.youtube.com/watch?v=5OaVno37KE8,1765889797,Use Trends to Level Up Your UI/UX and Brand! (Quick Tips) #shorts,Discover how to leverage current trends to enhance clarity and strengthen your brand identity in UI/UX design. Stay relevant and ...,web design trends
youtube,,https://www.youtube.com/watch?v=5YCpsYEaE_o,1765887449,2025 Web Design Trends in the USA,"Minimal UI, micro-animations, bold typography, and dark mode are dominating US web design in 2025. Looking for a modern, ...",web design trends
youtube,,https://www.youtube.com/watch?v=0rl4ixbsJ3U,1765852253,Graphic design trends 2026: The future of design,"The rules of graphic design are shifting fast, and 2026 is rewriting the playbook. From AI-powered workflows to chaotic packaging, ...",web design trends
youtube,,https://www.youtube.com/watch?v=urcwQ3NZB4k,1765831881,Top Web Design Trends Shaping the future (UI/UX &amp; Futuristic Design),Web design is changing fast. These are the key web design trends immerging the future: â€“ Dark mode dominance â€“ Neon UI ...,web design trends
youtube,,https://www.youtube.com/watch?v=314reMsgFGs,1765824134,Tricks 41/100 : 3D glassmorphism card #3d #webdesign  #csstricks  #coding,"Create a stunning glassmorphism card with blur, transparency, and smooth hover animation using pure CSS. Perfect for modern ...",web design trends
youtube,,https://www.youtube.com/watch?v=fPDLEdOot4I,1765818163,LEC 14 M2R5 Web Designing&amp; Publishing ||CSS||#practical #webdesign #html #olevel #ngi #olevelexam,AGNI BATCH [ O LEVEL- NEW BATCH] AGNI BATCH à¤®à¥‡à¤‚ à¤œà¥à¤¡à¤¼à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤²à¤¿à¤‚à¤• à¤ªà¤° ...,web design trends
youtube,,https://www.youtube.com/watch?v=87ETV3Bh4mE,1765811701,Creative Hover Effects Inspiration ğŸš€ Modern UI Interaction Trends,Intro & Hook Discover a curated selection of advanced hover effects and cursor-based micro-interactions designed to elevate your ...,web design trends
youtube,,https://www.youtube.com/watch?v=cawd8L_89bQ,1765805281,Top 10 Web Design Trends You Shouldnâ€™t Ignore,10 Web Design Trends You Shouldn't Ignore in 2026 (Big shout out to Ruwaifi Studio Ltd for compiling this) You spend hours ...,web design trends
youtube,,https://www.youtube.com/watch?v=FmFDxCTHpdQ,1765796424,PHP Chatbots sind wichtig fÃ¼r Webdesign Trends 2026,,web design trends
youtube,,https://www.youtube.com/watch?v=b6ebxEWKynk,1765744368,The Future of Web Design,The Future of Web Design: Why Visual Trends Won't Save Your Website Most websites don't fail because they look outdated.,web design trends
youtube,,https://www.youtube.com/watch?v=nl2NErCVR4k,1765731681,Design Faster Than Trends Move! #shorts #fashionshorts #viral #trending #foryoupageÂ #fashionai,"Here's the brutal truth â€” trends don't wait anymore. By the time you sample, revise, and reshoot, the moment is already gone.",web design trends
youtube,,https://www.youtube.com/watch?v=5UwltqC-nlU,1765646404,Basics of Web Development,"Basics of web development HTML, CSS and Javascript are the fundamental building blocks every aspiring developer needs to ...",web design trends
youtube,,https://www.youtube.com/watch?v=kyxxUlXy8Wc,1765631983,Electric Scooter Website Design  ğŸ›´âš¡ Modern Clean Ultra-Fast UI #webdesign #uiinspiration #websiteui,Electric Scooter Website Design âš¡ Modern Clean Ultra-Fast UI âš¡ Electric scooter website design for brands that want modern ...,web design trends
youtube,,https://www.youtube.com/watch?v=TVwD_NufU5g,1765609227,ğŸš€ 8 STUNNING Elements Website Projects for 2025,Get inspired for 2025! We're showcasing 8 absolutely STUNNING website projects built with Elements that define the latest web ...,web design trends
youtube,,https://www.youtube.com/watch?v=NT0TNFv1u4A,1765587637,Beyond Trends Practical Frontiers in Graphic Design 2025,An informative look at emergent design trends with practical tips and real world examples. Fresh case studies and expert insights ...,web design trends
youtube,,https://www.youtube.com/watch?v=zpVbhBjurck,1765568045,Liquid Web Design 2026 Explained in 60 Seconds #shorts,"Liquid Web Design 2026 uses gradients, curves, and smooth motion to make websites feel fluid and modern. Full guide and ...",web design trends
youtube,,https://www.youtube.com/watch?v=Jn5euWvQ6D8,1765564375,Website Design Trends to Watch in 2026,"Will the use of bold shapes, movement, and immersive branding that we saw so much of in 2025 continue to dominate website ...",web design trends
youtube,,https://www.youtube.com/watch?v=b_4ijnqxFx0,1765810718,Graphic Design Trends 2026 ğŸ”¥ | Digital Rama,"2026 à°²à±‹ graphic design totally next level ğŸ”¥ AI tools + human creativity à°•à°²à°¿à°¸à°¿à°¨à°ªà±à°ªà±à°¡à±‡ real magic âœ¨ Layouts flexible, ...",typography trends
youtube,,https://www.youtube.com/watch?v=BGl_WRTcUbk,1765638019,Typography trends: interactive fonts transforming user experience #shorts #fonts #15SecondsGraphics,Typography trends: interactive fonts transforming user experience #shorts #fonts #15SecondsGraphics #illustrator #tutorial.,typography trends
youtube,,https://www.youtube.com/watch?v=NFrUwC8HO6E,1765328436,Wavefront Design Trends 2025: Micro Typo to Ambient Data,A fast-paced exploration of new design trends and practical tips. Learn from experts through real-world examples.,typography trends
youtube,,https://www.youtube.com/watch?v=YKeSh8gWYrM,1765200640,Top 3 Fonts Every Designer Must Use in 2026,"2026 me kaunse fonts trend honge? Ye 3 fonts â€” GT America, Montserrat & Playfair Display â€” branding, UI/UX, posters, reels, ...",typography trends
youtube,,https://www.youtube.com/watch?v=tdbxUBHo9Eo,1765069281,Textures to Interfaces: Unpacking Sensory-Driven Design Trends,A visually engaging exploration of emerging graphic design trends with practical tips and real-world examples. Perfect for both ...,typography trends
youtube,,https://www.youtube.com/watch?v=-kjDm334b4s,1765025186,Best Trends Webdesign 2026: Kinetic Typography &amp; 3D Design,Explore the future of website development with SaaSNext. We break down the two biggest game-changers for your site: Kinetic ...,typography trends
youtube,,https://www.youtube.com/watch?v=GLpm8NXSrRY,1764667640,The Most Hated Fonts Ranked!,"In this video we analyze and rank the most iconic classic fonts, compare how they're used in modern design, explore typography ...",typography trends
youtube,,https://www.youtube.com/watch?v=qOFU7HZjs_c,1764516829,Les tendances design graphique de 2026,"Les tendances design graphique pour 2026. Et mÃªme si certaines ne vont pas plaire Ã  tout le monde, je pense qu'il faut en parler ...",typography trends
youtube,,https://www.youtube.com/watch?v=CggyZ1BvnPc,1764368198,How Are Typographic Trends Influenced By Variable Fonts?,Dive into the fascinating world of typography as we explore how variable fonts are revolutionizing design. This video uncovers the ...,typography trends
youtube,,https://www.youtube.com/watch?v=hhRHiUlDJDo,1764330234,What Characteristics Define Contemporary Typeface Trends?,Explore the exciting world of modern typography and uncover the defining characteristics that shape today's typeface trends.,typography trends
youtube,,https://www.youtube.com/watch?v=rt3jGfQHN0E,1764307955,Graphic Design Trends 2025 | Modern Design Ideas for Creators,Explore the latest graphic design trends of 2025! From bold typography to futuristic layouts upgrade your brand visuals now.,typography trends
youtube,,https://www.youtube.com/watch?v=MhHFkUF6s8w,1764167634,Typeone Issue 10: 25 Years of Type Design That Shaped the 21st Century,"Explore the tenth issue of Typeone Magazine, a fascinating look at the evolution of type design from 2000 to today. In this video ...",typography trends
youtube,,https://www.youtube.com/watch?v=IplolvGJRsc,1764161050,Typeone #10: Exploring 21st Century Typography &amp; Design Trends,"Dive into Typeone's tenth issue, highlighting the most important type design of the 21st century so far. From interviews with ...",typography trends
youtube,,https://www.youtube.com/watch?v=YUf9K8xbwtQ,1764159521,Type Design Evolution: 21st Century&#39;s Top Typefaces and Trends,"Explore the fascinating world of type design in the 21st century! In this video, we delve into the pages of Typeone's tenth issue, ...",typography trends
youtube,,https://www.youtube.com/watch?v=KEFMftFGCsw,1764079724,21st Century Type Design Trends: Typeone Magazine Issue 10 Review,"Type design, typography, 21st century design trends, graphic design, Typeone magazine. Dive into the evolution of type design ...",typography trends
youtube,,https://www.youtube.com/watch?v=TBVL9RrzFXE,1764032441,Accessible Futures Designing with Empathy in Generative Graphic Trends,Explore how AI can enhance accessibility in graphic design with practical tips and real-world case studies. This episode provides ...,typography trends
youtube,,https://www.youtube.com/watch?v=t9VMmA27QFo,1764010412,How Did Printing Technology Influence Typography?,Ever wondered how the letters we read every day came to look the way they do? This video delves into the fascinating history of ...,typography trends
youtube,,https://www.youtube.com/watch?v=LGN0TDQ3B_k,1763992405,Can You Identify Emo Typography Styles?,Think you know your screamo from your scene kid fonts? This video challenges your eye for design and takes you deep into the ...,typography trends
youtube,,https://www.youtube.com/watch?v=FIz5NLrEg6Q,1763571095,This Typography Trend Will Be Everywhere In 2026,Use These Type Collage Templates: https://kit.tl/typecollagetemplates ğŸ‘‰ Check The 2026 Trends Report: ...,typography trends
youtube,,https://www.youtube.com/watch?v=kh3NE4r0MlI,1763514066,Evolving Type and Tiny Motions: A Fresh Take on Design Trends,"This short explores a new episode focusing on generative typography, micro animations, and practical design system tips.",typography trends
youtube,,https://www.youtube.com/watch?v=ffHaBYQWQX4,1763313487,Top 5 Typography Trends You Can&#39;t Ignore in 2025,"A vibrant, glossy blue 3D capital letter B stands out. Its reflective surface contrasts with a dreamy background of soft yellow and ...",typography trends
youtube,,https://www.youtube.com/watch?v=yJ6tmf-c-xY,1763111447,Classy Fonts!,Classy fonts I am currently loving ğŸ¤ What's your favorite font? Comment below! ğŸ‘‡ Looking for the best fonts for designers?,typography trends
youtube,,https://www.youtube.com/watch?v=k034y30YFug,1763065419,Handwriting Font Trends,"Handwriting fonts are EXPLODING in 2025 and here's why: authenticity. In a world of AI and automation, hand-lettered typography ...",typography trends
youtube,,https://www.youtube.com/watch?v=XoI8w5k2rQ4,1762954177,2025 à¤®à¥‡à¤‚ à¤šà¤² à¤°à¤¹à¥‡ Top Graphic Design Trends ğŸ”¥ | Designer à¤œà¤¼à¤°à¥‚à¤° à¤¦à¥‡à¤–à¥‡à¤‚! ğŸ¨ #GraphicDesign2025,"2025 à¤®à¥‡à¤‚ Graphic Design à¤•à¥€ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤ªà¥‚à¤°à¥€ à¤¤à¤°à¤¹ à¤¬à¤¦à¤² à¤°à¤¹à¥€ à¤¹à¥ˆ! âœ¨ à¤¨à¤ AI Tools, 3D Elements, Minimal Style ...",typography trends
youtube,,https://www.youtube.com/watch?v=NUfwSlAbGJQ,1762779651,Top 5 UI Design Trends You Can&#39;t Ignore in 2025,"Top 5 UI Design Trends You Can't Ignore in 2025 top 5 design trends you can't ignore in 2025, top 5 machine learning trends in ...",typography trends
