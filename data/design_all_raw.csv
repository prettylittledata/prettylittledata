source,domain,url,created_utc,title,text,query
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/building-empathy-centred-ux-framework-mental-health-apps/,1770994800,Building Digital Trust: An Empathy-Centred UX Framework For Mental Health Apps,"Building Digital Trust: An Empathy-Centred UX Framework For Mental Health Apps

Designing for mental health means designing for vulnerability. Empathy-Centred UX becomes not a “nice to have” but a fundamental design requirement. Here’s a practical framework for building trust-first mental health products.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/designing-agentic-ai-practical-ux-patterns/,1770814800,"Designing For Agentic AI: Practical UX Patterns For Control, Consent, And Accountability","Designing For Agentic AI: Practical UX Patterns For Control, Consent, And Accountability

Autonomy is an output of a technical system. Trustworthiness is an output of a design process. Here are concrete design patterns, operational frameworks, and organizational practices for building agentic systems that are not only powerful but also transparent, controllable, and trustworthy.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/css-scope-alternative-naming-conventions/,1770278400,CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions,"CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions

Prescriptive class name conventions are no longer enough to keep CSS maintainable in a world of increasingly complex interfaces. Can the new `@scope` rule finally give developers the confidence to write CSS that can keep up with modern front ends?",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/combobox-vs-multiselect-vs-listbox/,1770112800,Combobox vs. Multiselect vs. Listbox: How To Choose The Right One,"Combobox vs. Multiselect vs. Listbox: How To Choose The Right One

Combobox vs. Multi-Select vs. Listbox vs. Dual Listbox? How they are different, what purpose they serve, and how to choose the right one. Brought to you by <a href=""https://ai-design-patterns.com"">Design Patterns For AI Interfaces</a>, **friendly video courses on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/desktop-wallpaper-calendars-february-2026/,1769850000,"Short Month, Big Ideas (February 2026 Wallpapers Edition)","Short Month, Big Ideas (February 2026 Wallpapers Edition)

Let’s make the most of the shortest month of the year with a new collection of desktop wallpapers that are sure to bring a smile to your face — and maybe spark your creativity, too. All of them were designed with love by the community for the community and can be downloaded for free. Happy February!",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/practical-use-ai-coding-tools-responsible-developer/,1769778000,Practical Use Of AI Coding Tools For The Responsible Developer,"Practical Use Of AI Coding Tools For The Responsible Developer

AI coding tools like agents can be valuable allies in everyday development work. They help handle time-consuming grunt work, guide you through large legacy codebases, and offer low-risk ways to implement features in previously unfamiliar programming languages. Here are practical, easy-to-apply techniques to help you use these tools to improve your workflow.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/unstacking-css-stacking-contexts/,1769508000,Unstacking CSS Stacking Contexts,"Unstacking CSS Stacking Contexts

In CSS, we can create “stacking contexts” where elements are visually placed one on top of the next in a three-dimensional sense that creates the perception of depth. Stacking contexts are incredibly useful, but they’re also widely misunderstood and often mistakenly created, leading to a slew of layout issues that can be tricky to solve.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking “Pixel Perfect” Web Design,"Rethinking “Pixel Perfect” Web Design

Amit Sheen takes a hard look at the “Pixel Perfect” legacy concept, explaining why it’s failing us and redefining what “perfection” actually looks like in a multi-device, fluid world.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designer’s Career Paths In 2026,"UX And Product Designer’s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI that’s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,Pivoting Your Career Without Starting From Scratch,"Pivoting Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, “Is this still what I want to be doing?” This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors.",
rss,uxdesign.cc,https://uxdesign.cc/natural-design-industry-vibeshift-jony-ive-bringing-buttons-back-a0b364f2a787?source=rss----138adf9c44c---4,1771244171,"Natural design, industry vibeshift, Jony Ive, bringing buttons back","Natural design, industry vibeshift, Jony Ive, bringing buttons back

<h4>Weekly curated resources for designers — thinkers and makers.</h4><figure><a href=""https://uxdesign.cc/the-natural-design-process-a4af7605ab90""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*vSpM_SYMvh588BxE.png"" /></a></figure><p>“It might be a sign of changing times and of our industry, it might be a marketing push from the companies betting big on AI. I don’t know. But there seems to be a sort of urgency for something new. For speed. For freedom. For paving a new path. For simplicity. For flexibility. A push for something else rather than Design Thinking as the standard design process.”</p><p><a href=""https://uxdesign.cc/the-natural-design-process-a4af7605ab90""><strong>The natural design process</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/324fbdeed844"">Filip Mishevski</a></p><figure><a href=""https://bit.ly/uxc-lab6""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*QZVTkHaTh8dVMpIU.png"" /></a></figure><p><a href=""https://bit.ly/uxc-lab6""><strong>What 200+ designers revealed about AI in 2026</strong></a><strong> →<br /></strong>[Sponsored] Designlab surveyed 200+ UX and product designers to understand how AI is shaping real workflows — from research and ideation to prototyping and delivery. See which tools are gaining traction, the biggest challenges teams face, and what’s actually working in practice. See the full findings.</p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/when-ai-passes-the-capitalist-turing-test-18baacbcf18f""><strong>When AI passes the capitalist Turing test</strong></a><strong> →</strong><br />AI was meant to augment human intelligence.<br />By <a href=""https://medium.com/u/722c205fbeec"">Natalia Talmina, PhD</a></li><li><a href=""https://uxdesign.cc/innovation-is-not-magic-its-technique-9b3c81a41877""><strong>Innovation is not magic; it’s technique</strong></a><strong> →</strong><br />Will your product change the world?<br />By <a href=""https://medium.com/u/41385acbccae"">Kike Peña</a></li><li><a href=""https://uxdesign.cc/the-design-vibeshift-894001f64fa8?sk=f4e6ec75976433aa0e56d3c6c84c97ac""><strong>The design vibeshift</strong></a><strong> →</strong><br />Code is becoming our new canvas.<br />By <a href=""https://medium.com/u/7f968435c6b9"">Pablo Stanley</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about their work.</em></p><figure><a href=""https://glyphs.djr.com/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*mqtcITwgIYQRW7jD.png"" /></a></figure><p><a href=""https://glyphs.djr.com/?ref=sidebar""><strong>David Jonathan Ross’s glyph navigator</strong></a><strong> →</strong></p><h3>Make me think</h3><ul><li><a href=""https://blog.jim-nielsen.com/2026/saying-no/?ref=sidebar""><strong>Saying “no” In an age of abundance</strong></a><strong> →</strong><br />“But wait, we have AI now. We don’t have to say no to 1,000 things. We can say yes to all the things — generate them all, simultaneously!”</li><li><a href=""https://dri.es/the-software-sovereignty-scale?ref=sidebar""><strong>The software sovereignty scale</strong></a><strong> →</strong><br />“Digital sovereignty depends less on where software comes from and more on who controls it. This post introduces a scale showing which technologies can never be taken away.”</li><li><a href=""https://www.shaunbent.co.uk/blog/is-there-too-much-design-in-design-systems/?ref=sidebar""><strong>Is there too much design in design systems?</strong></a><strong> →</strong><br />“Which raises an uncomfortable question: if the industry is hiring three designers for every engineer, who’s actually implementing all this design work?”</li></ul><h3>Little gems this week</h3><figure><a href=""https://uxdesign.cc/ais-text-trap-moving-towards-a-more-interactive-future-7035bbc4aaa5""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*lstvhis8ExHal12m.png"" /></a></figure><p><a href=""https://uxdesign.cc/ais-text-trap-moving-towards-a-more-interactive-future-7035bbc4aaa5""><strong>AI’s text-trap: Moving towards a more interactive future</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/ab207339675c"">Ishan Korde</a></p><figure><a href=""https://uxdesign.cc/bringing-buttons-back-rethinking-how-smart-your-smartphone-should-be-a38eed128ea3?sk=920c7755cb30cad4e3e134cb7ffd51bc""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*4X-h2sN7j0YLcM9V.png"" /></a></figure><p><a href=""https://uxdesign.cc/bringing-buttons-back-rethinking-how-smart-your-smartphone-should-be-a38eed128ea3?sk=920c7755cb30cad4e3e134cb7ffd51bc""><strong>Bringing buttons back: rethinking how smart smartphones should be</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/8ab653ea27a6"">Daley Wilhelm</a></p><figure><a href=""https://medium.com/design-bootcamp/jony-ive-ferrari-and-love-of-design-a3bbcf829952?sk=e7de92a00fbdef856c3854774617bb82""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*aaJjjWR4ZALId8S-.png"" /></a></figure><p><a href=""https://medium.com/design-bootcamp/jony-ive-ferrari-and-love-of-design-a3bbcf829952?sk=e7de92a00fbdef856c3854774617bb82""><strong>Jony Ive, Ferrari, and love of design</strong></a> →<br />By <a href=""https://medium.com/u/4f50a991667f"">Kartscrut</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/useful-ads-7899e1711157""><strong>Designing useful ads</strong></a><strong> →</strong><br />AI utility + digital advertising.<br />By <a href=""https://medium.com/u/592a18ec83da"">Tanner Walsh</a></li><li><a href=""https://uxdesign.cc/what-design-leaders-must-unlearn-to-lead-in-an-ai-first-world-f131652f828d""><strong>What design leaders must unlearn</strong></a><strong> →</strong><br />The path to designing for AI.<br />By <a href=""https://medium.com/u/2bea45f96a95"">Arin Bhowmick</a></li><li><a href=""https://uxdesign.cc/emotional-design-lets-design-for-silence-f2e3181d246f?sk=e1bb9d8d06fc71db611fbdc213f3b657""><strong>Emotional design</strong></a><strong> →</strong><br />Let’s design for silence.<br />By <a href=""https://medium.com/u/161b4eee2ac1"">Maxim Kich</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, here’s how you can support us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-lab6"">this week’s sponsor</a> and support their work too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor an edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a0b364f2a787"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/natural-design-industry-vibeshift-jony-ive-bringing-buttons-back-a0b364f2a787"">Natural design, industry vibeshift, Jony Ive, bringing buttons back</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/your-research-tools-got-smarter-did-you-9fd4339617ca?source=rss----138adf9c44c---4,1771239838,Your research tools got smarter… Did you?,"Your research tools got smarter… Did you?

<h4><em>Data collection is being automated. The strategic layer is wide open. The question is which side of that line you’re standing on.</em></h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*fXl_j6DCAK3_9UMzH7b_1w.jpeg"" /><figcaption>Photo by <a href=""https://unsplash.com/@sickhews?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"">Wes Hicks</a> on <a href=""https://unsplash.com/photos/man-wearing-headphones-while-sitting-on-chair-in-front-of-macbook-4-EeTnaC1S4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"">Unsplash</a></figcaption></figure><p>The research industry is getting commodified.</p><p>A wave of AI-powered platforms can now conduct interviews, run surveys at scale, transcribe sessions, cluster themes, and deliver summary reports faster than any human team. Tools like Maze, Dovetail, Outset AI, and Listen Labs have compressed what used to take six to eight weeks into hours.</p><p>The global AI-based research services market is projected to grow from roughly $8 billion in 2025 to over $35 billion by 2035, according to <a href=""https://www.futuremarketinsights.com/reports/ai-based-research-services-market"">Future Market Insights</a>:</p><blockquote>“During the first five-year period from 2025 to 2030, the market increases from USD 7,972.1 million to USD 16,804.0 million… AI-accelerated survey analytics dominates this period with 38.3% share, as enterprises increasingly automate survey feedback and real-time opinion tracking.”</blockquote><p>The commodity layer of research is being automated, and it is happening fast.</p><p>This is good, and it's terrifying.</p><p>Good, because the structured, repeatable parts of research have been heading toward automation for a while. I was using UserTesting.com over high-volume concept testing, quick-turn usability studies, and pattern recognition across large datasets. Machines are better at speed and scale. A <a href=""https://www.displayr.com/ai-in-market-research-today-trends-tools-and-whats-next/"">Displayr study</a> found that 85% of researchers said automated tools have already improved their workflow:</p><blockquote>“What once took weeks of manual labor can now be achieved in days — or even hours — freeing researchers to focus on the strategic questions that really matter.”</blockquote><p>Terrifying, because the industry is confusing data collection with understanding… two fundamentally different things. And if you have built your career on the gathering side of that equation, you are now competing with software that works faster, cheaper, and around the clock.</p><h3>The gathering is not the knowing: Where AI tools fall short</h3><p>Hot take: the hardest part of research was never gathering the data.</p><p>The hard part is <em>making sense</em> of what you find in the context of a business that has politics, constraints, competing priorities, and customers who say one thing and do another.</p><p>AI platforms work from their own interview data. They can surface the top themes from 50 conversations and present them in a tidy dashboard… Great!</p><p>What they cannot do is synthesize those themes against your:</p><ul><li>Analytics</li><li>Competitive landscape</li><li>Organizational dynamics</li><li>And the thing your VP said in a hallway conversation last Tuesday that reframed the entire strategic direction (Yes, this happens all the time)</li></ul><p>That synthesis layer requires <strong>judgment</strong>. It requires presence. It requires years of accumulated pattern recognition that no language model can replicate, because it depends on <strong>understanding your organization</strong>, not just your users.</p><p>Svend Brinkmann warned about the <a href=""https://tidsskrift.dk/qual/article/view/6273"">“McDonaldization” of qualitative research</a> over a decade ago: the reduction of a craft-based discipline into standardized, repeatable processes optimized for efficiency.</p><p>AI has accelerated that trajectory. A <a href=""https://www.frontiersin.org/journals/research-metrics-and-analytics/articles/10.3389/frma.2024.1331589/full"">2025 study in Frontiers in Research Metrics and Analytics</a> found that AI’s emphasis on structured, data-driven processes risks reinforcing positivist assumptions in qualitative work, losing the relational, situated, and cultural richness that makes qualitative research worth doing in the first place:</p><blockquote>“Automated programmes with clear rules and formulae consistently followed each time do not work well under interpretivism’s assumptions. Researchers who use a general artificial intelligence agent only cover the rules-based epistemological spectrum of positivism.”</blockquote><p>Lincoln and Guba said it best in 1985: The instrument of choice in qualitative research is the human. Humans are responsive to environmental cues, able to collect information at multiple levels simultaneously, and capable of exploring the unexpected. A machine can present raw material and initial patterns.</p><p>The act of meaning-making remains a <em>uniquely</em> human endeavor.</p><h3>Where humans must excel</h3><p>If the data collection layer is being commoditized, the question for every researcher becomes: what is left? The answer is everything that matters. But “everything that matters” demands specificity. Here are the five domains where human researchers are irreplaceable, and where the best practitioners are already doubling down.</p><h4><strong>1. Strategic synthesis across multiple inputs</strong></h4><p>AI gives you themes. A skilled researcher gives you a decision. The real value of research has always been the “so what should we actually do?” layer: integrating user data with business context, market dynamics, and organizational realities to produce recommendations that drive action.</p><p>This means your research readout cannot end with “here is what users said.” It must end with “here is what we should build, stop building, or invest in next, and here is why.”</p><p>If your deliverables do not connect to revenue, retention, or competitive positioning, you are delivering a report. The AI can do that now.</p><h4><strong>2. The relationship and trust layer</strong></h4><p>When organizations invest in research, they are buying judgment. They need someone who can push back on stakeholder assumptions, read a room, change a presentation on the fly, and tell a leadership team something they do not want to hear in a way they can actually hear it. This skill compounds over time. The researcher who understands a client’s organizational politics, who has built credibility with a skeptical CPO, who knows which battles to pick and which to table for next quarter, that person is not a vendor. They are a strategic partner. No platform replicates that.</p><h4><strong>3. Cross-cultural and international depth</strong></h4><p>AI interviews work well in English and a handful of other languages. The nuance of cross-cultural research, including regulatory differences, market-by-market strategy, and the things people mean but do not say, requires researchers who have spent years embedded in those markets.</p><p>No language model has lived in São Paulo, navigated regulatory frameworks in Mumbai, or understood why a French consumer’s “<em>No</em>” means something different than an American’s. As companies expand globally, this skill becomes a multiplier, not a nice-to-have.</p><h4><strong>4. Complex qualitative methods</strong></h4><p>Diary studies. Ethnography. Longitudinal research. Contextual inquiry in physical environments. These are immersive methods that require presence, adaptation, and the kind of rapport that only happens between people. They cannot be compressed into a chatbot interface.</p><p>And they produce the kind of deep, contextual insight that drives transformative product decisions, the kind of insight that a theme cluster in a dashboard will never surface. Even the AI knows this. When <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC11103925/"">Hitch et al.</a> asked ChatGPT to perform qualitative analysis, the model responded:</p><blockquote>“As an AI language model, I cannot perform qualitative analysis on the data above as it requires a more nuanced understanding of context, and the ability to interpret and analyze human language in context.”</blockquote><p>When the tool itself tells you it cannot do the work, that is worth paying attention to.</p><h4><strong>5. AI decision advisory</strong></h4><p>This is the frontier most researchers are ignoring entirely, and the one with the most upside.</p><p>As organizations deploy AI agents, copilots, and automated workflows, someone needs to figure out where those systems should and should not operate.</p><blockquote>How do you design human-AI workflows? Where does automation create value, and where does it destroy trust? What gets delegated to an agent, and what requires a human in the loop?</blockquote><p>These are research questions. They require researchers who understand both the technology and the humans it serves. The companies making the best AI decisions right now are not the ones with the best models. They are the ones with the best judgment about where to apply them. If you are not building fluency here, you are leaving the most strategic seat at the table empty.</p><h3>The researcher’s new job description</h3><p>The researchers who thrive in this landscape will be the ones who make the best decisions from data that is already abundant. This requires a shift in how you think about your role. Here is a framework for evaluating where you stand and what to do about it.</p><h4><strong>Three questions to ask yourself:</strong></h4><ol><li>Does my contribution on this project require judgment that depends on context a machine does not have? If yes, you are in the strategic layer. If no, you are doing work that will be automated within 18 months.</li><li>Does my deliverable connect research findings to a business decision? If your output is a report that summarizes what users said, that is commodity work. If your output is a recommendation backed by synthesis across multiple data sources, that is strategy.</li><li>Am I building relationships that make my judgment more valuable over time? Institutional knowledge, stakeholder trust, and cross-functional credibility are compounding assets. They are the moat.</li></ol><h4><strong>Build the skills that sit on top of the data</strong></h4><p>Learn to read a P&amp;L statement. Understand how your company makes pricing decisions. Shadow a sales call. Sit in on a board prep meeting. The researchers who will lead this industry are the ones who can walk into a room of executives and connect a research finding to a revenue outcome in language the CFO understands.</p><p>That is not a natural extension of most research training programs. It is the gap you need to close, and closing it is entirely within your control.</p><h4><strong>Use AI tools aggressively for the commodity layer</strong></h4><p>Do not resist the tools. Use them. Automate your transcription, your initial coding, your pattern recognition across large datasets. Let the machine handle what it handles well so you can spend more time on synthesis, strategy, and the client conversations that actually move the needle.</p><p>A <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC11103925/"">2024 study published in PMC</a> put it plainly: AI can augment, but not replace, the work of human researchers in producing rigorous analysis, so long as it is applied in a mindful and ethical manner.</p><p>Treat AI tools the way a skilled carpenter treats a power tool: useful for speed, dangerous if you let it do your thinking.</p><h4><strong>Start advising on AI decisions, not just user decisions</strong></h4><p>Every organization is asking some version of the same question right now: Where should we use AI, and where should we not? Researchers are uniquely positioned to answer this because the question is fundamentally about human behavior, trust, and context.</p><p>Start volunteering for AI strategy conversations. Offer to run evaluations of AI-powered workflows. Frame your expertise around the question that every executive is losing sleep over: How do we deploy this technology without alienating the people it is supposed to serve?</p><h4><strong>Position yourself as the person who turns signal into decisions</strong></h4><p>This is the through-line. Every skill on this list, every shift in how you approach your work, comes back to one distinction: Are you gathering signal, or are you turning signal into decisions? The first is being commoditized. The second is becoming more valuable every day.</p><p>If your work ends with a research readout, you are on the wrong side of that line. If your work ends with a decision that moves the business, i.e. your make the business money, you are <em>exactly</em> where you need to be.</p><h3>The Opportunity</h3><p>The research industry is being reorganized. That is not a threat. It is a correction.</p><p>For years, the value of research was bottlenecked by the logistics of data collection. It took weeks to recruit, schedule, conduct, transcribe, and analyze.</p><p>The practitioners who could manage that pipeline were valuable because the pipeline was hard. Now the pipeline is easy. And the people who always knew that the pipeline was not the point, that the real work starts after the data is collected, those people are about to have their moment.</p><p>The strategic layer of research is becoming <em>more</em> valuable, not less. Those of us who have spent years building judgment, who can synthesize across messy inputs, who can advise on the hardest questions organizations face about AI, growth, and customer strategy… we are holding the one asset that cannot be automated. And for the first time, the logistics of data collection are no longer standing between us and the work that actually matters.</p><p>This is the best time in a generation to be a researcher who thinks strategically. The noise is being filtered by machines. The signal is waiting for someone with the judgment to act on it.</p><p>The tools got smarter… the question is whether you did too.</p><p><em>Josh LaMar is a product growth strategy and AI decision advisor with over 20 years in product, technology, and customer strategy. He has spent well over 40,000+ hours listening to customers across 19 countries on 5 continents.</em></p><h3><strong>References</strong></h3><ol><li>Future Market Insights. (2025). <a href=""https://www.futuremarketinsights.com/reports/ai-based-research-services-market"">AI-based Research Services Market</a>.</li><li>Displayr. (2025). <a href=""https://www.displayr.com/ai-in-market-research-today-trends-tools-and-whats-next/"">Market Research Automation: Trends, Tools, and What’s Next</a>.</li><li>Williams, R. T. (2024). <a href=""https://www.frontiersin.org/journals/research-metrics-and-analytics/articles/10.3389/frma.2024.1331589/full"">Paradigm shifts: exploring AI’s influence on qualitative inquiry and analysis.</a> <em>Frontiers in Research Metrics and Analytics.</em></li><li>Brinkmann, S. (2012). <a href=""https://tidsskrift.dk/qual/article/view/6273"">Qualitative research between craftsmanship and McDonaldization.</a> <em>Qualitative Studies, 3</em>, 56–68.</li><li>Lincoln, Y. S., &amp; Guba, E. G. (1985). Chapter 7 (pages 193–194 of <em>Naturalistic Inquiry</em>). Sage Publications.</li><li>Hitch, D. et al. (2024). <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC11103925/"">Artificial Intelligence Augmented Qualitative Analysis: The Way of the Future?</a> <em>PMC.</em></li><li>Grand View Research. (2025). <a href=""https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market"">Artificial Intelligence Market Size Report, 2033</a>.</li></ol><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9fd4339617ca"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/your-research-tools-got-smarter-did-you-9fd4339617ca"">Your research tools got smarter… Did you?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/why-your-ceo-acts-like-a-clown-the-tribal-myths-of-leadership-b3c2a5f6cc17?source=rss----138adf9c44c---4,1771164775,Why your CEO acts like a clown: The tribal myths of leadership,"Why your CEO acts like a clown: The tribal myths of leadership

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-your-ceo-acts-like-a-clown-the-tribal-myths-of-leadership-b3c2a5f6cc17?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/995/0*7hDRRVUApWAOtn8e"" width=""995"" /></a></p><p class=""medium-feed-snippet"">When building and growing a company, you must be able to step away from numbers and KPIs and look at it from a human perspective &#x2014; as a&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-your-ceo-acts-like-a-clown-the-tribal-myths-of-leadership-b3c2a5f6cc17?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/the-blind-spots-of-inclusive-ai-3a66373d80f1?source=rss----138adf9c44c---4,1771164608,The blind spots of inclusive AI,"The blind spots of inclusive AI

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-blind-spots-of-inclusive-ai-3a66373d80f1?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1536/1*PODmEISlV0lEPu5uJb_3Jg.png"" width=""1536"" /></a></p><p class=""medium-feed-snippet"">AI has lowered real barriers for many users. But intelligence and inclusion do not always advance at the same pace.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-blind-spots-of-inclusive-ai-3a66373d80f1?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/get-behind-me-ai-writer-b783ba2f9851?source=rss----138adf9c44c---4,1771164581,"Get behind me, AI writer","Get behind me, AI writer

<h4>A reverse-engineered drafting process that keeps humans in charge</h4><figure><img alt=""Banner illustration showing a robed human figure walking ahead with one arm raised in a firm, dismissive gesture toward a cloaked android following behind. The android has a metallic head and robotic arm visible under its striped cloak. Large white text on a dark background reads “Get behind me, AI writer,” visually reinforcing the idea that artificial intelligence should follow the human author rather than lead the writing."" src=""https://cdn-images-1.medium.com/max/1024/1*b4mHENjpK6quxisbSYaf0g.png"" /><figcaption>(AI disclaimer: edited image of Jesus &amp; the St. Peter android was produced with AI assistance; the rest of the banner, copy, and layout are my own design) A writer keeps AI in the backseat: an android of St. Peter reaches toward Jesus who waves it behind, echoing “Get behind me, AI writer.”</figcaption></figure><h3>Reverse-engineered plagiarism</h3><p>A few years ago, a former design director used to pull me into random calls, appearing to be serious &amp; urgent. While I thought I was getting fired or about to get started on an urgent design ask, he just wanted to talk about philosophy &amp; K-Pop. As jarring as that was, I found it hilarious. During one of those calls, he shared an anecdote about how he helped his daughter with a college essay using ChatGPT. I used to work as a writing tutor, so any use of ChatGPT in the writing process struck me as suspicious. But, what they did with AI for her essay was actually brilliant.</p><p>He suggested that she write out the full essay with reckless abandon for citing sources: no reference formatting, no concern for straw-manned arguments, accurate quotes, or making sure paraphrases are in her own words. Rather, just write all the ideas down first. Then, upload the essay to ChatGPT and have it run a plagiarism check, finding the sources the draft is referencing. From there, they would review the ‘plagiarized’ sources, cite &amp; quote them properly, or remove the content from the essay, and weave it into her original work.</p><p>While, at first glance, I had my reservations, I realized this approach didn’t replace her voice or her original work; it reduced friction in her writing process. Here’s why: She first began writing everything on her own &amp; without AI, so the tone, style, and phrasing were hers alone. Second, while she might be inaccurate or wrong about how she alluded to or referenced sources, all that can be corrected later. Lastly, she had ChatGPT handle the critical &amp; clerical work: suggesting revisions, searching for relevant sources, and helping her integrate them properly into whatever citation style her class required. AI wasn’t writing the essay for her, she was using AI effectively by keeping her “authentic voice… to <em>enhance</em> expression, not to replace original thought,” as the <em>Enago Academy</em> would couch it.¹ Her voice came first, ChatGPT came second.</p><p>At the writing center I worked for, students could ask for help with anything from brainstorming paper topics to final edits. Our job was to guide students by keeping them on topic, catching blindspots, grammatical mistakes, and shaping the general structure. We gave them the feedback, but the students still had to apply it. The same is true for setting up AI as a writing tutor. I’ll argue that AI platforms setup with a tutoring persona can preserve a writer’s creative integrity and remove friction for research &amp; citing sources. I’ll demonstrate this through a reverse-engineering drafting (or reDraft) process for writing.</p><p>Before laying the process out, I’ll explain why we should care about writing, how AI can complement it, and some caveats to consider. Then, I’ll provide a high-level overview of the reDraft process, and go through it step by step on how I used it for my last article, noting what worked well &amp; what I would have done differently.</p><h3>Get behind me, AI writer</h3><p>You’re reading this article, which indicates you value writing already. Writing for our own sakes is important for many reasons too: it organizes our thinking, allows us to contribute our knowledge, and works as a self-teaching mechanism. If you can write about a given subject, it’s clear you understand it. I know many designers &amp; former colleagues in philosophy who have great things to say. My hope is to encourage the would-be writers who have insights to share with a process that fast-tracks them through the drafting stage and into editing.</p><p>That being said, using AI for written work or any creative material is tricky. On the one hand, it can operate as a great on-demand feedback generator. When writing centers are closed — or I’m just not in an easy or quick environment to get feedback — having something give me writing a second look has benefited me greatly. I still believe human feedback is more valuable — especially for brainstorming, style, and tone at least — but it’s nice to have something that compares sources, grammatical mistakes, and mechanics quickly too.</p><p>On the other hand, the temptation is to let AI creep into your work as a co-author or a ghostwriter. While some can differentiate the AI slop from crafted work, it’s becoming more difficult to tell when something is solely generated by AI. At the worst of times, people may just post completely AI-generated content and claim it as their own. I’ll take a firm stance against that approach. So, if you’re expecting an AI-first writing process, I’m afraid you’ll be disappointed. AI comes second here.</p><h3>A tale of two processes</h3><h4><em>Building snowmen</em></h4><p>Before any AI tools, my traditional writing process was more akin to Randy Ingermanson’s <em>Snowflake Method</em>. While that was geared towards long-form fiction, it served me well for nonfiction &amp; academic writing too. The idea was to start with a sentence capturing your general thought, idea, or argument and then continuously expand that sentence into a paragraph, from a paragraph to a page, and so on. It’s a <em>fractal</em> process, like how a snowflake is a fractal shape of itself.² So, I may have started with a thesis statement and then thought through how I needed to support my claim.</p><p>But I had serious struggles — like many others — with writer’s block, uncertain about direction in both my ideas &amp; method, and struggled with getting thoughts to paper even when I knew what I wanted to say. Usually, I enjoy the grind of a process, but I rarely did for writing.</p><h4><em>Throwing clay</em></h4><p>Pairing my tutoring experience with my director’s brilliance, my goal was to standardize his idea into a process to get me back on track with writing. His insight to ‘reverse engineer’ finding relevant sources, could be extrapolated in other areas of writing: drafting, revisions, alt-text, image captions, SEO, etc. Further &amp; most importantly, I wanted to maintain creative ownership, integrity, and approach this process with a solid ethical foundation.</p><p>The phrase <em>reverse-engineered drafting</em> is fitting because it inverts the snowflake method completely: crank out all the content and then clean it up. I rarely would just sit down &amp; write everything without worry for what my overall draft looks like, tone, voice, and grammar — all of which I should care about later in the editing stage. By way of analogy, think of the snowflake method like basket weaving by starting with one long leaf and continuously adding more and more to create a basket.</p><p>Alternatively, the reverse-engineered drafting, or <em>reDraft</em>, process is more akin to throwing clay in the sense that you start with an unformed lump that’s morphed into a pot. I soon realized that early drafts have a lot to offer; and this isn’t exclusive to the reDraft process either. AI can help shed some light through the muck like a writing tutor can help clarify some points that your paper could be saying without robbing the author of ownership.</p><p>I know AI isn’t required for a reverse-engineered approach in the way I’m describing, either; that’s perfectly fine. But for myself, I fall into so many tangents, get into the weeds on details that aren’t pertinent and sometimes end up writing nothing at all. It could take months or years (looking at my publishing history on Medium), before I actually finish a full draft. Just giving myself the permission to work with an unformed lump for a draft, knowing that AI can give me some clear feedbac,k was enough for me to crank out some undercooked, yet fully-baked thoughts.</p><p>If you’re wondering whether I used the reDraft process on this article, I absolutely did. And, of course, I asked AI for feedback on how to standardize &amp; refine the reDraft process too. I have a dedicated Perplexity Space called “Writer’s Room” that runs off the reDraft process. In what’s to come, though, I’ll walk through the process in detail, step by step, in case you’d want to bring it to your frontier model of choice. I’ll also share a link to the custom instructions I use on Perplexity as well.</p><h3>Reverse-engineered drafting</h3><p>With AI’s help, of course, I’ve distilled this down to a 5-step process from conception to submission. Depending on how much I already know about a subject, whether I’m constructing an argument or exploring an idea, the early steps may look slightly different. I’ll explain more when we go into more detail about each step.</p><p>In addition to Perplexity, I use Obsidian to help me keep track of where I’m at in the process with multiple note files as drafts with specific naming conventions. I’ll be sure to share those, too, that I’ll add after each step’s description. For now, let’s look at the process as a whole.</p><h4>reDraft process</h4><ul><li><strong>Step 1: </strong>free-form drafting (1 FF draft)</li><li><strong>Step 2: </strong>rough feedback (2 RF draft)</li><li><strong>Step 3: </strong>revision rounds (3 R# revision)</li><li><strong>Step 4: </strong>quality check (4 QA check</li><li><strong>Step 5: </strong>final review (published title)</li></ul><p>I’ll use my last article, “<a href=""https://medium.com/user-experience-design-1/useful-ads-7899e1711157"">Designing useful ads</a>,” to walk through each step in more detail since it was both an idea I wanted to explore &amp; to test out this process.³ I’ll share what worked well, learnings from mistakes I made, and some adjustments I did.</p><p>For reference, here’s how I organize my Obsidian notes based on the naming conventions for each of the five steps.</p><figure><img alt=""Sidebar view of an Obsidian-style note list titled “Frontier AI ads,” showing a sequential set of files named “0 idea — advertisements in AI chats,” “1 FF draft — ads in frontier AI,” “2 RF draft — ads in frontier AI,” three “3 R1/R2/R3 revision — ads in frontier AI” entries, “4 QA — ads in frontier AI,” and a final citation-style line, “Walsh, Tanner (2026) Designing useful ads.”"" src=""https://cdn-images-1.medium.com/max/1024/1*yX4JvumR4DZnc2RuDtkS0g.png"" /><figcaption>Obsidian sidebar showing the full reDraft workflow for the “Frontier AI ads” article from initial idea through free‑form draft, rough feedback, three revision rounds, and quality check; and it ends in the final citation for “Designing useful ads.”</figcaption></figure><h4>Step 1: Free-form drafting</h4><blockquote>Instructions:<br /><em>Begin writing without concern for spelling, grammar, or perfect citations. Focus on getting all ideas, arguments, visuals and references onto the page. Loosely note sources or ideas as you write.</em></blockquote><p>This step is about writing &amp; more writing. Get all the ideas on paper with that same reckless abandon, ignoring not only proper citations but also proper grammar, spelling, punctuation, paper structure, and having a clear thesis. Easier said than done, of course; I care too much about spelling &amp; grammar still. Yet, speed is key for step one. The more you have written down, the more you have to work with later.</p><p>With my last article, I began with general ideas and gave each paragraph an H4 heading in Obsidian that captured the thought for me. Because of the outline view and that headings can collapse like accordions, Obsidian makes it easy to quickly track &amp; scan a working draft. Here’s how that looked for me in step one:</p><figure><img alt=""Screenshot of Obisidian article draft in dark‑mode showing the “Intro” section with two subsections and a collapsed accordion section: a “YouTube &amp; Spotify example” paragraph describing how ads slowly appeared on free services and frustrated users, and a “frontier models &amp; search engines” paragraph comparing frontier AI models to search engines with sponsored tags and banner blindness, ending by noting an opportunity to add ads smartly."" src=""https://cdn-images-1.medium.com/max/1024/1*MoGTcAbBImMs8vV7a32LPw.png"" /><figcaption>Draft intro section for the frontier AI ads article with H4 headings to convey each paragraph’s idea in Obsidian.</figcaption></figure><p>It’s quick, messy, fairly coherent, but also some word vomit. But that’s the point. I can go back &amp; clean up what I wanted to say about YouTube during the editing stage.</p><h4><em>Reverse-engineering a brainstorm</em></h4><p>There’s another article idea I’m exploring about whether data trackers can help increase virtuous behavior. I have a Garmin watch &amp; a background in philosophy, so I know a bit about data tracking &amp; virtue ethics. What I don’t know is much about how the general data-tracking community might take data tracking to the extreme nor what the ethical implications of that might be. So, I wanted to learn more in two ways: top sources &amp; controversies. For this, I tend to use the following prompt as a starting point:</p><ul><li>“What are the top stories in [subject/topic] and what are people divided on?”</li></ul><p>If I’m just eager to write about <em>something</em> but nothing comes to mind, I might plug in either of these prompts into Perplexity:</p><ul><li>“Here are my interests [list of my interests], what are some topics I could consider writing about?”</li><li>“Generate writing prompts for me to explore based on my interests”</li></ul><p>AI is great for brainstorming &amp; giving some initial direction to start writing from scratch. I keep it ethical by making sure I’m doing the research though, looking through the summarized sources, and thinking about my own stance on the matter. AI is solely providing a general direction for me to do that. And I can narrow my focus, sources, and clarify my own position, taking notes for my Zettlekasten-inspired Obsidian vault to draw from later.</p><h4><em>Visual assets</em></h4><p>Since I work as a UX designer, Figma (and similar tools) works great for quick visuals to illustrate a point or make themed article banners like I have. I’ll create a page in a “writing” file for each article specifically with a component library that maintains a consistent color scheme &amp; typography.</p><figure><img alt=""Figma canvas showing a large black banner with a white roadside billboard mockup that reads “Driver in the red Camry, your left headlight is out. Take Exit 12 for Redline Autoshop. Typical fix for $75–120,” alongside the words “Useful ads,” with smaller UI mockups beneath illustrating conventional and “smart” AI ad responses and contextual panels."" src=""https://cdn-images-1.medium.com/max/1024/1*33L56B9WwY9gJkDmxe0XkA.png"" /><figcaption>Banner &amp; UI explorations for the frontier AI ads article: a “Useful ads” billboard warning a red Camry driver about a broken headlight, paired with AI interface mocks that reframe ads as contextual cards, coupons, and right‑rail panels designed to be genuinely helpful.</figcaption></figure><p>Figma recently added a generic component library making it easy for me to quickly wire out an AI chat interface to illustrate my points &amp; examples. Further, now that more AI features are in Figma, I had an easier time working with placeholder content and didn’t have to use <em>lorem</em> text anywhere. Until I had those visuals ready, I just added placeholders in the draft like so:</p><p>Before having my Perplexity Space give some feedback on it, I polished up the formatting a little by giving each paragraph an H4 heading that I may have missed earlier and clearly explain in my prompt what is meant to be placeholder in my draft. Sometimes the thesis comes later though too, which was true for the AI ads article. So, I’ll quickly take a shot on what point I’m trying to make that I can change up later if needed. For this I started with: <em>ads in AI can be useful and done better</em>. Sure it’s not punchy, that detailed, or even helpful; but it gets my aim in a nutshell.</p><h3>Step 2: Rough feedback</h3><blockquote>Instructions:<em><br />Upload the draft for feedback on:<br />- Structure: Logical flow and overall organization<br />- Thesis/Focus: Clarity and specificity of the central idea<br />- Flesh-out: Fill out details for core argument &amp; ideas<br />- Sources: Relevance and sufficiency of cited material<br />- Blind Spots: Identify missing context, underdeveloped arguments, or evidence</em></blockquote><p>I’ll export the free-form draft as a PDF and begin a thread in my “Writer’s Room” Perplexity Space. I typically write a prompt like this:</p><ul><li>“I have a free-form draft for a new article idea I’m writing as an attached PDF. So step 1 in the reDraft process is done. Provide initial feedback for Step 2. (attached PDF)”</li></ul><p>After all the feedback is generated, I have Perplexity compile it into a list of to-do items for me to tackle too.</p><figure><img alt=""Screenshot of a dark‑mode Perplexity response showing a four‑part “Step 2” revision checklist titled “Thesis / Central Focus,” “Structure &amp; Logical Flow,” “Core Sections &amp; Main Argument,” and “Facts, Sources, &amp; Credibility,” each with short bullet points about clarifying the thesis, adding headings, defining concepts, and verifying sources."" src=""https://cdn-images-1.medium.com/max/1024/1*cbPwA_KItM-yVkJDaaeLnQ.png"" /><figcaption>The Step 2 revision checklist I used for the frontier AI ads article, outlining how to tighten the thesis, restructure sections, flesh out the main argument, and shore up sources before moving on to detailed line edits.</figcaption></figure><p>If I’m struggling with a particular item, I’ll bring it to Perplexity and treat it like a writing tutorial. For example, my initial thesis lacked clarity &amp; direction. So, I asked Perplexity how it might phrase my thesis statement. While tutoring students, I would help them sharpen theses in a similar fashion, going back &amp; forth on several revisions with different wording, sentence structure, aim, and focus. I’d suggest my take on it, then the student would bounce back with theirs. Well, the same is true here:</p><p><strong><em>1 Perplexity’s suggestion:</em></strong></p><figure><img alt=""Close‑cropped dark‑mode chat snippet showing Perplexity’s message: “Got it. How about this as a next draft:” followed by the thesis sentence about advertisements in free services like ChatGPT risking frustration and brand trust while frontier AI models can integrate them smartly into threads and responses, enhancing utility instead of disappearing into banner blindness."" src=""https://cdn-images-1.medium.com/max/1024/1*QFGrj0tqdRFqeitmcS9ROA.png"" /><figcaption>Perplexity’s follow-up thesis suggestion for the frontier AI ads article, proposing a version that frames ads as smartly woven into AI threads and responses rather than lost to classic banner blindness.</figcaption></figure><p><strong><em>2 My revision:</em></strong></p><blockquote>While advertisements in any free service risk user frustration &amp; brand trust, frontier AI models have a unique opportunity to subvert user expectations for advertisements in a way that enhances the value of AI threads &amp; responses without compromising utility.</blockquote><p><strong><em>3 Perplexity’s revision:</em></strong></p><figure><img alt=""Dark‑mode chat screenshot showing Perplexity’s message: “Absolutely. Then I’d suggest this final version:” followed by the refined thesis about advertisements in free services like ChatGPT risking frustration and brand trust while frontier AI models can integrate them smartly into threads &amp; responses to enhance utility without compromise or banner blindness."" src=""https://cdn-images-1.medium.com/max/1024/1*vJ0sOtsfL2VoboCY5rIOSw.png"" /><figcaption>Perplexity’s last thesis recommendation for the frontier AI ads article, before I did my final two revisions.</figcaption></figure><p><strong><em>4 My revision:</em></strong></p><blockquote>While advertisements in free services like ChatGPT risk frustrating users and harming brand trust, frontier AI models have a unique opportunity to integrate them smartly via sponsored comparisons, optional sub-searches underpinned by UX principles like information scent, information grouping, and signal-to-noise ratio that can enhance utility without compromise.</blockquote><p><strong><em>5 My own final revision:</em></strong></p><blockquote>While advertisements in free services like ChatGPT risk frustrating users and harming brand trust, frontier AI models have a unique opportunity to integrate them smartly into the threads &amp; responses that have the potential to enhance utility without compromise or worry of banner blindness.</blockquote><p>It might be tempting to take AI’s revisions as is, but sometimes the word slop creeps in. So it’s important that you read it carefully &amp; adjust it to your voice &amp; needs — especially for your core argument. Setting up guard rails in your prompting can help curb that temptation &amp; have AI help focus on giving you actionable feedback, as opposed to doing the work for you. Consider explaining what your goals are for a thesis or what you don’t like about it for instance. Good prompts lead to good feedback; and, as Justin Jeffrey reported on students seeking AI feedback, “poor prompts led to weak feedback.”⁴</p><p>While I had to improve some structural changes in the article, Perplexity suggested I keep the general roadmap as is — which was flattering, I guess. But it suggested that I integrate my visuals within the case study &amp; provide analysis paragraphs that explain the design and the principles they adhere to. That suggestion was very insightful, and it was nice to decide how to capitalize on that insight myself.</p><p>Once I had fleshed out some weaker sections and cut redundant ones, it was time to check for ‘plagiarism’ and find some sources. Here’s the gist of the prompt I used:</p><blockquote>“Okay, let’s find sources that are talking about what I’m writing about, referencing or alluding to. And let’s find similar works that are talking about the same topics or ideas as I am.”</blockquote><p>While I saw many folks talking about ads in AI platforms, there didn’t appear to be a lot of discussion on how they could be better for people — admittedly, this could be me relying on AI a bit too much to catch blindspots like that. But with the sources it did recommend, Perplexity gave a brief summary for each one &amp; showed in my draft where each source challenged or complemented a point I was making. For my part, I’d check the source, read through it, and find what was most relevant or helpful or more concrete for my article.</p><p>Last, I asked Perplexity to provide a Chicago-style bibliography citation of the source for me to track references at the end of the draft and making sure the right information is included &amp; hyperlinked if needed.</p><h3>Step 3: Revision rounds</h3><blockquote>Instructions:<em><br />Compile feedback into action items for the following categories</em></blockquote><blockquote><strong><em>Round 1: Structure and Organization</em></strong><em><br />- Refine thesis or focus statement.<br />- Ensure logical flow and coherence.<br />- Organize sections with clear headings and subheadings.</em></blockquote><blockquote><strong><em>Round 2: Paragraphing and Clarity<br />- </em></strong><em>Improve topic sentences and transitions.<br />- Clarify arguments and evidence.<br />- Ensure each paragraph supports the main idea.</em></blockquote><blockquote><strong><em>Round 3: Sentence-level Polish<br />- </em></strong><em>Refine sentence structure for clarity and readability.<br />- Correct grammar, punctuation, spelling, and syntax.<br />- Adjust word choice, tone, and style for the intended audience.</em></blockquote><p><strong><em>Embarrassing but honest disclaimer:</em></strong><em> </em>Admittedly, I didn’t go through the three rounds as I laid out above. Perplexity’s custom instructions weren’t as solidified at this point, and I conflated a lot of steps 2 &amp; 3 together where I lost a good bit of focus on what I was doing. And the same is true for steps 4 &amp; 5 too, but I’ll table that for now. For the remainder of this section, read what I <em>should</em> have done instead.</p><h4>Round 1</h4><p>Here, the focus is on tying ideas together, being consistent, and making sure the draft is complete from start to finish. I’ll begin by first collapsing all paragraph headings between the introduction &amp; conclusion sections to get an overview of the narrative flow, and then revise the intro or conclusion as needed.</p><p>The rest of round one is spent examining how a section ties to the previous &amp; following sections, and then how each paragraph ties to the previous &amp; following ones. Having labelled each paragraph topic saved time by allowing me to glance at how the paragraphs relate to each other, cut them if they don’t, or reorganize them if there’s a better fitting spot.</p><p>For example, it was time to explain how the UX principles applied to my lo-fi content cards in a few analysis paragraphs. This began with a list of principles and some rough definitions of them that later merged into analysis paragraphs near the visual design:</p><p><strong><em>Before:</em></strong></p><figure><img alt=""Dark‑mode editor screenshot showing a short paragraph about “being smart with a few principles” followed by four bulleted definitions: information grouping, information scent, banner blindness, and signal‑to‑noise ratio, with a final bracketed note about adding wires or sketches later."" src=""https://cdn-images-1.medium.com/max/1024/1*gm9XUTSI81ByIITN901J8Q.png"" /><figcaption>Draft section defining the four UX principles that guide “useful ads” in frontier AI (information grouping, information scent, banner blindness, and signal‑to‑noise ratio) before moving into interface sketches and wireframes.</figcaption></figure><p><strong><em>After:</em></strong></p><figure><img alt=""Screenshot of explanatory copy above a Figma‑style card mockup for “BrightSpark Electrical,” showing a star rating, price tag reading “$4000,” short company description, “Read reviews” link, and two buttons labeled “Free inspection coupon” and “Request service.”"" src=""https://cdn-images-1.medium.com/max/998/1*G-Ib-XBbdLnn0zbHhD2PCw.png"" /><figcaption>The merged example of a “smart ad” card for an electrician that integrates the design principles in the analysis paragraph above it.</figcaption></figure><h4>Round 2</h4><p>Now that the ideas connect and the story is consistent, it’s time to polish the formatting. I’ll start thinking through names for each section or at least a phrase that explains what the section talks about. Eventually, my hope is that I’ll come up with something clever or cheesy — like Lewis &amp; Clark themed section headings on how to <em>trailblaze</em> the <em>frontier</em> for <em>frontier</em> AI advertisements. While there seemingly isn’t a lot for this round, finalizing the larger essay structure &amp; themes would allow me to hone in on the finer details now.</p><h4>Round 3</h4><p>If anyone caught my case study article immediately after it published, you’ll know that I overlooked a lot I needed to do in this round. Unfortunately, I can’t blame the sloppy writing on AI either since it’s directly from my rougher drafts — at least it’s <em>my</em> slop though. Again, learn from my mistakes; never skip sentence-level edit day.</p><p>While the tasks might differ from article to article, some things were already done more or less like thesis statement revisions, case study coherence, and so on. So what I have above was how I approached each task per round.</p><p>This round has a higher workload than the others, as the focus is to go through each paragraph &amp; tighten up the sentences, flow, and grammar for a cleaner polish. Usually, I aim to keep sentences as short as I can without losing clarity of the ideas. But making sure your tone, voice, and style are showcased is most important.</p><p>If needed, take one section at a time. I’ve learned it’s better not to approach this round all at once, too. All the writing &amp; structure is there, so it’s easier to come back and know what’s left to do after a break from editing. Once I’m satisfied with the sentences, coherence, and structure of the paragraph, I’ll delete the paragraph headings then move to the next section. For me, this gives me the sense of completion for what sections are revised and indicates that I’ve given this some close attention at the sentence level too.</p><p>So, after three rounds of editing, I’ll move into the next step in the process. At this point, I should have my draft in good shape, my visuals replaced the placeholder spots, and trimmed down the excess content I don’t need.</p><h3>Step 4: Quality check</h3><blockquote>Instructions:<br /><em>Check that your draft meets the following criteria before publishing<br />- Clear and specific thesis or focus<br />- Logical and coherent structure<br />- Credible and well-integrated evidence<br />- Readable and engaging style<br />- No major errors in grammar or mechanics<br />- Visual appeal and formatting where appropriate<br />- Strong conclusion (summary, call to action, or takeaway)<br />- Relevant tags or SEO if publishing online<br />- Banner image<br />- Article title &amp; subtitle</em></blockquote><p>Many of the tasks here may feel they’ve already been done. But it’s nice to have Step 4 as another round of feedback from Perplexity to catch my gaffs that I’ll miss in Obsidian or just mistakes I plainly overlooked. As Riwa By claims, AI goes beyond a traditional spellchecker because it can “analyze entire sentences, understand context, suggest rephrasing, and… match tone and intent,” making it a solid writing tutor.⁵</p><p>With what AI can do now, there’s really no excuse for leaving out alt-text &amp; captions for visuals. At the very least, I think there’s an argument for having this content generated — especially if the visuals are your own work or if you want to properly reference copyrighted imagery. But if you want to keep things in your own words, draft the captions, alt-text, and SEO descriptions of the article too. The AI tutor can give solid feedback on this also for screen reader users and teasing out details in captions that might be subtle in the imagery.</p><p>What’s unique to this section, though, is coming up with a title. I would spend way too much time crafting a title &amp; subtitle before I had even the idea fully formed in my head. However, with the reDraft process, content comes first &amp; cool titles come after. For the AI ads article, I threw some of my rough title ideas at Perplexity to refine further:</p><ul><li>“AI Trailblazing: the final AI frontier”</li><li>“Helpful marketing: how AI can make ads useful”</li><li>“UX for ads: AI’s unique opportunity”</li></ul><p>I ended up with “Useful ads: Trailblazing UX for Frontier AI” but quickly realized that’s a very vague title that doesn’t convey much. So I quickly changed it to “Designing useful ads” and the good folks at <em>UX Collective</em> provided a cleaner, more descriptive subtitle (thank you!): “Redefining the relationship between AI utility and digital advertising.” Thankfully, I didn’t have to rework my article banner image, since I usually don’t have those matching one-to-one with the title anyway.</p><h3>Step 5: Final review</h3><p>For my own peace of mind, I’ll have Perplexity review it one last time, providing exactly what I’d put in Medium’s draft page. However, since most AI platforms probably could offer endless feedback for ‘improvement,’ I had included in the Perplexity custom instructions to say when something is ‘good enough for my purposes.’ I’m not trying to be the next Dostoyevsky or Nobel Prize winner, so I can strive for excellence on my own standards rather than absolute perfection.</p><p>But if you — like me — eagerly tried a new writing process and noticed a lot of mistakes after it’s posted, I have two thoughts. First, Medium thankfully allows edits after posting; I can make some minor tweaks, fix grammar, or correct mistakes that I come across. Second &amp; more generally speaking, even if you can’t (or shouldn’t) make changes, I’m comfortable with saying that was not my best work &amp; can do better next time. Even though I notice things in my very first Medium article that I want to change or improve, I’m resisting the temptation and trying to lean into my own advice.</p><h4>Don’t just eat fish, learn how to fish</h4><p>While AI can be easily abused for any creative process, it can remove a lot of friction while maintaining human ownership of a work. It just has to be done with care &amp; self-restraint on what we allow AI to do for us. The goal is to identify clear boundaries in prompts &amp; instructions so that we focus more on our ideas, style, and prose.</p><p>More work does need to be done on a process like this for more stringent, professional work. The reDraft could be a decent start which academics could refine further — keeping the ethics, ownership, and standards honest for peer-review publications.</p><p>For newer writers, it may be more challenging to pushback against an AI tutor also. The <em>Enago Academy</em> warns that these platforms sound very confident, tout expertise, and have convincing explanations even when they’re factually wrong. But sources are linked in AI responses; click the links, skim the sources, and make your own judgement — especially for topics you’re still learning. Your name is on the byline for what you post online regardless if you had human or AI feedback.¹ Thus, it’s important to couch AI as an assistant, a librarian, and as a tutor that gives <em>suggestions</em> as opposed to gospel.</p><p>I love learning new things, and I don’t do myself nor my readers any good by having AI generate content I know nothing about. The old proverb “give a man a fish, and you feed him for a day; teach a man to fish, and you feed him for a lifetime” applies to AI creativity too. Write for yourself to understand new ideas, pay attention to what feedback AI gives you, and improve your writing style. In Jeffrey’s study, he found that AI helped students improve their writing where “82% reported improved error recognition” and “80% noticed details they typically missed.”⁴ AI can give you a full article to share in minutes, but it can also teach you how to write one yourself.</p><blockquote><strong>AI usage disclaimer</strong>:<em> AI tools were used for editing visual assets, writing feedback, assistance in locating relevant sources, &amp; Chicago-style citation formatting; all early drafts, ideas, arguments, &amp; experiences in this article are my own.</em></blockquote><h3>References</h3><ul><li>Link to <a href=""https://1drv.ms/w/c/369b550a350cb50a/IQCJ0YrsXADQTaamDDJ2kmC3AY5dQuZYKD3lm92JmwqpuUQ?e=bhLFTw"">custom instructions</a> for Perplexity Space.</li></ul><p>[1] Enago Academy. “AI in Academic Writing: How to Use Technology Without Losing Your Voice.” <em>Enago Academy</em>, December 14, 2025. <a href=""https://www.enago.com/academy/ai-in-academic-writing-how-to-use-technology-without-losing-your-voice/"">https://www.enago.com/academy/ai-in-academic-writing-how-to-use-technology-without-losing-your-voice/.</a></p><p>[2] Ingermanson, Randy. <em>How to Write a Novel Using the Snowflake Method</em>. North Charleston, SC: CreateSpace Independent Publishing Platform, 2014.</p><p>[3] Walsh, Tanner. “Designing Useful Ads: Redefining the Relationship Between AI Utility and Digital Advertising.” <em>UX Collective</em> (Medium), February 9, 2026. <a href=""https://medium.com/user-experience-design-1/useful-ads-7899e1711157."">https://medium.com/user-experience-design-1/useful-ads-7899e1711157.</a></p><p>[4] Jeffrey, Justin. “Draft–Redraft–Reframe: Using ChatGPT to Build Student Ownership of Writing.” <em>Impact</em> (Chartered College of Teaching), October 27, 2025. <a href=""https://my.chartered.college/impact_article/draft-redraft-reframe-using-chatgpt-to-build-student-ownership-of-writing/"">https://my.chartered.college/impact_article/draft-redraft-reframe-using-chatgpt-to-build-student-ownership-of-writing/.</a></p><p>[5] By, Riwa. “AI vs Traditional Grammar Checkers (2025): Which Is Best?” <em>ByRiwa</em>, October 13, 2025. <a href=""https://www.byriwa.com/ai-vs-traditional-grammar-checkers/"">https://www.byriwa.com/ai-vs-traditional-grammar-checkers/.</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b783ba2f9851"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/get-behind-me-ai-writer-b783ba2f9851"">Get behind me, AI writer</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/practice-notes-on-including-citizens-in-the-design-process-d28bf115700f?source=rss----138adf9c44c---4,1771164551,Practice notes on including citizens in the design process,"Practice notes on including citizens in the design process

<h4>Field notes on trust, participatory scaffolding, and shared agency.</h4><figure><img alt=""Photo of the Citizen Participation? Hell No! Card game."" src=""https://cdn-images-1.medium.com/max/1024/0*qVGxbJQbTng9jN0d.png"" /><figcaption><a href=""https://urbact.eu/articles/citizen-participation-hell-no"">Citizen participation? Hell no!</a></figcaption></figure><p>Involving citizens in public design is much more than running an “open” process. It is about redistributing agency — enabling people to shape decisions, define problems, and participate in making change happen. It is as much about co-authoring a story of change as it is about delivering outcomes.</p><p>Over the past eight years, I’ve been fortunate to work with a broad range of people — from children on dialysis wards or someone’s friend’s uncle in Germany looking to rent power tools to everyday citizens wanting to inquire about their tax bill, and the people I work with. Across all of these experiences, I’ve come to trust something quite simple. That work gets better when people (or <em>citizens</em>) are involved in defining needs, shaping response,s and proposing designs — not just talking about change, but helping to make it happen, together.</p><p>Given that I’m currently working with a brilliant teaching team on the MPA in Innovation, Public Policy and Public Value at UCL’s Institute for Innovation and Public Purpose — with <a href=""https://www.linkedin.com/in/rowan-conway-09bab58/"">Rowan Conway</a>, <a href=""https://www.linkedin.com/in/gabriella-gomez-mont-1186a417b/"">Gabriella Gomez-Mont</a>, <a href=""https://www.linkedin.com/in/agostinaargirofuertes/"">Agostina Argiro Fuertes</a>, <a href=""https://www.linkedin.com/in/cecilia-santucho-65578a133/"">Cecilia Santucho</a> and <a href=""https://www.linkedin.com/in/nlaport/"">Nickolas Laport Aldunate</a> — supporting students to start tuning into how we better engage, enable and empower citizens through participatory scaffolding, it felt timely to pause and reflect on what it really means to include citizens in the design process.</p><p>Drawn from fieldwork, facilitation, practice, research, and a somewhat substantial volume of reading across public innovation and social infrastructure in recent years, here are some notes from the field that I’ve been marinating on.</p><h3><strong>1. Spend more time outside than in the office.</strong></h3><p>Being and doing things together on site is where trust and respect are built across differences. Thinking doesn’t happen in spreadsheets alone; it happens in kitchens, on pavements, in school corridors, in workshops and vans. We can’t expect colleagues — or citizens — to always come to us, or to log into a Team’s call, when they are balancing lives of their own.</p><p>Instead, jump in a tradesman’s van for a ride-along, chat to your taxi driver, go on a dog walk, have spontaneous conversations where people naturally gather: the barber shop, the football pitch, the school gate. These are all so much more than romantic gestures, they are cultural and essential ethnography into how people actually live their lives.</p><figure><img alt=""Illustration of a community engagement cycle."" src=""https://cdn-images-1.medium.com/max/1024/1*x5J5gXYxwAkHOl5lvkERBw.png"" /><figcaption>Hilary Cottam — <a href=""https://www.hilarycottam.com/radical-help/"">Radical Help</a></figcaption></figure><p>This echoes much of Hilary Cottam’s work on relational welfare — the idea that change does not emerge from service transactions but from relationships built in the everyday spaces of life. In <a href=""https://www.hilarycottam.com/wp-content/uploads/2019/12/Social-Revolution-5.0-_dec19.pdf""><em>Revolution 5.0 A Social Manifesto</em></a> (which inspired this post) Hilary argues that our public systems are over-optimised for institutional efficiency and under-designed for human connection. Spending time outside the office is not a gimmick; it is a much-needed human correction.</p><p>A varied working process also opens more ways of contributing. Different spaces unlock different competencies. Some people speak best in formal rooms; others in motion, or over tea. Inclusion is not only about who is invited, but about the environments we design for participation. Basically, complex systems can’t be redesigned in conference rooms.</p><h3><strong>2. Hold back and wait.</strong></h3><p>Spend time. Percolate. Let plans evolve and be open to change. So much pressure comes from what we assume are procedural rules of the system — deadlines, reporting cycles, funding windows. But what happens when we loosen our grip? What could happen if communities genuinely shaped the direction, rather than reacting to pre-set options?</p><p>This isn’t easy. It often means moving at the “pace of trust” — and trust, that pesky, vague word, takes years to build and only moments to lose. It really means that this work cannot be rushed to meet artificial six-month timelines or funding deadlines. This theme has surfaced repeatedly in my conversations with practitioners and articulated much more fluently than I could dream of, particularly those working in place-based change like <a href=""https://www.linkedin.com/in/johnhitchin/"">John Hitchin</a> or <a href=""https://www.linkedin.com/in/jo-blundell-1b746811/"">Jo Blundell, </a>who have that special skill at crystallising thoughts. The <a href=""https://placeandevidence.substack.com/"">Place &amp; Evidence substack</a> is a shining example of this.</p><p>In many of my own experiences, breakthroughs came only after long stretches of what looked, from the outside, like slow work: listening, showing up, returning again and again. Staying in the deep end long enough for patterns and signals to manifest. People (and by people I mean anyone from the policy teams I work with to the students I support) often ask, “How much research do we need?” But that’s a category error. You don’t know until you start learning — and learning takes time.</p><p>In complex systems, premature solutions often risk strengthening the status quo because they fail to shift underlying conditions. In this context, holding back does not mean being passive. It means resisting premature convergence of ideas. It means allowing relationships to form before solutions harden. It means accepting that the “messy middle” is not a phase to rush through, but that relationships are the core of transformation. Our role as practitioners is to continually pry open the space between problems and solutions, creating room for deeper exploration before closure.</p><h3><strong>3. Lead with deep generosity and an abundance mindset.</strong></h3><p>Reject the conventional economic logic of the “bare minimum” and instead bring intentional generosity and care into every interaction — throughout life and your work.</p><p>This can mean many things and, in public systems, it’s not easy. Generosity can feel naïve. We are trained to optimise, to reduce, to streamline. Time is scarce. Budgets are tight. Engagement becomes extractive almost by default: What do we need from people? How quickly can we get it? How cheaply can we deliver it?</p><p>Leading with deep generosity flips that frame.</p><p>It can mean taking the time to listen deeply to citizens to understand what they value and what makes a place work, rather than leading with data-heavy, deficit-focused profiles. It can mean hosting rather than merely facilitating — setting the boundaries of a space physically, socially and conceptually. Considering how much natural light is in the room. Whether the snacks are nourishing. Whether the space smells right. Whether the premise of gathering feels intentional and human. Even ensuring the font sizes in your document are consistent — because coherence communicates care.</p><figure><img alt=""Example sketch of street transition in Malmö — as part of the Climate KIC Deep Demo project"" src=""https://cdn-images-1.medium.com/max/1024/0*WJ8gULYyxoffYrlU.png"" /><figcaption>Scaling the Right to Retrofit — <a href=""https://provocations.darkmatterlabs.org/scaling-the-right-to-retrofit-3b74aa6b08ad"">Dark Matter Labs</a></figcaption></figure><p>I think that Dark Matter Labs is fantastic at illustrating this principle by arguing that transformation requires shifting underlying logics — not just introducing new tools (See: <a href=""https://provocations.darkmatterlabs.org/dm-threads-52b6a66d939b"">Dm Threads</a>). In this framing, generosity is not softness; it is a structural move. It changes incentives. It signals safety. It invites reciprocity rather than compliance. And when people feel respected and safe, experimentation becomes possible. Risk becomes shared rather than imposed. Generosity creates the conditions for long-term relationships (in perpetuity) rather than one-off transactions. It moves us from episodic engagement to ongoing stewardship.</p><p>Fundamentally, working from abundance recognises the immense skills, networks and energy already present in communities or teams, rather than viewing them through a lens of scarcity, conflict or decline. In complex work, what you choose to amplify matters. An abundance mindset amplifies capability — and capability compounds over time.</p><h3><strong>4. Provide the “milk carton,” not the “flavour.”</strong></h3><p>We have the amazing <a href=""https://www.linkedin.com/in/lauren-dark-566b6965/"">Lauren Dark</a> to thank for this framing. As practitioners, our role is to provide the “scaffolding” and guardrails for participation (the “milk carton”) — such as safeguarding, policies, and frameworks — while allowing the local community to provide their specific identities, responses and lived experiences (the “flavour”).</p><p>This means designing participatory scaffolding around psychological safety and sensory comfort. As with my note on leading with deep generosity, the physical environment is a super easy way to think about shaping how people participate. A bland community hall with poor coffee can put people on edge. Designing lounge-room-like environments — creating front rooms rather than back offices — is part of this shift. Physical space communicates whether power is shared or retained. The container should feel safe enough for people to experiment, disagree and create.</p><p>But the “milk carton” is not only physical. It extends to the social and governance scaffolding we build around engagement. Frameworks such as Free, Prior and Informed Consent (FPIC) ensure that decisions are made freely, in advance and with full information — acting as safeguards for self-determination and sustainable development. This is not bureaucratic box-ticking; it is participatory infrastructure. Practitioners such as <a href=""https://www.linkedin.com/in/julian-thompson-66924652/"">Julian Thompson</a> (through <a href=""https://rootedcentre.org/"">Rooted</a>) are doing super important work in this space, grounding engagement in Design Justice principles. Their work reminds us that inclusion is not neutral. It requires increasing our own capacity to build empathy, recognise positionality and actively avoid harm.</p><p>My own mental model is to remember to avoid the trap of being the “hero” designer and being eternally optimistic about solving everything and helping everyone; instead, we should be striving to act as a translator or craftsperson who helps amplify the brilliant things the community is already doing.</p><h3><strong>5. Building “breadcrumbs” for policy change</strong></h3><p>Relational work is powerful — but fragile. Without translation, it evaporates at the policy interface. To ensure local insights aren’t lost, codify community conversations into thematic “breadcrumbs” that future policy decisions can remain accountable to. Make things tangible.</p><p>Dan Hill (in his book: <a href=""https://medium.com/dark-matter-and-trojan-horses/dark-matter-and-trojan-horses-a-strategic-design-vocabulary-strelka-press-18551fff3133"">Dark Matter and Trojan Horses</a>) refers to these, from a strategic design perspective, as “MacGuffins” — artefacts or interventions that carry narrative weight and create movement within complex systems. Extended through ideas like Trojan Horses, they become strategic devices: visible, workable objects or experiments that bridge the gap between radical local practice and the institutional mindsets of national policymakers. They make change experiential rather than rhetorical — ensuring that inclusive growth is rooted in lived, everyday experience rather than abstract ambition.</p><p>In practice, this means getting your hands dirty. Improvising. Being creative. Perhaps it’s my background in industrial design, but I believe in working through prototypes and experiments that allow participation to become a collective act of change. It means using probes, pilots and live tests to understand how ideas behave in real space — not just on paper. When something is built, placed, trialled or enacted physically, it shifts the narrative. It becomes evidence that listening has occurred in a way people can experience.</p><figure><img alt=""Boris Johnson on a rental bike in London."" src=""https://cdn-images-1.medium.com/max/976/0*ATIXdbuQTLuRMq9l.jpg"" /><figcaption>Question if you will, they’ve had an impact on mobility</figcaption></figure><p>There is something powerful about interventions you can see, touch and use. Think about Santander Cycles — or “Boris Bikes.” Whatever your view on their politics (of both the service and the bureaucrat), they were tangible. Rows of red bicycles appearing across London were visible proof that a conversation about congestion, health and mobility had translated into action. You didn’t need to read a strategy document or look through a spreadsheet to understand that something had changed. The city felt different.</p><p>A shared reference point was created — something that allowed disagreement to be productive rather than abstract. Something for communities to respond to, debate, adapt and reinterpret — not just hypotheticals, but lived experience.</p><p>Without these breadcrumbs, participation risks becoming episodic — a series of conversations that dissolve once the workshop ends. With them, it becomes cumulative. It becomes part of how a place understands itself, and how institutions learn to act differently over time.</p><p><strong>To close…</strong></p><p>None of these thoughts is particularly new. Most of it is slow. All of it is relational. Fundamentally, this note is acting as a reminder. Including citizens in design is not a technique to master, but a way of working to practise — one that redistributes agency not just in theory, but in the everyday spaces where change actually happens.</p><p><em>This post is part of </em><a href=""https://civicworks.substack.com/""><em>CIVICWORKS</em></a><em>; a publication on (re)thinking civic bureaucracy, institutional reform, dynamic capabilities, policymaking and technology.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d28bf115700f"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/practice-notes-on-including-citizens-in-the-design-process-d28bf115700f"">Practice notes on including citizens in the design process</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/innovation-is-not-magic-its-technique-9b3c81a41877?source=rss----138adf9c44c---4,1771003214,Innovation is not magic; it’s technique,"Innovation is not magic; it’s technique

<h4>Who hasn’t been part of a team or company that promises you that the next product will change the world?</h4><figure><img alt=""Designed by kikehey,com"" src=""https://cdn-images-1.medium.com/max/1024/1*kkEcDE6z01zArjC0gLXqZg.png"" /><figcaption>We are used to admiring, copying, and adopting ideas from other companies that have innovated the market.</figcaption></figure><p>Who hasn’t been part of a team or company that promises you that the next product will change the world? Or being part of a project whose mission is to deliver brand new products every x time and behave as an innovation lab? These promises have long been the spirit of the technology business; we know that, but it still feels refreshing every time you jump into a new project or job.</p><p>Maybe this stake is more prominent in start-up environments, where new ideas surface every day and the opportunity for growth is potentially wider. Philosophies like <em>“</em><a href=""https://www.linkedin.com/pulse/build-fast-fail-faster-embracing-agility-imperfection-jonathan-chang/""><em>Build fast, fail fast</em></a><em>” </em>are at the core of an agile mindset, helping us determine whether an idea is viable in the early stages or whether a pivot is necessary to achieve the desired numbers and experience.</p><p><strong>But what happens when an “innovation promised cycle” is built on unsteady ground?</strong> Maybe some of you think that’s the whole point of innovating <em>(building under uncertainty)</em>, but for someone with many years in the industry, I don’t think that formula is always effective.</p><p>I know I’m maybe being very pessimistic, but, truth be told, behind some great product ideas is a lot of mess that eventually generates long-term <em>stress (I’ll explain in a few paragraphs ahead).</em></p><p>When thinking about innovation, most product teams associate this term with ideas and justifications like: “We’re obsessed with users”, “this is what the market needs,” “we need to launch as fast as possible, and then we’ll figure out…”</p><p>From my perspective, <strong>this approach is OK, but somehow incomplete </strong>because it<strong> </strong>neglects everything that might happen within the teams before putting something into the market, and failing to account for this variable will lead to future issues. To explain my point, let me use a graphic.</p><h3>The innovation iceberg</h3><figure><img alt=""Designed by kikehey,com"" src=""https://cdn-images-1.medium.com/max/1024/1*__lobXS7s3dgj1inR-IkDQ.jpeg"" /><figcaption>Innovation is as the result of solid knowledge, experience, and good practices</figcaption></figure><p>We are used to admiring, copying, and adopting ideas from other companies that have innovated the market. It is always a good idea to be inspired by others who have been on a journey like ours. But what we see is the tip of an iceberg, the final shape of something that has been built with some dynamic by some team; But what happens internally in the company is not always visible, and if so, it will be a positive innovation product case open to the public, no one is willing to say that after creating something new, now they have more problems to solve than before.</p><p>The way I see innovation is <strong>as</strong> <strong>the result of solid knowledge, experience, and good practices</strong> that allow me to spot opportunities or issues others haven’t seen, or to make moves others don’t expect. Take, for example, the greatest sports players in history; one of their characteristics is that they dominated the game they played and even changed it, but to do so, they always started with fundamental knowledge and abilities.</p><p><strong>The technique (base of the iceberg)</strong></p><p>Imagine all the greatest players and their glory without knowing how to throw a ball, or dribble, or jump, or make a stroke, hard to believe, right? Technique is what stimulates innovation once you have control of it. For example, in soccer, to perform a bicycle kick, you must first control your kick.</p><p>In companies, I refer to “the technique” as the fundamentals that enable teams to have healthy product dynamics and work as a unit; this is the hidden part of the iceberg, where several factors may influence innovative outcomes. From bottom to top, these are the most relevant:</p><ul><li><strong>The right talent</strong> understands business, anticipates adversity, creates opportunities, and solves issues effectively.</li><li><strong>Proper communication channels and ceremonies</strong> with no room for misunderstanding or assumptions that affect the execution of ideas.</li><li><strong>Defined roles</strong> that leave no room for doubt regarding deliverable expectations and responsibilities.</li><li><strong>Effective work dynamics</strong> that ensure the synchronization of multiple roles towards an objective.</li><li><strong>C-level and stakeholders with a clear business vision</strong> that avoids confusion or ambiguous directions to the teams.</li></ul><p>At the base of the iceberg, you are most likely to find a company's most difficult challenges. The reasons are endless, but it is also a great opportunity to start looking at your company or team and solve foundational problems before thinking about how to change the world with an idea.</p><p>Without “the technique”, launching products might be a wild card with a high probability of being a flawed experience, hard to scale, and hard to manage in the future. Sorry to say this, but sometimes we fall in love with a superficial layer <em>(the tip of the iceberg)</em> rather than changing things from the foundations up.</p><p><strong>The magic (the tip)</strong></p><p>This part of the iceberg is the clutch play in game seven, where glory is the reward. In general, this is the action that makes history or changes the way we see or interact with things. In companies, this is the million-dollar idea: a product that not only performs excellently but also changes user habits and generates money and engagement.</p><p>We’ve all heard stories of people who, one day, spotted or stumbled upon an opportunity and turned it into a billion-dollar business out of nowhere. This part is the romantic side of success, but I’m sure that behind that story, there was a trained instinct or some business preparation that enabled this person to make business magic.</p><p>As the innovation iceberg shows us, a company’s approach to innovation spans multiple levels that directly affect a product. Products should also have a solid foundation that ensures proper management and scalability.</p><h3>Layers of product innovation</h3><figure><img alt=""Designed by kikehey,com"" src=""https://cdn-images-1.medium.com/max/1024/1*M-hzbe6BlQ71X0QaWuXo4g.jpeg"" /></figure><p>If your product development is stable, innovation can be a fun process. Think about having a solar system where the sun is the core that keeps everything working and in sync. The same effect can occur if you have a solid product core <em>(technology, design systems, methodologies, frameworks, communication channels, etc.)</em> that is perfectly orchestrated, so that if one disruptive idea succeeds, it will be easy to scale while maintaining high product standards.</p><p><strong>Levels of experimentation</strong></p><p>As in solar systems, elements farthest from the center are more susceptible to changes in their composition due to their distance. The same effect can occur when you have product ideas that are distant from the product’s core; <strong>they take an experimental nature.</strong> These quick ideas, like satellites, can have a short period of visibility and be fleeting (as in experimentation). When one of these ideas succeeds, making it back to the center to become part of “the system” is easier, and, for sure, it will adopt all your best product standards.</p><figure><img alt=""Designed by kikehey,com"" src=""https://cdn-images-1.medium.com/max/1024/1*RDA2FQZ80fwm4BvAowvmBg.jpeg"" /></figure><p>On the contrary, not having a solid product core and launching experimental ideas to test can be tricky for the company. Imagine you have a wonderful product idea that, in effect, might change the world. Once it shows high adoption and market demand, you need to scale up its structure from an experimental to an official product structure after the test period. Now you have a new product to operate, new users, a new market to seduce, or new technology to support; how do you do this without a proper production dynamic? Well, this is the everyday thing in some start-ups: on the inside, it’s just a mess, and we know messy environments lead to rushed delivery times, people burning out, massive resignations, a fragile culture, or, due to inefficient product growth, massive layoffs.</p><p><strong>My reflection:</strong></p><p><strong>Innovation is not wrong; it is actually the heart of the industry, and we should keep trying harder. </strong>What I think is wrong is trying without first setting high product standards for the company or its teams. In this era of technology-expert proliferation, inspiring messages <em>(the tip of the iceberg)</em> may hide an uncomfortable truth that no one is willing to acknowledge. Maybe I’m being too dramatic about this, but I’ve witnessed this “innovation issue” several times, and its only contribution has been posting on LinkedIn to appear revolutionary.</p><p><em>To write this article, I want to credit all the fantastic information sources and other authors who have written about related topics, each from a different exciting perspective.</em></p><p><a href=""https://medium.com/quirky-rants/from-flexibility-to-innovation-why-the-future-of-work-puts-people-first-01c075865352""><em>From Flexibility to Innovation: Why the Future of Work Puts People First</em></a><em><br /></em><a href=""https://dayakumar06588.medium.com/10-tech-innovation-by-2030-that-will-change-your-life-f8417a163247""><em>10 Tech innovation by 2030 that will change your life</em></a><em><br /></em><a href=""https://www.linkedin.com/pulse/build-fast-fail-faster-embracing-agility-imperfection-jonathan-chang/""><em>Build Fast, Fail Faster: Embracing Agility and Imperfection</em></a><em><br /></em><a href=""https://andreaiorio.com/en/blog/what-is-innovation-in-technology/""><em>What Is Innovation in Technology? A Complete Guide to Digital Transformation</em></a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9b3c81a41877"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/innovation-is-not-magic-its-technique-9b3c81a41877"">Innovation is not magic; it’s technique</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/how-to-start-writing-like-its-easy-e6c344cdb142?source=rss----138adf9c44c---4,1770899238,How to start writing (like it’s easy),"How to start writing (like it’s easy)

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-to-start-writing-like-its-easy-e6c344cdb142?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1280/1*j6LBbKoNukwkrOYnFeQrog.jpeg"" width=""1280"" /></a></p><p class=""medium-feed-snippet"">And how to do hard things in general &#x2014; based on dopamine addiction studies and the pleasure-pain principle.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-to-start-writing-like-its-easy-e6c344cdb142?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/the-80-job-how-design-leads-are-using-ai-and-its-not-about-mockups-ce5df0ed78cf?source=rss----138adf9c44c---4,1770812267,The 80% job: how design leads are using AI — and it’s not about mockups,"The 80% job: how design leads are using AI — and it’s not about mockups

<h3><strong>The 80% job: how design leads are using AI — and it’s not about mockups</strong></h3><h4>Design leads spend 80% of their time communicating, aligning, and justifying. That’s exactly where AI helps most.</h4><figure><img alt=""A drawing of a man looking straight at the camera surrounded by a crowded desk"" src=""https://cdn-images-1.medium.com/max/1024/1*bR4xPhoVSjwHhgLtf6Pdew.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 1: The Reality of Design Leadership</h3><p>Here’s what my job description says I do: set design vision, mentor designers, elevate craft quality, drive innovation.</p><p>Here’s what I actually do: run 1:1s, mediate conflicts, write justifications for decisions, align with stakeholders, update Jira, answer Slack, prepare for meetings, sit in meetings, follow up on meetings.</p><p>I lead a team of 7 designers at a European bank. I can’t remember the last time I opened Figma for actual design work.</p><p>This isn’t a complaint. This is the job. And if you’re a design lead, you probably recognize it.</p><p>(Whether your title is Design Lead, Chapter Lead, Head of Design, or Design Manager — if you’re responsible for other designers and their output, this is for you.)</p><h4>The Myth vs The Reality</h4><p>When I was an individual contributor, I assumed design leads spent their days reviewing designs, setting creative direction, and occasionally stepping in to solve tough UX problems.</p><p>Then I became one.</p><p><a href=""https://medium.com/u/72103bc2102b"">Megan Schofield</a> <strong>Experience Design Manager at Google</strong>, put it perfectly in an interview with <a href=""https://www.goabstract.com/blog/stakeholder-review-meetings"">Abstract</a>:</p><blockquote>“I would be inclined to propose that we, as designers, actually spend a significant amount of time, not designing, but in fact communicating, reviewing, justifying and defending.”</blockquote><p>Here’s what the typical breakdown actually looks like:</p><h4>What job descriptions say:</h4><p>- 30% Design strategy &amp; vision<br />- 25% Mentoring &amp; craft elevation<br />- 20% Stakeholder collaboration<br />- 15% Process improvement<br />- 10% Hands-on design work</p><h4>What the calendar says:</h4><p>- 30% Meetings (syncs, reviews, alignments, 1:1s)<br />- 25% Communication (Slack, email, status updates)<br />- 20% People management (coaching, conflict resolution, career conversations)<br />- 20% Justification (proposals, business cases, defending decisions)<br />- 5% Operations (Jira, planning, HR, tools, budgets)</p><p><strong>That’s 100% before you even get to design.</strong></p><p>Notice what’s missing? Exactly.</p><p>This isn’t because we’re bad at our jobs. It’s because the job isn’t what we thought it was.</p><h4>Why This Happens</h4><p>This isn’t a failure of time management. It’s structural.</p><p>Design leads sit at an intersection that no one else occupies. You’re translating between:</p><p>- Designers who think in users and flows<br />- Developers who think in systems and constraints<br />- Business stakeholders who think in metrics and deadlines</p><p><strong>You’re the only one in the room who speaks all three languages</strong>. So you become the translator, the mediator, the justifier.</p><p>Add to that: most design teams exist inside non-design hierarchies. You report to Product, or Engineering, or in my case, a Tribe Lead responsible for multiple disciplines.</p><p>This means every design decision carries a “<strong>justification tax</strong>” — the time spent explaining, documenting, and defending choices that other disciplines make in a quick conversation.</p><p>When your engineering counterpart says “we’ll use microservices,” nobody asks for a slide deck. When you say “we need to simplify this flow,” suddenly you need user data, business impact, and a prototype to prove it.</p><p>That’s the job. And once you accept it, you can start optimizing for it.</p><h4>The 80% Opportunity</h4><p>Here’s where it gets interesting.</p><p>If 80% of the job is communication, documentation, and justification — that’s exactly where AI tools excel.</p><p>And yes, AI is already changing design work itself. Tools like <a href=""https://cursor.sh/"">Cursor</a>, <a href=""https://lovable.dev/"">Lovable</a>, and <a href=""https://www.figma.com/ai/"">Figma AI</a> mean we’re not starting from scratch anymore — not on code, not on prototypes, not on layouts.</p><p>But here’s what most “AI for designers” content misses: design leads don’t spend their days in Figma. W<strong>e spend them in Slack, Docs, and meetings.</strong></p><p>So while AI-generated mockups get the headlines, the bigger opportunity for leads is quieter: drafting that stakeholder update. Summarizing research into exec-friendly bullets. Turning meeting notes into action items. Writing the first version of a business case.</p><p>The stuff that eats your calendar but doesn’t require your craft skills.</p><p>The next parts of this series will break down exactly how I use AI for each of these:</p><p>- Synthesizing research without drowning in transcripts<br />- Writing business cases that actually get read<br />- Communicating with stakeholders in their language<br />- Enabling my team without becoming a bottleneck</p><p>This isn’t about working faster. <strong>It’s about reclaiming time for the 20% that actually needs a design lead’s judgment</strong>.</p><figure><img alt=""A drawing of an old desk with a big red clock above the desk"" src=""https://cdn-images-1.medium.com/max/1024/1*Q6efJjHmz22Z4Cve-8SPOQ.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 2: AI for Admin — Reclaim Your Time</h3><p>Before we get to the exciting stuff (building prototypes, validating ideas), let’s address the elephant in the room: the 80% of your week that isn’t design work.</p><p>The <a href=""https://www.stateofaidesign.com/"">State of AI in Design Report 2025</a> by Foundation Capital and Designer Fund found that <strong>89% of designers say AI has improved their workflow, with 84% using it in the research and ideation phase while only 39% use it during delivery.</strong>*</p><p><em>*Note: This report comes from VC and investment firms with stakes in the AI design space — it’s useful directional data, not independent academic research.</em></p><p>Design leads? We’re not even in those stats. We’re too busy in meetings.</p><p>So let’s fix that.</p><h4>Start with what hurts most</h4><p>For me, it was meetings. Six a day, sometimes more. By Friday, I couldn’t remember what we decided on Monday. Sound familiar?</p><p>I started using <a href=""https://tactiq.io/"">Tactiq</a>— it sits quietly in my Google Meet or Zoom calls, transcribes everything, and at the end gives me a summary with decisions and action items. What used to take me 20 minutes of post-meeting note cleanup now takes 2. <a href=""https://fireflies.ai/"">Fireflies.ai</a> does something similar and integrates with Slack if that’s where your team lives.</p><p>The trick isn’t the tool. It’s breaking the habit of thinking you need to manually capture everything. You don’t. Let the robot do it.</p><h4>Research doesn’t have to be a black hole</h4><p>Here’s a scenario: you’ve got 12 user interviews, survey results from 200 people, and a competitor analysis your team put together last quarter. Your stakeholder meeting is Thursday. They want “the key insights.”</p><p>This used to mean two days of reading, highlighting, and synthesizing. Now I dump everything into a tool like <a href=""https://dovetail.com/"">Dovetail</a> and ask it to find patterns. “<strong>What are the top 5 pain points mentioned by at least 3 users? Give me direct quotes as evidence.</strong>”</p><p>Is it perfect? No. You still need to sanity-check the output. But it gets you 70% of the way there in 30 minutes instead of 2 days.</p><p><a href=""https://notion.so/product/ai"">Notion AI</a> works well for this too if you’re already living in Notion. It can summarize messy interview notes, pull themes from a database, and clean up transcripts that look like someone typed with their elbows.</p><h4>A note on confidentiality</h4><p>If you work in a regulated industry — banking, healthcare, finance — <strong>you need to think carefully about what data you feed into AI tools</strong>. I work at a European bank with a security department that takes data classification seriously, and rightfully so.</p><p>User interview transcripts, internal research, and anything containing customer data should never go into a public AI tool without clearance. <strong>Check with your security and compliance teams first</strong>. Many organizations now have approved AI tool lists or enterprise versions with data processing agreements in place.</p><p>This isn’t a small thing. In financial services, confidentiality isn’t optional — it’s regulated. Plan your AI workflow around what’s approved, not what’s convenient. The last thing you want is to save 2 hours on research synthesis and spend 2 months explaining a data breach to regulators.</p><h4>Speaking stakeholder</h4><p>This one’s personal. I spend a lot of time translating design decisions into language that non-designers understand. “We need to simplify this flow” doesn’t land. “This flow has a 40% drop-off at step 3, and here’s why” does.</p><p>I use <a href=""https://claude.ai/"">Claude</a> for this. When I need to justify a timeline change or explain why we’re recommending a different approach, I’ll draft my argument and ask it to pressure-test it. “What would a skeptical product manager push back on here?” Then I refine before the actual conversation.</p><p>You can do the same with <a href=""https://chat.openai.com/"">ChatGPT</a>, though I find it tends to be more… diplomatic. Sometimes too diplomatic. When I ask for honest feedback, I want honest feedback, not a sandwich with compliments on both sides.</p><p>For research with sources, I use <a href=""https://perplexity.ai/"">Perplexity</a>. The key is always asking AI to provide references and data — it keeps hallucinations in check.</p><p><strong>Glen Coates, former VP of Product at Shopify (now at OpenAI)</strong>, put it well on <a href=""https://productschool.com/resources/product-podcast/Glen-coates-Ai-first-products"">The Product Podcast</a>:</p><blockquote>“I’ve now started taking screenshots and prompting AI to create a prototype from that. It speeds up the feedback cycle. It also helps me realize how dumb my ideas are before my team has to waste time on them.”</blockquote><p>That’s the mindset. Use AI to stress-test your thinking before you take it to the room.</p><h4>Documentation (the thing nobody wants to do)</h4><p>Engineers need specs. You have Figma files and a head full of context that hasn’t made it onto paper.</p><p>Here’s a prompt I use regularly:</p><p><em>“I’m handing off a new savings goal widget to engineering. It shows progress toward a target amount, lets users adjust their goal, and sends notifications at milestones. Write three user stories in standard format with acceptance criteria.”</em></p><p>What comes back isn’t production-ready, but it’s a solid draft I can refine in <strong>10 minutes</strong>. Compare that to the hour I used to spend staring at a blank Confluence page.</p><p>If your organization runs on Microsoft, <a href=""https://copilot.microsoft.com/"">Copilot</a> does this inside Word and can pull context from your emails and previous docs. Useful if you’re in a corporate environment where everything lives in SharePoint.</p><h4>Budget for exploration</h4><p>One thing I’d recommend: <strong>set aside a small monthly budget</strong> — even €20–30 — specifically for trying new AI tools. Treat it as a learning investment, the same way you’d invest in a course or a design book. Subscribe, experiment for a week, and cancel if it doesn’t add value. Many tools offer free tiers or trials, but the paid features are usually where the real time savings live.</p><p>Just remember to cancel the ones that don’t stick. I’ve learned this one the expensive way.</p><h4>One tool. One week. That’s it.</h4><p>Don’t try to automate your entire workflow overnight. Pick the one task that consistently eats your time:</p><p>- Meetings? Try <a href=""https://tactiq.io/"">Tactiq</a> or <a href=""https://fireflies.ai/"">Fireflies</a><br />- Research synthesis? Try <a href=""https://dovetail.com/"">Dovetail</a> or <a href=""https://notion.so/product/ai"">Notion AI</a><br />- Stakeholder communication? Try <a href=""https://claude.ai/"">Claude</a> or <a href=""https://chat.openai.com/)"">ChatGPT</a><br />- Documentation? Use AI prompts for user stories and specs</p><p><strong>Use it for one week. See if it actually saves time.</strong> Then add another.</p><p>The goal isn’t to become an AI power user. The goal is to reclaim 5 hours a week so you can do the work that actually matters.</p><figure><img alt=""A drawing of a crowded desk with multiple pictures and sketches on the wall"" src=""https://cdn-images-1.medium.com/max/1024/1*DVcMh1vYif_vEckSaRlCqg.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 3: AI for Prototyping — How to Create Again</h3><h4>Remember why you got into design?</h4><p>Not the stakeholder emails. Not the capacity planning spreadsheets. The actual making of things.</p><p>Here’s what happened: as you climbed the ladder, you traded Figma time for meeting time. Makes sense — your value shifted from pixels to decisions. But somewhere along the way, most of us stopped creating anything at all.</p><p>I’m not here to argue that design leads should be doing hands-on design work. We shouldn’t — not for production anyway. That’s our team’s domain, and I’m fortunate to have an amazing team that handles craft with skill and care. <strong>What I don’t want to do is bypass them or create a dynamic where they feel undermined by a lead who keeps jumping into production work</strong>.</p><p>But there’s a different kind of creating that matters: the quick prototype that proves a point. The functional demo that ends the debate. The working thing that gets stakeholders to finally *see* what you’ve been trying to explain.</p><p>That’s what this part is about. Not replacing your team’s work — <strong>de-risking ideas before committing their time</strong>.</p><h4>The Real Problem with Figma Prototypes</h4><p>Traditional Figma prototypes are great for showing flows. Click here, go there, animate this.</p><p>But they hit a wall when you need to prove something works, not just looks right.</p><p>Try explaining a complex interaction to a VP who keeps asking “but what happens when…” and you’ll know what I mean. Or trying to get engineering buy-in on an approach they think is technically impossible.</p><p><a href=""https://medium.com/u/d07005ae7037"">Bryce York</a>, a startup product leader, nails this:</p><blockquote>“If you’re trying to get buy-in on a big concept, this can massively help your stakeholders really understand what you’re pitching. PMs have to have good imaginations, but most stakeholders’ roles don’t!”</blockquote><p>Static prototypes leave too much to imagination. Working prototypes end debates.</p><h4>Enter “Vibe Coding”</h4><p><a href=""https://medium.com/u/ac9d9a35533e"">Andrej Karpathy</a> (co-founder of OpenAI) coined the term in early 2025. The idea: describe what you want in plain language, let AI write the code, iterate by running and refining.</p><p>You don’t need to become an engineer. You need to be able to say “I want a dashboard that shows account activity with filters for date range and transaction type” and get something functional back in minutes.</p><p>For design leads, this isn’t about learning to code. It’s about removing the bottleneck between your vision and something people can actually use.</p><p><a href=""https://www.cmu.edu/iii/about/news/2026/how-ai-and-vibe-coding-transform-product-management.html"">Carnegie Mellon’s Integrated Innovation</a> is already teaching this approach: “We now require vibe-coded prototypes rather than basic wireframes or sketches — reflecting what the workplace will demand.”</p><h4>The Tools (And When to Use Each)</h4><p>There’s no single right tool. Here’s how I think about them:</p><p><a href=""https://www.figma.com/make/"">Figma Make</a> — Best for: staying in your existing workflow</p><p>If your designs already live in Figma, this is the lowest friction option. Paste a frame, describe what you want interactive, and it generates working code. The killer feature: it understands your layers, components, and structure — not just the image.</p><p><a href=""https://medium.com/u/95d97a7d5732"">David Kossnick</a>, Head of AI Product at Figma, describes it:</p><blockquote>“We’re not just bringing the image when you copy a Figma frame. We’re giving AI the rich, structured data — layers, metadata, and styling details.”</blockquote><p>Good for: Quick interactive versions of existing designs, staying in familiar territory, sharing with team</p><p><a href=""https://lovable.dev/"">Lovable</a> — Best for: standalone prototypes without touching code</p><p>Lovable is probably the most designer-friendly of the bunch. You describe what you want, it generates a complete working app. No code editor, no terminal, no git.</p><p><a href=""https://medium.com/u/dc020be79c95"">Christine Vallaure</a> at UX Collective shares a practical tip:</p><blockquote>“If the first result feels messy or off, don’t try to rescue it. Start fresh with a cleaner prompt. It saves time and sanity.”</blockquote><p>The <a href=""https://blog.logrocket.com/ux-design/lovable-ai-for-ux/"">LogRocket team</a> tested it for UX workflows and found it generated a working, mobile-responsive UI with logic in about 20 seconds. Not production code, but enough to validate an idea.</p><p>Good for: Proving concepts to stakeholders, testing flows before committing design resources, personal projects</p><p><a href=""https://cursor.com/"">Cursor</a> — Best for: maximum control and flexibility</p><p>This one has a steeper learning curve — it’s a code editor, not a design tool. But it’s also the most powerful.</p><p><a href=""https://medium.com/u/72b03f90cf7d"">Joel Unger</a> Design Director at Atlassian, uses it to prototype complex Trello interactions:</p><blockquote>“AI is helping designers focus on higher-level thinking, communicate better with developers, and push creative boundaries.”</blockquote><p><a href=""https://medium.com/u/745607030d8e"">Hardik Pandya</a>, also at Atlassian, spent 60+ hours vibe coding an elaborate product experience with data visualization, multi-device flows, and motion. His advice:</p><blockquote>“Your prototype gains the realism that makes stakeholders take it seriously.”</blockquote><p>Good for: Complex interactions, data-driven prototypes, designs that need to work with real APIs</p><h4>When It Goes Wrong</h4><p>It’s worth being honest about the limitations. Vibe coding can go spectacularly wrong when you trust the output without understanding it.</p><p><a href=""https://medium.com/u/9f12350bf325"">Tina Singh</a> wrote about this in Bootcamp: AI-generated prototypes often lose context between iterations, behavior exposes gaps that looked fine in a static design, and evolving a prototype through prompts can start to feel more like chance than craft. Her rule is practical: if you need twenty-plus prompt iterations to get something right, stop. At that point, it’s consuming more time than it saves.</p><p>I’ve hit this myself. I once spent an hour trying to get an AI-generated dashboard to handle edge cases in filter combinations — something my team could have resolved in a fraction of that time with a proper Figma prototype and a dev conversation. The lesson: vibe coding is excellent for proving *concepts*, not for polishing *details*. Know when to hand off.</p><p>Even Karpathy himself — <strong>the person who coined the term </strong>— has acknowledged the limitations. His later projects were hand-coded because AI agents weren’t reliable enough for what he needed.</p><p>The takeaway isn’t “don’t use these tools.” It’s “use them for what they’re good at: quick, disposable prototypes that prove a point and then get thrown away.”</p><h4>The Design Lead Angle</h4><p>Here’s what most “vibe coding tutorials” miss: they’re written for individual contributors who want to build side projects.</p><p>As a design lead, you’re not trying to ship code. You’re trying to:</p><p><strong>1. Win arguments faster</strong> — Instead of three rounds of stakeholder review on a concept, show them something working<br /><strong>2. De-risk before committing resources</strong> — Test if an idea is even viable before putting your team on it<br /><strong>3. Align engineering early</strong> — Nothing gets devs engaged like seeing a working prototype and being asked “is this technically feasible?”</p><p><a href=""https://medium.com/u/abbf40336b08"">Patrick Neeman</a> tested several tools and concluded:</p><blockquote>“These tools are on a path to be game-changing for concept validation and stakeholder buy-in. While it’s not pixel perfect, it gives everyone a good idea how something would work, in some cases eliminating weeks to months of engineering time for realistic testing.”</blockquote><h4>Start Small</h4><p>You don’t need to build a complete product. You need to build enough to prove your point.</p><p>Pick one upcoming decision that’s stuck in debate. Maybe it’s:</p><p>- A new onboarding flow that stakeholders can’t visualize<br />- A dashboard concept engineering thinks is too complex<br />- A mobile feature that keeps getting deprioritized because “we’re not sure it’ll work”</p><p><strong>Spend an hour with one of these tools</strong>. Not to ship anything — just to have something to show.</p><p>The goal isn’t to replace your team’s work. It’s to create the artifact that gets everyone aligned before your team does the real work.</p><h4>What Stays Human</h4><p>One important caveat: these tools get you 70–80% of the way there. The last mile still needs judgment.</p><p><a href=""https://medium.com/u/dfe95783e10e"">Arpi Chugh</a>, a UX designer who tested Lovable extensively, captures it well:</p><blockquote>“I wasn’t using Lovable to come up with the design. I used it to test the design I already had in my head — faster than I ever could with traditional tools.”</blockquote><p>The thinking is still yours. The strategy is still yours. The AI just removes the friction between having an idea and being able to show it.</p><figure><img alt=""Drawing of an agenda with a big green checkmark and multiple annotations"" src=""https://cdn-images-1.medium.com/max/1024/1*3kpUMG70NfcAj12FpgoR1Q.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 4: Validate Fast — From Prototype to Proof</h3><p>You built the prototype. It looks good. Stakeholders can click around.</p><p>Now what?</p><p>Here’s where most design leads make a mistake: they treat the AI-generated prototype as the deliverable. It’s not. The prototype is a hypothesis. What you need is evidence.</p><p>This part is about turning “I think this works” into “Here’s proof it works” — fast enough that you don’t lose momentum.</p><h4>The Justification Tax</h4><p>In Part 1, I introduced the “justification tax” — the disproportionate amount of time design leads spend defending decisions that other disciplines make with a quick conversation. That tax doesn’t disappear once you have a prototype. If anything, it gets heavier: now stakeholders have something tangible to have opinions about.</p><p><a href=""https://medium.com/u/172db8dc4450"">Tom Greever</a>, author of <a href=""https://www.goodreads.com/book/show/25520974-articulating-design-decisions"">Articulating Design Decisions</a>, puts it bluntly:</p><blockquote>“The most articulate person often wins.”</blockquote><p>That’s the problem. You shouldn’t have to be the most articulate person. You should have data.</p><p>AI prototyping gets you the artifact faster. Quick validation gets you the evidence to defend it.</p><h4>Why AI Prototypes Still Need Testing</h4><p>There’s a reason <a href=""https://www.nngroup.com/"">Nielsen Norman Group</a> keeps warning about AI-generated designs: <strong>they often have visual issues like poor hierarchy, inconsistent spacing, and low contrast. They look plausible but don’t actually work.</strong></p><p><a href=""https://maze.co/collections/ai/validate-ai-prototypes/"">Maze’s research</a> on testing AI prototypes found three common problems:</p><p><strong>1. Looks right, works wrong</strong> — AI creates what’s statistically likely, not what’s strategically correct. Navigation that seems logical might confuse real users.<br /><strong>2. Lacks real context</strong> — AI doesn’t understand your business goals, audience history, or product constraints. It generates generic solutions.<br /><strong>3. Breaks design systems</strong> — Enterprise teams find AI-generated designs ignore component rules and brand guidelines.</p><p>The fix isn’t to avoid AI prototyping. It’s to validate quickly before anyone falls in love with the wrong solution.</p><h3>The 30-Minute Validation Loop</h3><p>Here’s the workflow that changed how I approach stakeholder debates:</p><h4>Step 1: Build competing prototypes (30–60 min)</h4><p>When your team argues about approaches, don’t debate. Build both versions using <a href=""https://lovable.dev/"">Lovable</a>, <a href=""https://www.figma.com/make/"">Figma Make</a>, or <a href=""https://cursor.com/"">Cursor</a>.</p><p>Two functional prototypes beat two hours of whiteboard arguments.</p><h4>Step 2: Set up a quick test (15–30 min)</h4><p><a href=""https://maze.co/"">Maze</a> integrates directly with Figma prototypes and now supports AI-generated prototypes from Lovable and Bolt. Define one clear task: “<strong>Find and start a savings goal</strong>” or “<strong>Complete the first step of onboarding.</strong>”</p><p>Keep it simple. One task. One success metric. Five to ten participants.</p><h4>Step 3: Let data settle the debate (results in 1–2 hours*)</h4><p>Maze shows completion rates, time-on-task, and heatmaps in near real-time. You’re not looking for statistical significance — you’re looking for obvious signals.</p><p>If Version A has 80% completion and Version B has 45%, t<strong>he debate is over</strong>.</p><ul><li><em>Note: The 1–2 hour turnaround depends on using Maze’s paid participant panel. If you’re recruiting your own users, expect longer. The completion rate example above is hypothetical to illustrate the point — in practice, your numbers will vary based on task complexity and audience.</em></li></ul><h4>Depersonalizing Design Debates</h4><p>Here’s something I’ve learned managing 7 designers: ego kills collaboration.</p><p>When designers argue about approaches, they’re often defending their taste, not the user. “I think users would prefer X” vs “No, Y is more intuitive” is an unwinnable argument because it’s subjective.</p><p>Quick validation shifts the conversation. The prototype becomes neutral ground. It’s not “your idea vs. my idea” — it’s “let’s see what users actually do.”</p><p><a href=""https://www.lyssna.com/blog/data-driven-design/"">TEG (The Economist Group)</a> adopted this approach and found they could “set up tests and get data in minutes, reducing the need for lengthy discussions and debates based on assumptions.”</p><p>As a lead, you’re not always the tiebreaker. You’re the one who creates conditions for evidence-based decisions.</p><h4>Tools for Quick Validation</h4><p><a href=""https://maze.co/"">Maze</a> — The fastest path from prototype to data</p><p>Best for: Quantitative validation (completion rates, heatmaps, paths). Integrates with Figma, supports AI-generated prototypes from Lovable, Bolt, and Figma Make. Results arrive in 1–2 hours with their panel, or share with your own users.</p><p><em>Pricing: Free tier available, paid starts at $99/month.</em></p><p><a href=""https://attentioninsight.com/"">Attention Insight</a> — Predict attention before testing</p><p>Uses AI to generate eye-tracking heatmaps based on visual saliency. Good for quick gut-checks on hierarchy and CTA visibility before you run real tests.</p><p><a href=""https://hotjar.com/"">Hotjar</a> — For live products</p><p>If your prototype is deployed (Lovable and Bolt can do this), Hotjar gives you session recordings and heatmaps of real behavior.</p><p><strong>Lightweight alternatives:</strong></p><ul><li>5-second tests (first impressions, what users notice)<br />- First-click tests (where users expect to tap)<br />- Quick surveys right after tasks (“How confident did you feel?”)</li></ul><h4>The Prompt Formula for Clear Results</h4><p>Speaking of prompts — they matter for testing too. Borrowed from the <a href=""https://adplist.org/"">ADPList AI Design ebook</a>, here’s a formula worth bookmarking:</p><p><strong>[Context] + [Task] + [Format] + [Tone] + [Constraints]</strong></p><p>Applied to test task writing:</p><p><strong>Bad:</strong> “Explore the app and tell us what you think.”</p><p><strong>Better:</strong> “You want to start saving €50/month for a vacation. Find where to set up a savings goal and complete the first step.”</p><p>The second version has context (user goal), clear task (specific action), and implicit success criteria (completing the step).</p><h4>When NOT to Validate</h4><p>Quick validation isn’t always the answer. Skip it when:</p><p>- <strong>The decision is reversible </strong>— If you can ship and iterate, ship and iterate<br />- <strong>Stakeholders aren’t actually blocking </strong>— Don’t create process where you don’t need it<br /><strong>- You’re optimizing prematurely</strong>— Early concepts need room to breathe</p><p>Use validation strategically: when there’s real disagreement, real risk, or real investment at stake.</p><h4>From Evidence to Alignment</h4><p>The goal isn’t just to win arguments. It’s to create shared understanding.</p><p>When you bring test results to a stakeholder meeting, you’re not saying “<strong>I was right.</strong>” You’re saying “<strong>Here’s what we learned together.</strong>”</p><p><a href=""https://attentioninsight.com/complete-guide-to-data-driven-design/"">Data-driven design</a> research shows that “<strong>data provides a common language for teams and stakeholders to discuss design decisions.</strong>” The evidence becomes the foundation, not your opinion.</p><figure><img alt=""Drawing of three papers on a desk with multiple stamps and signatures"" src=""https://cdn-images-1.medium.com/max/1024/1*f6-q_lL-gf11hrpeYyza-w.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 5: The Pitch — Prototype + Data = No Debate</h3><p>You’ve built the prototype. You’ve tested it. You have data.</p><p>Now comes the moment that separates design leads who get things built from those who get stuck in endless review cycles: the pitch.</p><p>This isn’t about presentation skills or PowerPoint templates. It’s about bringing the right artifacts to the right people and making decisions inevitable.</p><h4>Why Most Design Pitches Fail</h4><p>Here’s the pattern I see constantly:</p><p>Designer presents beautiful mockups. Stakeholder says “I like it, but…” followed by personal preferences. Engineering says “That looks hard.” Meeting ends with “Let’s iterate and reconvene.”</p><p>Three weeks later, same meeting.</p><p><strong>The problem isn’t the design. It’s the forma</strong>t.</p><p>Static mockups invite opinion. Working prototypes invite reaction. Data invites alignment.</p><p><a href=""https://medium.com/u/9093eee038b2"">Todd Zaki Warfel</a>, former design executive at Twitter, Cisco, and Workday, puts it simply:</p><blockquote>“When you learn to present your work with the right balance of proof and persuasion, you can win over your stakeholders.”</blockquote><p>The balance matters. Proof without persuasion is a data dump. Persuasion without proof is just opinion vs. opinion.</p><h3>The Three-Part Pitch Stack</h3><p>After years of pitching designs (and watching many fail), here’s the structure that works:</p><h4>1. The Working Prototype</h4><p>Let them click. Let them experience. Don’t explain what it does — show them.</p><p>AI-generated prototypes from <a href=""https://lovable.dev/"">Lovable</a>, <a href=""https://www.figma.com/make/"">Figma Make</a>, or <a href=""https://cursor.com/"">Cursor</a> change the dynamic immediately. Instead of imagining what something might feel like, stakeholders interact with it directly.</p><p><a href=""https://blog.pixelfreestudio.com/how-to-use-interactive-prototypes-for-stakeholder-presentations/"">PixelFreeStudio’s research</a> on prototype presentations found:</p><blockquote>“When stakeholders are actively involved in the presentation, they’re more likely to feel a sense of ownership over the project, which can lead to stronger support and enthusiasm for your ideas.”</blockquote><p>The prototype creates shared experience. <strong>Everyone saw the same thing</strong>.</p><h4>2. The Validation Data</h4><p>This is where Part 4’s work pays off.</p><p>Don’t just say “users preferred this approach.” Show them:</p><p>- Completion rates (80% vs. 45%)<br />- Time-on-task differences<br />- Heatmaps showing where attention goes<br />- Direct user quotes from testing</p><p>Data doesn’t eliminate disagreement. But it changes the nature of the conversation from “<strong>I feel</strong>” to “<strong>users showed us</strong>.”</p><h4>3. The Engineering Alignment</h4><p>Here’s where most design leads drop the ball: they pitch to stakeholders <strong>before</strong> talking to engineering.</p><p>Then engineering raises feasibility concerns in the meeting. Stakeholder confidence drops. The pitch stalls.</p><p>Flip the order. Before your stakeholder meeting:</p><p>- Share the prototype with engineering leads<br />- Ask: “<strong>Is this technically feasible? What would be hard?</strong>”<br />- Identify constraints and incorporate them into your pitch</p><p>When you present, you’re not saying “here’s what we want.” You’re saying “<strong>here’s what we’ve validated with users and confirmed with engineering.</strong>”</p><p>That’s a different conversation entirely.</p><h3>Tailoring the Pitch to Your Audience</h3><p>Different stakeholders care about different things. Obvious, but most design leads present the same deck to everyone.</p><h4>For Executives (VP+):</h4><p>- Lead with business impact, not design rationale<br />- Keep it short — they’re comparing your pitch to ten other priorities<br />- Show you’ve de-risked it: “Users validated this, engineering confirmed feasibility”<br />- Have a clear ask: approval, resources, timeline</p><h4>For Product Managers:</h4><p>- Connect to roadmap and OKRs<br />- Show user evidence that supports their metrics<br />- Be clear about dependencies and trade-offs</p><h4>For Engineering Leads:</h4><ul><li>Show the prototype early (before the big meeting)<br />- Ask genuine questions about feasibility<br />- Demonstrate you’ve thought about edge cases<br />- The AI prototype’s code isn’t production-ready — acknowledge that</li></ul><p>As <a href=""https://medium.com/u/216d1f5cc211"">Greg Becker</a> notes:</p><blockquote>“They don’t speak your language — you must speak theirs.”</blockquote><h3>The “No Surprises” Rule</h3><p>The biggest pitching mistake I see design leads make: surprising people in meetings.</p><p>Stakeholders hate surprises. If your VP learns about a major design direction for the first time in a review meeting, you’ve already lost — even if the design is perfect.</p><h4>Here’s my pre-meeting checklist:</h4><p>• Engineering has seen the prototype and raised concerns (which I’ve addressed)<br />• Product knows how this connects to their goals<br />• Key stakeholders got a heads-up about the direction<br />• I know what objections are coming and have responses ready</p><p>The meeting becomes confirmation, not revelation.</p><h4>Handling the “But What About…” Questions</h4><p>Even with great prep, you’ll get questions. Here’s how to handle common ones:</p><p><strong>”Can we also add [feature X]?”</strong></p><p>Don’t say no. Say: “We can test that. Let me add it to the next validation round and show you what users think.”</p><p>You’ve shifted from defending to learning.</p><p><strong>”Engineering says this is too complex.”</strong></p><p>If you’ve done pre-alignment, this shouldn’t happen. If it does: “Let’s schedule a technical review. I want to understand the constraints so we can find a solution that works.”</p><p><strong>”I just don’t like [specific element].”</strong></p><p>This is the hardest one — pure preference. Your response: “I hear you. We tested this with [X] users and [specific result]. Happy to test an alternative if you’d like to see the comparison.”</p><p>You’re not dismissing their opinion. You’re offering to put it to the same test everything else went through.</p><h4>The AI Advantage in Pitching</h4><p>Here’s what changes with AI prototyping in your pitch toolkit:</p><p><strong>Speed of alternatives:</strong> Stakeholder suggests a different approach? You can often build and test it before the next meeting. That used to take weeks.</p><p><strong>Tangibility over imagination:</strong> Working prototypes bridge the imagination gap. Most stakeholders’ roles don’t require them to envision complex interactions from mockups alone — so don’t ask them to.</p><p><strong>Lower stakes for testing:</strong> When prototypes take days, testing every idea feels expensive. When they take hours, you can test stakeholder suggestions without derailing your timeline.</p><p><strong>Code as communication:</strong> If your prototype was built in Cursor with React components, engineering can see exactly what you’re proposing. It’s not “can you build something that looks like this?” — it’s “here’s a working version, how close is this to production-ready?”</p><h4>The Follow-Through</h4><p>The pitch doesn’t end when the meeting ends.</p><p><strong>Within 24 hours:</strong></p><p>- Send a summary of decisions made and next steps<br />- Share the prototype link (so stakeholders can revisit)<br />- Note any open questions and when you’ll address them<br />- Thank engineering for their input (publicly, if appropriate)</p><p>This isn’t just courtesy. It creates a paper trail that prevents “I don’t remember agreeing to that” in future meetings.</p><h4>From Pitch to Build</h4><p>When your pitch succeeds, the transition to development should be smooth because you’ve done the work:</p><p>- Prototype demonstrates the interaction model<br />- Test data shows user acceptance<br />- Engineering has already reviewed feasibility<br />- Stakeholders are aligned on the direction</p><p><a href=""https://www.figma.com/blog/the-designers-handbook-for-developer-handoff/"">Figma’s design handoff guide</a> emphasizes:</p><blockquote>“By working together with a shared language, designers and developers can avoid misalignment, reduce re-work, and confidently build a well designed and technically sound product together.”</blockquote><p>The prototype isn’t the deliverable. The prototype was the tool that got everyone to “yes.”</p><figure><img alt=""The same character from the beguining of the article looking at a selfie camera and smiling"" src=""https://cdn-images-1.medium.com/max/1024/1*aTOIjzE93lnX9E4-vfv2zw.png"" /><figcaption>Image generated with <a href=""https://www.midjourney.com"">Midjourney</a></figcaption></figure><h3>Part 6: The Future of Design Leads — What Stays Human</h3><p>Let’s end where we started: with the reality of the job.</p><p>Design leads don’t spend their days designing. They spend them communicating, aligning, justifying, and managing. The 80% job.</p><p>AI is getting very good at the 20% — the mockups, the prototypes, the visual production. What it can’t do is the 80%.</p><p>That’s not a bug. That’s your future.</p><h4>The Skill Shift Is Already Happening</h4><p><a href=""https://www.figma.com/blog/figma-2025-ai-report-perspectives/"">Figma’s 2025 AI Report</a> surveyed thousands of designers and found something interesting: 52% of AI builders say design is <strong>more important</strong> for AI-powered products than traditional ones, not less.</p><p>The reason? AI outputs need curation, judgment, and quality control. Someone has to decide what’s good. Someone has to connect it to strategy. Someone has to make sure it actually solves the user’s problem.</p><p><strong>That someone is still human.</strong></p><p><a href=""https://www.nngroup.com/"">Nielsen Norman Group</a> noted in 2025 that while generative tools can speed up tasks like asset creation and copy generation, <strong>“they still can’t replicate the insight of human designers.”</strong></p><p>The tools are changing. The need for design thinking isn’t.</p><h3>What AI Cannot Do</h3><p>Let me be specific about what stays human — not in theory, but from experience.</p><h4>Judgment and taste.</h4><p>AI generates options. Humans choose. <a href=""https://medium.com/u/677fcb8f826d"">Andrea Grigsby</a> in UX Collective put it simply: <strong>“AI may automate technical skills in design, but it can’t replicate human taste.”</strong> Taste isn’t preference — it’s the accumulated wisdom of knowing what works, what feels right, what aligns with brand and user and context simultaneously. It’s the thing that makes you say “this doesn’t feel right” before you can articulate why. AI can produce a thousand variations. You’re the one who knows which one is <strong>right</strong>.</p><h4>Stakeholder navigation.</h4><p>No AI is sitting in your meeting reading the room. Understanding that the VP is skeptical because of a failed project last quarter. Knowing that engineering is stretched and needs a simpler solution. Sensing that the PM is worried about timeline but won’t say it directly. I learned this lesson deeply at a previous job, when I had to present a product vision directly to the multinational CEO. Before the meeting, <strong>I did extensive research — his decision-making style, his priorities, what resonated with him</strong>. I talked to people who’d presented to him before. Then I spent weeks quietly getting his most trusted advisors on my side, making sure they understood and supported the vision before I ever walked into that room. The presentation was a success — <strong>it defined a product we worked on for two years, led to hiring two new development teams from Portugal, and more than doubled the UX team size</strong>. No AI could have navigated that. The research, the relationship-building, the reading of organizational dynamics — those are fundamentally human skills that determine whether your work gets built or gets stuck.</p><h4>Team development.</h4><p>You manage people. Each has different strengths, motivations, and career goals. AI can’t coach someone through a confidence crisis. It can’t mediate a conflict between two designers who have different working styles. It can’t help a junior designer see the gap between where they are and where they want to be. <a href=""https://www.thecaragroup.com/leadership-in-the-ai-era/"">Research from the Top Employers Institute</a> shows that <strong>68% of employees believe non-work-related training that supports their overall well-being is vital</strong>. Leadership is about the whole person, not just their output.</p><h4>Ethical decision-making.</h4><p>Should we use this dark pattern that increases conversions but frustrates users? Should we collect this data even though users probably don’t understand what they’re agreeing to? Should we ship this feature knowing it’s not accessible? AI doesn’t have values. You do. <a href=""https://aijourn.com/human-intelligence-in-an-ai-world-why-empathy-sense-making-and-ethical-judgement-still-decide-enterprise-success/"">McKinsey’s research</a> found that <strong>only 1% of companies feel “mature” in AI integration</strong>, and the biggest barriers are not technical but leadership and organizational factors.</p><h4>Sense-making in ambiguity.</h4><p>When the strategy is unclear, when stakeholders disagree, when the data points in multiple directions — <strong>that’s when human judgment matters most</strong>. AI excels with clear inputs and defined parameters. Real design leadership happens when neither exists.</p><h3>The Design Lead of 2028</h3><p>Based on everything we’ve covered, here’s my bet on what the design lead role looks like in a few years.</p><p><strong>AI transformation of creative work is accelerating</strong> — the tools we’ve discussed in this series were barely functional two years ago, and they’re now reshaping workflows daily. I don’t know exactly how fast or how far this goes, but the direction is clear: the tactical parts of design work will increasingly be handled by AI, and the strategic, human parts will become more valuable, not less.</p><p>Design leads will <strong>spend less time on creating production-ready mockups</strong>, writing documentation from scratch, synthesizing research manually, and building presentation decks. <strong>They’ll spend more time on evaluating and curating AI outputs</strong>, coaching team members through AI-augmented workflows, stakeholder alignment and organizational navigation, defining what “good” looks like for AI tools, and ethical oversight and quality judgment.</p><p>The title might stay the same. <strong>The job changes significantly.</strong></p><p><a href=""https://medium.com/u/1dd0fcefd09a"">Maya Brennan</a> 2026 predictions in <a href=""https://medium.com/design-bootcamp/10-predictions-for-ai-design-in-2026-823da9f1db7b"">Bootcamp</a> capture it:</p><blockquote>“It’s an undoubtedly exciting time to be a Product Designer: the technical foundations have been built — and it is now up to us to re-imagine what the visual and interactive frameworks for these AI experiences will look like.”</blockquote><p>The people defining those frameworks won’t be AI. <strong>They’ll be design leaders with taste, judgment, and organizational skill.</strong></p><h3>Your Competitive Advantage</h3><p>If you’ve made it through this series, you have something most design leads don’t: a practical framework for using AI <strong>as a lead</strong>, not just as an individual contributor.</p><p>Let’s recap what we covered:</p><p><strong>Part 1: The reality of design leadership </strong>— the 80% job is communication, not creation.</p><p><strong>Part 2: AI for admin work</strong> — reclaim time through meeting notes, research synthesis, stakeholder communication, and documentation.</p><p><strong>Part 3: AI for prototyping</strong> — vibe coding tools that let you create again, not to ship production work, but to prove ideas faster.</p><p><strong>Part 4: Quick validation</strong> — testing tools to turn prototypes into evidence that ends debates.</p><p><strong>Part 5: The pitch</strong> — prototype + data + engineering alignment = decisions that stick.</p><p><strong>Part 6: What stays human</strong> — judgment, taste, leadership, ethics, and the ability to navigate ambiguity.</p><p>This isn’t about AI replacing you. It’s about <strong>AI handling the friction so you can focus on the work that actually requires a design lead</strong>.</p><h3><strong>What To Do Next</strong></h3><p>If you take one thing from this series:</p><p><strong>Start using AI for one task this week.</strong></p><p>Not everything. Not a complete workflow transformation. One task.</p><p>Maybe it’s meeting notes. Maybe it’s drafting a stakeholder email. Maybe it’s spinning up a quick prototype for an idea that’s been stuck in your head.</p><p>Build the muscle. See what works. Iterate.</p><p>That’s how design leads have always improved — by doing, learning, and adjusting.</p><p>The tools are different now. The approach is the same.</p><p><em>I’m a Chapter Lead managing designers at a European bank. I write about the messy intersection of AI, design leadership, and organizational reality — the stuff that doesn’t fit into neat tutorials. If this resonated with you (or you disagree with any of it), I’d genuinely like to hear from you. The best conversations I’ve had about this topic started with someone telling me I was wrong about something.</em></p><p><em>Find me on </em><a href=""https://linkedin.com/in/vladderdeicea""><em>LinkedIn</em></a><em> or </em><a href=""https://medium.com/@vlad.derdeicea""><em>Medium</em></a></p><p><em>Resources &amp; referrals:</em></p><ul><li><em>Meghan Schofield / Abstract: </em><a href=""https://www.goabstract.com/blog/stakeholder-review-meetings""><em>https://www.goabstract.com/blog/stakeholder-review-meetings</em></a></li><li><em>Cursor: </em><a href=""https://cursor.sh/""><em>https://cursor.sh/</em></a></li><li><em>Lovable: </em><a href=""https://lovable.dev/""><em>https://lovable.dev/</em></a></li><li><em>Figma AI: </em><a href=""https://www.figma.com/ai/""><em>https://www.figma.com/ai/</em></a></li><li><em>State of AI in Design Report 2025: </em><a href=""https://www.stateofaidesign.com/""><em>https://www.stateofaidesign.com/</em></a></li><li><em>Tactiq: </em><a href=""https://tactiq.io/""><em>https://tactiq.io/</em></a></li><li><em>Fireflies.ai: </em><a href=""https://fireflies.ai/""><em>https://fireflies.ai/</em></a></li><li><em>Dovetail: </em><a href=""https://dovetail.com/""><em>https://dovetail.com/</em></a></li><li><em>Notion AI: </em><a href=""https://notion.so/product/ai""><em>https://notion.so/product/ai</em></a></li><li><em>Claude: </em><a href=""https://claude.ai/""><em>https://claude.ai/</em></a></li><li><em>ChatGPT: </em><a href=""https://chat.openai.com/""><em>https://chat.openai.com/</em></a></li><li><em>Perplexity: </em><a href=""https://perplexity.ai/""><em>https://perplexity.ai/</em></a></li><li><em>Glen Coates / The Product Podcast: </em><a href=""https://productschool.com/resources/product-podcast/Glen-coates-Ai-first-products""><em>https://productschool.com/resources/product-podcast/Glen-coates-Ai-first-products</em></a></li><li><em>Microsoft Copilot: </em><a href=""https://copilot.microsoft.com/""><em>https://copilot.microsoft.com/</em></a></li><li><em>Bryce York: </em><a href=""https://bryceyork.com/vibe-coding-prototypes/""><em>https://bryceyork.com/vibe-coding-prototypes/</em></a></li><li><em>Andrej Karpathy: </em><a href=""https://x.com/karpathy""><em>https://x.com/karpathy</em></a></li><li><em>Carnegie Mellon III: </em><a href=""https://www.cmu.edu/iii/about/news/2026/how-ai-and-vibe-coding-transform-product-management.html""><em>https://www.cmu.edu/iii/about/news/2026/how-ai-and-vibe-coding-transform-product-management.html</em></a></li><li><em>Figma Make: </em><a href=""https://www.figma.com/make/""><em>https://www.figma.com/make/</em></a></li><li><em>David Kossnick / Creator Economy: </em><a href=""https://creatoreconomy.so/p/figmas-make-ai-prototyping-tool-is-here""><em>https://creatoreconomy.so/p/figmas-make-ai-prototyping-tool-is-here</em></a></li><li><em>Lovable: </em><a href=""https://lovable.dev/""><em>https://lovable.dev/</em></a></li><li><em>Christine Vallaure / UX Collective: </em><a href=""https://uxdesign.cc/getting-started-with-lovable-the-no-hype-beginner-tips-to-building-with-ai-36460d46249d""><em>https://uxdesign.cc/getting-started-with-lovable-the-no-hype-beginner-tips-to-building-with-ai-36460d46249d</em></a></li><li><em>LogRocket on Lovable: </em><a href=""https://blog.logrocket.com/ux-design/lovable-ai-for-ux/""><em>https://blog.logrocket.com/ux-design/lovable-ai-for-ux/</em></a></li><li><em>Cursor: </em><a href=""https://cursor.com/""><em>https://cursor.com/</em></a></li><li><em>Joel Unger / Lenny’s Newsletter: </em><a href=""https://www.lennysnewsletter.com/p/a-designers-guide-to-ai-building""><em>https://www.lennysnewsletter.com/p/a-designers-guide-to-ai-building</em></a></li><li><em>Hardik Pandya: </em><a href=""https://hvpandya.com/vibe-coding""><em>https://hvpandya.com/vibe-coding</em></a></li><li><em>Tina Singh / Bootcamp: </em><a href=""https://medium.com/design-bootcamp/ai-isnt-replacing-designers-but-vibe-coding-is-already-failing-them-265950813edb""><em>https://medium.com/design-bootcamp/ai-isnt-replacing-designers-but-vibe-coding-is-already-failing-them-265950813edb</em></a></li><li><em>Arpi Chugh: </em><a href=""https://medium.com/@arpichugh/lovable-ai-review-rapid-prototyping-complex-ux-ideas-without-code-a04e63ed8494""><em>https://medium.com/@arpichugh/lovable-ai-review-rapid-prototyping-complex-ux-ideas-without-code-a04e63ed8494</em></a></li><li><em>Patrick Neeman: </em><a href=""https://medium.com/@usabilitycounts/the-vibe-coding-bakeoff-for-generative-ai-prototyping-tools-bolt-lovable-replit-and-v0-876bfc13fd2f""><em>https://medium.com/@usabilitycounts/the-vibe-coding-bakeoff-for-generative-ai-prototyping-tools-bolt-lovable-replit-and-v0-876bfc13fd2f</em></a></li><li><em>Tom Greever / Articulating Design Decisions: </em><a href=""https://www.goodreads.com/book/show/25520974-articulating-design-decisions""><em>https://www.goodreads.com/book/show/25520974-articulating-design-decisions</em></a></li><li><em>Nielsen Norman Group: </em><a href=""https://www.nngroup.com/""><em>https://www.nngroup.com/</em></a></li><li><em>Maze on AI prototypes: </em><a href=""https://maze.co/collections/ai/validate-ai-prototypes/""><em>https://maze.co/collections/ai/validate-ai-prototypes/</em></a></li><li><em>Maze: </em><a href=""https://maze.co/""><em>https://maze.co/</em></a></li><li><em>Figma Make: </em><a href=""https://www.figma.com/make/""><em>https://www.figma.com/make/</em></a></li><li><em>Attention Insight: </em><a href=""https://attentioninsight.com/""><em>https://attentioninsight.com/</em></a></li><li><em>Hotjar: </em><a href=""https://hotjar.com/""><em>https://hotjar.com/</em></a></li><li><em>ADPList AI Design ebook: </em><a href=""https://adplist.org/""><em>https://adplist.org/</em></a></li><li><em>TEG / Lyssna: </em><a href=""https://www.lyssna.com/blog/data-driven-design/""><em>https://www.lyssna.com/blog/data-driven-design/</em></a></li><li><em>Data-driven design guide: </em><a href=""https://attentioninsight.com/complete-guide-to-data-driven-design/""><em>https://attentioninsight.com/complete-guide-to-data-driven-design/</em></a></li><li><em>Todd Zaki Warfel / IxDF: </em><a href=""https://www.interaction-design.org/master-classes/present-your-designs-effectively""><em>https://www.interaction-design.org/master-classes/present-your-designs-effectively</em></a></li><li><em>PixelFreeStudio: </em><a href=""https://blog.pixelfreestudio.com/how-to-use-interactive-prototypes-for-stakeholder-presentations/""><em>https://blog.pixelfreestudio.com/how-to-use-interactive-prototypes-for-stakeholder-presentations/</em></a></li><li><em>Greg Becker: </em><a href=""https://www.linkedin.com/pulse/art-pitching-design-stakeholders-greg-becker""><em>https://www.linkedin.com/pulse/art-pitching-design-stakeholders-greg-becker</em></a></li><li><em>Figma design handoff guide: </em><a href=""https://www.figma.com/blog/the-designers-handbook-for-developer-handoff/""><em>https://www.figma.com/blog/the-designers-handbook-for-developer-handoff/</em></a></li><li><em>Figma 2025 AI Report: </em><a href=""https://www.figma.com/blog/figma-2025-ai-report-perspectives/""><em>https://www.figma.com/blog/figma-2025-ai-report-perspectives/</em></a></li><li><em>Nielsen Norman Group: </em><a href=""https://www.nngroup.com/""><em>https://www.nngroup.com/</em></a></li><li><em>Andrea Grigsby / UX Collective: </em><a href=""https://uxdesign.cc/ai-is-coming-for-our-design-jobs-but-it-cant-touch-taste-afd5c7a48184""><em>https://uxdesign.cc/ai-is-coming-for-our-design-jobs-but-it-cant-touch-taste-afd5c7a48184</em></a></li><li><em>Top Employers Institute / Cara Group: </em><a href=""https://www.thecaragroup.com/leadership-in-the-ai-era/""><em>https://www.thecaragroup.com/leadership-in-the-ai-era/</em></a></li><li><em>McKinsey / AI Journal: </em><a href=""https://aijourn.com/human-intelligence-in-an-ai-world-why-empathy-sense-making-and-ethical-judgement-still-decide-enterprise-success/""><em>https://aijourn.com/human-intelligence-in-an-ai-world-why-empathy-sense-making-and-ethical-judgement-still-decide-enterprise-success/</em></a></li><li><em>Maya Brennan / Bootcamp: </em><a href=""https://medium.com/design-bootcamp/10-predictions-for-ai-design-in-2026-823da9f1db7b""><em>https://medium.com/design-bootcamp/10-predictions-for-ai-design-in-2026-823da9f1db7b</em></a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce5df0ed78cf"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-80-job-how-design-leads-are-using-ai-and-its-not-about-mockups-ce5df0ed78cf"">The 80% job: how design leads are using AI — and it’s not about mockups</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/when-ai-passes-the-capitalist-turing-test-18baacbcf18f?source=rss----138adf9c44c---4,1770757865,When AI passes the capitalist Turing test,"When AI passes the capitalist Turing test

<h4><em>AI was meant to explain and augment human intelligence. Why aren’t we getting any closer?</em></h4><figure><img alt=""A collage showing a human brain, a computer, and a question mark between them"" src=""https://cdn-images-1.medium.com/max/1024/1*v1kRKKNAbbcydVYRHJ9eUg.jpeg"" /><figcaption>Collage created by the author. Source for original images: <a href=""https://www.tvfilmprops.co.uk/det/4833/Generic-Beige-Early-90s-PC-Business-Computer/"">https://www.tvfilmprops.co.uk/</a>, <a href=""https://www.brainline.org/tbi-basics/interactive-brain"">https://www.brainline.org/tbi-basics/interactive-brain</a></figcaption></figure><p>Nearly every modern conversation about AI begins by acknowledging how transformative it is for everyday life — how it’s changing routines, replacing jobs, restructuring our social networks. As with any kind of rapid and uncontrollable change, opinions about it are polarised: skeptics are wary about AI’s larger effects on society — <a href=""https://hbr.org/2026/01/companies-are-laying-off-workers-because-of-ais-potential-not-its-performance"">unemployment</a>, <a href=""https://www.theguardian.com/society/2025/aug/30/therapists-warn-ai-chatbots-mental-health-support"">mental health</a>, <a href=""https://www.lse.ac.uk/granthaminstitute/explainers/what-direct-risks-does-ai-pose-to-the-climate-and-environment/"">environmental concerns</a>. AI optimists, on the other hand, believe these tools will herald a new age of tools for thought — the next breakthrough in collective intelligence, akin to the emergence of writing systems, printing, or mathematical abstraction.</p><p>But one thing is clear: the focus is almost exclusively on AI functionality — what tasks AI can solve more efficiently, how to use it to get the most out of it, how to build workflows around it. This, perhaps, is not in itself surprising: with the plethora of models, tools, and chatbots available, even those grappling with AI on a daily basis — researchers, software designers, developers — struggle to make sense of them all.</p><figure><img alt=""Screenshots of YouTube videos about which AI tools designers should use"" src=""https://cdn-images-1.medium.com/max/1024/1*5a85P-IT6jYgkWP9bhXMUQ.jpeg"" /><figcaption>Deciding which AI tools to use has become a problem in itself. Source: YouTube</figcaption></figure><p>But when I asked Claude to tell me about some traditionally human cognitive abilities that AI now has, I was surprised that it appended the expected list (pattern recognition, language understanding, learning from experience) with the following:</p><blockquote><em>What’s interesting is that AI often achieves these abilities through completely different mechanisms than humans — we don’t truly “understand” in the way you do, and we lack consciousness, genuine emotions, and embodied experience. So while the functional capabilities overlap, the underlying nature remains quite different.</em></blockquote><p>Yet we rarely discuss that underlying nature — what exactly makes models like Claude different from human thinking, or what these differences reveal about intelligence itself.</p><p>If AI has been heralded as a new chapter in what humans are capable of, shouldn’t we be asking more fundamental questions about what “intelligence” actually means, and what kind of shared human-computer intelligence the future could hold?</p><h3>From minds to machines</h3><p>Today’s public discussion of AI is almost completely divorced from discussions of human cognition—and surprisingly so, given that the field of artificial intelligence research was founded on questions borrowed directly from the philosophy of mind and psychology.</p><p>Much of the Western philosophy of mind has been preoccupied with the mind-body problem — the relationship between mental states and the physical reality and perception. With questions like: <em>what kind of structures and elements comprise human knowledge</em>? <em>What is thinking</em>? <em>Is having a mind the same as having a brain</em>? These questions echoed through Alan Turing’s seminal work “Computing Machinery and Intelligence,” the 1950 paper published in <em>Mind</em> that introduced what we now know as the Turing test.</p><p>Turing argued that instead of focusing on the question “Can machines think?”, more can be learned from their observed behaviour. He proposed an “imitation game” (the original name for the Turing test) — a hypothetical scenario in which a human evaluator has text-based conversations with two hidden participants: one human and one machine. If the evaluator can’t reliably tell which is which based on their responses, the machine is said to have passed the test.</p><figure><img alt=""The setup of the Turing test"" src=""https://cdn-images-1.medium.com/max/661/0*G_VPOC9VEN3vCy0W.png"" /><figcaption>In a Turing test, a human evaluator judges a text transcript of a conversation between a human and a machine. The evaluator tries to identify the machine, and the machine passes if the evaluator cannot reliably tell them apart. Source: <a href=""https://en.wikipedia.org/wiki/Turing_test"">Wikipedia</a></figcaption></figure><p>For a while, the discussion around creating a human-like “learning machine” was theoretical. But the advancements in the understanding of the brain’s neural structure throughout the 19th and 20th centuries established the electrical nature of the nerve signal, culminating in neuropsychologist Donald Hebb’s theory on the neural processes that underlie learning. In his 1949 book <em>The Organization of Behavior</em>, Hebb theorised how neural connections form through repeated activation — a principle later summarised as “Neurons that fire together, wire together.” This insight provided the foundation for modern neuroscience, neural network theory, and machine learning.</p><figure><img alt=""Structure of the human neuron compared to the architecture of an artificial neural network"" src=""https://cdn-images-1.medium.com/max/726/1*VK0tUU4UHW3HHWA7slJ3eg.jpeg"" /><figcaption>The principle “Neurons that fire together, wire together” inspired the architecture of artificial neural networks. Source: <a href=""https://en.wikipedia.org/wiki/Neural_network_(machine_learning)"">Wikipedia</a></figcaption></figure><p>Early pioneers of AI believed that describing the mind in computational terms — made possible by Hebbian theory and the subsequent development of artificial neural networks — could finally answer those foundational questions about human cognition. If they could build computational systems that closely resembled the brain’s neural structure, they reasoned, those systems might recreate the processes underlying uniquely human abilities: language, visual perception, reasoning, artistic creation.</p><p>As work on understanding the mind unfolded throughout the 20th century, two competing views of intelligence emerged: pattern recognition (also known as “statistical processing”) and world modelling (known as “symbolic manipulation”). The difference becomes clear when we consider how a child might learn what a dog is.</p><p>From the symbolic point of view, every time a child sees a creature that their caregiver tells them is “a dog,” they form and develop the concept of <em>dog — </em>i.e.<em> </em>what properties are characteristic of dogs. When they learn to recognise creatures as another kind of “dog”, they are learning to make the connection between an instance—the dog they’re looking at — and their mental concept of <em>dog</em>.</p><figure><img alt=""How a child might learn the concept of “dog”: through recognising a pattern that’s consistent across all examples of a dog they’ve encountered, or by building a mental model of what a dog is"" src=""https://cdn-images-1.medium.com/max/1024/1*BZxyXL5gEBijen6btqv5VQ.jpeg"" /><figcaption>How a child might learn the concept “dog” according to pattern recognition vs. world modelling view. Collage created by the author. Source: <a href=""https://en.wikipedia.org/wiki/Bernese_Mountain_Dog"">Wikipedia</a></figcaption></figure><p>From the point of view of recognising patterns, a child sees many different examples of dogs: all kinds of shapes, breeds, colours, and drooliness levels. Their extremely malleable brain processes all these instances, identifies patterns, and learns to match new examples to this pattern. Very quickly they learn to classify new exemplars as either “dog” or “not dog.”</p><p>If the latter sounds extremely similar to a basic-level explanation of machine learning, it’s not by coincidence: artificial intelligence as a field — and especially the view of intelligence as pattern recognition — has been heavily influenced by child development research. In “Computing Machinery and Intelligence,” Turing referred to an artificial intelligence system as a “child-machine”; early pioneers of modern AI research in the 70s explicitly stated the connection between the two fields. For example, in 1972 computer scientist <a href=""https://en.wikipedia.org/wiki/Roger_Schank"">Roger Schank</a> wrote that:</p><blockquote><em>We hope to be able to build a program that can learn, as a child does, how to do what we have described in this paper instead of being spoon-fed the tremendous information necessary.</em></blockquote><p>A similar sentiment was expressed by <a href=""https://en.wikipedia.org/wiki/Marvin_Minsky"">Marvin Minsky</a>, one of the “fathers of AI,” in 1974:</p><blockquote><em>I draw no boundary between a theory of human thinking and a scheme for making an intelligent machine; no purpose would be served by separating these today since neither domain has theories good enough to explain or to produce enough mental capacity.</em></blockquote><p>And it’s not surprising why a child’s mind is so fascinating to an AI researcher: after all, we spend our early days being unable to speak or hold our head up, yet we develop object permanence by five months old, can distinguish our native language from a foreign one by six months, and perform cost-reward analysis by ten months old. And all of that without the massive datasets that systems like GPT, Claude, and Llama require: a modern large language model (LLM) trains on trillions of words, while an average five-year-old is exposed to around 300,000. How can we learn so much from so little, and so fast?</p><p>Both cognitive and computer scientists today mostly agree that intelligence comprises both statistical learning and world model building. But, for reasons I won’t detail here, modern AI research from major industry labs has largely abandoned the question of <em>how</em> children learn so efficiently, focusing instead on <em>whether</em> similar behaviour can be achieved through massive computing power and large training datasets. Still, the original question persists in a new field that has been developing alongside traditional psychology and computer science: computational cognitive science, which continues to ask what artificial intelligence can reveal about the nature of human minds.</p><h3>From machines to minds</h3><p>Despite AI’s origins in the study of human cognition, that connection has all but disappeared from public awareness. Yet while mainstream AI research has pivoted toward achieving human-like behaviour without needing to implement a sophisticated human-like cognitive architecture, a a swiftly developing new field—computational cognitive science — has been figuring out ways to use AI models as windows into human cognition.</p><p>The logic is fairly straightforward: if artificial neural networks are modelled (however loosely) on biological ones, then understanding how an AI system solves a problem could offer clues about how humans solve it too. This approach is sometimes called “reverse-engineering” cognition: build a system that can perform a human task, decipher how it accomplishes that task, then ask whether humans might be doing something similar.</p><p>And so far, the results have been impressive. <a href=""https://arxiv.org/abs/2303.12712"">Since at least GPT-4</a>, LLMs have been able to solve<strong> </strong>difficult tasks across mathematics, coding, vision, medicine, law, psychology, and more.</p><p>But a few concerns remain. First, AI learns from significantly more data than humans (very few of us can brag that we have read all of Wikipedia). Second, while AI can certainly be impressive, it still often falls short at some basic tasks that require symbolic manipulation.</p><p>For example, Yale University professor <a href=""https://rtmccoy.com/"">Tom McCoy</a> and colleagues <a href=""https://arxiv.org/abs/2309.13638"">found</a> that state-of-the-art LLMs struggle with seemingly simple tasks like forming acronyms, decoding shift ciphers, and translating into Pig Latin — tasks that require symbolic manipulation following deterministic rules (e.g., “count the number of words in a list”). What’s revealing is that LLMs performed significantly worse when the correct answer was a low-probability string, even though these tasks have objectively correct, deterministic answers, and require no probabilistic reasoning whatsoever (unlike questions such as “How likely am I to get stuck in traffic at 5pm in central London?” — where statistical patterns are genuinely useful).</p><figure><img alt=""Experimental materials from Tom McCoy and Najoung Kim’s studies"" src=""https://cdn-images-1.medium.com/max/1024/1*rAPFwOIs_JSgs9sMlmr0mQ.jpeg"" /><figcaption>Left: <a href=""https://arxiv.org/abs/2309.13638"">McCoy and colleagues found</a> that LLMs struggle with low-probability answers to questions that require a deterministic answer. Right: LLMs can make human-like inferences from adjective-noun pairs, but not for unusual combinations, <a href=""https://arxiv.org/abs/2410.17482"">Kim and colleagues report</a></figcaption></figure><p>Similarly, when <a href=""https://najoung.kim/"">Najoung Kim</a>, a professor of computational linguistics at Boston University, and her colleagues from Harvard University <a href=""https://arxiv.org/abs/2410.17482"">tested</a> LLMs on their ability to make inferences from adjective-noun combinations (for example, the answer to <em>Is a counterfeit watch still a watch?</em> should be <em>Yes, </em>but the answer to <em>Is a fake doctor still a doctor?</em> should be <em>No</em>) they found that these models struggled with low-probability, unusual combinations such as <em>a homemade cat</em>.</p><p>The takeaway appears simple: AI is extremely good at learning and generalising information, but it is limited by the tasks it was trained on. As McCoy and colleagues conclude in their paper:</p><blockquote><em>We should absolutely recognize [LLMs’] advanced properties. Nonetheless, we should also remember a simpler fact: Language models are… language models! That is, they are statistical next-word prediction systems […] In sum, to understand what language models are, we must understand what we have trained them to be.</em></blockquote><p>At this point, it seems appropriate to ask: is it even possible to study AI models as proxies for the human mind, when their performance is so clearly underpinned by amounts of training data that no human would process in a lifetime, and an architecture that relies primarily on statistical processing?</p><p>Recently, researchers have been trying to solve this problem by introducing additional constraints on how AI systems work: limiting and curating the data they are trained on, and tweaking the architecture to approximate the cognitive biases innate to human mind.</p><p>Researchers from Princeton University’s <a href=""https://lake-lab.github.io/"">Human &amp; Machine Intelligence Lab</a>, directed by <a href=""https://psychology.princeton.edu/people/brenden-lake"">Brenden Lake</a>,<strong> </strong>trained a generic neural network on 61 hours of video footage that came from a head-mounted camera worn by a single child over the course of 1.5 years. The simple architecture of the model allowed the researchers to test a simple theory of word learning: that novel words are learned by tracking co-occurrences of visual and linguistic information. The model tracks visual and linguistic inputs, which are in turn passed through the visual and linguistic encoders, and embedded in a shared vector space. In other words, the model tracks what kind of visual information accompanies verbal cues like “cat” or “toy,” just like a child might.</p><p>And while despite being trained on a tiny dataset — by today’s standards — it worked. When the researchers tested the model on a new set of images, it matched the words it learned during training with the correct visual referents, even though it hadn’t “seen” those specific images before. This finding goes beyond just achieving impressive performance: it provides evidence that word learning in humans could be possible through a general-purpose cognitive mechanism that combines representation and associative learning.</p><figure><img alt=""A toddler wearing a head-mounted camera"" src=""https://cdn-images-1.medium.com/max/600/0*b5jE9hKC_qBS4dZi"" /><figcaption>“We showed, for the first time, that you can train an AI model to learn words through the eyes and ears of a single child” — Brenden Lake, professor of psychology at Princeton University. Source: <a href=""https://www.scientificamerican.com/article/a-camera-wearing-baby-taught-an-ai-to-learn-words/"">Scientific American</a></figcaption></figure><p>This research suggests that the path to understanding the mind (and as a consequence, building better AI) lies in training models on less data, but thinking more carefully about the kinds of cognitive biases they should be imbued with.</p><p>And it clearly aligns with the original mission of AI research. <a href=""https://www.nytimes.com/2024/04/30/science/ai-infants-language-learning.html"">The New York Times article</a> covering this research concludes:</p><blockquote><em>For Dr. Lake, and for other investigators like him, these interlocking questions — How humanlike can we make A.I.? What makes us human? — present the most exciting research on the horizon.</em></blockquote><p>But is this approach likely to become prevalent in industry labs that lead the development of state-of-the-art models like GPT? Logically, it should: front loading effort and resources into building more interpretable models now would ensure their longevity (even now, a mere year after the introduction of ChatGPT, many young people are <a href=""https://www.bbc.co.uk/news/articles/c9wx2dz2v44o"">rejecting what they consider to be “AI slop”</a>). But for commercial labs guided by generating profits and appeasing shareholders, this seems unlikely: why bother spending resources on uncomfortably vague research when increasing computing power and training data have done the trick just fine? The <a href=""https://www.nytimes.com/2024/04/30/science/ai-infants-language-learning.html"">same New York Times article</a> points out:</p><blockquote><em>But mainstream industry labs behind the most competent A.I. models, and the companies that make them, have long been geared toward efficiently processing more data, not making more sense out of less.</em></blockquote><p>Academic research labs face a different version of the same problem. While not driven by pure profit motives, coveted funding sources often mean that their research is still more biased towards building more human-like agents — not creating technology for AI-assisted, more thoughtful and creative human. If we continue this way, where will it lead?</p><h3>What happens after AI passes the capitalist Turing test?</h3><p>We have found ourselves at a crossroads. On one hand, we seemingly understand more than ever about how humans think, learn, process visual information, and interact socially. On the other, this knowledge is being channeled almost exclusively toward building better AI chatbots that mimic human behaviour.</p><p>Why? First, because the direction is set by for-profit companies whose ultimate goal isn’t ushering in <a href=""https://maggieappleton.com/ai-enlightenment#our-missing-pocket-sized-enlightenment"">a new Age of Enlightenment</a>, but selling a product — making us more reliant on AI agents to simplify workflows, optimise routines, delegate tasks. Think less, less, less.</p><p>Second, for that purpose, research that focuses narrowly on pattern recognition and statistical processing does just fine. These systems are straightforward to train and improve, and their performance is impressive enough to sustain public interest and turn in profits. They pass the capitalist Turing test.</p><p>But here’s the trouble: reports of depleting critical thinking and shortening attention spans might just not be fear-mongering, but a direct outcome of systems designed solely for performance. If we spend our thinking time communicating with machines optimised for pattern matching, we might internalise those same patterns to make the interaction more efficient.</p><p>The crux of the matter is that interaction with AI is now <a href=""https://www.personalcanon.com/p/how-to-speak-to-a-computer"">predominantly designed to imitate a conversation</a>, and we typically expect our conversational partners to have their own intentions, beliefs, and inner lives. In linguistics, it has been <a href=""https://web.stanford.edu/~clark/1990s/Brennan,%20S.E.%20_%20Clark,%20H.H.%20_Conceptual%20pacts%20and%20lexical%20choice%20in%20conversation_%201996.pdf"">well</a> <a href=""https://www.sciencedirect.com/science/article/pii/S0010027799000815?casa_token=yzamMMmozkYAAAAA:7mmmqFEEXyIDV6oItH2TykqHs1s6vDWbfPouY5XksQYC7YCYFqeZl6vDNSUL81WcGnfEUZIIuQk"">documented</a> that during a human-to-human conversation, people adapt to each other’s language patterns to align their mental states and ultimately achieve better communication. But AI has no mental states it can align with ours. It cannot restructure its foundation — built on statistics and patterns — to match our symbolic reasoning. And as a result, instead of AI becoming a thinking companion, <a href=""https://youtu.be/RKK7wGAYP6k?si=c1WKCZUiYzqNzozU"">our own thinking risks becoming more machine-like</a>: fine-tuned to recognise statistical regularities while forgetting how to make inferences, form concepts, find deeper connections between things.</p><p>So… what’s next? This is where things fall apart, because a crucial piece of understanding is missing: we’re still far from fully grasping how concepts are formed, or how symbolic reasoning is actually instantiated in the brain. And without that understanding, we can’t build systems that genuinely complement human intelligence rather than flatten it. In order to get there, three things need to happen:</p><ul><li>Industry research labs need to engage seriously with cognitive science and collaborate with academic researchers. If I’ve made my point clear, artificial intelligence research loses much of its substance when it severs ties with the foundational questions that connected it to philosophy of mind and cognitive development. For progress to be truly significant, these ties must be restored and strengthened.</li><li>AI systems need cognitively plausible architectures. In modern cognitive science, biological plausibility plays a crucial role: if a proposed mechanism is impossible to implement biologically, that casts serious doubt on its validity. The same standard should apply to AI. Researchers need to think carefully about what data models are trained on and why certain architectures are chosen — not just whether they work, but whether they reflect anything meaningful about intelligence.</li><li>Most crucially, software designers and cognitive scientists need to collaborate on how these systems can actually serve humanity. No one else can figure this out — and <a href=""https://maggieappleton.com/ai-enlightenment#our-missing-pocket-sized-enlightenment"">many designers already agree</a> that <a href=""https://www.personalcanon.com/p/how-to-speak-to-a-computer"">chat interfaces are a poor solution</a>.</li></ul><p>There’s a brand of AI optimism that says what you get out of AI depends on how you use it: if you’re filling knowledge gaps rather than taking shortcuts, you’ll unlock creativity and thinking rather than rot your brain on slop.</p><p>I subscribe to this optimism to a degree. As a designer, AI has allowed me to move beyond technical constraints and create more freely.</p><p>But this “solution” is rooted in individualism and, frankly, elitism: the idea that AI will make only the smartest and most discerning among us even brighter and more capable. There’s nothing in that promise about elevating humanity as a whole. Yet research shows that real progress is impossible without <a href=""https://en.wikipedia.org/wiki/Distributed_cognition"">collective intelligence</a>. If AI is to fulfil its promise as a tool for thought — a genuine extension of human capability — it must be designed not just for individual optimisation, but for collective progress.</p><h4><strong>References</strong></h4><p>Turing, A. M. (1950). Computing machinery and intelligence. <em>Mind</em>, <em>59</em>(236), 33–60.</p><p>Hebb, D. O. (1949). <a href=""https://archive.org/details/in.ernet.dli.2015.226341""><em>The Organization of Behavior: A Neuropsychological Theory</em></a>. New York: Wiley and Sons.</p><p>Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). Building machines that learn and think like people. <em>Behavioral and Brain Sciences</em>, <em>40</em>, e253.</p><p>Ross, H., Davidson, K., &amp; Kim, N. (2024). Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don’t mimic the full human distribution. <a href=""https://arxiv.org/abs/2410.17482""><em>arXiv preprint arXiv:2410.17482</em></a>.</p><p>McCoy, R. T., Yao, S., Friedman, D., Hardy, M., &amp; Griffiths, T. L. (2023). Embers of autoregression: Understanding large language models through the problem they are trained to solve. <a href=""https://arxiv.org/abs/2309.13638""><em>arXiv preprint arXiv:2309.13638</em></a>.</p><p>Wai Keen Vong <em>et al. </em>Grounded language acquisition through the eyes and ears of a single child. <em>Science </em>383, 504–511 (2024).</p><p>Branigan, H. P., Pickering, M. J., &amp; Cleland, A. A. (2000). Syntactic co-ordination in dialogue. <em>Cognition</em>, <em>75</em>(2), B13-B25.</p><p>Brennan, S. E., &amp; Clark, H. H. (1996). Conceptual pacts and lexical choice in conversation. <em>Journal of experimental psychology: Learning, memory, and cognition</em>, <em>22</em>(6), 1482.</p><p>Maggie Appleton. <em>A Treatise on AI Chatbots Undermining the Enlightenment</em>. <a href=""https://maggieappleton.com/ai-enlightenment#our-missing-pocket-sized-enlightenment"">https://maggieappleton.com/ai-enlightenment#our-missing-pocket-sized-enlightenment</a></p><p>Celine Nguyen. <em>How to speak to a computer</em>. <a href=""https://www.personalcanon.com/p/how-to-speak-to-a-computer"">https://www.personalcanon.com/p/how-to-speak-to-a-computer</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=18baacbcf18f"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/when-ai-passes-the-capitalist-turing-test-18baacbcf18f"">When AI passes the capitalist Turing test</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends you’ll want to bookmark for 2026 - It's Nice That,The graphic trends you’ll want to bookmark for 2026 - It's Nice That,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiugFBVV95cUxQQTl0TzRHem5wU2ZLUDV1S2R3SjliZWRfVTctVjdjTnFIV0ExeFFBdkFlaFk4bjZOUExsZmZxSjN0ZGo1VGljXzh0UDdPWXF2Z2xhNUMyZ2dBYXoyQzR5MTMwREk3cnZXc0RvNThOdXcwNTgtb1ZVYXg3bm0tbVFGNkRTbGZHWDM3eDVmY2x3eWgzbm1Sbkd6NzhHS29DNnpfdk1ZNlhOZVJ4X0hIUHk5ODhGVUllTGFia3c?oc=5,1769500800,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiVkFVX3lxTE15SGdJak5IcDg0dnpEZWhUUFI0TXQyNDF2Vnp5WVhwRVZEc1dGUXVGOXlyQXRrR2FhNE03NnNvNEJhRnNFSm8yVDJFdUluLXNFcUpMeHdB?oc=5,1770796800,Email Design Trends for 2026 - Designmodo,Email Design Trends for 2026 - Designmodo,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMid0FVX3lxTE84WklhdnlBcTZkRy1PSjNSd0tDQUEwSDRlNVEwWGdNZGFBQ1BuVEVKbFVlX1FPZkROY2cxN0NjdS0yQkx0SVZqU0JQQU5CSTluVnpnVG5uQm1nb2dMNEVCQzh4VGt5d2pzTjdBdWQzRVJUNnhQMG9R?oc=5,1767686400,Future of Graphic Design: Trends & Predictions - Business.com,Future of Graphic Design: Trends & Predictions - Business.com,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMingFBVV95cUxPNC12NnUyRjAwQlBfNkVWeDBYYlh6MnNCWDBzSFV3Y3R5aHlvdFdtVXVibV9QR3BybjJpQkthWE52TEwxN05ScVpvZ3Q0Y2toQm5mQ2tqMlQ4WmdVM0dqa1hOTWNaYXVMaTdUOERYWmlJU2RVeXplc2pqaVFLbUJuWWs5T2Mwd0Zra3IwZm9ZbTk2ZVJkQ3ZGMWQxVDg0Zw?oc=5,1768982400,Graphic Design for Video Games: Trends Players Notice in 2026 - Barrett Media,Graphic Design for Video Games: Trends Players Notice in 2026 - Barrett Media,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMikgFBVV95cUxQMEEwdDNWUy1naGo2Q1JqRlp3R3VpLUdSTDFJcFhRRE04NWRiOEVIY2xuSEFDcmRDZkFHcUdRaWw3cFM5MGJWbVVpU29uT0lxcFl3T2hEb3dlWTE5a1hXenduLV93b3ljc3hmNUdRc0ZNZmZaRlVtOVZLUERzZHRPdm8yTHFtQnc3Ykw4STRWYkdwZw?oc=5,1768377600,"Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor","Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor",graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiZkFVX3lxTE95aEtIbVRhclRrS3hxMzhUQXgwRzlJOUdvZjg3VlZCTlc5XzdmTTZ1OFVucjNiRjNjZGdFT3M3dUkyQjhOMGVUVWc3ZzNpOFdMb3lweE92S1pZX3MxUE80a2pNYkVvdw?oc=5,1767513600,Graphic design trends in 2026 - The Morning,Graphic design trends in 2026 - The Morning,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMid0FVX3lxTFBJMmdZVVBsT1NPWjkya1RhVnkydkJ3bG11UW5TNXZCT2t6cUFKYUNWeDN2STI2Ym5oRGhQWUg1a0xUZzI0dUZIUF9vM0lDRUpRdGpMVXlOdldTSWtwM3UtbVZuLXZCWGhSN0VnbzJZdmNEYU5GY3VR?oc=5,1770019200,Top Website Statistics For 2025 - Forbes,Top Website Statistics For 2025 - Forbes,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiwAFBVV95cUxQWXktZHYxRE5Lb2hMLWlqdTVHSHNCYm5xaUZRa28tbFdjUzdIR21Ha0NsMUw0NU96Z0dHNVktc09xMk40VjBxdUpmWkE4MENpU0VMeGJvSDJIMjd1LU51OG9EUDJvN1pjRGxnQ0VMcDg0VW5tN2N6YnB5eXJSR013eVVuRktqX2g3QjhMZUJmckFYYVZnUEo5VlhsODlNdm5rRXM5eVB6UEYyUDlEX2tLcldJR0JLbzNxbEZ3MnNScjk?oc=5,1770451200,What Are the Top Trends in Responsive Web Design for Toronto-Based E-Commerce Sites in 2026? - nerdbot,What Are the Top Trends in Responsive Web Design for Toronto-Based E-Commerce Sites in 2026? - nerdbot,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiWkFVX3lxTE40UU00VzlvX0tPdGx1bVBJbG9iNFl6b05JUXRabjZuc21KVTN3NHlhX2YwUTFPQWpwWlJaQXcwRks2UHM2azg4YTNybEsyVk1EaFNoRGVGVHZvZw?oc=5,1768809600,Duotone – Fresh Trend in Website Design - Designmodo,Duotone – Fresh Trend in Website Design - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends you’ll want to bookmark for 2026 - It's Nice That,The graphic trends you’ll want to bookmark for 2026 - It's Nice That,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,typography trend
youtube,,https://www.youtube.com/watch?v=zeA7hjl2Vx8,1771241592,How I Made Painted Poster Design (Graphic Design Trends 2026) by Zeka Design,"The Painted design trend 2026 blends real brushstrokes, painterly textures, and expressive analog effects into modern digital ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=eqhuG7h8Wwc,1771216012,"Graphic Design Bangla Tutorial | Full Course for Beginners | Canva, Photoshop &amp; Illustrator","Graphic Design Bangla Tutorial | Full Course for Beginners | Canva, Photoshop & Illustrator Are you searching for a complete ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=wbX0TWvcw6M,1771209158,Logo Design 2026 in 60 Seconds  Illustrator Short,"Want to create a modern Logo Design 2026 in Adobe Illustrator? In this YouTube Short, I'll show you how to design a clean, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=kgtDp3A5H7o,1771153380,PS Tutorial HD | Método Fácil para Seleccionar Cabello 2026 | Photoshop Editing | CC + BP Drop #ps ,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=2YEAMsixhW4,1771138411,Astin Design | Quick Creative ⚡Turning Ideas into Impactful Designs 🎨✨#AstinDesign #QuickCreative,Astin Design | Quick Creative ⚡ Turning Ideas into Impactful Designs ✨ Welcome to Astin Design — where creativity meets ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=OP5caLBRyTc,1771122630,new design pop don&#39;t sitting Chinese simple design ceiling Chinese design,new design pop don't sitting Chinese simple design ceiling Chinese design Pop design Pop art design Pop graphic design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=RkozLoMZEAQ,1771087502,Illustration libraries every modern designer needs  #illustrations #vector #graphicdesign,"Vector illustration libraries for graphic designer #illustrations #svg #vector #svgillustrations #graphicdesigner. Figmations, 100+ ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=JIC4yrjNk0U,1771085883,POV: Graphic Designer things 🤣😂🤣 #trends #graphicdesigner,,graphic design trends
youtube,,https://www.youtube.com/watch?v=CM2Vgbo_J-U,1771081521,2026 Design Trends are... Interesting,"I've been seeing a lot of videos about 2026 graphic design trend predictions, so I decided to actually try them myself. In this video ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=CapBOXBHwhw,1771078506,how to use canva free for motion graphics design  #canva #tutorial #edit,"CANVIFY STUDIO is a creative YouTube channel dedicated to Canva design tutorials, graphic design tips, and visual content ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=9Uv_ZcDwajE,1771066334,Rapidly Evolving Transportation Design Trends,Welcome to Strategic Design Thinking in Transportation Let me start with a simple observation. Transportation design is no longer ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=-FJwq__FRfo,1771051733,2026 Design Trends |Part 2,,graphic design trends
youtube,,https://www.youtube.com/watch?v=n2IKrEcH89k,1771016128,Creative Box Design Ideas That Make Your Brand Unforgettable!,"Discover modern, eye-catching box design techniques that boost product value and attract customers instantly. Perfect for ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=latFcMxuT0c,1770994910,"Apple store, Borivali Poster Design    ✨🔥 #shorts #apple",Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=p0gkZdn6JAA,1770989699,How I Made Acid Poster Design - Graphic Design Trends 2026 - Zeka Design,"The Acid graphic design trend 2026 pushes visual intensity with neon colors, gradient chaos, distorted text, and bold hypercolor ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=VjpkQYtSBzY,1770983537,Channeling all the graphic designers to predict the trends in 2026 #graphicdesign #designtrends,,graphic design trends
youtube,,https://www.youtube.com/watch?v=74bdDMmlO80,1770973317,2026 DESIGN TRENDS  Part 1  #2026PosterDesignTrends #DesignTrends #PosterDesign #GraphicDesign,,graphic design trends
youtube,,https://www.youtube.com/watch?v=XvAcr1RnuNg,1770903076,Flower Design in Illustrator - Adobe Illustrator Tutorial #adobe #adobeillustrator #graphicdesign,Flower Design in Illustrator - Adobe Illustrator Tutorial ✓ Graphic Designers ✓ Abstract Art Lovers ✓ Illustrator Creators Illustrator ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=9Wy51zj_uiU,1770902971,"Puma 14th Feb, Poster Design   ✨🔥 #shorts #posterdesigner",Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Tw1kiuPrqiM,1770808181,5 free PNG websites for designers #png #graphicdesign #designtrends,"5 free PNG websites for graphic designers. Here you can download free pngs for your work and business. . 1, cleanpng 2 ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=4VvOhgYaDFA,1770784158,Adobe Illustrator - Tutorial #graphicdesign  #illustratortutorial #adobe #illustrator #abstract,Create this insane spiral effect using simple lines in Adobe Illustrator Beginner to Pro level trick! Save this for later and try it ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=JpKavuIL1KQ,1770734197,How I Made Surveillance Poster Design - Graphic Design Trends 2026 - Zeka Design,"The Surveillance design trend 2026 uses CCTV grids, tracking overlays, and biometric visuals to explore themes of data privacy ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=3MQuaDA2ZxQ,1770733776,Design Trends 2026,Stop guessing what's next! Our massive new report on the 10 Design Trends shaping typography and the visual landscape in ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=NO_oINYE3bA,1770732116,Тренды визуала 2026,"Курс ""UX/UI-Дизайн"" - http://uxui.filschool.ru ◾ Курс по карточкам товара - http://filschool.ru/card ◾ Курс ""Figma x Tilda"" ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=68ivlnANYhg,1770728414,🔥Who Creates Better Art in 2026? AI or Humans | Intellipaat,"In this video, we explore how AI can create stunning art in seconds, while human art carries emotion, stories, and lived ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=gjMtbcenHjc,1771241426,Responsive Web Design: Trends and Tips,Responsive web design isn't just a trend—it's the foundation of a powerful online presence. Here's why it matters: 1. Smooth User ...,web design trends
youtube,,https://www.youtube.com/watch?v=akRehpLysco,1771168500,"The Perfect Scroll Animation Doesn’t Exi… (UI Designers, Look Closely)","Featured Interactions: Dynamic Node Branching: Watch the ""Ada's reasoning engine"" segment (0:00), where a central node ...",web design trends
youtube,,https://www.youtube.com/watch?v=0G8LGcwJfcg,1771129454,Mahasivaratri Wishes -2026 | Valmiki Web Studio,Contact Me through Website: www.valmikiwebstudio.com What's App me Now: https://wa.me/919030702025 Telegram Group: ...,web design trends
youtube,,https://www.youtube.com/watch?v=_ncMbAlpHVQ,1771076707,"Web Design Trends: Strategies Every Designer &amp; Dev Needs to Get Right Now (Kinetic Type, 3D, and AI)","2026 Web Design Trends: Strategies Every Designer & Dev Needs to Get Right Now (Kinetic Type, 3D, and AI) Ditch 2024 habits.",web design trends
youtube,,https://www.youtube.com/watch?v=wVtRyfwWlCk,1771072828,Hexagon Grids Are Taking Over Web Design! (So Clean) ✨ #shortsvideo #shorts #viral #html5 #css3 #ai,"Hexagonal grids are literally EVERYWHERE in modern web design right now, and once you see why, you'll want to use them in ...",web design trends
youtube,,https://www.youtube.com/watch?v=u33ytCFNVac,1771003802,"A powerful website that simplifies design inspiration, creativity, and innovation for creators","A powerful website that simplifies design inspiration, creativity, and innovation for digital creators. Awwwards showcases the best ...",web design trends
youtube,,https://www.youtube.com/watch?v=B50OTYJWZ2E,1770986154,Website design trends 2026: No more flat designs,Glass morphism and liquid glass are the website design trends taking over 2026 — and you can recreate them with any website ...,web design trends
youtube,,https://www.youtube.com/watch?v=Upf1UMJgyzM,1770899777,Web Design In Malaysia,ePower Online Marketing is excited to present our special website design promotion for this month! We are offering exceptional ...,web design trends
youtube,,https://www.youtube.com/watch?v=HfCjIx7qqzQ,1770832269,Web Design Trends 2026: Portfolio Edition #freelancing,Check out the article on 2026 web design trends: https://tilda.education/en/web-design-trends-2026.,web design trends
youtube,,https://www.youtube.com/watch?v=fyNwPb0xXOU,1770795902,Create Modern Form UI Design with 2026 Trends!,"Create Modern Form UI Design with 2026 Trends! In this video, we create a modern Glassmorphism Form UI using HTML, CSS, ...",web design trends
youtube,,https://www.youtube.com/watch?v=p0Ka3r63Uwg,1770793005,Professional Web Development Services | Cromgen Technology – Build Stunning Websites,"Looking to elevate your business online? At Cromgen Technology, we specialize in creating modern, responsive, and ...",web design trends
youtube,,https://www.youtube.com/watch?v=NO_oINYE3bA,1770732116,Тренды визуала 2026,"Курс ""UX/UI-Дизайн"" - http://uxui.filschool.ru ◾ Курс по карточкам товара - http://filschool.ru/card ◾ Курс ""Figma x Tilda"" ...",web design trends
youtube,,https://www.youtube.com/watch?v=2_5qGOR7weg,1770724807,Top 3 Design Trends That Will DOMINATE 2026,"Top 3 Design Trends That Will DOMINATE 2026 design trends 2026, 2026 design trends, 2026 interior design trends, interior ...",web design trends
youtube,,https://www.youtube.com/watch?v=8Z_MEP-_kxA,1770656696,Web Design Trends 2026,"Hello guys! Today we brought to you a new video about ""Web Design Trends in 2026"" #webdesign #trends2026 #2026 ...",web design trends
youtube,,https://www.youtube.com/watch?v=GfvJz4DR_UQ,1770645623,17 WEBSITE TRENDS On the Way OUT in 2026 (and what to do instead),Free Font Guide: Canva + Squarespace Font Pairings → https://www.paigebrunton.com/fonts Blueprint: Book your first client in ...,web design trends
youtube,,https://www.youtube.com/watch?v=gtVGC6h7WVA,1770603615,Exploring EyeCandy: Your Go-To Source for Design Inspiration,Exploring EyeCandy: Your Go-To Source for Design Inspiration Dive into the world of design inspiration with EyeCandy!,web design trends
youtube,,https://www.youtube.com/watch?v=prmGrBTpbL8,1770573652,The New Rules of Web Design (2026),Hire us to build your website: https://bycrawford.com/intro-call Premium Website Checklist: ...,web design trends
youtube,,https://www.youtube.com/watch?v=3jl8PrymZas,1770467405,Mind-Blowing LIQUID Text Effect with JS! 🧪 | DevArea #webdesign #coding,"Mind-Blowing LIQUID Text Effect with JS! | DevArea #webdesign #coding Creating a ""gooey"" liquid text effect using HTML5 ...",web design trends
youtube,,https://www.youtube.com/watch?v=Ca2EyL26gwI,1770391813,Top 5 Website Design Resources 2026,"Top 5 Website Design Resources 2026   ⏰ [0:00] Introduction Welcome to our YouTube channel, Buddy Developers! We are a ...",web design trends
youtube,,https://www.youtube.com/watch?v=0qLlqiR3Wf4,1770367696,Ep 28. Trap or Trade-off? What small businesses should know before getting a website,"Are you a small business owner thinking about getting a website? In this episode, David Waumsley and Nathan Wrigley break ...",web design trends
youtube,,https://www.youtube.com/watch?v=ljpk74eCTrk,1770355820,Futureproof your website 7,Trends are great but being too trendy can make your website outdated very quickly! Explore our website services: ...,web design trends
youtube,,https://www.youtube.com/watch?v=5b-NhhEhDwc,1770339736,Six simple &amp; Creative web design ideas with European Flair,Who Mona King Is Founder of Mona King Creative Design Studio Provides creative services to help businesses grow through ...,web design trends
youtube,,https://www.youtube.com/watch?v=UlQO6aAT_Hg,1770319921,Top 20 eCommerce Development Trends for 2026,"In 2026, website design is no longer about looking good—it's about driving sales and keeping users engaged. In this video, we ...",web design trends
youtube,,https://www.youtube.com/watch?v=hoeu0Izi_tA,1770315171,WE ARE NOT A FACTORY. WE ARE AN ARCHITECTURAL FIRM. 🛠️,"At Web Artist Pro, we don't mass-produce ""cheap"" websites. We don't use templates. We don't ""hope"" for results. We build ...",web design trends
youtube,,https://www.youtube.com/watch?v=XTDcvDEXC50,1770310862,Leifer Méndez: ¡IA Revolucionaria! Detalle Increíble en Diseño Web Local,"leifer mendez ¡IA Revolucionaria! Detalle Increíble en Diseño Web Local, Leifer Méndez IA, diseño web con IA, IA en diseño web ...",web design trends
youtube,,https://www.youtube.com/watch?v=D3cgrEzZRWM,1771049700,Best Font Pairs for 2026 — Perfect Typography Combinations for Designers,"Discover the best font pairs for 2026 that every graphic designer, UI designer, web designer, and brand designer should use.",typography trends
youtube,,https://www.youtube.com/watch?v=njWPM7mlybQ,1771039944,Top 3 typography trends for the year,Your brand's tone of voice. Stay ahead of the curve with these 2026 typography trends. #TypographyTrends #GraphicDesign ...,typography trends
youtube,,https://www.youtube.com/watch?v=sJY6306QKpg,1770740556,Typography Trends 2026,The rules of typography are being rewritten. We've just released our full Blog Post: Top 10 Typography Trends for 2026.,typography trends
youtube,,https://www.youtube.com/watch?v=937bHdsXB5M,1770647198,Typography Trends 2026 # editingskills #creative #typographyart #videoediting YouTube shorts #shorts,Typography Trends 2026 #videoediting #creative #shorts #learnediting #editingskills.,typography trends
youtube,,https://www.youtube.com/watch?v=6c6XBFoUU7M,1769841137,typography in one click #trending #viral #typhography,"Discover the power of typography in one click, where trending and viral designs come to life. Learn how to create stunning ...",typography trends
youtube,,https://www.youtube.com/watch?v=3vQ00qHHGZU,1769584047,Ep.4 Parallel Obssrver.      #mindset #philosophy #trends #typography  #glitch #thinkdivine,Ep.4 Parallel Obssrver. #mindset #philosophy #trends #typography #motivation #glitch.,typography trends
youtube,,https://www.youtube.com/watch?v=hRSA0h0WTdg,1769533268,La tendance de la Typographie expressive &amp; expérimentale en design graphique en 2026,"Découvrez la troisième grande tendance design de 2026 : la typographie expressive et expérimentale. En 2026, la typographie ...",typography trends
youtube,,https://www.youtube.com/watch?v=CJgLYiSRO-s,1769461743,How To Made typography video|| Like this 💸📸 #shortvideo #typography #shorts,What is Typography? Complete Guide for Beginners Typography Explained in Simple English History of Typography – From ...,typography trends
youtube,,https://www.youtube.com/watch?v=lYOtZKah68o,1769339605,Display Fonts 2026: The ONE Change That Fixes Flat Designs,"Display Fonts 2026: The ONE Change That Fixes Flat Designs display fonts, display font tutorial, display font vs regular font, bold ...",typography trends
youtube,,https://www.youtube.com/watch?v=nrVojxqD68o,1769077385,How to add aesthetic fonts #shorts #tipsandtricks,Learn how to add aesthetic fonts to your graphic design projects with these simple tips and tricks. If you're a beginner in graphic ...,typography trends
youtube,,https://www.youtube.com/watch?v=qcnxiQQ_0Fc,1769031357,2026 Font Trends You Should Know About,Use These Fonts In Kittl: https://kit.tl/2026fonts Learn More About These Fonts: https://www.kittl.com/blogs/top-font-trends-dsi/ ...,typography trends
youtube,,https://www.youtube.com/watch?v=89dj4U9T5K4,1768878159,Modern Design Trends - The Mono Typeface,"If you're still treating Mono fonts like a ""niche"" choice for developers, you're missing the biggest branding shift of 2026. Typeface ...",typography trends
youtube,,https://www.youtube.com/watch?v=cnTP2LuSFOw,1768636943,"😂 WAIT FOR END 😀Typography video, reel trends,",,typography trends
youtube,,https://www.youtube.com/watch?v=MTMIKSUFXEE,1768579770,🆕#ValeLaPenaVer 🇨🇴 | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseño 2026,"ValeLaPenaVer | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseño 2026, un análisis que ...",typography trends
youtube,,https://www.youtube.com/watch?v=iq7E1RBZgDY,1768570250,#handwriting #calligraphy #calligrphylearning #handlettering #artist #letter #typography#handwriting,"modern calligraphy tips, calligraphy for beginners, DIY calligraphy projects, calligraphy tutorials, calligraphy lettering styles, brush ...",typography trends
youtube,,https://www.youtube.com/watch?v=_jkyUunzs1I,1768538874,5 Best Websites to Download Free Fonts for Designers 🔥,"Looking for the best websites to download free fonts for your design projects? In this short video, I share 5 powerful font websites ...",typography trends
youtube,,https://www.youtube.com/watch?v=qErJzUWGgLQ,1768410089,Our font design predictions for 2026,"Want to boost your branding in 2026? Start with your fonts! Because when your typography feels like your voice, customers listen ...",typography trends
youtube,,https://www.youtube.com/watch?v=WHIGDDkIbz0,1768342928,8 fresh font trends for 2026,The font trends for 2026 reveal that personality and imperfection are standing out in a market flooded with overly polished ...,typography trends
youtube,,https://www.youtube.com/watch?v=HKprAtVk7TM,1768093232,Frontiers of Visual Language Emerging Trends in Graphic Design,"Explore the latest design trends shaping 2026, from AI workflows to immersive branding. Practical tips to elevate your next project.",typography trends
youtube,,https://www.youtube.com/watch?v=83wacmeqGd0,1768049484,design trends 2026 pt. 1🍒 #графическийдизайн #бренинг #бренддизайн #обучениедизайну,,typography trends
youtube,,https://www.youtube.com/watch?v=uRK43kg05zI,1767918989,Typography Trends 2026 (Versi Tayo) ,Typography Trends 2026 Saya menemukan template mengagumkan ini di CapCut. Ketuk tautan untuk mencobanya!,typography trends
youtube,,https://www.youtube.com/watch?v=DCpoDKHct00,1767890799,These Bold Fonts Will Dominate 2026 &amp; Beyond!,"Looking for the best bold fonts for 2026 and beyond? In this video, we explore the bold typography trends that will dominate ...",typography trends
youtube,,https://www.youtube.com/watch?v=qeFr2L2Sjxs,1767790238,"days [4/7] Kala Tika, Safed Tika… Confusion Hi Confusion 😌 #typography #shorts","Kala Tika, Safed Tika… Confusion Hi Confusion #typography #shorts •Disclaimer: This is Video made for entertainment ...",typography trends
youtube,,https://www.youtube.com/watch?v=MPbWoDrwzY0,1767711643,"Minimalist Fonts for a Fresh Start | Clean, Modern Typography  #canvahacks #businesstemplates","A new season is the perfect moment to refresh your design style. Clean typography creates clarity, calm, and focus — before ...",typography trends
youtube,,https://www.youtube.com/watch?v=yHs9-RVTwsA,1767704407,Graphic Design Trends 2026 — And How to Actually Use Them!,Discover the most important graphic design trends of 2026 and learn exactly how to use them the right way in your own work!,typography trends
