source,domain,url,created_utc,title,text,query
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/unstacking-css-stacking-contexts/,1769508000,Unstacking CSS Stacking Contexts,"Unstacking CSS Stacking Contexts

In CSS, we can create â€œstacking contextsâ€ where elements are visually placed one on top of the next in a three-dimensional sense that creates the perception of depth. Stacking contexts are incredibly useful, but theyâ€™re also widely misunderstood and often mistakenly created, leading to a slew of layout issues that can be tricky to solve.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking â€œPixel Perfectâ€ Web Design,"Rethinking â€œPixel Perfectâ€ Web Design

Amit Sheen takes a hard look at the â€œPixel Perfectâ€ legacy concept, explaining why itâ€™s failing us and redefining what â€œperfectionâ€ actually looks like in a multi-device, fluid world.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designerâ€™s Career Paths In 2026,"UX And Product Designerâ€™s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI thatâ€™s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development.",
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,PivotingÂ Your Career Without Starting From Scratch,"PivotingÂ Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, â€œIs this still what I want to be doing?â€ This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as youâ€™re reading this or youâ€™re still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? Weâ€™ve got you covered.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/giving-users-voice-virtual-personas/,1766484000,Giving Users A Voice Through Virtual Personas,"Giving Users A Voice Through Virtual Personas

Turn scattered user research into AI-powered personas that give anyone consolidated multi-perspective feedback from a single question.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/,1766138400,How To Measure The Impact Of Features,"How To Measure The Impact Of Features

Meet TARS â€” a simple, repeatable, and meaningful UX metric designed specifically to track the performance of product features. Upcoming part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today).",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/smashing-animations-part-7-recreating-toon-text-css-svg/,1765965600,Smashing Animations Part 7: Recreating Toon Text With CSS And SVG,"Smashing Animations Part 7: Recreating Toon Text With CSS And SVG

In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk) shows his techniques for creating [Toon Text titles](https://stuffandnonsense.co.uk/toon-text/index.html) using modern CSS and SVG.",
rss,uxdesign.cc,https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4,1769775212,Thinking clearly while everything speeds up,"Thinking clearly while everything speeds up

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*9ODCVnUP3kLQO6hYu_ePiQ.jpeg"" width=""5712"" /></a></p><p class=""medium-feed-snippet"">It&#x2019;s a crazy time to be alive, let alone be a UX designer.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/thinking-clearly-while-everything-speeds-up-af5399ac0f7f?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/beyond-the-waterfall-state-why-missions-need-a-different-decision-making-architecture-d81fadb93106?source=rss----138adf9c44c---4,1769729047,Beyond the waterfall state: why missions need a different decision-making architecture,"Beyond the waterfall state: why missions need a different decision-making architecture

<h4>Why government keeps forcing uncertainty through systems designed for stabilityâ€Šâ€”â€Šand what an alternative might lookÂ like</h4><p>In a previous article, I argued that<a href=""https://civicworks.substack.com/p/unfit-for-uncertainty-rethinking""> the UK government is structurally unfit for uncertainty</a>â€Šâ€”â€Štaking 21st-century challenges, evaluating them with 20th-century tools, and responding within 19th-century institutionsâ€Šâ€”â€Šbuilt for a different time, and for different kinds of problems. And, if Labourâ€™s<a href=""https://labour.org.uk/change/mission-driven-government/""> mission-driven government</a> is to mean anything in reality, the civil service needs a new grammar of everyday decision-making: one that treats uncertainty as navigable, frames choices in terms of <em>risk and opportunity</em> rather than cost and control, and builds learning into how problems are defined and actedÂ upon.</p><p>This piece starts where that argument ends, asking what a <em>different architecture for decision-making</em> might look like when uncertainty is highâ€Šâ€”â€Šand stability still matters. To answer it, this article explores why existing innovation efforts repeatedly collapse back into business-as-usual routines, before setting out an alternative, <em>overlaying</em> architecture for decision-making under uncertainty: one built on the premise of strength without weight and dynamic learning at itsÂ core.</p><h3>Beyond the waterfall state</h3><p>To be clear, the answer is not to burn everything down and start again. It points in a very different direction from the chainsaw, scorched-earth approach of the Elon Musks of the world. As<a href=""https://apolitical.co/communities/reimagining-public-institutions/8d06fbe0-ceab-11f0-8080-8001537bea73#1cf87f8c-d7ad-408c-a626-0640c5768499""> Andy Knight reminded me</a>, most of what government does is stewardshipâ€Šâ€”â€Šand that function is indispensable. It depends on stable, convergent, waterfall prediction policymaking. It is what keeps the lights on. Literally.</p><p>But the architecture that underpins stability is not the architecture that enables transformative change. Keeping the lights on today mattersâ€Šâ€”â€Šbut so does ensuring they stay on in the future. Missions, systems change, and early-stage sense-making require something different: space for divergent creativity, structured exploration, and collective judgement. This is the foundation for a state that is able to work with uncertainty rather than suppress itâ€Šâ€”â€Šwhat Kattel, Drechsler, and Karo describe as<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/final_innovation_bureaucracies_20_dec.pdf""> agile stability</a>: the capacity to generate new directions while maintaining long-term institutional coherence.</p><p>The problem is that we continue to run all forms of decision-makingâ€Šâ€”â€Šcertain <em>and</em> uncertainâ€Šâ€”â€Šthrough the same architecture inherited from a New Public Management era, an architecture built on the assumption that if you press a button, you know something will happenâ€Šâ€”â€Šas if governing were<a href=""https://plato.stanford.edu/entries/bounded-rationality/""> a computational task with bounded rationality</a> rather than a socio-technical one. While this logic may work tolerably well for stewarding stable systems, organisationsâ€Šâ€”â€Šand the world around themâ€Šâ€”â€Šare not computers. When uncertainty is high and judgement, learning, and creativity matter most, this type of computational â€œbounded rationalityâ€ repeatedly fails (See:<a href=""https://www.ucl.ac.uk/bartlett/publications/2024/may/mission-critical-statecraft-21st-century""> Statecraft for the 21st Century</a>) leaving us with a hollowed-out version of what Charles Lindblom once described as<a href=""https://academic.oup.com/policyandsociety/article/30/1/1/6422222""> â€œmuddling throughâ€</a>: not pragmatic adaptation, but institutional drift in the face of uncertainty.</p><p>James Plunkett has suggested that this<a href=""https://medium.com/@jamestplunkett/what-if-government-is-stuck-in-a-local-maximum-b54ad3f9dd0d""> traps government in a kind of â€œlocal maximum</a>â€ able to improve what it can already see, but unable to perceive or reach a wider landscape of possibility. Sophia Parker<a href=""https://sophiaparker-241.medium.com/a-larger-reality-how-governments-can-escape-the-local-maximum-d62018ec3949""> extends this argument</a>, noting that when institutions are caught â€œbetween worlds,â€ the familiar tools of optimisation cannot open up a larger realityâ€Šâ€”â€Šthey only make us better at navigating the statusÂ quo.</p><blockquote><em>â€œA local maximum is a place where everything you try seems to make things a bit better, but nothing you try can make things fundamentally differentâ€â€Šâ€”â€ŠJamesÂ Plunkett</em></blockquote><p>This is precisely why the re-emergence of mission-oriented and responsible approaches to policymakingâ€Šâ€”â€Šused here as an umbrella for systems thinking, futures thinking, user-centred design, agile methods and other exploratory practicesâ€Šâ€”â€Šhas put the limits of the administrative system in the spotlight. Instead of becoming a routinised way of organising systemic change, missionsâ€Šâ€”â€Šand the transformative methods attached to themâ€Šâ€”â€Šrepeatedly collapse back into incrementalism and business-as-usual routines when they are forced through an architecture built for stability.</p><blockquote>See<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/mission_oriented_innovation_policies_in_europe_from_normative_to_epistemic_turn.pdf""> Kattel &amp; Mazzucato</a> on why missions struggle to make an epistemic turn within existing bureaucratic logics, Demos Helsinkiâ€™s â€œ<a href=""https://demoshelsinki.fi/wp-content/uploads/2022/10/Missions-for-Governance-Demos-Helsinki.pdf"">Missions for Governance</a>â€ on how missions constrained by current mechanisms tend to produce only incremental improvements.</blockquote><p>So, if the architecture is the limit, the question becomes not how to replace the existing system (we rely on its stability more than we admit), but how to create an overlaying architecture that can be activated when uncertainty is high and when public value depends on exploration. Geoff Mulgan refers to this type of bureaucracy as having â€œ<a href=""https://substack.com/home/post/p-158372382"">strength without weight</a>,â€ the ability to use institutional power without the bureaucratic drag that stifles learningâ€Šâ€”â€Šenabling decision-making supported by intelligence, curiosity and adaptability, rather than the machinery of implementation andÂ control.</p><h3>The capabilities the state needs to work under uncertainty</h3><p>Any discussion of a second, more agile organisational architecture for navigating uncertainty and producing public value must begin with capability. Not whether an organisation has the <em>right structures</em> on paper, but whether it can learn, coordinate, and adjust as conditions change. Working under uncertaintyâ€Šâ€”â€Šand delivering any form of transformative, systemic changeâ€Šâ€”â€Šrequires a different way of thinking about both public value and the organisational capabilities that sustainÂ it.</p><p>First, public value cannot be treated only as an outcome delivered at the end of a policy process, or as a means-to-an-end justified through appraisal. As<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government""> Mark Moore argues</a>, it is both an outcome and something produced through the policy process itself. Under conditions of uncertainty, the quality of these processes is not incidental;<a href=""https://www.gov.uk/government/publications/the-public-design-evidence-review/public-design-evidence-review-literature-review-paper-2-public-value-html#how-to-define-public-value""> it is constitutive of public value</a>, shaped across an organisationâ€™s mission, sources of legitimacy and operational capacity. Treating value as both an outcome and a process provides a practical way to judge whether particular actions are improving a situation and are worth theirÂ costs.</p><p>This shifts attention to the dynamic capabilities embedded within public organisations: the capacities that allow institutions to sense change, coordinate across boundaries and deliberately reshape resources and priorities as the environment shifts. These are not specialist innovation skills or isolated tools, but foundational capabilitiesâ€Š<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government"">â€”â€Šcentral to public value management</a>â€Šâ€”â€Šthat determine whether an alternative decision-making architecture can function atÂ all.</p><p>This aligns closely with work on<a href=""https://www.humanlearning.systems/""> <em>Human Learning Systems</em></a>, which frames outcomes as emergent properties of complex systems and treats learning, adaptation and relationship-building not as phases of reform, but as the core work of public management under complexity.</p><p>This is where the Institute of Innovation and Public Purposeâ€™s<a href=""https://www.ucl.ac.uk/bartlett/publications/2022/mar/dynamic-capabilities-public-sector-towards-new-synthesis""> work on dynamic capabilities</a> is particularly useful. For this discussion, it helps clarify both what decision-making under uncertainty requires and why so many innovation efforts struggle to influence practice. Three dynamic capabilities are especially relevantÂ here:</p><ul><li><strong>Sense-making:</strong> the ability to scan an environment, surface weak signals, and develop shared interpretations of what is happening and why. This is not about better forecasting or more data, but about collective orientation when evidence is partial, contested, or evolving.</li><li><strong>Connecting:</strong> the capacity to coordinate across organisational, disciplinary, and sectoral boundaries. Under uncertainty, no single team or function holds the full picture. Effective decision-making depends on integrating different forms of knowledge and negotiating trade-offs across silos that were never designed toÂ meet.</li><li><strong>Shaping:</strong> the ability to reconfigure priorities, resources, and routines in response to what is being learned. Without this capability, insight accumulates but decisions remain locked inâ€Šâ€”â€Šlearning exists, but it has no leverage.</li></ul><p>Taken together, these capabilities frame public value as something produced <em>through</em> decision-making itself (or<a href=""https://www.hks.harvard.edu/publications/creating-public-value-core-idea-strategic-management-government""> â€œstrategic managementâ€</a> if you would rather). How problems are framed, whose knowledge is included, when commitments are made, and whether learning is allowed to alter direction all shape whether public value is createdâ€Šâ€”â€Šor quietlyÂ eroded.</p><h3>Why innovation efforts collapse back into business asÂ usual</h3><p>The difficulty is not a lack of innovation activity, itâ€™s where that activity sits relative to how decisions are actually made. Uncertainty demands dynamic capabilities such as sense-making, connecting, and shaping. Yet, most public-sector decision-making architectures are designed to steward stable systems, not to navigate contested, evolving or genuinely new ones. This creates a structural mismatch where even when teams attempt to work differentlyâ€Šâ€”â€Šthrough experimentation, design or mission-led approachesâ€Šâ€”â€Šthe surrounding architecture pulls decision-making back towards certainty.</p><p>Public Digitalâ€™s<a href=""https://public.digital/the-radical-how""> The Radical How</a> illustrates this issue. In the dominant waterfall model of policymaking, the most consequential decisions are made upfrontâ€Šâ€”â€Šprecisely when uncertainty is highestâ€Šâ€”â€Šwhile learning arrives later, once direction has already been fixed. The process follows a familiar pattern: <strong><em>Write policy â†’ guess requirements â†’ procure IT systems â†’ Inflict on users at scale â†’ operate indefinitely.</em></strong></p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*eFXc3Zpnftr_W-NR.png"" /><figcaption>Waterfall-style programmes start with many risky assumptions (<a href=""https://d1rnadml6vbx0i.cloudfront.net/Public-Digital_The-Radical-How.pdf"">The Radical How</a>,Â 2024)</figcaption></figure><p>Seen through this lens, learning is systematically pushed downstream, when its capacity to shape outcomes is weakest. Innovation efforts are not failing because they lack ambition or quality, but because they are layered <em>onto</em> an architecture that is structurally hostile to uncertainty.</p><p>This pattern repeats across governments. New methods are introduced, capabilities are developed, and insights are generatedâ€Šâ€”â€Šbut only <em>after</em> the moments when direction is set, resources committed, and alternatives foreclosed. The result is activity without leverage: innovation that is visible and energetic, but ultimately powerless.</p><p>Three examples help bring this structural mismatch toÂ life.</p><ol><li><strong>Policy Labs</strong></li></ol><p>Policy labs are among the most significant attempts to embed learning into policymaking through user-centred and systems perspectives. They are designed to intercept policy ideas early and improve decision quality (see<a href=""https://www.tandfonline.com/doi/full/10.1080/25741292.2021.1883834""> Anna Whicher</a> on the evolution of Policy Labs in the UK). In capability terms, labs are particularly strong at sensemaking in many ways. A large part of my own work is surfacing lived experiences, identifying risks and challenging the assumptions of policy teams while at the same time bringing together multidisciplinary actors who would not normally work together and creating relational infrastructure across policy and deliveryÂ siloes.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*n1BImJe4q3SJUECH.png"" /><figcaption>Policy Labs embed agile learning after decisions have beenÂ made</figcaption></figure><p>The problem, however, is not <em>what</em> labs do, but <em>when</em> they are able to do it. Within the existing decision-making architecture, the moments when assumptions can genuinely be challenged are tightly constrained. Policy labs rarely control the decision gates where commitments are made, budgets locked in or political capital spent. Their insights enter policy processes already moving toward closure. Learning exists, but it arrives downstream ofÂ power.</p><p>As a result, insight is absorbed rather than acted uponâ€Šâ€”â€Šoften filed away in the proverbial â€œpolicy drawerâ€ while assumptions remain untested. Labs generate understanding, but without authority to reopen decisions, that understanding struggles to shape outcomes.</p><p><strong>2. Technology-centric or challenge-driven funding</strong></p><p>Technology programmes and challenge-driven funds apply shaping pressure differently. They create momentum around emerging technologies and capabilities, directing attention, investment, and experimentation towards what <em>might</em> be possible. In doing so, they generate valuable insight into technical feasibility and future optionsâ€Šâ€”â€Šoften through pilots, prototypes, and partnerships that test new approaches in practice.</p><p>This activity frequently supports sense-making as wellâ€Šâ€”â€Šimagining new uses of AI, automation, or data at scale, and expanding the perceived solutionÂ space.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*KvUr5gH0dFZJEfMh.png"" /><figcaption>Technology and challenge-driven funds struggle to diffuse into the decision-making system</figcaption></figure><p>The problem is not the quality of this learning, but its <strong>position</strong> in the decision-making system and who it involves. Insights generated through challenge funds rarely travel upstream into everyday policy work. Policy teams struggle to access or apply what has been learnedâ€Šâ€”â€Šnot through resistance or lack of interest, but because there are few institutional pathways for the diffusion of knowledge.</p><p>As a result, innovation happens <em>around</em> the policy system rather than <em>within</em> itâ€Šâ€”â€Šshaping the environment without reshaping the decisions that govern it. Insight accumulates, but without leverage where it matters most (see my note on the frustration of AI pilots<a href=""https://substack.com/@jackstrachan/note/c-164601193"">Â here</a>).</p><p><strong>3. Generalist training, hackathons and experimentation initiatives</strong></p><p>Perhaps the most compressed illustration of the problem comes from generalist training programmes, hackathons, and short-term experimentation initiatives. These are designed to introduce brief moments of learning and collaborationâ€Šâ€”â€Šshort bursts of sense-making and connectingâ€Šâ€”â€Šoften framed as ways of normalising experimental decision-making.</p><p>Yet, in practice, they frequently do the opposite. Because these initiatives are time-bound, performative and disconnected from approval, commissioning and resource-allocation processes, their outputs struggle to survive contact with existing governance routines. What is learned rarely reshapes decisions; instead, participants return to an architecture that rewards certainty, compliance, and delivery over adaptation. It is often theatre over substance.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*zYFSfCbZgnPcu8j5.png"" /><figcaption>Generalist training, hackathons and sandboxes are often isolated occasions ofÂ theatre</figcaption></figure><p>Viewed in isolation, these initiatives can appear valuable. Participants report insight, energy, and motivation. But because they sit outside the moments where commitments are made, they offer no sustained pathway for learning to translate into publicÂ value.</p><p>This is not a failure of individuals or intent. It reflects a deeper structural issue. When learning is experienced as an exception rather than a condition of everyday decision-making, it is easily dismissed as â€œinteresting but unrealistic.â€ Without repeated, consequential exposure to uncertaintyâ€Šâ€”â€Šwhere learning genuinely alters directionâ€Šâ€”â€Šcounter-intuitive ways of working struggle toÂ stick.</p><p><strong>Across each of these examples, the same patternÂ repeats.</strong></p><p>Learning happens, but too late. Insight accumulates, but without leverage. Innovation is active, but powerless.</p><p>Seen through the waterfall architecture, this is not surprising. These mechanisms are attempting to introduce uncertainty, exploration, and adaptation into a system designed to eliminate them as early as possible. This is why mission-oriented approaches, design methods, and experimental practices so often collapse back into incrementalism: they are forced to operate <em>after</em> direction is set, resources committed, and alternatives foreclosed.</p><p>This is not a capability problem. It is an architectural one. Until the conditions exist for sense-making, connecting, and shaping to influence decisions <em>when they matter most</em>, innovation efforts will remain episodic and low-impact. Which leads to the next question: what would an alternativeâ€Šâ€”â€Š<em>complementaryâ€Šâ€”â€Š</em>decision-making architecture need to lookÂ like?</p><h3>An alternative (mission-driven) decision-making architecture</h3><p>Rather than replacing existing policymaking systems, this section sets out an overlaying decision-making architecture designed for moments of uncertainty. Drawing on Vinnovaâ€™s<a href=""https://www.vinnova.se/en/publications/mission-oriented-innovation---a-handbook-from-vinnova/""> mission-design framework</a>â€Šâ€”â€Šand learning from the UK Government Digital Serviceâ€™s<a href=""https://gds.blog.gov.uk/2014/04/01/a-year-in-the-making-the-digital-by-default-service-standard/""> agile delivery model for digital services</a>â€Šâ€”â€Šthe model below translates these insights into a participatory decision-making architecture for moments of uncertainty. Its purpose is not to generate <em>better</em> analysis, but to change how <em>direction, commitment, and resourcing decisions are formed</em> by deliberately activating the dynamic capabilities discussed earlier: sense-making, connecting, andÂ shaping.</p><p>Put simply, this architecture embeds learning <em>throughout</em> the policy design and delivery process, rather than treating it as something that arrives after key decisions have already beenÂ made.</p><p>This architecture rests on four principles.</p><ol><li><strong>Conditional, not universal: </strong>It is activated only where uncertainty is high and stakes are systemicâ€Šâ€”â€Šnot as a default mode of governance.</li><li><strong>Triggered by uncertainty, not default:</strong> It complements, rather than competes with, existing stewardship systems.</li><li><strong>Relational and procedural, not structural:</strong> it works through roles, practices and decision rights, not new hierarchies. This means a focus on making stakeholders active participants of the designÂ process.</li><li><strong>Time-bound and reversible:</strong> Its purpose is to resolve uncertainty, not institutionalise exploration indefinitely. ResultsÂ matter.</li></ol><p>Critically, it also depends on what Dan Hill describes as<a href=""https://medium.com/dark-matter-and-trojan-horses/the-city-is-my-homescreen-317673e0f57a""> <em>â€œsoft eyesâ€</em></a>: the capacity to observe and work with the dark matter of bureaucracyâ€Šâ€”â€Šthe informal relationships, tacit norms and interdependencies that sit between teams, directorates and policy domains. Without this, attempts to engage uncertainty are either blocked by premature certainty or absorbed back into business-as-usual routines before they can influence decisions.</p><p>This is not an abstract sensibility either. Variants of this capability have been articulated over the past decade through relational practices such as<a href=""https://www.linkedin.com/pulse/what-do-we-mean-relational-services-dennis-vergne-fq9he/?trackingId=ovP%2BQ3INid7UUUDxmYDavQ%3D%3D""> Relational Service Design</a>,<a href=""https://www.humanlearning.systems/""> Human Learning Systems</a>, Dark Matter Labâ€™s<a href=""https://freight.cargo.site/m/Q2581255008246565147592803666662/Governing-Together-MASTER-DECK-September-2025-v6.pdf""> Governing Together</a>, and the<a href=""https://www.strategy-business.com/article/00344""> TEAL movement</a>, which foreground trust, continuity, and institutional relationships as core operating conditions rather than delivery-side effects. The challenge is not their absence, but their marginal position relative to where decisions are actuallyÂ made.</p><p>What follows sets out how this overlaying architecture works in practice: the stages it moves through, the capabilities it embeds, and how it interfaces with the stateâ€™s existing delivery and stewardship machinery.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*LSRj1lPPAt4Y84RE.png"" /><figcaption>An overlaying decision-making architecture</figcaption></figure><p>At a high level, the architecture is organised around four overlapping learning loops. These are not phases or stage gates. They are modes of work that structure how learning, judgement, and commitment evolve under uncertainty. What distinguishes this model from familiar innovation or design frameworks is not the loops themselves, but where decision authority and resource commitment sit withinÂ them.</p><p>The flow follows Vinnovaâ€™s mission-design framework, moving from <strong>Angles â†’ Missions â†’ Prototypes â†’ Demonstrators</strong>, progressively reducing uncertainty while keeping direction open for as long as possible.</p><h3>A. Angles: orienting theÂ system</h3><p>The Angles loop focuses on collectively developing an initial view of the system: identifying where uncertainty lies, what matters, and where intervention might be possible.</p><p>Rather than jumping to solutions, this loop brings a core group together to surface <em>different ways of seeing the problem space</em>. It deliberately draws together a trans-disciplinary team of policy, operational, user, technical, and political perspectives to build a shared orientation to the system as it is experienced, not just described.</p><p>The emphasis here is on sense-making and connecting. The output is not a strategy or recommendation, but a set of <em>plausible directions</em>â€Šâ€”â€Šangles of intervention worth exploring further.</p><h3>B. Missions: committing to direction</h3><p>The Missions loop translates the most promising angles into statements of intent and design principles. These articulate <em>what kind of change is being pursued and why</em>, without prematurely specifying how it will be delivered. Design principles matter because they act as decision constraints under uncertaintyâ€Šâ€”â€Ša function<a href=""https://gds.blog.gov.uk/2025/12/10/designing-public-services-that-work-for-everyone/""> GDS has long used to align teams</a> without over-specifying solutions.</p><p>At this point, connecting remains centralâ€Šâ€”â€Šaligning actors around a shared purposeâ€Šâ€”â€Šwhile shaping begins to matter more. Missions create directionality by setting boundaries, clarifying intent, and establishing criteria for learning in the nextÂ stages.</p><p>Crucially, missions are treated as provisional commitments. They are strong enough to mobilise action, but flexible enough to adapt as learning accumulates. Their role is not to close down debate, but to focus itâ€Šâ€”â€Šsimilar to<a href=""https://futurestatedesign.co/futurestate-design""> futurestate strategy</a> or<a href=""https://www.ucl.ac.uk/bartlett/sites/bartlett/files/stakeholder_engagement_for_policy_design_planning.pdf""> strategic foresight practices</a>.</p><h3>C. Prototypes: learning through tangible commitments</h3><p>The Prototypes loop explores missions through a portfolio of concrete experimentsâ€Šâ€”â€Špolicy, service, regulatory, or organisationalâ€Šâ€”â€Šdesigned to test assumptions and surface consequences.</p><p>Prototypes are decision-shaping commitments: deliberately designed to inform judgement about whether, how, and where to scale. Multiple prototypes ask different questions, reducing uncertainty through comparison rather than consensus. Vinnovaâ€™s<a href=""https://arkdes.se/en/projects/street-moves/""> <em>Street Moves</em></a> programme is a good example: place-based experiments used not as pilots, but as learningÂ devices.</p><p>Here, connecting and shaping are tightly coupled. Prototypes act as boundary objects, aligning actors, mobilising resources and enabling learning through doing. The emphasis is not speed for its own sake, but efficiency: learning as much as possible for the least irreversible cost. Or, in Public Digitalâ€™s â€œ<a href=""https://d1rnadml6vbx0i.cloudfront.net/Public-Digital_The-Radical-How.pdf"">The Radical Howâ€</a> terms: doing whatever it takes to speed up the loop of testing the things that matter the most and learning from theÂ results.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/966/0*pj4BbouEHOw6rmkz.png"" /><figcaption>Agile learning. The Radical How,Â 2024.</figcaption></figure><h3>D. Demonstrators: integrating learning atÂ scale</h3><p>The Demonstrators loop brings together insights from multiple prototypes into large-scale system demonstrations. These are not end states; they are decision-shaping devices. Their purpose is to determine whether uncertainty has been reduced <em>enough</em> to re-enter the stateâ€™s core delivery and stewardship architecture.</p><p>Here, sense-making resurfaces, alongside continued connecting and shaping, as priorities and resources are adjusted in response to what has been learned. Demonstrators help decision-makers see how interventions interact at scale before irreversible commitments are made. At this point, work can deliberately transition from exploratory modes into more stable delivery pathwaysâ€Šâ€”â€Šmoving from adaptive learning to reliable execution.</p><h3>Switching modes</h3><p>At this point, I want to stress that this proposed second architecture is conditional, not universal. It is activated only when uncertainty is highâ€Šâ€”â€Šwhen outcomes cannot be reliably predicted, causal pathways are contested, and early lock-in would be costly or irreversible. Itâ€™s about introducing a dynamic learning process so that the state can <em>return</em> to its stable delivery architecture once uncertainty has beenÂ reduced.</p><p>When activated, several conditions matter:</p><ul><li>decision authority must sit close to theÂ work</li><li>learning must have formal routes into commitment and resourcing</li><li>participation must include those affected, not only those accountable</li><li>exit conditions must beÂ explicit</li></ul><p>The intent is not to weaken the stateâ€™s capacity for delivery, but to protect it by ensuring that stability is not achieved at the cost of learning, and that exploration does not become detached from power. In other words, this is not about replacing the machinery that keeps the lights on. It is about creating the conditions under which the state can <em>decide differently when it needs to</em>â€Šâ€”â€Šand then return, deliberately, to what it already doesÂ well.</p><h3>Preparing the ground: agile team models when working under uncertainty</h3><p>Transformative change starts by <em>preparing the ground</em>: creating the conditions for a small, multidisciplinary team to work differently, with political cover, protected space, and the authority to bypass routine constraints long enough to prove what is possible. This was true of the early Government Digital Service in 2011, and it remains true of any attempt to change how the state decides under uncertainty.</p><p>Fundamentally, if we expect teams to sense, connect, and shape under uncertainty, we cannot treat them as interchangeable delivery units. Different phases of decision-making require different, malleable team purposes and archetypes that evolve as uncertainty reduces.</p><p>Kate Tarlingâ€™s work on<a href=""https://www.theserviceorg.com/""> service organisations</a> is useful here. Rather than assuming static â€œagile teams,â€ she shows how teams shift over time: from exploratory, functional groupings with hand-offs, towards whole teams responsible for delivering and improving joined-up services. She stresses that hand-offs are not inherently problematic but they are often necessary early onâ€Šâ€”â€Šwith problems arising when teams are <em>locked</em> into a structure that no longer matches the nature of the work and are forced into incompatible handovers.</p><p>It is therefore more helpful to think in terms of complementary team types, rather than a single ideal form. Drawing loosely on team typologies developed by<a href=""https://teamtopologies.com/book""> Skelton and Pais</a> (and Tarling), a mission-driven architecture typically relies on a portfolio of teams with distinctÂ roles:</p><ul><li><strong>Service teams</strong> are responsible for delivering and improving outcomes for users and operations.</li><li><strong>Depth teams</strong>, which explore complex issues, generate insight and reduce uncertainty on behalf ofÂ others.</li><li><strong>Common-capability teams</strong>, which build shared tools, platforms, and processes that make learning and deliveryÂ easier.</li><li><strong>Enabling teams</strong>, which unblock, coach, and support other teams to adopt new ways ofÂ working.</li><li><strong>Coordinating teams</strong>, which align activity across services or missions when interdependencies areÂ high.</li><li><strong>Operational teams</strong>, which steward stable systems and deliver continuity overÂ time.</li></ul><p>Crucially, these teams do not all operate in the same way, nor at the same time. Early in the lifecycle of a missionâ€Šâ€”â€Šwhen uncertainty is highestâ€Šâ€”â€Šdepth, enabling, and coordinating teams play a larger role in sense-making and connecting. As direction stabilises and uncertainty reduces, service and operational teams take on greater responsibility for shaping and delivery.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*Mue1QZS_TrhSJKpp.png"" /><figcaption>Different types of decision-making demand different types ofÂ teams</figcaption></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*12rV9jFOQ7-1YVOL.png"" /><figcaption>Team types, roles and sizes are malleable to the context of theÂ decision</figcaption></figure><p>Seen this way, team models are not an implementation detail, but a core part of the decision-making architecture. Without the right mix of teamsâ€Šâ€”â€Šand the ability for them to change as conditions changeâ€Šâ€”â€Ševen well-designed missions will struggle to move from exploration toÂ impact.</p><h3>Conclusion</h3><p>The world is not a machine where, if you pull a policy lever, something will happen. Reconnecting policymaking with this reality means moving beyond top-down, disconnected approaches and towards a decision-making architecture that treats uncertainty as something to be worked with, not engineered away. One that embeds learning, judgement, and adaptation into how direction is setâ€Šâ€”â€Šwithout sacrificing the stability the state depends on. Whatâ€™s required is <em>strength without weight.</em> The ability to do the hard things well, while remaining flexible enough to change when conditions demandÂ it.</p><p>I want to be clear about what this piece isâ€Šâ€”â€Šand is not. Itâ€™s not a story of pessimism, nor a claim that the government lacks innovation or intent. Quite the opposite. There is a great deal of thoughtful, committed work happening across UK government and beyond (See:<a href=""https://academic.oup.com/pa/article/77/4/837/7729221?login=false""> The state of British policymaking: How can UK government become more effective</a>). This is an attempt to frame those effortsâ€Šâ€”â€Šthrough theory and lived experienceâ€Šâ€”â€Šin a way that surfaces a deeper constraint: not ambition or capability, but the architectures through which decisions areÂ made.</p><p>This article is not <em>the</em> answer either. The critique, and the model that follows it, could easily be read as two-dimensional: one person diagnosing a system and proposing a cleaner alternative. That reading misses the point. The issue is not a shortage of models for change. Itâ€™s that institutionsâ€Š<a href=""https://demos.co.uk/research/the-human-handbrake-how-whitehall-culture-holds-back-public-service-reform/"">â€”â€ŠWhitehall included</a>â€Šâ€”â€Šoften convince themselves they are uniquely resistant to new ways of doing, while continuing to route uncertainty through systems designed to suppressÂ it.</p><p>This is as much a cultural challenge as a structural one. Work on systems change reminds us that transformation rarely follows linear cause-and-effect pathways. It emerges through overlapping activity, partial learning and shifting coalitions over time. For those of us working inside the government, that means holding multiple perspectives at once: staying curious, working across boundaries, and treating thinking itself as a form of actionâ€Šâ€”â€Šsomething that shapes what becomes possibleÂ next.</p><p>Much of what Iâ€™ve drawn on here builds on existing ground: the early work of Government Digital Service, mission-oriented innovation frameworks, action-based approaches to social change, and emerging practices around Human Learning Systems and other relational practices. The open questions, for me, are less about invention than application. How do these principles actually reshape decision-making at scale? What role does digital playâ€Šâ€”â€Šnot as infrastructure alone, but as an enabler of learning, coordination and judgement? Have we laid the horizontal foundations for a third era of digital governance, or are we still struggling to move beyond enterprise-era assumptions?</p><p>Those are questions for anotherÂ time.</p><h3>Next stepsâ€¦</h3><p>As with most of my writing on substack, this is thinking-as-writing rather than a finished argument. Itâ€™s an attempt to synthesise lived experience wrestle with the ideas and practices Iâ€™ve been immersed in over the past few years, to see whether they hold together. Itâ€™s written as self-provocations, loose ends, tensions and partial conclusionsâ€Šâ€”â€Šthatâ€™s part of the point forÂ me.</p><p>For now though, this thinking is feeding directly into my own work at HM Revenue &amp; Customs where Iâ€™m currently leading a review of our internal <em>Budget Policy Starter</em> technology-impacting process by working with policymakers, solution architects, cost engineers and user-centred designers to better bridge stable and agile ways of workingâ€Šâ€”â€Šand, in doing so, improve how policy decisions are shaped upstream so they serve citizens more effectively downstream.</p><p><em>This post is part of </em><a href=""https://civicworks.substack.com/""><em>CIVICWORKS</em></a><em>; a publication on (re)thinking civic bureaucracy, institutional reform, dynamic capabilities, policymaking and technology.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d81fadb93106"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/beyond-the-waterfall-state-why-missions-need-a-different-decision-making-architecture-d81fadb93106"">Beyond the waterfall state: why missions need a different decision-making architecture</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4,1769728943,Vibe prototyping is a double-edged sword,"Vibe prototyping is a double-edged sword

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*Ez3xrHNO1FxfTH0By1-Ekg.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">Vibe coding prototypes is so fun we forget what prototypes are for</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/vibe-prototyping-is-a-double-edged-sword-0e092435c07c?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4,1769623657,The rise of the Orchestrated User Interface (OUI),"The rise of the Orchestrated User Interface (OUI)

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2452/1*WyC312mkKkITB1eOo56HrA.jpeg"" width=""2452"" /></a></p><p class=""medium-feed-snippet"">Designing for intent in a brave new world.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-rise-of-the-orchestrated-user-interface-oui-ac4202d1777d?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/giraffe-muppet-or-human-9c5457d44a50?source=rss----138adf9c44c---4,1769602303,"Giraffe, muppet, or human?","Giraffe, muppet, or human?

<h4>Discuss childrenâ€™s preference on avatarÂ design</h4><figure><img alt=""a white board with three quick sketches on it: doll, human face, and giraffe"" src=""https://cdn-images-1.medium.com/max/1024/1*3UX4wIsuV9HFPyR68K1AnA.png"" /><figcaption>Image created by AI tool ElevenLabs</figcaption></figure><p>As a developer in a childrenâ€™s hospital, Iâ€™ve designed some playful VR simulations for young patients. We try to avoid serious medical settings because there are still concerns about using VR in serious clinical contexts. Instead, we use VR in two main ways: making tedious treatments more engaging through gamification, and providing distraction during painful moments. Itâ€™s become pretty common, and itâ€™s effective.</p><p>But when these simulations need avatars, thereâ€™s always that one question: <strong>What should they look like? </strong>An animal character? A cartoon character? AnotherÂ human?</p><p>This matters more than youâ€™d think. In VR, kidsâ€™ emotions intensify. Theyâ€™re still figuring out whatâ€™s real and whatâ€™s not, so getting the details wrong can cause real confusion and discomfort.</p><p>Hereâ€™s what I learned from the research:</p><h3>Not too real, not tooÂ fake</h3><p><a href=""https://dl.acm.org/doi/fullHtml/10.1145/3544548.3581501"">Research </a>tested three VR avatars with kids: a human, a giraffe, and a Muppet. I thought the Muppet would win because itâ€™s cute (well, I think so) and familiar toÂ kids.</p><p>The giraffeÂ won.</p><figure><img alt=""sad Elmo"" src=""https://cdn-images-1.medium.com/max/753/1*fSqwbDbYH8_Mi8K7xic8Bg.png"" /><figcaption>Sad Elmo (<a href=""https://tenor.com/view/fairysoobs-elmo-sad-elmo-sad-stare-gif-26846922"">imageÂ source</a>)</figcaption></figure><p>Researchers think <strong>social realism</strong> is one reason. Social realism means how closely something matches what kids experience in real life. A human has high social realism (kids see humans daily). A giraffe has moderate social realism (it exists, but kids donâ€™t encounter one up close). A Muppet has low social realism (itâ€™s a fantastical TV character, not a livingÂ being).</p><figure><img alt=""Three different social realism"" src=""https://cdn-images-1.medium.com/max/1000/1*aUetvXe6GSzGacdC2MWPfQ.png"" /><figcaption>Three different socialÂ realism</figcaption></figure><p>The giraffe hit the sweet spot: real enough to be believable, special enough to be exciting. As one kid said, â€œI have never seen one so itâ€™s reallyÂ cool.â€</p><p>The human characterâ€™s high social realism created its own problem. Because humansâ€™ brains are so good at identifying faces, kids noticed and commented on every imperfection: â€œweird hair,â€ â€œbig head.â€ They also found the eye movements unsettling.</p><p>Kids found the Muppet â€œweirdâ€ and â€œcreepyâ€ because â€œitâ€™s not a real thing.â€ When children are still learning to separate fantasy from reality, encountering something contradictory can be unsettling. However, kids who recognized the Muppet from Sesame Street actually responded positively, which means prior exposure mightÂ help.</p><p>Still, itâ€™s hard to predict each childâ€™s experience with specific characters. A safe design principle is to choose something with moderate social realism. Itâ€™s clearly non-human, clearly plausible, and doesnâ€™t trigger that uncomfortable â€œthis shouldnâ€™t existâ€ or â€œsomethingâ€™s offâ€Â feeling.</p><h3>Getting the proportions right</h3><p>Okay, so letâ€™s say we pick a character with moderate social realism, like a fox. How should we design its appearance? Most designers are aware of uncanny valley effects and avoid hyper-realistic designs. So what if we make it cute and cartoon-like with bigger eyes andÂ head?</p><p>Well, it turns out that kids arenâ€™t fans of exaggerated proportions either. <a href=""https://www.webofscience.com/wos/woscc/full-record/WOS:000449027600041"">Fengâ€™s research</a> showed that childrenâ€™s preference declined as eye size enlarged. The reason is likely the same: <strong>exaggerated proportions conflict with kidsâ€™ understanding of the world.</strong> <a href=""https://journals.sagepub.com/doi/10.1177/2042753021994337"">Research</a> with young adults showed that a 25% eye size increase can be optimal, suggesting small tweaks might help. However, more research is needed to determine if this applies to children asÂ well.</p><p>When designing the appearance, consistency is crucial. If you choose a cartoon style, commit fully across the entire body, not just the face. Mixing realistic bodies with cartoonish features creates the kind of mismatch that makes kids uncomfortable.</p><h3>Movement matters</h3><p>Besides appearance, many kids commented on avatarsâ€™ behaviors. Interestingly, they mentioned movement first and appearance second, showing the importance of behavioral realism.</p><p>Kids made comments about all kinds of movements, including head movements and facial expressions. But among all their observations, eyes were the most critical feature.<strong> They assessed realism mainly through eye behavior.</strong> For instance, they found avatars creepy because of â€œunsettling eye movement,â€ staring, or unnatural blinking speed. They also wanted avatars to â€œacknowledge their existence by making eye contact.â€</p><p>However, realism alone isnâ€™t enough. Consistency matters. A cartoon fox with hyper-realistic blinking will still feel off. Behavioral realism needs to match visual realism. Designers need to find the balance between all elements.</p><h3>Keep distance inÂ mind</h3><p>Compared to adults, kids showed more attempts to interact with avatars. They wanted to play with them and touch them. Some expressed disappointment that avatars felt â€œfakeâ€ because they couldnâ€™t physically interact withÂ them.</p><p>Not all applications need direct avatar interaction. For experiences where interaction isnâ€™t intended, distance design can help. Well-designed distance can improve both visual and behavioral realism. It not only prevents unwanted interactions but also keeps certain imperfect features from being too noticeable.</p><p>Distance design is relatively new compared to traditional media. On flat screens, characters maintain a certain distance from users. However, in VR, characters share the same space asÂ kids.</p><p>In real life, people naturally keep some distance from one another. Hallâ€™s proxemics theory (1966) explains this: people maintain different zones of personal space depending on their relationship and social context. <a href=""https://link.springer.com/article/10.1007/s10055-025-01127-y"">Studies </a>show people maintain similar distance zones in VR. When approaching others, they typically stay within social space range (1.22â€“3.65m), which is consistent with Hallâ€™s theory. (1 unity unit in VR = 1Â meter)</p><figure><img alt=""Hallâ€™s proxemics theory"" src=""https://cdn-images-1.medium.com/max/1024/1*dPODKM01alTqpWRGVKxvcw.png"" /><figcaption>Hallâ€™s proxemics theory</figcaption></figure><p>However, some <a href=""https://link.springer.com/article/10.1007/s10055-024-00982-5"">studies</a> find people keep much larger distances in VR than in real life, which is around 160% farther. This might be because distance perception works differently in virtual environments.</p><p>These differences are normal. They can stem from environmental settings, age range, or usersâ€™ prior VR experience.<strong> The safest design principle is to position avatars slightly farther away and allow kids to close the gap if theyÂ want.</strong></p><p>In VR, kidsâ€™ emotions intensify because characters share the same space, making everything feel more real. This makes designing avatars trickier than itÂ looks.</p><p>Itâ€™s not just about making something cute. We need to understand how children process reality and what triggers their â€œsomethingâ€™s wrongâ€ feeling. Kids are still in their developmental phase, learning whatâ€™s real and whatâ€™s not. Being cautious helps us avoid triggering discomfort and confusion.</p><p>And remember: consistency is key. Pick your level of realism and stick to it across appearance, movement, and distance. Otherwise, your design is just â€œcreepyâ€ andÂ â€œweirdâ€.</p><h4>Reference:</h4><ul><li>Segaran, K., Ali, A. Z. M., &amp; Hoe, T. W. (2021). â€œDoes avatar design in educational games promote a positive emotional experience among learners?â€ <a href=""https://journals.sagepub.com/doi/10.1177/2042753021994337"">https://journals.sagepub.com/doi/10.1177/2042753021994337</a></li><li>Bailey, J. O., &amp; Schloss, I. (2023). â€œâ€˜Awesomely freaky!â€™ The impact of type on childrenâ€™s social-emotional perceptions of virtual reality characters.â€ <a href=""https://dl.acm.org/doi/fullHtml/10.1145/3544548.3581501"">https://dl.acm.org/doi/fullHtml/10.1145/3544548.3581501</a></li><li>Nolte, D., Hjoj, R., SÃ¡nchez Pacheco, T. <em>et al.</em> Investigating proxemics behaviors towards individuals, pairs, and groups in virtual reality. <em>Virtual Reality</em> <strong>29</strong>, 58 (2025). <a href=""https://doi.org/10.1007/s10055-025-01127-y"">https://doi.org/10.1007/s10055-025-01127-y</a></li><li>Kim, I., Sung, J. New proxemics in new space: proxemics in VR. <em>Virtual Reality</em> <strong>28</strong>, 85 (2024). <a href=""https://doi.org/10.1007/s10055-024-00982-5"">https://doi.org/10.1007/s10055-024-00982-5</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9c5457d44a50"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/giraffe-muppet-or-human-9c5457d44a50"">Giraffe, muppet, or human?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/how-wrong-becomes-normal-381f5a33f8b7?source=rss----138adf9c44c---4,1769602280,How wrong becomes normal,"How wrong becomes normal

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-wrong-becomes-normal-381f5a33f8b7?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/600/0*JXRwEX75j7eXFNr1"" width=""600"" /></a></p><p class=""medium-feed-snippet"">The quiet normalization of dark patterns</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-wrong-becomes-normal-381f5a33f8b7?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/are-we-doing-ux-for-ai-the-right-way-aea01e14138e?source=rss----138adf9c44c---4,1769542429,Are we doing UX for AI the right way?,"Are we doing UX for AI the right way?

<h4>How chatbot-first thinking makes products harder forÂ users</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*7x1tlD3qYPDu58RQ-u1veQ.png"" /></figure><p>Weâ€™ve lived with AI long enough to witness some groundbreaking changes in how we live, work, and design. But weâ€™ve also lived with it long enough for misconceptions to emergeâ€Šâ€”â€Šbefore best practices have really had a chance toÂ settle.</p><p>The pace of disruption remains wild. However, <a href=""https://www.nngroup.com/articles/state-of-ux-2026/"">2026 is already being described as the year of AIÂ fatigue</a>.</p><p>For product leaders, this creates a new challenge: we need to define ways to approach UX for AI without making AI-powered products exhausting, inconvenient, risky, and unsustainable.</p><p>This article focuses on one of the widespread misconceptions that could send the future of UX along a very wrong trajectory. I call it <em>chatbot-first thinking</em>: the assumption that conversational interfaces canâ€Šâ€”â€Šor shouldâ€Šâ€”â€Šreplace most existing UI patterns completely.</p><h3><strong>The Promise of ZeroÂ UI</strong></h3><p>Letâ€™s start with the most obvious question on theÂ surface:</p><p><strong>Is the future of user experience purely conversational?</strong></p><p>For many, itâ€™s tempting to dream about it. Especially if youâ€™re a frequent user of large LLM interfaces today. Especially if you follow <a href=""https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/"">announcements like OpenAIâ€™s recent promise of a screen-free, pocketable product</a> that hints at a life increasingly driven by AI orchestration. And especially if your mental model of AI experience is based on the early ChatGPT experience, which was entirely conversational, with no UI snippets and micro-apps within the chat dialogue.</p><p>Itâ€™s also easy to fall into this line of thinking after watching the rise of ChatGPT appsâ€Šâ€”â€Špulling familiar services, like OpenTable, directly into the chat dialogue (spoiler alert: you still need to visit OpenTableâ€™s website to complete your user journey, as is the case with almost every app in the ChatGPT app directory). The idea that everything could eventually live inside a single conversational interface starts to feel not just plausible, but inevitable.</p><a href=""https://medium.com/media/c1daf7b9a5b088348fa7d2943f70612d/href"">https://medium.com/media/c1daf7b9a5b088348fa7d2943f70612d/href</a><p>In my personal life, as an enthusiast of AI tools, I increasingly try to experiment and outsource tasks to LLMs via text or voice. Agents from tools like ChatGPT or Claudeâ€Šâ€”â€Šdespite being clumsy, slow, and often struggling with all the still-non-AI-first websitesâ€Šâ€”â€Šcan handle a variety of scenarios, all of which I can trigger via a voice command in theÂ chat.</p><p>But thereâ€™s only so much I can do via text, let aloneÂ voice.</p><h3>Can we always use conversational UX?</h3><p>The reality is much more complex. Many of the tasks we deal with in our personal life and at work require <strong>rich, multi-modal interaction patterns that conversational interfaces simply cannotÂ support</strong>.</p><p>If youâ€™re a product leader evaluating whether UX of your AI functionality should become purely conversational, I recommend thinking twice whether it will become an accelerator or a blocker for yourÂ product.</p><p>One of the good starting points is <a href=""https://developers.google.com/assistant/conversation-design/is-conversation-the-right-fit#is-conversation-the-right-fit"">Googleâ€™s checklist</a> for the conversational approachÂ fit:</p><figure><img alt=""â€œIs conversation the right fit?â€ from Googleâ€™s Assistant / Conversation Design Guidance"" src=""https://cdn-images-1.medium.com/max/1024/1*adb9a_2AQYvfkCIsl69UtA.png"" /><figcaption>â€œIs conversation the right fit?â€ from <a href=""https://developers.google.com/assistant/conversation-design/is-conversation-the-right-fit#is-conversation-the-right-fit"">Googleâ€™s Assistant / Conversation DesignÂ Guidance</a></figcaption></figure><blockquote>When working with clients, we take this evaluation to the next level by guiding them to the interaction pattern choice via a series of validating questions, and essentially checkingâ€Šâ€”â€Šdoes the conversational approach check all theÂ boxes?</blockquote><h4>Question 1: Is it accessible?</h4><p>Chat-based interfaces require users to describe their problems in written text. <a href=""https://nces.ed.gov/surveys/piaac/ideuspiaac/"">Recent literacy research</a> shows that nearly half of the population in wealthy countries struggles with complex texts and wonâ€™t get good results from chatbots. <a href=""https://www.uxtigers.com/post/ai-articulation-barrier"">Jacob Nielsen called it a fundamental usability problem</a>, because it forces users to become prompt engineers just to reach the same basic level of user experience that visual interfaces previously provided.</p><figure><img alt=""Data collected by the OECD. Countries are sorted by the percentage of their adult population within literacy levels zero through two. â€œScandinaviaâ€ is the average of Denmark, Finland, Norway, and Sweden."" src=""https://cdn-images-1.medium.com/max/1024/1*BNh8aQnIHCnFkf9IrA0wMw.avif"" /><figcaption><a href=""https://nces.ed.gov/surveys/piaac/ideuspiaac/"">Data collected by the OECD</a>. Countries are sorted by the percentage of their adult population within literacy levels zero through two. â€œScandinaviaâ€ is the average of Denmark, Finland, Norway, andÂ Sweden.</figcaption></figure><h4>Question 2: Does it promote the productâ€™s adoption and discoverability?</h4><p>Letâ€™s imagine all of your productâ€™s users are articulate enough. Could they still use a conversational approach for virtually everything?</p><p>Consider food ordering as an example. Major players in the AI industry like to paint a future where ordering a lunch delivery is as simple as issuing a voice command. But what if you donâ€™t know what you want to order at all and would prefer to see the menu first? Listening to a menu, when it could be presented via graphical interface, violates one of the <a href=""https://www.nngroup.com/articles/ten-usability-heuristics/#:~:text=6%3A%20Recognition%20Rather%20than%20Recall"">core usability principles, <em>â€œrecognition rather than recallâ€</em></a> which advises <strong>minimising memory load by keeping interfaces self-evident.</strong></p><blockquote>Unlike a screen, spoken commands and outputs vanish instantly, giving users nothing to refer back to. Itâ€™s <em>â€œmuch easier to pick out the desired item from a list when the list is displayed on a monitor than when itâ€™s read aloud,â€</em> <a href=""https://www.nngroup.com/articles/voice-interfaces-assessing-the-potential/#:~:text=,feedback%20%20on%20its%20actions"">as Jacob Nielsen explains</a>.</blockquote><p>Back to our example with food ordering: how often do you actually spell out the names of your favourite food items in your head when youâ€™re hungry? Maybe you just donâ€™t remember the quirky name of that rice bowl you always order. Which leads us to the next issue with conversational interfaces.</p><p>Everything we put in a chat prompt is a piece of context, and the result of our collaboration with a chatbot can be only as good as the precision and relevance of our input.<strong> Therefore, prompt-based products work best for the users who already know how to ask the right question.</strong></p><p>In a purely conversational system, users often donâ€™t know what features or commands exist, unless they actively ask or the system hints at them. Moreover, when they do discover the product capabilities and get their job done successfully via chat, how can they be sure they can still get the exact same result next time? Generative AI is probabilistic by nature, and the results may differ slightly each time. Of course, building a knowledge graph, templates, or guardrails can reduce this variationâ€Šâ€”â€Šbut it can never remove it entirely. Conversational interfaces are a poor fit for high-precision tasksâ€Šâ€”â€Šunless they are heavily supported by non-conversational structure.</p><h4>Question 4: Is it reliable?</h4><p>Imagine a business user using a purely conversational assistant to update a contract term: â€œChange the renewal period to one year and apply the standard discount.â€</p><p>That sounds clear to a human, but in practice it leaves room for interpretation. Which contract version? Which definition of â€œstandardâ€? Does the discount apply immediately or at renewal? Is it one year from today or from the original start date? Small variations in phrasingâ€Šâ€”â€Šor in how the model interprets contextâ€Šâ€”â€Šcan lead to different outcomes eachÂ time.</p><p>In high-precision scenarios like this, users need to see exact fields, values, and constraints, review changes side by side, and explicitly confirm what will be saved. A conversational interface can help guide the process, but relying on chat alone makes the experience fragile.</p><h4>Question 5: Is it necessary?</h4><p>Just because a task <em>can</em> be done via chat, should it be done viaÂ chat?</p><p>Letâ€™s take an example of an atomic, well-defined task that looks like a textbook success case for an AI agent: I recently needed a transcript for a YouTube video and decided to outsource the task to the ChatGPTÂ agent.</p><p>The old way of doingÂ it:</p><ol><li>Search for an online transcription service</li><li>Copy and paste the YouTubeÂ link</li><li>Click a call-to-action button</li><li>Download the transcript</li></ol><p>The new, agentic way of doing it (as of JanuaryÂ 2026):</p><ol><li>Prompt ChatGPT: Get me the transcript of this YouTube video (link included)</li><li>(Optional) Observe how the agent navigates across multiple third-party transcription services, struggles with permissions, cookies, paywalls, or rate limits, retries failed requests, reformats output several times, takes minutes to complete the task but finally provides the transcript</li><li>Download the transcript</li></ol><p>If I need the transcript now, the experience quickly becomes frustrating. But itâ€™s not justÂ that.</p><h4>Question 6: Is it sustainable?</h4><p>The described experience raises another debate. When an LLM agent spends five minutes crawling the web, calling tools, retrying failures, reasoning through intermediate steps, it is running on energy-intensive infrastructure, contributing to real data-center load, energy usage, and COâ‚‚ emissions. For a task that could be solved with less energy by a specialised service, this is computational overkill.</p><p>From a systems perspective, this isnâ€™t just inefficient UXâ€Šâ€”â€Šitâ€™s inefficient infrastructure usage. <strong>The question becomes: was AI the right tool for this task atÂ all?</strong></p><h3>But what about agentic experiences? Wonâ€™t they remove the need for UI (andÂ UX)?</h3><p>First, letâ€™s explore what an AI agentÂ is.</p><blockquote><a href=""https://cloud.google.com/discover/what-are-ai-agents"">An AI agent is a software system that autonomously pursues goals and completes tasks on behalf of a user by reasoning, planning, and acting across tools and environments with minimal humanÂ input.</a></blockquote><p>The agentâ€™s role is to support human workflows: making information visible or drawing attention to what matters, handling parts of the workflow, exploring alternative scenarios, suggesting a best-guess next step, translating intent into actions by interfacing with APIs, coordinating signals across systems, or executing commands. <strong>The human remains the primary problem solver, with the agent augmenting and supportingâ€Šâ€”â€Šnot replacing them.</strong></p><p>In line with service design thinking, agents need humans to support them across several stages of the agentic lifecycle: 1) <strong>Set up</strong> â†’ 2) <strong>Delegate</strong> â†’ 3) <strong>Execute</strong> â†’ 4) <strong>Observe</strong> â†’ 5) <strong>Intervene</strong> â†’ 6) <strong>Confirm</strong> â†’ 7) <strong>Complete</strong> â†’ 8) <strong>Learn and Disengage. </strong>This system layer is called <a href=""https://www.ibm.com/think/topics/human-in-the-loop"">human-in-the-loop (HITL)</a> and is intended to ensure accuracy, safety, accountability or ethical decision-making of AI workflows.</p><blockquote>Agentic experiences require a service design approach to mapping and designing of these novel, dual experiences where agents and humans collaborate to achieve results we earlier could only dreamÂ of.</blockquote><figure><img alt=""Service blueprint for human-agentic experiences"" src=""https://cdn-images-1.medium.com/max/1024/1*O6-4hKkZyanuzI-4UN1zTw.png"" /><figcaption>Service blueprint for human-agentic experiences</figcaption></figure><p>All of the described stages and touchpoints require choosing from a variety of interface approaches, beyond just the conversational one <a href=""https://arxiv.org/html/2410.22370v1"">(canvas UI, contextual UI, modular UI, simulation environment, and other types)</a>. But this is a topic for a different article.</p><figure><img alt=""Various UX layouts for generative AI"" src=""https://cdn-images-1.medium.com/max/1024/1*h3gLQka9I-VzYo2rKBLe3g.png"" /><figcaption>Various <a href=""https://arxiv.org/html/2410.22370v1"">UX layouts for generative AI</a></figcaption></figure><h3>The price of (not) doing UX for AI the rightÂ way</h3><p>Customer fatigue with AI slop is growing across all industries, with business initiatives like <a href=""https://www.nngroup.com/articles/ai-ad/"">AI-generated ad campaigns triggering massive online backlash</a>.</p><p>In 2024 LinkedIn <a href=""https://www.fastcompany.com/91196335/linkedin-ai-powered-prompt-questions-under-posts-feeds-premium-removed"">silently removed the shallow and unhelpful AI prompt suggestions</a> in the feed which were spotted frequently by Premium users. Meta was also <a href=""https://www.nbcnews.com/tech/tech-news/meta-putting-ai-front-center-apps-users-are-annoyed-rcna148857"">criticised for rolling out Meta AI as a default part of the interface in their major apps</a>, such as in the search bar or with prominent icons users canâ€™t easily remove. Despite the user backlash, Meta is continuing to push AI features and earning the reputation of a company that is leading with AI for AIâ€™s sake and hurting user experience rather than helpingÂ it.</p><p>On the other hand, companies that apply user-centered approach to the design of AI-powered products are enjoying success as pioneers setting new mentalÂ models.</p><p>For example, <a href=""https://news.microsoft.com/en-hk/2024/11/20/ignite-2024-why-nearly-70-of-the-fortune-500-now-use-microsoft-365-copilot/"">Microsoft 365 Copilotâ€™s success with 70% of Fortune 500</a> companies is partially explained by their<strong><em> </em></strong>inline-style interaction pattern which has become the baseline of intuitive AI UXâ€Šâ€”â€Šthe one that enhances existing workflows, not replaces them with inferior interaction patterns.</p><p>Notion AI has been one of the first companies which enabled the interaction pattern of AI suggesting contextual preset actions. This is just one example of how thoughtful selection of a UX pattern can remove the cognitive load of wondering what the AI can actually do with the text and what the best way to prompt itÂ is.</p><figure><img alt=""Notion AI providing contextual actions to guide the user"" src=""https://cdn-images-1.medium.com/max/580/1*XVYmQSKVS2aJfaKlYxfleg.png"" /><figcaption>Notion AI providing contextual actions to guide theÂ user</figcaption></figure><blockquote>The future of UX for AI will not be a single interface or interaction patternâ€Šâ€”â€Šit will be layered ecosystems of tools, touchpoints, and safeguards. As these ecosystems become more agentic, the need for thoughtful UX design only increases.</blockquote><p>This is where user-centered design and service design become essentialâ€Šâ€”â€Šnot as supporting roles, but as foundational disciplines. UX and service designers are uniquely equipped to map end-to-end journeys, identify moments where human judgment must remain in the loop, and design systems that clearly communicate intent, limits, confidence, and accountability. They help answer the hard questions that AI alone cannot (at least not in its pre-AGI era): <em>When should the system act? When should it pause? When should it explain itself? And when should it step aside entirely?</em></p><p>If there is one lesson we should take from the last decade of digital product design, itâ€™s that technology rarely fails because it isnâ€™t powerful enough. It fails because it isnâ€™t shaped around real human needs and contexts. AI is no exceptionâ€Šâ€”â€Šand the cost of getting it wrong is significantly higher.</p><h4>Recommended furtherÂ reading</h4><p><a href=""https://www.smashingmagazine.com/2024/02/designing-ai-beyond-conversational-interfaces/""><em>When Words Cannot Describe: Designing For AI Beyond Conversational Interfaces</em></a> by Maximillian Piras</p><p><a href=""https://www.nngroup.com/articles/ai-changing-search-behaviors/?utm_source=chatgpt.com""><em>State of UX 2026: Design Deeper to Differentiate</em></a><em> </em>by Nielsen NormanÂ Group</p><p><a href=""https://lukew.com/ff/entry.asp?2107""><em>Common AI Product Issues</em></a><em> </em>by Luke Wroblewski</p><p><a href=""https://www.uxtigers.com/post/ai-articulation-barrier""><em>The Articulation Barrier: Prompt-Driven AI UX Hurts Usability</em></a><em> </em>by JakobÂ Nielsen</p><p><a href=""https://www.nngroup.com/articles/ai-paradigm/#:~:text=I%20doubt%20that%20the%20current,coughs%20up%20the%20right%20results""><em>AI: First New UI Paradigm in 60 Years</em></a> by JakobÂ Nielsen</p><p><a href=""https://arxiv.org/html/2410.22370v1""><em>Survey of User Interface Design and Interaction Techniques in Generative AI Applications</em></a> by ReubenÂ Luera</p><p><a href=""https://youtu.be/e3Pj7W0xl_c?si=vVhKSHDnyrbfezkp""><em>The Hidden Cost of Instant Answers</em></a> by SalehÂ Kayyali</p><p><a href=""https://arxiv.org/html/2410.22370v1"">Survey of User Interface Design and Interaction Techniques in Generative AI Applications</a> by ReubenÂ Luera</p><p><a href=""https://zapier.com/blog/human-in-the-loop/?utm_source=chatgpt.com""><em>Human-in-the-loop in AI workflows: HITL meaning, benefits, and practical patterns</em></a> by JulietÂ John</p><p><a href=""https://www.researchgate.net/publication/395298892_How_AI_Agents_Are_Reshaping_the_Internet_from_Human-Centered_to_Machine-Mediated_Commerce""><em>How AI Agents Are Reshaping the Internet from Human-Centered to Machine-Mediated Commerce</em></a> by A. ShajiÂ George</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=aea01e14138e"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/are-we-doing-ux-for-ai-the-right-way-aea01e14138e"">Are we doing UX for AI the right way?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/stop-burying-your-impact-why-most-ux-storytelling-advice-falls-flat-0ff864039b0b?source=rss----138adf9c44c---4,1769516846,Stop Burying Your Impact: Why Most UX Storytelling Advice Falls Flat,"Stop Burying Your Impact: Why Most UX Storytelling Advice Falls Flat

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/stop-burying-your-impact-why-most-ux-storytelling-advice-falls-flat-0ff864039b0b?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2000/1*UZ3ifLdm_bCzDC0xxm3nGA.jpeg"" width=""2000"" /></a></p><p class=""medium-feed-snippet"">Fiction story frameworks aren&#x2019;t effective for telling a UX story</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/stop-burying-your-impact-why-most-ux-storytelling-advice-falls-flat-0ff864039b0b?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/spatial-vibe-coding-prototyping-immersive-reality-with-ai-c2b99fd4cd84?source=rss----138adf9c44c---4,1769516732,AR/VR vibe coding: prototyping immersive reality with AI,"AR/VR vibe coding: prototyping immersive reality with AI

<h4><em>Vibe coding is the buzzword of the moment, and for good reasonÂ , AI tools have given product designers a massive new superpower. They have turned us all into â€œmakers.â€ </em>In this article, Iâ€™ll show how I vibe coded two different projects: a floating UI cooking app and an XR basketball game.</h4><figure><img alt=""A photo of a street with a 3D hood in the middle. Two arms are in front as if were to throw a ball"" src=""https://cdn-images-1.medium.com/max/1024/1*TOwitEhHrw2eRiVNjXkF2g.jpeg"" /></figure><p>While Figma put vibe coding on the map for designers, this approach goes far beyond just one tool. There is an army of incredible tools serving different purposes: design-focused tools like <a href=""https://stitch.withgoogle.com/"">Stitch</a>; prototyping engines like <a href=""https://vercel.com/"">Vercel</a>, <a href=""https://lovable.dev/"">Lovable</a>, <a href=""https://aistudio.google.com/"">Google AI Studio</a>, and production-ready environments like <a href=""https://antigravity.google/"">Antigravity </a>or <a href=""https://cursor.com/"">Cursor</a>. Itâ€™s worth mentioning that even the ones I categorize as prototyping can send its code to GitHub which add a new step towards production-ready code.</p><p>After â€œvibe codingâ€ mobile and web app prototypes for a while, I realized these tools should be able to handle XR 3D canvases as well. This led to a thoughtâ€¦ can they also prototype XR experiences?</p><p>The technology is certainly there. <a href=""https://immersiveweb.dev/"">WebXR </a>is the standard API for immersive experiences on the web, and frameworks like <a href=""https://aframe.io/"">A-Frame</a> provide ready-to-use XR components, covering inputs, primitives, teleportation, gestures and so on. Since AI coding tools can already interact with external libraries, I realized I only needed to provide the intent and guide the AI toward the spatial outcome IÂ wanted.</p><p>So, thatâ€™s exactly what I did. And it worked. Suddenly, I could tell the AI what I wanted, and it created a 3D canvas with a head-tracked camera, hand controllers, and functional interactions. This is the beginning of spatial vibeÂ coding!</p><h3>My approach to Spatial VibeÂ Coding</h3><p>In practice, vibe coding for immersive experiences is similar to vibe coding for mobile or desktop, but with an added dimension.</p><p>While you donâ€™t need to be a developer to make functional prototypes, the more you know about the tech stack, the more control you have. Pure vibe codingÂ , focusing solely on intent without thinking about the â€œhowâ€Â , is valid and often the best way to avoid biasing the AI. If you give the agent freedom, it often finds the most efficient path. Conversely, if you try to micromanage it, you end up with â€œtwo brainsâ€ working against each other on the sameÂ task.</p><p>However, understanding the tools allows you to speak the same language as the AI, increasing speed and precision. For example, A-Frame has a specific component called <a href=""https://aframe.io/docs/1.7.0/components/hand-tracking-controls.html"">hand-tracking-controls</a>. If you tell the AI to use this specific component, it generates a standardized, ready-to-use solution that creates fewer problems than a custom solution.</p><p>My recommendation? Focus on intent, but establish â€œrulesâ€ based on the components you know workÂ best.</p><h3>The prompting strategy: Freedom vsÂ Bias</h3><p>When it comes to technically complex projects, I prefer to let the main AI agent figure out the solution rather than asking a <em>second</em> AI to polish or â€œengineerâ€ myÂ prompt.</p><p>In my experience, when another AI takes my rough prompt and â€œpolishesâ€ it, it introduces a biases. It often guides the final coding agent in a direction it wouldnâ€™t have naturally taken, leading to worse results. I get better outcomes when I either tell the AI to refine the prompt without dictating <em>how</em> to solve it, or simply go with my original, intent-based prompt.</p><h4>The â€œintent-basedâ€ prompt (successful in thisÂ example)</h4><figure><img alt=""A screenshot of Figma Make environment with the preview of the UI panel"" src=""https://cdn-images-1.medium.com/max/1024/1*NGyz2eAkBtUfFHL_cXmvTg.jpeg"" /><figcaption>Figma Make environment</figcaption></figure><p>Here is the original prompt I created. It focused on the <em>what</em>, not the minute details of theÂ <em>how</em>:</p><blockquote>â€œI want you to create an MR cooking app. The app should provide a passthrough experience with a UI panel rendered inside it. When the app is published and the URL is opened in a VR headset such as Meta Quest 2 or 3, the user should see the standard Open in VR button in the browser. After clicking it, the user can enter the experience.</blockquote><blockquote>Use WebXR and A-Frame. I will be referencing A-Frame components and primitives frequently, so make sure to use native A-Frame primitives where possible.</blockquote><blockquote>Ensure that the UI is rendered within the MR experience. Place the UI panel to the left of the user and slightly tilted toward the userâ€™s camera. For now, include placeholder elements in the panel: a title, an image, and someÂ text.</blockquote><blockquote>The input system should be hand tracking, using the A-Frame raycaster component. Prepare a structure to group all UI elements, as the app will include multiple screens and navigation. Build the UI using A-Frame primitives.â€</blockquote><p><strong>The Result:</strong> I got a functional 3D canvas, an input system, passthrough, and a UI in place. It wasnâ€™t polished, but it was a solid baseline for iteration.</p><h4>The â€œover-engineeredâ€ prompt (failed in thisÂ example)</h4><p>I then tried using an AI to â€œprofessionalizeâ€ the prompt. This version was too prescriptive:</p><blockquote>â€œCreate a functional WebXR prototype for a Mixed Reality (MR) cooking app using the A-Frame framework.</blockquote><blockquote>1. Scene &amp; Environment Setup:<br />Initialize an &lt;a-scene&gt; configured for AR/MR passthrough. Ensure the background is transparent (&lt;a-sky&gt; removed or transparent) so the user sees the real world. Ensure the WebXR button is enabled by default so the user can click â€œEnter VR/ARâ€ on Meta Quest 2/3 browsers.</blockquote><blockquote>2. Camera &amp; Input:<br />Set up a camera rig with a position of 0 1.6 0. Implement Hand Tracking controls. Add &lt;a-entity&gt; components for both left and right hands using the hand-tracking-controls component. Attach a raycaster to the hands (configured to interact with UI objects) so the user can point and pinch/select elements.</blockquote><blockquote>3. UI Architecture:<br />Create a parent &lt;a-entity&gt; to act as a â€œScreen Containerâ€ to group all UI elements. This will allow for easy visibility toggling for future navigation. Placement: Position this UI group to the left of the user (approx x: -1, z: -1.5) and rotate it on the Y-axis (approx rotation=â€0 45 0&quot;) so it is tilted to face the userâ€™sÂ camera.</blockquote><blockquote>4. UI Design (A-Frame Primitives):<br />Inside the UI group, build a panel using an &lt;a-plane&gt; as the background (dark color, slight opacity). Add an &lt;a-image&gt; placeholder for a recipe title image. Add &lt;a-text&gt; for the recipe title and instruction placeholders. Ensure all UI elements are children of the parent group and are rendered properly in the MRÂ view.â€</blockquote><p><strong>The Result:</strong> This prompt guided the AI agent too much. It ended up strictly following instructions rather than finding a cohesive solution, which led to broken code. Itâ€™s like micromanaging a graphic designer, if you tell them exactly where to put every pixel, you wonâ€™t get their bestÂ work.</p><h3>Iterating on theÂ design</h3><p>Once the foundations were defined, I decided to push the fidelity. I noticed some errors in my initial brief, specifically, trying to build complex UI with primitives. I realized it was better to design a high-fidelity UI in Figma, export it as a PNG, and import it into the experience. While tools like Figma Make struggled slightly with the point-and-pinch input system, it was enough to visualize what the production version could lookÂ like.</p><figure><img alt=""A UI panel floating in an actual kitchen"" src=""https://cdn-images-1.medium.com/max/1024/1*LnDX2_CS64n6-AlK2Lyi_Q.gif"" /><figcaption>Cooking up testing inÂ XR</figcaption></figure><figure><img alt=""Hight fidelity UI of the cooking app"" src=""https://cdn-images-1.medium.com/max/1024/1*qYhj6cwODYlhoYoUv8_ZVQ.jpeg"" /><figcaption>Cooking app UI inÂ Figma</figcaption></figure><h3>Going further: complex interactions with Gemini 3Â Pro</h3><figure><img alt=""An animated gif of a player throwing a ball into the hoop"" src=""https://cdn-images-1.medium.com/max/1024/1*g4w0VTg3NNNF5M30CvYWDA.gif"" /><figcaption>Testing the game inÂ VR</figcaption></figure><p>To push beyond UI panels, I went with Gemini Pro in Google AIÂ Studio.</p><p>This demonstrated that a 15-minute prompting session can result in a fully functional WebXR prototype featuring physics, grabbing mechanics, and game logic. The generated physics are amazing, they feel very smooth andÂ real.</p><figure><img alt=""An animated gif of a player throwing the ball into the hoop in mixed reality, in the actual street"" src=""https://cdn-images-1.medium.com/max/1024/1*N5mMubfltF_5fFGajWXOAA.gif"" /><figcaption>Testing the game inÂ XR</figcaption></figure><p>While this method requires deployment via Cloud Run (rather than a simple â€œpublishâ€ button), the setup only takes two minutes. The outcome is a prototype that works in both VR and AR, creating a seamless transition between worlds. From this point, adding counters, sound effects, or textures is just a matter of conversation.</p><figure><img alt=""A screenshot of the Google AI Studio environment that shows the inital page of the game in a preview"" src=""https://cdn-images-1.medium.com/max/1024/1*jJ1ukBfs5SEo9fiITLxyhA.jpeg"" /><figcaption>Google AI Studio environment</figcaption></figure><figure><img alt=""Google AI Studio environment with a preview of the actual game"" src=""https://cdn-images-1.medium.com/max/1024/1*vzcrmxbrbE75KYydDoQ6nQ.jpeg"" /><figcaption>Preview of the game in Google AIÂ Studio</figcaption></figure><p>âœ¨ Adding a touch of Nano Banana magic! By upgrading to a high-fidelity visual, we can deliver a more convincing and impactful pitch.</p><figure><img alt=""An image of the game enhanced visually by Nano Banana Pro"" src=""https://cdn-images-1.medium.com/max/1024/1*Ac_9k374shjDoOuBw9XGBA.jpeg"" /><figcaption>Image enhanced with Nano BananaÂ Pro</figcaption></figure><p>These are early experiments, but they demonstrate how accessible Spatial Vibe Coding is becoming. I am eager to test this approach with even more powerful tools like Antigravity, which, combined with the newest Blender or Unity MCPs (Model Context Protocols), will open the door to production-ready code, not just prototypes.</p><p>The most important takeaway <strong>is not how far the <em>tools</em> can go, but how far <em>I</em> can go</strong> as a non-developer. I can now conceive an XR game or app idea, design it, and prototype it entirely on my own. The barrier to entry for creating immersive realities has never beenÂ lower.</p><p>Thank you for reading, please feel free to drop a comment or open a discussion. Iâ€™d love to hear fromÂ you!</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c2b99fd4cd84"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/spatial-vibe-coding-prototyping-immersive-reality-with-ai-c2b99fd4cd84"">AR/VR vibe coding: prototyping immersive reality with AI</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/ai-wont-re-generate-your-focus-6a3453b057d7?source=rss----138adf9c44c---4,1769462770,AI wonâ€™t (re)generate your focus,"AI wonâ€™t (re)generate your focus

<h4><em>Weâ€™re consuming more content than ever, and remembering less of it. </em>Hereâ€™s what the research says about our shrinking focusâ€Šâ€”â€Šand whatâ€™s fuelling theÂ problem.</h4><figure><img alt=""Top-down view of a tablet on a grey desk displaying a digital illustration of a human head profile composed of circuit board patterns and mechanical elements in blue tones against a dark background. Yellow and green pencils, sticky notes, papers, and a cup of coffee surround the tablet."" src=""https://cdn-images-1.medium.com/max/1024/1*p3X-yCvmXoaBq1tb9His-w.jpeg"" /><figcaption>Image by <a href=""https://www.freepik.com/author/pixelshunter"">Pixelshunter</a> onÂ <a href=""https://www.freepik.com/"">Freepik</a></figcaption></figure><p>You settle in for a quick scroll through your feed, maybe just to unwind for a minute or two. But somewhere between a cooking hack and a clip youâ€™ve already forgotten, forty minutes vanished. Itâ€™s all a blur. Welcome to the era of infinite content and finite attention, where our brains are working overtime just to keep up with theÂ deluge.</p><p>Hereâ€™s the uncomfortable truth: our ability to focus is dwindling at a startling rate. <strong>According to </strong><a href=""https://gloriamark.com/attention-span/""><strong>Gloria Mark</strong></a><strong>, a professor of informatics at the University of California, the average attention span on any screen has plummeted from around two and a half minutes in 2004 to just 47 seconds in recent years.</strong> Thatâ€™s not a typo. Forty-seven seconds. The median is even lower at 40 seconds, which means half of the time weâ€™re switching our focus faster than it takes to microwave popcorn.</p><p>And in case you were wondering whether AI is helping or hindering the situation, well, the plot thickens.</p><figure><img alt=""Bar chart or timeline graphic illustrating the decline in average human attention span on screens over two decades. Three data points are shown: 150 seconds (2.5 minutes) in 2004, 75 seconds in 2012, and 47 seconds from 2018 onwards, representing a decrease of approximately 69% over the period studied."" src=""https://cdn-images-1.medium.com/max/1024/1*ahnUnhiOt5daivhLYbbZUw.png"" /><figcaption>Attention spans have decreased by two-thirds since 2004, <a href=""https://www.brainscape.com/academy/top-students-increasing-attention-span/"">graph by Brainscape</a></figcaption></figure><h3><strong>The contentÂ tsunami</strong></h3><p>If youâ€™ve ever felt like the internet is getting, shall we say, noisier, your instincts arenâ€™t deceiving you. <a href=""https://futurism.com/artificial-intelligence/over-50-percent-internet-ai-slop"">Recent data from Graphite</a>, an SEO firm that analysed 65,000 English-language articles published between 2020 and 2025, found that over half of all written content on the internet is now generated by AI. Before ChatGPT launched in late 2022, that figure was hovering around 5%. Talk about an explosion.</p><p><a href=""https://ahrefs.com/blog/what-percentage-of-new-content-is-ai-generated/""><strong>A separate study from Ahrefs</strong></a><strong> painted an even more dramatic picture, finding that a staggering 74% of newly created web pages in April 2025 contained AI-generated content. </strong>Meanwhile, <a href=""https://arxiv.org/abs/2504.08755"">research published on arXiv</a> suggested that roughly a third to almost half of the text on active web pages now originates from AI sources. Suffice to say, weâ€™re swimming in machine-made material, and our cognitive lifeboats are gettingÂ cramped.</p><p>The trouble is, more content doesnâ€™t necessarily mean better content. In fact, the sheer volume creates what researchers call â€œattention fragmentation,â€ a relentless toggling between tasks, tabs, and tools that leaves us perpetually half-focused. Gloria Mark describes this phenomenon as â€œkinetic attention,â€ where our mental state becomes dynamic and restless, flitting from screen to screen like a caffeinated hummingbird.</p><h3><strong>The dopamineÂ machine</strong></h3><p>It would be somewhat unfair to pin all of this on AI alone. Short-form video platforms like TikTok, Instagram Reels, and YouTube Shorts have been doing a phenomenal job of hijacking our neural reward systems well before the generative AI boom. But hereâ€™s where things get interesting: AI is now supercharging these platformsâ€™ ability to serve up hyper-personalised content at unprecedented scale.</p><p>Dr John Hutton, a pediatric neuropsychologist and director of the Reading &amp; Literacy Discovery Center at Cincinnati Childrenâ€™s Hospital, has <a href=""https://theweek.com/health-and-wellness/1025836/tiktok-brain-and-attention-spans"">described TikTok as a â€œdopamine machine.â€</a> The platform delivers quick hits of novelty and pleasure with every swipe, reinforcing cravings in much the same way a tasty meal or, less pleasantly, an addictive substance might. <strong>Each scroll triggers a little burst of feel-good neurochemistry, and our brains quickly learn to wantÂ more.</strong></p><p>The neurological evidence behind this is pretty eye-opening. In 2025, <a href=""https://www.sciencedirect.com/science/article/pii/S105381192500031X"">researchers at Tianjin Normal University</a> in China scanned the brains of more than 100 university students and found that those most hooked on short-form videos had noticeable differences in their brain structure. Specifically, they had more grey matter in the orbitofrontal cortex, the part of your brain that processes rewards and pleasure. The researchers suspect these students are simply more sensitive to the dopamine hits these platforms are designed to deliver, meaning theyâ€™re getting a stronger buzz from every personalised video that lands on theirÂ feed.</p><figure><img alt=""Infographic titled â€œSocial Mediaâ€™s Toll on the Mindâ€ showing TikTok and Instagram Reels icons pointing down to a colourful brain illustration. Labels around the brain identify effects: poorer cognitive and mental health (with anxiety and depression), addiction symptoms, decreased attention (with puzzle piece icons), and decreased activity in self-reflection and risk evaluation areas. A red warning banner at the bottom reads â€œMore prone to impulsive, short-term thinking.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*t7d4dJA0JxVsNSOCjsiyhw.png"" /><figcaption>Image byÂ author</figcaption></figure><p><strong>Meanwhile, </strong><a href=""https://www.psypost.org/large-meta-analysis-links-tiktok-and-instagram-reels-to-poorer-cognitive-and-mental-health/""><strong>a large meta-analysis</strong></a><strong> linked heavy use of TikTok and Instagram Reels to poorer cognitive and mental health outcomes, including higher levels of anxiety, depression, and, crucially, attention difficulties. </strong>Users with addiction symptoms showed decreased activity in brain regions responsible for self-reflection and risk evaluation, making them more prone to impulsive, short-term thinking.</p><h3><strong>When the brain goes on autopilot</strong></h3><p>So what exactly happens when we marinate our minds in bite-sized, algorithmically-curated content day after day? According to emerging research, the prefrontal cortex starts to feel the strain. This is our brainâ€™s control centre for executive function, impulse restraint, and focused attention.</p><p>A <a href=""https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2024.1383913/full"">2024 study by Yan and colleagues</a> found that individuals with high short-video use tendencies showed weaker executive function and poorer self-control. <strong>Itâ€™s a bit like training for a marathon by exclusively doing 10-second sprints: the sustained-focus muscle simply doesnâ€™t get the workout itÂ needs.</strong></p><p>But how does this translate in real life? When young peopleâ€™s brains grow accustomed to the constant environmental changes delivered by an infinite scroll of 15-second clips, they may struggle to adapt to activities that donâ€™t move quite asÂ fast.</p><p><strong>The term â€œTikTok brainâ€ has emerged to describe this pattern: impulsivity, preference for novelty, low tolerance for delayed gratification, and difficulty maintaining attention.</strong> Itâ€™s not exactly the cognitive toolkit youâ€™d want for, say, reading a novel, sitting through a lecture, or tackling complex problems atÂ work.</p><h3><strong>The AI amplifier effect</strong></h3><p>Hereâ€™s where AI-generated content adds a particularly spicy ingredient to this already potent cocktail. Traditional content creation had natural bottlenecks: someone had to actually write, film, or design things, which took time and effort. AI has essentially removed those constraints, enabling content to be produced at a scale and speed that would make any human creatorâ€™s headÂ spin.</p><p>The result? <strong>An endless buffet of highly engaging, hyper-personalised material designed to capture and hold our attention. </strong>AI algorithms analyse vast amounts of user data, from search history and social media behaviour to physiological signals, crafting recommendations so compelling that stepping away feels almost painful. <a href=""https://sqmagazine.co.uk/social-media-attention-span-statistics/"">TikTokâ€™s algorithm alone tracks over 300 data points per user </a>to tailor content within the first hour of usage, making recommendations increasingly irresistible.</p><p><strong>And hereâ€™s the kicker: some research suggests that even AI itself isnâ€™t immune to the effects of junk content.</strong> A <a href=""https://fortune.com/2025/10/22/ai-brain-rot-junk-social-media-viral-addicting-content-tech/"">pre-print study from researchers at Texas A&amp;M, the University of Texas at Austin, and Purdue University</a> found that when large language models were trained on short, viral social media posts, they exhibited lasting cognitive decline, including increased â€œthought-skippingâ€ and reduced reasoning abilities. If the machines are getting â€œbrain rotâ€ from low-quality content, what does that say aboutÂ us?</p><figure><img alt=""Infographic titled â€œThe 25-Minute Problem: The Cost of Cognitive Switching&quot; on a steel blue background. Three white cards show: â€œThe Interruptionâ€ (stopwatch and brain with lightning boltsâ€Šâ€”â€Šattention switches every 47 seconds), â€œThe Daunting Recoveryâ€ (orange header, stopwatch displaying 25 minutes to refocus, figure climbing an arrow), and â€œPerpetual Loopâ€ (circular diagram of brains and stopwatches showing the endless cycle: distraction â†’ 25 min â†’ new distraction)."" src=""https://cdn-images-1.medium.com/max/1024/1*oYMDR7MT6pwL5K7RPJFPKg.png"" /><figcaption>Image byÂ author</figcaption></figure><h3><strong>The 25-minute problem</strong></h3><p>Perhaps the most concerning finding from Gloria Markâ€™s research is what happens after we get distracted. <a href=""https://www.universityofcalifornia.edu/news/cant-pay-attention-youre-not-alone""><strong>On average, it takes about 25 minutes</strong></a><strong> to fully refocus on the original task after an interruption.</strong> Given that weâ€™re switching our attention every 47 seconds or so, the maths becomes rather grim. Weâ€™re essentially living in a perpetual state of cognitive switching, never quite present, never quiteÂ focused.</p><p>The consequences ripple outward. Laboratory studies consistently show that people make more errors when they switch their attention frequently. Performance suffers: tasks take longer to complete, and the quality of work declines. Medical professionals, pilots, and other high-stakes workers have long known this; now the rest of us are discovering it in our daily digitalÂ lives.</p><p><strong>A </strong><a href=""https://www.news-medical.net/news/20250718/Social-media-use-linked-to-declining-focus-and-emotional-strain-in-youth.aspx""><strong>2025 NTU Singapore study</strong></a><strong> found that over two-thirds of young people reported difficulty focusing, with many struggling to engage with content lasting more than a minute.</strong> Heavy users (those clocking five or more hours daily) were significantly more likely to experience what researchers call â€œattention fragmentation symptoms,â€ alongside weaker working memory. These arenâ€™t just numbers; they represent real-world impacts on how we think, learn, andÂ work.</p><h3><strong>Can we reclaim ourÂ focus?</strong></h3><p>Before you throw your phone into the nearest body of water, there is some cause for optimism. Gloria Mark emphasises that our ability to focus isnâ€™t lost; itâ€™s just changing. <strong>The key, she argues, is developing what she calls </strong><a href=""https://blog.dropbox.com/topics/work-culture/gloria-mark-how-to-get-your-attention-span-back""><strong>â€œmeta-awarenessâ€</strong></a><strong>: </strong>the skill of catching yourself mid-drift, mid-scroll, or mid-sentence, and consciously deciding whether to follow that impulse or pull your attention back.</p><p>In one study, participants were asked to estimate how often they switched tasks. They guessed around 15 times per hour. The actual number? Over 30. Simply becoming aware of how fragmented our attention really is can be a powerful first step towardÂ change.</p><p>She also champions the value of what she calls â€œrote activity,â€ meaning simple, mindless tasks like playing a quick game or doing something repetitive. These give our overtaxed minds a genuine break. Think of it as cognitive snacking: strategic mental downtime that can actually help replenish our attentional resources rather than deplete themÂ further.</p><figure><img alt=""Infographic comparing â€œTraditional Contentâ€ versus â€˜Microlearning.â€ Left side shows an overwhelmed person surrounded by chaotic app icons and notifications with a stopwatch indicating 8 seconds, leading to a confused head silhouette with a question mark. Right side shows a calm person with organised content cards (videos, tips, concepts) and a stopwatch showing 2 minutes, leading to an illuminated brain icon. Bottom text highlights â€œ15-fold improvementâ€ with the tagline â€œIntention &gt; Engagement.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*IvpJqk7aTD7RgRlyLa10lQ.png"" /><figcaption>Image byÂ author</figcaption></figure><p><strong>Thereâ€™s also </strong><a href=""https://www.amraandelma.com/user-attention-span-statistics/""><strong>evidence that microlearning</strong></a><strong> can actually stretch attention spans from 8 seconds to 2 minutes.</strong> This type of short, focused video content is designed with intention rather than just engagement, and the results speak for themselves: a 15-fold improvement simply by changing how content is delivered. The difference between content designed to capture attention and content designed to build it may well be the cognitive battleground of the comingÂ years.</p><h3><strong>The bottomÂ line</strong></h3><p>We are, in many ways, living through an unprecedented experiment in human attention. AI-generated content is flooding the internet, algorithms are becoming ever more sophisticated at predicting and exploiting our psychological vulnerabilities, and <strong>our brains, evolved for a very different information environment, are scrambling toÂ adapt.</strong></p><p>The research shows itâ€™s not a simple story. Yes, our attention spans are shrinking, and yes, the combination of short-form video platforms and AI-generated content appears to be accelerating this trend. The neurological evidence suggests real changes in how our brains process information, particularly among younger users whose prefrontal cortices are still developing.</p><p><strong>But humans have always been remarkably adaptable creatures.</strong> The challenge now is to become intentional about our relationship with technology: to recognise when weâ€™re being pulled into patterns that donâ€™t serve us, and to actively cultivate the focused attention that deeper thinking requires.</p><p>After all, the irony would be too rich if we couldnâ€™t even pay attention long enough to notice weâ€™d lostÂ it.</p><blockquote><strong><em>Thanks for reading!Â ğŸ“–</em></strong></blockquote><blockquote><em>If you liked this post, </em><a href=""https://medium.com/@doracee""><em>follow me on Medium</em></a><em> forÂ more!</em></blockquote><h3><strong>References &amp;Â Credits</strong></h3><ul><li>Mark, G. (2023). <em>Attention Span: A Groundbreaking Way to Restore Balance, Happiness and Productivity. </em>Hanover SquareÂ Press.</li><li>Yan T, Su C, Xue W, Hu Y and Zhou H (2024). â€œMobile phone short video use negatively impacts attention functions: an EEG study.â€ <em>Frontiers in Human Neuroscience</em>, 18:1383913.</li><li>University of California, Irvine. (2023). Canâ€™t pay attention? Youâ€™re not alone. <a href=""https://www.universityofcalifornia.edu/news/cant-pay-attention-youre-not-alone"">https://www.universityofcalifornia.edu/news/cant-pay-attention-youre-not-alone</a></li><li>Microsoft WorkLab. (2023). Regain Control of Your Focus and Attention with Researcher Gloria Mark. <a href=""https://www.microsoft.com/en-us/worklab/podcast/regain-control-of-your-focus-and-attention-with-researcher-gloria-mark"">https://www.microsoft.com/en-us/worklab/podcast/regain-control-of-your-focus-and-attention-with-researcher-gloria-mark</a></li><li>Dropbox Blog. (2025). Behold, the 47-second workday (and how to get your attention span back). <a href=""https://blog.dropbox.com/topics/work-culture/gloria-mark-how-to-get-your-attention-span-back"">https://blog.dropbox.com/topics/work-culture/gloria-mark-how-to-get-your-attention-span-back</a></li><li>Graphite. (2025). AI-generated articles study. As reported in Futurism: Over 50 Percent of the Internet Is Now AI Slop, New Data Finds. <a href=""https://futurism.com/artificial-intelligence/over-50-percent-internet-ai-slop"">https://futurism.com/artificial-intelligence/over-50-percent-internet-ai-slop</a></li><li>Ahrefs. (2025). 74% of New Webpages Include AI Content (Study of 900k Pages). <a href=""https://ahrefs.com/blog/what-percentage-of-new-content-is-ai-generated/"">https://ahrefs.com/blog/what-percentage-of-new-content-is-ai-generated/</a></li><li>Spennemann, D. H. R. (2025). Delving into: the quantification of AI-generated content on the internet (synthetic data). <em>arXiv. </em><a href=""https://arxiv.org/abs/2504.08755"">https://arxiv.org/abs/2504.08755</a></li><li>Gao, X., et al. (2025). Neuroanatomical and functional substrates of the short video addiction and its association with brain transcriptomic and cellular architecture. <em>ScienceDirect. </em><a href=""https://www.sciencedirect.com/science/article/pii/S105381192500031X"">https://www.sciencedirect.com/science/article/pii/S105381192500031X</a></li><li>PsyPost. (2025). Large meta-analysis links TikTok and Instagram Reels to poorer cognitive and mental health. <a href=""https://www.psypost.org/large-meta-analysis-links-tiktok-and-instagram-reels-to-poorer-cognitive-and-mental-health/"">https://www.psypost.org/large-meta-analysis-links-tiktok-and-instagram-reels-to-poorer-cognitive-and-mental-health/</a></li><li>Coleman, T. (2024). â€˜TikTok brainâ€™ may be coming for your kidâ€™s attention span. <em>The Week. </em><a href=""https://theweek.com/health-and-wellness/1025836/tiktok-brain-and-attention-spans"">https://theweek.com/health-and-wellness/1025836/tiktok-brain-and-attention-spans</a></li><li>ResearchGate. (2025). Short-form Video Use and Sustained Attention: A Narrative Review (2019â€“2025). <a href=""https://www.researchgate.net/publication/397712802_Short-form_Video_Use_and_Sustained_Attention_A_Narrative_Review_2019-2025"">https://www.researchgate.net/publication/397712802_Short-form_Video_Use_and_Sustained_Attention_A_Narrative_Review_2019-2025</a></li><li>Fortune. (2025). Just like humans, AI can get â€˜brain rotâ€™ from low-quality text and the effects appear to linger, pre-print study says. <a href=""https://fortune.com/2025/10/22/ai-brain-rot-junk-social-media-viral-addicting-content-tech/"">https://fortune.com/2025/10/22/ai-brain-rot-junk-social-media-viral-addicting-content-tech/</a></li><li>SQ Magazine. (2025). Social Media Attention Span Statistics 2025: By Platform, Age, and Content Type. <a href=""https://sqmagazine.co.uk/social-media-attention-span-statistics/"">https://sqmagazine.co.uk/social-media-attention-span-statistics/</a></li><li>Amra &amp; Elma. (2025). Best User Attention Span Statistics 2025. <a href=""https://www.amraandelma.com/user-attention-span-statistics/"">https://www.amraandelma.com/user-attention-span-statistics/</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6a3453b057d7"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ai-wont-re-generate-your-focus-6a3453b057d7"">AI wonâ€™t (re)generate your focus</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiugFBVV95cUxQQTl0TzRHem5wU2ZLUDV1S2R3SjliZWRfVTctVjdjTnFIV0ExeFFBdkFlaFk4bjZOUExsZmZxSjN0ZGo1VGljXzh0UDdPWXF2Z2xhNUMyZ2dBYXoyQzR5MTMwREk3cnZXc0RvNThOdXcwNTgtb1ZVYXg3bm0tbVFGNkRTbGZHWDM3eDVmY2x3eWgzbm1Sbkd6NzhHS29DNnpfdk1ZNlhOZVJ4X0hIUHk5ODhGVUllTGFia3c?oc=5,1769499900,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,Stills 2026 Trends Report points to the rise of human-centred design - Creative Boom,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMid0FVX3lxTE84WklhdnlBcTZkRy1PSjNSd0tDQUEwSDRlNVEwWGdNZGFBQ1BuVEVKbFVlX1FPZkROY2cxN0NjdS0yQkx0SVZqU0JQQU5CSTluVnpnVG5uQm1nb2dMNEVCQzh4VGt5d2pzTjdBdWQzRVJUNnhQMG9R?oc=5,1767686400,Future of Graphic Design: Trends & Predictions - Business.com,Future of Graphic Design: Trends & Predictions - Business.com,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMickFVX3lxTE9WcHZJUFRiREJ4OUl1dzlrRW9uMVlZUmppbnhNaEwxaVY5YUZtbERGWFRxdXBlMkpBQ3hIYkxVMF9qUFI3aE1UeHRZQ3lfNFFDcE1UcVM1YUlfYzZpcm96VDVIa2k5dFFqb0JXWjA1QVBSQQ?oc=5,1768896000,10 Interior Design Trends That Are on Their Way Out in 2026 - The Everygirl,10 Interior Design Trends That Are on Their Way Out in 2026 - The Everygirl,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMingFBVV95cUxPNC12NnUyRjAwQlBfNkVWeDBYYlh6MnNCWDBzSFV3Y3R5aHlvdFdtVXVibV9QR3BybjJpQkthWE52TEwxN05ScVpvZ3Q0Y2toQm5mQ2tqMlQ4WmdVM0dqa1hOTWNaYXVMaTdUOERYWmlJU2RVeXplc2pqaVFLbUJuWWs5T2Mwd0Zra3IwZm9ZbTk2ZVJkQ3ZGMWQxVDg0Zw?oc=5,1769032800,Graphic Design for Video Games: Trends Players Notice in 2026 - Barrett Media,Graphic Design for Video Games: Trends Players Notice in 2026 - Barrett Media,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMikgFBVV95cUxQMEEwdDNWUy1naGo2Q1JqRlp3R3VpLUdSTDFJcFhRRE04NWRiOEVIY2xuSEFDcmRDZkFHcUdRaWw3cFM5MGJWbVVpU29uT0lxcFl3T2hEb3dlWTE5a1hXenduLV93b3ljc3hmNUdRc0ZNZmZaRlVtOVZLUERzZHRPdm8yTHFtQnc3Ykw4STRWYkdwZw?oc=5,1768377600,"Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor","Pinterest's 2026 Color Trends Include Moody Plums, Electric Greens, and One Very Familiar Orange - ELLE Decor",graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiV0FVX3lxTE9wU1dmbVZMREZQc3dULTA3OHdoZXdhOGEyemJ2c2xMNGFGZHpQajFEaE1GaU40RExnYzNSS3JvY1RJN05WeHBPUXBhb05na0JaclhRMVdyMA?oc=5,1768214475,Forward Thinking - It's Nice That,Forward Thinking - It's Nice That,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipwFBVV95cUxOODlDdWw5R3FrNlpnNS1uZTliQmx6MUdiTG1wUUNiLTR6Z2dKTWNpS0ZIYUpJMnMtTlNVVzNISkZYMzBRUTdJTnRId1lfSHhsZDF1NGVjU2doTnktbGxKU0lCdXl0N0g4LVJjVzc1UHZCdG9hWUxfLUFiNWZUQU00TW9Ra25abGV0YjgxbTE3NU01QVZmVzlENjRhQXlKd0oyV2hUMGtrOA?oc=5,1767254400,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMijgFBVV95cUxNcXRhQWtNWGRCNUdRRS13ZXd6Y2lvQ3BETGlwQmstSEo1WGlKOXlKRHh3aXZoMEp1RlpRNEN4OXk0RlZyODNjZlpwOTVGdF8wc2F1RG1QSEo4NWVOLWpiUkozUFdYSnk5Y3dKbC1WVm9yYnQtSG4yTjVXb0JteVVTc0xwMUlYdS1sQmtZd0t3?oc=5,1766044800,Six surprising illustration trends for 2026 - Creative Boom,Six surprising illustration trends for 2026 - Creative Boom,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMickFVX3lxTE1rMHNBX1V5VHEyLThjeFN4LTFqd0FnWWY1eTRGNnhOdXV4NGlmWGxQby0zWWJQdklOSzRXV3FtNGUtdllkVXB5bW0wUzU2cDNGRW1MV2hpNXVDSzdHb0ZCaTJfQ2JlT2pPOE9DTTAxSzZhUQ?oc=5,1766131200,Decoding Chinaâ€™s â€œNew Uglyâ€ Graphic Design: The Rise of Intentional Imperfection - RADII,Decoding Chinaâ€™s â€œNew Uglyâ€ Graphic Design: The Rise of Intentional Imperfection - RADII,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMilAFBVV95cUxNMTc2SGFDU2h0OEVINzhWMVlTRy1Cb1BOd1FCZDdKbHRTYjdfTHpuMzNUNDRiRUF6THhkYXF4UDYyRnFSbTk2R0VkamU0bmx4d0J3c0tSZV80ak5wZGVhU1FiTGZvVjVfV2x0azhNMmRlMDBjTGJPWVBOMWJ5WGRNMVFocFdxbnI1WC1vaHpJeEFsbjll?oc=5,1766908800,Canva's 2026 trend predictions have filled me with hope - Creative Bloq,Canva's 2026 trend predictions have filled me with hope - Creative Bloq,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiZkFVX3lxTE95aEtIbVRhclRrS3hxMzhUQXgwRzlJOUdvZjg3VlZCTlc5XzdmTTZ1OFVucjNiRjNjZGdFT3M3dUkyQjhOMGVUVWc3ZzNpOFdMb3lweE92S1pZX3MxUE80a2pNYkVvdw?oc=5,1767513600,Graphic design trends in 2026 - The Morning,Graphic design trends in 2026 - The Morning,graphic design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMilAFBVV95cUxNVVZGRDlFUF95aHhVSmJQcV9pTmk2Qjhyel9YeGx0VGRDcXpOVWo1RFhjZXhmUzVWMEJaVXhlWVFYU3R4M0wwem1xbVZnNl94Y1IxcTR1emdHRDZSVk9ia3lCejZ2djdkekRabkJ1M2JOUWlJT0xmSGJ6ZmN3cWxyenA1SndfaGQ4UWNQMlJaMHdxY1Ut?oc=5,1769719656,Custom Web Development Trends Shaping Business Growth In 2026 - Geek Vibes Nation,Custom Web Development Trends Shaping Business Growth In 2026 - Geek Vibes Nation,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMiWkFVX3lxTE40UU00VzlvX0tPdGx1bVBJbG9iNFl6b05JUXRabjZuc21KVTN3NHlhX2YwUTFPQWpwWlJaQXcwRks2UHM2azg4YTNybEsyVk1EaFNoRGVGVHZvZw?oc=5,1768809600,Duotone â€“ Fresh Trend in Website Design - Designmodo,Duotone â€“ Fresh Trend in Website Design - Designmodo,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipwFBVV95cUxOODlDdWw5R3FrNlpnNS1uZTliQmx6MUdiTG1wUUNiLTR6Z2dKTWNpS0ZIYUpJMnMtTlNVVzNISkZYMzBRUTdJTnRId1lfSHhsZDF1NGVjU2doTnktbGxKU0lCdXl0N0g4LVJjVzc1UHZCdG9hWUxfLUFiNWZUQU00TW9Ra25abGV0YjgxbTE3NU01QVZmVzlENjRhQXlKd0oyV2hUMGtrOA?oc=5,1767254400,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,Wilderkind could be 2026's biggest trend. Here's how to use it - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMikwFBVV95cUxPRzlkRnZUUFI1bjhNUDBEVDQ5Z3MxYnJ2amlnTWgzd2ptRHNVaVdXM1hyLVpqU3NiNVE1RmFxak9uVW11ZjRpLXNxWHA4UkhZQzcwTFdfSnFVNWVROFBYMFdBN2dIa3huWUlYUUpyLVloOHZaZ0xlTlkyXzFrQWhyQ0NGaUNPY2RSaXAwMHdhZmQ4TlE?oc=5,1767081600,These logo design trends will define 2026 - Creative Bloq,These logo design trends will define 2026 - Creative Bloq,web design trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMitgFBVV95cUxQVnlTLTRJaHU3MTh0clNEc2xKZHpfbWc1X2ZvaGdYamM5azFvTW92VDFnQ2xNbjl2RHV4cXZpY0FfRnVDTjVsaS1mTGR4aUpyZ3lDSC1PS2pRQUhuWEx0cWJ4a2l0cWJralE3N2ZCU1hJYTYwa3VIQ0FyRXBmMThiQkFBM3pVNGEyZmdVeFliVFA3M1NRUEZ6bG1WWFdGT0M4aUVUd2FDZ050SVFtOWV2bFNHaE9iZw?oc=5,1766822400,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,Breaking rules and bringing joy: top typography trends for 2026 - Creative Bloq,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMimwFBVV95cUxNel9fcXhWWVRKYmg3U21qcVNrNHFNMFgzZ1dHaFp2M2tIRk1RTlRDaTdObWVvZHBacEdtYW5vRkZnQUJibFB1S0pXU2twOGVRM2k3VFZPeE1XZmkxMFFDQzFxbkgyeGVoUVdOdlROMnlRc1JwVWJXZ1lPNXdHQ0ptVm15TDNHSG5uVERmUVR4N1dXYW5uX0xtUXFYRQ?oc=5,1768204800,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,The graphic trends youâ€™ll want to bookmark for 2026 - It's Nice That,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMipgFBVV95cUxQVUwyNWV3RmhNNnhoXzF2VWJTQWJfdjc3UkVfODFiVHRKVG5RU19lQmZDdUtmWlNfdXJCT3c4czY1Y0NiU2NLcFMtWDBZRXA1T3lBbE1yY2RNSkFiX1VEbWczY2IzZ1F0RTY0OE5sQnNkMGNYWkJhQmdQY3JTOXFHWV9OVEpRS2VjT3lZYnZicWZPeFVGZ2tFTk8xb3pIUGNCdFZFUjZR?oc=5,1767600000,This 2026 design trend fills me with joy - Creative Bloq,This 2026 design trend fills me with joy - Creative Bloq,typography trend
gnews,news.google.com,https://news.google.com/rss/articles/CBMisgFBVV95cUxPM0kweW1QNENpcHdNZEpPM0dZcWg1dUd1Uzl1cE9NY2prX1V6d1Jkdl9TeV9TUDRVVWNNc2YtWVRBd1FPSm5LNWVzTnFZOF91RFFUZktvZUJ6Z29wWk5RM0JzZ2V6OHVEZzZHbjAwamgzdVJqazJBY3VrU0d4d1ZRcVBWT2lVTG0yRE5weS1JMXBIQzhqZkRMUE8zOWFqb2RFaFBRa0VSQy1femltaE5zZVFn?oc=5,1766131200,"What is the yellow font trend, and why is is all over TikTok? - Creative Bloq","What is the yellow font trend, and why is is all over TikTok? - Creative Bloq",typography trend
youtube,,https://www.youtube.com/watch?v=BxeGIhSmdNs,1769758615,The Future of Interior Design (Trends &amp; Predictions),Discover the latest trends and predictions shaping the future of interior design. From sustainable materials to smart home ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=csmEHU_LviM,1769754320,Social Media Poster Design #GraphicDesign #LogoDesign #designtips #posterdesign,"Social Media Poster Design #GraphicDesign #LogoDesign #designtips #posterdesign Graphic Design,"" ""Logo Design,"" ""Poster ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=jShJCuCiFkY,1769714661,2026: Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ¼Ğ¾ÑƒÑˆĞ½-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ°,"Ğ Ñ‚Ğ¾Ğ¼, ĞºÑƒĞ´Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ²Ğ¸Ğ¶ĞµÑ‚ÑÑ Ğ¼Ğ¾ÑƒÑˆĞµĞ½-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ Ğ² 2026, Ğ±ĞµĞ· Ñ…Ğ°Ğ¹Ğ¿Ğ° Ğ¸ Â«Ñ‚Ğ¾Ğ¿-10 ÑÑ„Ñ„ĞµĞºÑ‚Ğ¾Ğ²Â». Ğ“Ğ¾Ğ²Ğ¾Ñ€Ñ Ğ¿Ñ€Ğ¾: â€” Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ¼Ğ¾ÑƒÑˆĞ½ ÑÑ‚Ğ°Ğ» ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=v9cvuG6cvIQ,1769706089,La tendance du Mix MÃ©dia &amp; du Collage Style en design graphique en 2026,"DÃ©couvrez la septiÃ¨me grande tendance design de 2026 : le mix mÃ©dia et le collage style. Photos, illustrations, textures et ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=tCBmv04npJY,1769705973,Social Media Poster Design   âœ¨ğŸ”¥ #shorts #posterdesigner,Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=GUbXlWxh1ho,1769702423,Mon avis sur les tendances graphiques ! #graphiste #freelance #branding #graphictrends,,graphic design trends
youtube,,https://www.youtube.com/watch?v=EfEiz3eeJfg,1769701924,The Trend: 2026 Graphic Tee Trends you NEED to see. ğŸ‘•âœ¨,"The 2026 Streetwear scene is officially here. From ""Rule the Jungle"" to ""Street Culture,"" we're redefining the graphic tee.",graphic design trends
youtube,,https://www.youtube.com/watch?v=u34kEVhg9GY,1769693421,Beginner Vs Pro | Adobe Illustrator #adobe #graphicdesign #illustration #shorts #sylusskydesigns,Beginner vs Pro Same shapes. Same colors. The difference? Design thinking. Can you spot what makes the Pro version better ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=z7YY687B9ow,1769691997,Weâ€™re Hiring! Graphic Designer &amp; Video Editor at Staging Spaces &amp; Design #shorts,"We're growing at Staging Spaces & Design, and we're looking for a creative powerhouse to join our team! Are you a Graphic ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=_YZKOzUoFaQ,1769680853,Graphic Design Trends 2026: The Rise of Punk &amp; Rebellious Design,"Graphic design is changing fast. From perfectly polished and predictable layouts to bold, messy, and rebellious visuals, the ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=Ks7Cqe7AMU8,1769637617,La tendance du Retrofuturisme en design graphique en 2026,DÃ©couvrez la sixiÃ¨me grande tendance design de 2026 : le retrofuturisme. Ce style mÃ©lange la nostalgie du passÃ© et les codes du ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=pasM-XtMx8A,1769634359,2026 Graphic Design Trends You Need to Know,"What will graphic design look like in 2026? In this video, I break down the emerging design trends shaping branding, digital ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=mbenbQ7QPF8,1769623533,Dog Face Fashion Styles 2026 ğŸ¶ğŸ”¥ | Creative Clothing Design Trends,"Explore the top dog face design styles for clothing in 2026 âœ¨ Perfect for streetwear, casual fashion, hoodies, and t-shirt designs.",graphic design trends
youtube,,https://www.youtube.com/watch?v=jpOUwpLiFvQ,1769619689,La tendance du 3D immersif &amp; Motion Design en design graphic en 2026,"DÃ©couvrez la cinquiÃ¨me grande tendance design de 2026 : le 3D immersif et le motion design. En 2026, la 3D et le mouvement ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=31DwQrDwzyQ,1769614388,PS Tutorial HD 2026 | Efecto Halftone Pop Art | Photoshop Editing | CC + BP Drop #ps Netto Doch Yt ,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=8p_m-Pdo7PY,1769610029,Bike Poster Design   âœ¨ğŸ”¥ #shorts #posterdesigner,Creative ad design Poster design ideas Modern poster design Photoshop techniques for designers Advanced poster design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=rvnXE4pPkjs,1769607015,Beginner vs Pro in adobe illustrator#adobe #adobeillustrator#illustration#illustrator #graphicdesign,Beginner vs Pro Same elements. Different understanding of perspective. Which one looks more realistic? âœ“ Graphic ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=fRU2XH9LcGw,1769599447,"A New Platform for Designers: Trends, Briefs &amp; Recognition | Buzzeeify","Welcome to Buzzeeify â€” a creative platform built to help designers get recognized, discovered, and featured. Follow us on ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=jo_hy0jjePY,1769567179,Burger Poster Design 2 | Graphics Designing 2026 #shorts #graphicdesign #canva,Burger Poster Design | Graphics Designing 2026 #shorts #graphicdesign Beginner Designers Make This MistakeYour Poster ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=dqWkjyBXrR8,1769552388,Bubble fonts &amp; handwritten scripts are HOT! [2026 event trends] #shorts,"Forget stuffy, old serif fonts. Bubble fonts and handwritten scripts are IN! Rylee, one of pc/nametag's graphic designers, says ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=mK5qH7aSD-s,1769551251,La tendance du AI Generated Design en design graphique en 2026,DÃ©couvrez la quatriÃ¨me grande tendance design de 2026 : le AI Generated Design. L'intelligence artificielle devient un vÃ©ritable ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=6FjWCOVDJ3s,1769535278,2026 Interior Design Trend Watch | The Good Stuff with Mary Berg,Steven Sabados takes us on a tour of the 2026 Interior Design Show in Toronto to give us a sneak peek at the hottest design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=K-UGaV8WHQ4,1769534258,Real Design Takes Time,Speed changed the conversation completely. Fast used to mean a few days. Now it means right now. Templates and drag and ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=51YNR06dnl0,1769533703,Dubata design GraphicDesign#DesignInspiration#CreativeDesign#DigitalDesig,best colors for websites best graphic design websites best ui websites best web page design best web design websites best ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=hRSA0h0WTdg,1769533268,La tendance de la Typographie expressive &amp; expÃ©rimentale en design graphique en 2026,"DÃ©couvrez la troisiÃ¨me grande tendance design de 2026 : la typographie expressive et expÃ©rimentale. En 2026, la typographie ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=fobQHXU5SHs,1769780377,3 Free Design Websites Every UI Designer Should Bookmark | Emcee IT Solutions,"If you're designing websites or UI screens and you want faster ideas without sacrificing quality, these 3 free resources are worth ...",web design trends
youtube,,https://www.youtube.com/watch?v=zT00cUinQN8,1769778258,ğŸ’» Login Form Design Using Glassmorphism #FrontendDeveloper #TechShorts #shorts #JavaScript #WebDev,"In this video, I have created a Modern Glassmorphism Login Form UI Design with an attractive Neon Glow effect âœ¨.",web design trends
youtube,,https://www.youtube.com/watch?v=fm6swbEslIw,1769756896,"Complete WordPress Web Design Tutorial | Beginner to Pro (Free Templates, No Paid Themes)","In this full-length tutorial, I'll walk you step by step through how to design and build a clean, professional business website using ...",web design trends
youtube,,https://www.youtube.com/watch?v=FbpEcA8n3bU,1769755519,Ever wondered how websites looked before modern UI trends? ğŸ‘€#uxdesign #uidesign #webdesign,,web design trends
youtube,,https://www.youtube.com/watch?v=X4P2l5vvO1w,1769752835,9000+ Free 3D Icons for Designers (Better than FlatIcon) ğŸ”¥,Stop using boring 2D icons! Upgrade your design with these free 3D assets. The Website Link: Check the Link in my Bio ...,web design trends
youtube,,https://www.youtube.com/watch?v=vgV-bkcKjuk,1769749272,Cool Web Designs ğŸ¤¯ | Where Creativity Meets Functionality #Shorts #Viral #Creativity #Hacks #Html,"These cool web designs prove that creativity + functionality = From smooth animations to clean UI layouts, this is what modern ...",web design trends
youtube,,https://www.youtube.com/watch?v=eL2nOKEt2rk,1769728811,Why Bento Grid Layouts are Everywhere in 2026 Web Design,"Bento grid layouts are redefining how modern websites organize content. Inspired by modular design and editorial layouts, this ...",web design trends
youtube,,https://www.youtube.com/watch?v=QhGkZz9xGxg,1769721967,2026 Website Design Trends #colorpalette #webdesign2026,"Website color trends are evolving fast, and 2026 is bringing a new wave of design choices that balance personality, clarity, and ...",web design trends
youtube,,https://www.youtube.com/watch?v=vpZxGjX1TKM,1769707667,The invisible code Exploring generative AI&#39;s impact on web design trends #motivation #shorts,The invisible code Exploring generative AI's impact on web design trends #motivation #shorts.,web design trends
youtube,,https://www.youtube.com/watch?v=W1x4iratmTs,1769698805,Learn the Latest Front-End Development &amp; UI / UX Design Trends at Pixel Pioneers 2026!,Pixel Pioneers Website: https://pixelpioneers.co/ --- Learn The Latest Front End Development and UI / UX Design Trends At Pixel ...,web design trends
youtube,,https://www.youtube.com/watch?v=ViuqiN2Hh7E,1769697000,2026 Web Design Trends to Easily Upgrade Your Site,"Want your website to look modern, engaging, and professional without spending a fortune? In this video, we break down the top ...",web design trends
youtube,,https://www.youtube.com/watch?v=0LkfTj2QVxY,1769696778,8 Web Design Trends That Are About to Change Everything in 2026,"In 2026, web design trends focus on creating faster, more intuitive, and visually dynamic experiences. From modular bento grid ...",web design trends
youtube,,https://www.youtube.com/watch?v=mPClFpP0ZT0,1769692266,How to Create a Professional Business Website in WordPress in 2026 â€” without any coding! ğŸš€,2026 mein apne business ke liye professional website kaise banaye? Is video mein maine step-by-step bataya hai ki kaise aap ...,web design trends
youtube,,https://www.youtube.com/watch?v=A6atF5TI5Yg,1769686581,Stop Following Website Design Trends in 2026. Do This Instead,"Every year, business owners are told to follow the latest website design trends. New fonts. New layouts. New styles. But 2026 is ...",web design trends
youtube,,https://www.youtube.com/watch?v=da4fScaoth0,1769654668,These 2026 Web Design Trends Will Change Everything,"Step into the future of web design! In 2026, websites are evolving to combine human-centered design, cutting-edge technology, ...",web design trends
youtube,,https://www.youtube.com/watch?v=pasM-XtMx8A,1769634359,2026 Graphic Design Trends You Need to Know,"What will graphic design look like in 2026? In this video, I break down the emerging design trends shaping branding, digital ...",web design trends
youtube,,https://www.youtube.com/watch?v=bYWj0uGRAvo,1769632206,"Inside the IT World: Web Design Careers, Trends &amp; Future Tech | Business Matters Podcast","In this episode, we dive deep into the IT sector with a special focus on web designâ€”exploring career paths, in-demand skills, ...",web design trends
youtube,,https://www.youtube.com/watch?v=qm5eZSVoY0o,1769630526,Design trends keep changing. #websites #webdesign #digitaltrends,,web design trends
youtube,,https://www.youtube.com/watch?v=CPaePv21b9A,1769621133,Ğ¢Ñ€ĞµĞ½Ğ´Ğ¸ Ñƒ Ğ²ĞµĞ± Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ñ– Ğ½Ğ° 2026Ñ€Ñ–Ğº,ĞŸĞ¾Ğ²Ğ½Ğµ Ğ²Ñ–Ğ´ĞµĞ¾ ÑƒĞ¶Ğµ Ğ½Ğ° ÑÑ‚ÑƒĞ±âœ¨ #webdesign2026 #webdesigntrends.,web design trends
youtube,,https://www.youtube.com/watch?v=794pAZlQhGU,1769606102,Stop Using Outdated Web Design,"Stop clinging to outdated web design trends. In just 21 years, we've seen a dramatic shift from the cluttered aesthetics of the 90s, ...",web design trends
youtube,,https://www.youtube.com/watch?v=CfKsKzOz1rw,1769605200,Stop Using Outdated Web Design,"Stop clinging to outdated web design trends. In just 21 years, we've seen a dramatic shift from the cluttered aesthetics of the 90s, ...",web design trends
youtube,,https://www.youtube.com/watch?v=GQz1fME1tt8,1769548375,2026 Web Design Trends - Part 5,,web design trends
youtube,,https://www.youtube.com/watch?v=v45fa5iiYgE,1769544050,Stop designing. Start launching.,Stop designing. Start launching. #StartupFounder #WebDesign #WebsiteTemplates.,web design trends
youtube,,https://www.youtube.com/watch?v=XuLnih20r2g,1769528831,Best Design Inspiration Websites for Graphic Designers | Daily Creative Ideas &amp; Trends,"In this video, I share the best design inspiration websites that professional graphic designers use to stay updated with trends, ...",web design trends
youtube,,https://www.youtube.com/watch?v=jOeBBGtcBcc,1769439771,Ğ“Ğ´Ğµ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ² Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğµ?,"ĞšÑƒÑ€Ñ ""UX/UI-Ğ”Ğ¸Ğ·Ğ°Ğ¹Ğ½"" - http://uxui.filschool.ru â—¾ ĞšÑƒÑ€Ñ Ğ¿Ğ¾ ĞºĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºĞ°Ğ¼ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° - http://filschool.ru/card â—¾ ĞšÑƒÑ€Ñ ""Figma x Tilda"" ...",web design trends
youtube,,https://www.youtube.com/watch?v=3vQ00qHHGZU,1769584047,Ep.4 Parallel Obssrver.      #mindset #philosophy #trends #typography  #glitch #thinkdivine,Ep.4 Parallel Obssrver. #mindset #philosophy #trends #typography #motivation #glitch.,typography trends
youtube,,https://www.youtube.com/watch?v=hRSA0h0WTdg,1769533268,La tendance de la Typographie expressive &amp; expÃ©rimentale en design graphique en 2026,"DÃ©couvrez la troisiÃ¨me grande tendance design de 2026 : la typographie expressive et expÃ©rimentale. En 2026, la typographie ...",typography trends
youtube,,https://www.youtube.com/watch?v=CJgLYiSRO-s,1769461743,How To Made typography video|| Like this ğŸ’¸ğŸ“¸ #shortvideo #typography #shorts,What is Typography? Complete Guide for Beginners Typography Explained in Simple English History of Typography â€“ From ...,typography trends
youtube,,https://www.youtube.com/watch?v=lYOtZKah68o,1769339605,Display Fonts 2026: The ONE Change That Fixes Flat Designs,"Display Fonts 2026: The ONE Change That Fixes Flat Designs display fonts, display font tutorial, display font vs regular font, bold ...",typography trends
youtube,,https://www.youtube.com/watch?v=nrVojxqD68o,1769077385,How to add aesthetic fonts #shorts #tipsandtricks,Learn how to add aesthetic fonts to your graphic design projects with these simple tips and tricks. If you're a beginner in graphic ...,typography trends
youtube,,https://www.youtube.com/watch?v=qcnxiQQ_0Fc,1769031357,2026 Font Trends You Should Know About,Use These Fonts In Kittl: https://kit.tl/2026fonts ğŸ‘‰ Learn More About These Fonts: https://www.kittl.com/blogs/top-font-trends-dsi/ ...,typography trends
youtube,,https://www.youtube.com/watch?v=9_Da1xf_LF0,1768974240,What Are the Top School Leavers Top Trends Students Actually Love to Wear? | Colour Up Uniforms,What Are the Top School Leavers Top Trends Students Actually Love to Wear? | Colour Up Uniforms What Are the Top School ...,typography trends
youtube,,https://www.youtube.com/watch?v=cnTP2LuSFOw,1768636943,"ğŸ˜‚ WAIT FOR END ğŸ˜€Typography video, reel trends,",,typography trends
youtube,,https://www.youtube.com/watch?v=MTMIKSUFXEE,1768579770,ğŸ†•#ValeLaPenaVer ğŸ‡¨ğŸ‡´ | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseÃ±o 2026,"ValeLaPenaVer ğŸ‡¨ğŸ‡´ | New Sapiens presenta la primera parte de On The Wave: Tendencias de diseÃ±o 2026, un anÃ¡lisis que ...",typography trends
youtube,,https://www.youtube.com/watch?v=iq7E1RBZgDY,1768570250,#handwriting #calligraphy #calligrphylearning #handlettering #artist #letter #typography#handwriting,"modern calligraphy tips, calligraphy for beginners, DIY calligraphy projects, calligraphy tutorials, calligraphy lettering styles, brush ...",typography trends
youtube,,https://www.youtube.com/watch?v=_jkyUunzs1I,1768538874,5 Best Websites to Download Free Fonts for Designers ğŸ”¥,"Looking for the best websites to download free fonts for your design projects? In this short video, I share 5 powerful font websites ...",typography trends
youtube,,https://www.youtube.com/watch?v=qErJzUWGgLQ,1768410089,Our font design predictions for 2026,"Want to boost your branding in 2026? Start with your fonts! Because when your typography feels like your voice, customers listen ...",typography trends
youtube,,https://www.youtube.com/watch?v=HKprAtVk7TM,1768093232,Frontiers of Visual Language Emerging Trends in Graphic Design,"Explore the latest design trends shaping 2026, from AI workflows to immersive branding. Practical tips to elevate your next project.",typography trends
youtube,,https://www.youtube.com/watch?v=nN7IWFanI0M,1768052624,day 1 journey of my life #viral #typography #motivation #editing #trending #day1,Welcome to my channel! ğŸ˜Š In this video you'll see amazing **typography text animations** and **design inspiration** â€” perfect ...,typography trends
youtube,,https://www.youtube.com/watch?v=83wacmeqGd0,1768049484,design trends 2026 pt. 1ğŸ’ #Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ #Ğ±Ñ€ĞµĞ½Ğ¸Ğ½Ğ³ #Ğ±Ñ€ĞµĞ½Ğ´Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ #Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ñƒ,,typography trends
youtube,,https://www.youtube.com/watch?v=kRmT9kJ_E-E,1767981896,day 0 journey of my life    #viral #motivation #typography #day0 #editing,Welcome to my channel! ğŸ˜Š In this video you'll see amazing **typography text animations** and **design inspiration** â€” perfect ...,typography trends
youtube,,https://www.youtube.com/watch?v=uRK43kg05zI,1767918989,Typography Trends 2026 (Versi Tayo) ,Typography Trends 2026 Saya menemukan template mengagumkan ini di CapCut. Ketuk tautan untuk mencobanya!,typography trends
youtube,,https://www.youtube.com/watch?v=DCpoDKHct00,1767890799,These Bold Fonts Will Dominate 2026 &amp; Beyond!,"Looking for the best bold fonts for 2026 and beyond? In this video, we explore the bold typography trends that will dominate ...",typography trends
youtube,,https://www.youtube.com/watch?v=qeFr2L2Sjxs,1767790238,"days [4/7] Kala Tika, Safed Tikaâ€¦ Confusion Hi Confusion ğŸ˜Œ #typography #shorts","Kala Tika, Safed Tikaâ€¦ Confusion Hi Confusion ğŸ˜Œ #typography #shorts â€¢Disclaimer: This is Video made for entertainment ...",typography trends
youtube,,https://www.youtube.com/watch?v=MPbWoDrwzY0,1767711643,"Minimalist Fonts for a Fresh Start | Clean, Modern Typography  #canvahacks #businesstemplates","A new season is the perfect moment to refresh your design style. Clean typography creates clarity, calm, and focus â€” before ...",typography trends
youtube,,https://www.youtube.com/watch?v=yHs9-RVTwsA,1767704407,Graphic Design Trends 2026 â€” And How to Actually Use Them!,Discover the most important graphic design trends of 2026 and learn exactly how to use them the right way in your own work!,typography trends
youtube,,https://www.youtube.com/watch?v=RPnW-5FqgCk,1767676992,Typography #typographyart #banglatypography #starrynightvibes #artandcraft #trends #virals,,typography trends
youtube,,https://www.youtube.com/watch?v=voXeijA9CJw,1767486301,The Dark &amp; Torturous History of Typography.,The Dark & Torturous History of Typography. #shortvideo #newcreator #shorts #typography #editing #popular #fyp #viralcontent ...,typography trends
youtube,,https://www.youtube.com/watch?v=5_jdQR6qwe8,1767449223,[Day 2/7] Down to Earth âŒ Nich Behaviour âœ… ğŸ˜‚ #typography #shorts,[Day 2/7] Down to Earth âŒ Nich Behaviour âœ“ ğŸ˜‚ #typography #shorts Day 2/7 of our consistency series âœ¨ â€œDown to earthâ€ bolna ...,typography trends
youtube,,https://www.youtube.com/watch?v=2N9PacsSc70,1767391184,web design trends 2026,webdesigner #digitaldesigner #uiuxdesigner#visualdesign #uiuxdesign.,typography trends
