source,domain,url,created_utc,title,text,query
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/smashing-animations-part-6-svgs-css-custom-properties/,1762527600,Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties,"Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties

SVG is one of those web technologies thatâ€™s both elegant and, at times, infuriating. In this article, pioneering author and web designer Andy Clarke explains his technique for animating SVG elements that are hidden in the Shadow DOM.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/practical-guide-ux-strategy/,1762347600,Six Key Components of UX Strategy,"Six Key Components of UX Strategy

Letâ€™s dive into the building blocks of UX strategy and see how it speaks the language of product and business strategy to create user value while achieving company goals. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today).",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/how-leverage-component-variants-penpot/,1762250400,How To Leverage Component Variants In Penpot,"How To Leverage Component Variants In Penpot

With component variants, design systems become more flexible, letting you reuse the same component while adapting its look or state with ease. In this article, Daniel Schwarz demonstrates how design tokens can be leveraged to manage components and their variations using <a href=""https://penpot.app?utm_source=SmashingMag&amp;utm_medium=Article&amp;utm_campaign=Variants"">Penpot</a>, the open-source tool built for scalable, consistent design.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/desktop-wallpaper-calendars-november-2025/,1761912000,Fading Light And Falling Leaves (November 2025 Wallpapers Edition),"Fading Light And Falling Leaves (November 2025 Wallpapers Edition)

The new month is just around the corner, and that means: Itâ€™s time for some new desktop wallpapers! All of them are designed by the community for the community and can be downloaded for free. Enjoy!",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/javascript-for-everyone-iterators/,1761570000,JavaScript For Everyone: Iterators,"JavaScript For Everyone: Iterators

Here is a lesson on Iterators. Iterables implement the iterable iteration interface, and iterators implement the iterator iteration interface. Sounds confusing? Mat breaks it all down in the article.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/ambient-animations-web-design-practical-applications-part2/,1761138000,Ambient Animations In Web Design: Practical Applications (Part 2),"Ambient Animations In Web Design: Practical Applications (Part 2)

Motion can be tricky: too much distracts, too little feels flat. Ambient animations sit in the middle. Theyâ€™re subtle, slow-moving details that add atmosphere without stealing the show. In part two of his series, web design pioneer Andy Clarke shows how ambient animations can add personality to any website design.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/ai-ux-achieve-more-with-less/,1760688000,AI In UX: Achieve More With Less,"AI In UX: Achieve More With Less

A simple but powerful mental model for working with AI: treat it like an enthusiastic intern with no real-world experience. Paul Boag shares lessons learned from real client projects across user research, design, development, and content creation.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/how-make-ux-research-hard-to-ignore/,1760619600,How To Make Your UX Research Hard To Ignore,"How To Make Your UX Research Hard To Ignore

Research isnâ€™t everything. Facts alone donâ€™t win arguments, but powerful stories do. Hereâ€™s how to turn your research into narratives that inspire trust and influence decisions.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/the-grayscale-problem/,1760349600,The Grayscale Problem,"The Grayscale Problem

From A/B tests to AI slop, the modern web is bleeding out its colour. Standardized, templated, and overoptimized, itâ€™s starting to feel like a digital Levittown. But it doesnâ€™t have to be.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/smashing-animations-part-5-building-adaptive-svgs/,1759755600,"Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries","Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries

SVGs, they scale, yes, but how else can you make them adapt even better to several screen sizes? Web design pioneer Andy Clarke explains how he builds what he calls â€œadaptive SVGsâ€ using ``, ``, and CSS Media Queries.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/intent-prototyping-practical-guide-building-clarity/,1759485600,Intent Prototyping: A Practical Guide To Building With Clarity (Part 2),"Intent Prototyping: A Practical Guide To Building With Clarity (Part 2)

Ready to move beyond static mockups? Here is a practical, step-by-step guide to Intent Prototyping &mdash; a disciplined method that uses AI to turn your design intent (UI sketches, conceptual models, and user flows) directly into a live prototype, making it your primary canvas for ideation.",
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/desktop-wallpaper-calendars-october-2025/,1759230000,Shades Of October (2025 Wallpapers Edition),"Shades Of October (2025 Wallpapers Edition)

How about some new wallpapers to get your desktop ready for fall and the upcoming Halloween season? Weâ€™ve got you covered! Following our monthly tradition, the wallpapers in this post were created with love by the community for the community and can be downloaded for free. Enjoy!",
rss,uxdesign.cc,https://uxdesign.cc/what-we-lose-when-we-lose-the-creative-struggle-09ad3a5df2c9?source=rss----138adf9c44c---4,1762812773,What we lose when we lose the creative struggle,"What we lose when we lose the creative struggle

<h4><em>How removing friction from creative tools removes the meaning from creativeÂ work</em></h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*TbMmpNxAhRk0ywBhw_Xo7w.png"" /><figcaption>illustration byÂ author</figcaption></figure><p>Twenty-five or so years ago, one day after school I went to visit my dad at his office. We didnâ€™t have a computer at home at the time so whenever I was around his, I would beg him to let me use it to play with MSÂ Paint.</p><p>I was probably around 7 or 8, and my go-to artwork was a portrait of my him made with the spray toolâ€Šâ€”â€Šperfect to recreate his short, spiky hair and stubbleâ€Šâ€”â€Šand Iâ€™d make his head ridiculously big and tease him about it. He still has one of these masterpiece in his desktop wallpapers rotation, Iâ€™m prettyÂ sure.</p><p>I couldnâ€™t draw much else with the mouse, nothing more complicated than a lopsided house and a tree, so I would ask him, knowing full well he wasnâ€™t the artist in the family, to draw something for me; that day I asked for a dog. He tried his best, but what came up on the canvas was a misshapen thingâ€Šâ€”â€Ša kind of pig-dog hybrid that was so bad it had us laughing for a goodÂ while.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*bAbEBu0_nMOmt2viK_-_2w.png"" /><figcaption>MS paint GUI circa 1999 (screenshot byÂ author)</figcaption></figure><p>I wasnâ€™t always sure why that random ugly dog had stayed with me for so long, but I see now it was a symbol of the connection my dad and I shared that day. This memory has resurfaced a few times now that thereâ€™s so much emphasis on AI image generatorsâ€Šâ€”â€Šthese tools that can (sometimes, for now) create breathtaking art effortlessly yet leave me, <a href=""https://www.youtube.com/watch?v=Vz0oQ0v0W10"">and many others</a>, wondering about their realÂ purpose.</p><p>Iâ€™ve been thinking about what it would have been like if instead of just our best intention and some basic tools we would have had at our disposal Midjourney or something else that day, how my request to my dad would have been the same but the result much more different. The quality of the artwork itself is beside the pointâ€Šâ€”â€Šthe whole interaction and the unexpected moment between us itâ€™s what would have beenÂ lost.</p><p>Thereâ€™s been <a href=""https://philosophynow.org/issues/169/What_Makes_A_Work_Of_Art_Great"">countless debates</a> on what makes art <em>art</em>, why or why not AI outputs can or should be considered the <a href=""https://news.harvard.edu/gazette/story/2023/08/is-art-generated-by-artificial-intelligence-real-art/"">same as human ones</a>. Now every month we have a new tool we can use, one of the latest being <a href=""https://openai.com/index/sora-2/"">Sora 2</a>, adding no value to the human experience while claiming to â€˜democratiseâ€™ creativityâ€Šâ€”â€Šan overused phrase that does nothing, if not mistaking access forÂ meaning.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*Zz1vLggJm8LYsGkNulSnAA.png"" /><figcaption>Google Gemini UI (screenshot byÂ author)</figcaption></figure><p>From a UX perspective, the process of AI image generation is as frictionless as it can be: type, click, wait and receive what youâ€™ve asked for, perhaps refine it. As ever, the promise is accessibility by letting anyone create regardless of skill, but I would argue thereâ€™s a difference between democratising outcomes and democratising the creative processÂ itself.</p><p>With these tools itâ€™s like weâ€™re giving everyone a printer instead of a paint brush, and by doing that, what weâ€™re losing is the struggle and the lessons that come with it, so much so that creation doesnâ€™t even feel like creatingÂ anymore.</p><p>When the outputs are automated weâ€™re stripping away the messy, truly generative, experience where actual creativity lives.</p><p>I canâ€™t deny that, in some cases, these programs can spit out objectively beautiful outputs. But as much as those AI images might look right, thereâ€™s always something missing: whether itâ€™s the person behind it trying to communicate something they canâ€™t quite articulate, or the surprise and frustration of actually getting your hands dirty with aÂ tool.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*tyxcDKSGvU2XD8QihHyCVA.png"" /><figcaption>Geminiâ€™s image created form the prompt â€œdraw me a dogâ€. Technically much better than my dadâ€™s dog, thatâ€™s for sureâ€¦ but I donâ€™t think I would remember it 20 years from now (image byÂ author)</figcaption></figure><p>If youâ€™ve ever tried Midjourneyâ€™s on Discord, youâ€™ll know that the experience is quite far from one of creativity. Youâ€™re left to watch dozens of other peopleâ€™s prompts and outputs stream by, and few will truly experiment since itâ€™s much easier to copy successful formulas when wanting a certainÂ result.</p><p>Or the variation buttonsâ€Šâ€”â€Šwhy struggle with your vision when you can just generate alternatives until one feels â€œgood enoughâ€? I canâ€™t get over how these â€œcreativeâ€ tools take away the mess and uncertainty where creativity actually happens, and offload whatâ€™s arguably the best part of the process to a randomising algorithm.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*nx1xERWbQHABlj3iNGXx4Q.png"" /><figcaption>Midjourney running on Discord (screenshot <a href=""https://aituts.com/adding-midjourney-bot-discord-server/"">source</a>)</figcaption></figure><p>Looking at the bigger picture, itâ€™s disheartening how as a society we can go from celebrating paintings made hundreds, even thousands of years ago, studying each stroke, letting them tell us a story and move us, to being satisfied with something so fundamentally different.</p><p>The point of art, no matter the categoryâ€Šâ€”â€ŠI believeâ€Šâ€”â€Šis that itâ€™s inseparable from the artist behind it. To an extent we can see the quirks and struggle in every piece, sometimes a message, or at the very least, the personality of the artist. What draws us to art isnâ€™t only its beautyâ€Šâ€”â€Šitâ€™s the artistâ€™s way of seeing that gets captured by all the tiny decisions made while creating it. And thatâ€™s what makes art unique andÂ human.</p><p>I am <a href=""https://medium.com/user-experience-design-1/the-design-of-shallow-thinking-4627e254a7b3?sk=d121456de089061f1293e7063524e1b4"">by my own admission</a> a bit of romantic when it comes to oldschool software, but if creativity becomes automated we risk losing the very thing that makes art meaningfulâ€Šâ€”â€Šthe experience of creating something. Then whatâ€™s going to happen to all those â€œhappy little accidentsâ€ and self expression, that come with the creative struggle?</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/459/1*sWVduw3OEoS-5uKxL17q4Q.gif"" /><figcaption>gif of Bob Rossâ€™ famous quote â€œwe donâ€™t make mistakesâ€Šâ€”â€Šwe just have happy accidentsâ€ (<a href=""https://giphy.com/gifs/fail-college-mistakes-rYEAkYihZsyWs"">source</a>)</figcaption></figure><p>As designers, we always aim to reduce friction and remove barriers, but watching people use AI tools for art is, frankly, just a bit sad. Scrolling through options until you find a good one doesnâ€™t really scream creativeÂ process.</p><p>Recently I had a conversation with someone comparing AI art to electronic music (along the lines of <em>â€œnew technology disrupts an art form, skeptics resist but creativity adaptsâ€</em>). Iâ€™m not a musician myself but I think that when you dig deeper, the two situations are quite different in terms of what technology is doing to the creative process: electronic music gave artists new ways to create, while AI art gives <em>machines</em> new ways to imitate creation.</p><p>We should recognise this distinction especially because we spend our careers thinking about how interfaces guide decisions. We know that removing steps from a process doesnâ€™t just make it faster, but it can change what that processÂ <em>is</em>.</p><p>So I keep thinking about this ugly digital dog from 1999, how it might be the most valuable piece of art in my memory, even thoughâ€Šâ€”â€Šor especially becauseâ€Šâ€”â€Šit was not perfect and looked almost nothing like aÂ dog.</p><h4>Further reads/watch</h4><p><a href=""https://www.bloodinthemachine.com/p/ai-is-not-democratizing-creativity"">AI is not â€œdemocratizing creativity.â€ Itâ€™s doing the opposite</a>â€Šâ€”â€ŠBrian Merchant<br /><a href=""https://www.youtube.com/watch?v=55Z4cg5Fyu4"">Sora proves the AI bubble is going to burst so hard</a>â€Šâ€”â€ŠAdam Conover<br />Reclaiming Art in the Age of Artificeâ€Šâ€”â€ŠJ. F.Â Martel</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=09ad3a5df2c9"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/what-we-lose-when-we-lose-the-creative-struggle-09ad3a5df2c9"">What we lose when we lose the creative struggle</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/the-color-reflex-psychology-that-fires-before-you-think-e5e6556919da?source=rss----138adf9c44c---4,1762812655,The color reflex: Psychology that fires before you think,"The color reflex: Psychology that fires before you think

<h4>Design doesnâ€™t start with pixels or shapes, but with how the brain perceives color andÂ emotion.</h4><figure><img alt=""A yellow LEGO head with a colorful brain sticking out, against a vertical rainbow-striped background."" src=""https://cdn-images-1.medium.com/max/1024/1*MTkEF1AH8tRpG1IR5iNxSA.png"" /><figcaption>Some elements were created using AI. The final image was composed by Maxim Shevchenko-Tymchuk.</figcaption></figure><p>As designers, we all understand how deeply psychology shapes our work. After all, everything we create is meant to be used by people and their perception and experience are what truly define our products. We listen to our users and aim to make their interaction with our products as effortless and intuitive as possible.</p><p>My goal with this article isnâ€™t just to share theories, but to start a dialogue within the design community, to exchange perspectives, challenge assumptions, and uncover new ways of thinking about how design truly interacts with the humanÂ mind.</p><p>Before we move on to specific practices and theories, Iâ€™d like to set the stage for how weâ€™ll be talking about psychology inÂ design.</p><h3>Psychology is aÂ science</h3><p>In short, <a href=""https://www.britannica.com/science/psychology""><em>psychology</em></a><em>,</em> according to Britanica, is the science of human behavior, emotions, and perception. For us as designers, it provides a lens that helps us build hypotheses and create meaningful concepts. But I believe itâ€™s crucial to remember that <em>design</em><strong> </strong>is<strong> </strong>neither a result nor a goal only but a process of solving problems, as Design Council mentions it in <a href=""https://www.designcouncil.org.uk/fileadmin/uploads/dc/Documents/DesignCouncil_Design%2520methods%2520for%2520developing%2520services.pdf"">their paper</a>. And this process can integrate methods and theories from many different disciplines.</p><figure><img alt=""A red double diamond diagram representing the design process, with two connected diamonds labeled sequentially: Discover, Define, Develop, and Deliver."" src=""https://cdn-images-1.medium.com/max/936/0*UBFR6q7A4iVOekRE.png"" /><figcaption><a href=""https://www.designcouncil.org.uk/our-work/the-double-diamond/"">The Design Councilâ€™s</a> visual representation of their Double Diamond design and innovation process.</figcaption></figure><p>No matter how appealing our hypotheses may seem, whether theyâ€™re based on cutting-edge research or well-established principles, real value for users emerges only when we listen to them, understand what they actually need, and iterate our solutions accordingly.</p><p>So what weâ€™re discussing here is perfect for building design hypotheses but it should never be mistaken for their final proof. Now, letâ€™s examine these concepts of Color Psychology moreÂ closely.</p><h3>How our brain perceives color</h3><p>I think we sometimes underestimate the meaning and importance of color in interfaces and design. Yet I would argue that color is one of the most crucial aspects of design itself. I would like support this interpretation with the findings from two scientific paper <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC6673893/""><em>Estimation of the Timing of Human Visual Perception from Magnetoencephalography</em></a><em> </em>and <a href=""https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2014.00674/full""><em>Early recurrent feedback facilitates visual object recognition under challenging conditions</em></a><em>.</em></p><p>Our perception of color begins the moment light hits the retina and activates the cone cells, each sensitive to different wavelengths. The signal is then sent directly to the limbic system, the part of the brain responsible for emotional responses.</p><figure><img alt=""Diagram illustrating the visual pathways in the human brain."" src=""https://cdn-images-1.medium.com/max/600/0*WS_-cGEcUotrnrQ2"" /><figcaption>Image source - <a href=""https://www.britannica.com/science/human-eye/The-nervous-messages"">Britanica</a></figcaption></figure><p>This structure evolved long before the neocortex, which handles rational thought. In other words, our emotional brain reacts to color before our logical brain even gets involved. The limbic system also connects emotions with memory, motivation, and instincts, which explains why color can instantly trigger feelings, associations, and even behavioral responses.</p><p>In other words, our brains have evolved to process color before form or content and, importantly, to do so while bypassing the neocortex, which handles rational thinking.</p><p>This means that before your user even begins to consciously recognize shapes or read text, theyâ€™ve already experienced an emotional response to the colors on theÂ screen.</p><p>Of course, in research weâ€™re talking about milliseconds but to me, even a reaction that happens up to four times fasteris a huge difference. It reminds us that color doesnâ€™t just decorate a design; it sets the emotional stage for how users will interpret everything thatÂ follows.</p><p>Letâ€™s look at an example. Iâ€™ll be showing you a series of illustrative images that serve as analogies for how our brain perceives visual information.</p><h4>Sensory perception ofÂ color</h4><p>In the first <strong>0â€“50 milliseconds</strong> after light hits the retina, the cone cells react to the wavelengthâ€Šâ€”â€Šitâ€™s <strong>pure physics</strong>. At this stage, your brain doesnâ€™t yet â€œknowâ€ what happened: <em>the signal has just begun its journey through the visualÂ pathway.</em></p><figure><img alt=""Dark background without content on it."" src=""https://cdn-images-1.medium.com/max/1024/1*566ikSMtMS3wXR8SPB7yQA.png"" /><figcaption>Example created by Maxim Shevchenko-Tymchuk.</figcaption></figure><h4><strong>Primary color processing</strong></h4><p>Around <strong>80â€“120 milliseconds</strong> after the stimulus, your brain isolates color as a distinct signal. A pure sensation of color forms, along with an <strong>emotional reaction</strong>â€Šâ€”â€Šbecause the information is already being processed in the limbic system. <em>You see red. Itâ€™s a strong visual stimulus, which is why my element has already captured your attention.</em></p><figure><img alt=""A blurred circular composition with a dark center, a soft gray halo, and a small red area on the left side"" src=""https://cdn-images-1.medium.com/max/1024/1*zWPpuLH8_NWA1lF5n5so6g.png"" /><figcaption>Example created by Maxim Shevchenko-Tymchuk.</figcaption></figure><h4><strong>Analysis of shape, contours, andÂ motion</strong></h4><p>At around <strong>150â€“200 milliseconds</strong>, the brain begins to <strong>calculate geometry, boundaries, texture, and depth</strong>. At this stage, the information is still fragmented. <em>The brain has simply detected a rectangle and a collection of other visual elements,</em> but hasnâ€™t yet formed a completeÂ picture.</p><figure><img alt=""A blurred rectangular shape with a red circle on the left and several black rectangles arranged in two rows on a light gray background, centered against a dark backdrop."" src=""https://cdn-images-1.medium.com/max/1024/1*Cygio0MxO1iY0-g_bcZl6g.png"" /><figcaption>Example created by Maxim Shevchenko-Tymchuk.</figcaption></figure><h4><strong>Object and context recognition</strong></h4><p>After about <strong>200â€“300 milliseconds</strong>, the information is integrated in the associative cortexâ€Šâ€”â€Šthis is the moment when <strong>we recognize what weâ€™re seeing. </strong><em>This is probably a notification.</em></p><figure><img alt=""A light gray rectangular box centered on a black background, featuring scattered black letters of varying sizes and a red exclamation mark symbol inside a circle on the left side."" src=""https://cdn-images-1.medium.com/max/1024/1*Msmw53t4mBaJQw1hGEIdQg.png"" /><figcaption>Example created by Maxim Shevchenko-Tymchuk.</figcaption></figure><h4>Cognitive evaluation</h4><p>Only after about <strong>300â€“450 milliseconds</strong> from the moment you look at the button does the rational process begin. The neocortex interprets the meaning. <em>A red banner with the word â€˜errorâ€™ and a warning iconâ€Šâ€”â€Šthat means something went wrong in theÂ system.</em></p><figure><img alt=""A centered rectangular notification box with rounded corners on a black background. Inside, a red exclamation mark icon appears to the left of the bold black text â€œERROR,â€ followed by the smaller phrase â€œOops! Something went wrong.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*ZETQsgl4h4a5pKm9rU_ThA.png"" /><figcaption>Example created by Maxim Shevchenko-Tymchuk.</figcaption></figure><p>So Iâ€™d like you to notice something: by the time you already felt a slight sense of alert from seeing the red color, your brain still needed another 200â€“300 milliseconds to fully decode what was actually happening.</p><p>And now, my dear designers, I invite you to try a little experiment. Take any interface design and increase the duration of all animations by 250 milliseconds. Youâ€™ll instantly feel how even such seemingly tiny time differences can dramatically change your perception of what youÂ see.</p><h3>The reality ofÂ color</h3><p>The second aspect of color that absolutely fascinates me is its duality, especially when it comes to how we perceive it. On one hand, color is a subjective experience but on the other, itâ€™s something we can measure with extraordinary precision.</p><h4>The immeasurable side ofÂ color</h4><p>We know that every person is unique, and we still canâ€™t definitively prove or disprove whether we all see colors in the same way as Prof. Semir Zeki states in his Lecture on Color Perception. What we do know is that perception depends on the cone cells in our eyes and their quantity and ratio can vary from person toÂ person.</p><a href=""https://medium.com/media/319a9b559cd834f86cbc166659569f70/href"">https://medium.com/media/319a9b559cd834f86cbc166659569f70/href</a><p>And another mystery remains, how exactly our brain interprets colors, and whether it does so in the same way for everyone. Some people can see more or fewer shades, while others might not distinguish basic colors at all. In very rare cases, some individuals may even experience monochromatic vision, not only due to missing cones, but also as a result of brainÂ damage.</p><h4>The true nature ofÂ color</h4><p>Color doesnâ€™t actually exist in nature. Yes, thatâ€™s right: leaves arenâ€™t really green, the sky isnâ€™t truly blue, and even an emerald isnâ€™t <em>actually</em> green. All of this is an illusion. Our brainâ€™s interpretation of light according to an article <a href=""https://www.spectroscopyonline.com/view/where-perception-meets-reality-the-science-of-measuring-color""><em>Where Perception Meets Reality: The Science of Measuring Color</em></a>.</p><p>In reality, what we see is not color but light. Depending on the wavelength of that light, the cone receptors in our retina are activated in different ways. The wavelength changes because light reflects off objects and that reflection shifts the wave. Whatâ€™s fascinating is that this shift is influenced not just by the objects themselves but by theirÂ atoms.</p><figure><img alt=""Horizontal gradient from dark purple through green to bright red."" src=""https://cdn-images-1.medium.com/max/1024/0*1QxEAuRmQORL5qkn.png"" /><figcaption>Image source -Â <a href=""https://commons.wikimedia.org/w/index.php?curid=4639774"">Gringer</a></figcaption></figure><p><a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC5207327/"">This principle is used by astrophysicists to determine which elements dominate on distant exoplanets</a>: by calculating how specific atoms interact with light. With ultra-sensitive sensors, we can detect even the slightest variations in wavelength reflected from thoseÂ planets.</p><p>And hereâ€™s the key point the atom, the fundamental building block of all matter, has no color of its own. It merely interacts with photons. So, the matter and objects around us are colorless withoutÂ light.</p><p>So weâ€™ve now touched on the second side of what makes color so fascinating: itâ€™s a sensory stimulus that can be described quantitatively: wavelength, intensity, saturation.</p><p>Unlike many other aspects of psychology, color is something we can measure with extreme precision, minimizing any margin of error in experimental data and making it one of the most reliable subjects for psychological research. Yet it remains a complex phenomenon because, we still canâ€™t fully measure the brain that perceives it.</p><h4><em>The color model I trustÂ most</em></h4><p>At the end of the 19th century, long before Johannes Ittenâ€™s theories, Wilhelm Wundt laid the foundation for the psychological classification of color in his work <a href=""https://psychclassics.yorku.ca/Wundt/Physio/intro.htm""><em>Principles of Physiological Psychology</em></a>.</p><p>In my opinion, every designer should be familiar with and understand this framework. Wundt was the first to describe color not merely as a physical property of light, but as a set of psychological parameters of perception forming so called â€œpsychological space of colorâ€, defined by three independent dimensions:</p><ol><li><strong>Hue</strong>â€Šâ€”â€Šthe actual type of color (red, green, blue,Â etc.)</li><li><strong>Saturation</strong>â€Šâ€”â€Šthe degree of color purity, or how much â€œgrayâ€ is mixed intoÂ it</li><li><strong>Brightness</strong>â€Šâ€”â€Šthe perceived lightness or luminance of theÂ color</li></ol><p>This concept became the foundation for the later development of these ideas and the creation of the <a href=""https://en.wikipedia.org/wiki/HSL_and_HSV""><strong>HSV colorÂ model</strong></a>.</p><figure><img alt=""Comparison of HSL and HSV color models showing hue, saturation, and lightness/value relationships in 3D diagrams and gradient slices."" src=""https://cdn-images-1.medium.com/max/1024/0*U-kK5AmTp2noWFGJ.png"" /><figcaption>Image source - <a href=""https://commons.wikimedia.org/w/index.php?curid=9445469"">JacobÂ Rus</a></figcaption></figure><p>Personally, I tend to use this model most often in design, as it gives far greater control over the visual outcome compared to the more rigid machine-encoded HEX or the physically-based RGB formats. HSV allows you to work with color in a way that feels more natural and intuitive, while still providing precise control for subtle adjustments in the finalÂ result.</p><h3>The influence of color onÂ humans</h3><p>Letâ€™s now move from how we perceive color to how it affects usâ€Šâ€”â€Šand how we interpret it from a scientific point ofÂ view.</p><h4>Emotional response toÂ color</h4><p>Weâ€™ve already touched on the emotional component earlier, so letâ€™s start there. <strong>Warm colors are known to speed up reactions and increase physiological arousal</strong>. According to the <a href=""https://www.researchgate.net/publication/279871278_Color-in-Context_Theory""><em>Color-in-Context Theory</em></a>, warm colors stimulate the nervous system and enhance motor responses. Thatâ€™s exactly why shades of red, orange, and yellow are so often used for CTA buttons, alerts, and error messages, anywhere we need to grab attention instantly or create a sense ofÂ urgency.</p><p>At the same time, the same study notes that <strong>cool colors help reduce stress and create a sense of stability</strong>. Blue and green hues are shown to lower anxiety levels, slow down breathing, and evoke feelings of trust and safety.<br />Thatâ€™s why these colors are so commonly used in banking, healthcare, and other sensitive interfacesâ€Šâ€”â€Šwherever calmness, reliability, and reassurance are essential.</p><h4>Cognitive response toÂ color</h4><p>We also know that color influences cognitive functions such as concentration, memory, and creativity. In a 2009 study <a href=""https://www.appstate.edu/~steelekm/classes/psy5300/Documents/Mehta%26Zhu2009.pdf""><em>Blue or Red? Exploring the Effect of Color on Cognitive Task Performances</em></a>, researchers found that <strong>blue enhances creative thinking</strong> and promotes exploration of new ideas, while <strong>red improves focus and attention</strong> to detail. This means that through color, we can influence not only the emotional state of our users but also guide their cognitive processes, subtly steering their minds toward the state most aligned with the task atÂ hand.</p><h4>Cultural perception ofÂ color</h4><p>Itâ€™s important to note that the <strong>psychological response to color is largely universal</strong> among humans, according to <a href=""https://journals.sagepub.com/doi/10.1177/002202217300400201""><em>A Cross-Cultural Study of the Affective Meanings of Color</em></a>, emotional reactions to a colorâ€™s brightness and warmth are not dependent on cultural or socialÂ context.</p><p>However, <strong>color can also acquire symbolic meaning</strong> such as associations with mourning, happiness, or pain, which are shaped by socio-cultural factors. For instance:</p><ul><li>White represents purity in Western cultures but mourning inÂ China.</li><li>Red is often seen as danger in the West, yet as a symbol of luck and prosperity inÂ Asia.</li><li>Green generally feels positive and natural to most of us, but in Indonesia, it signifies â€œforbidden.â€</li></ul><figure><img alt=""Traffic light with red, yellow, and blue signals above a Japanese sign against a blue sky and green trees."" src=""https://cdn-images-1.medium.com/max/690/0*9CILeKbx0ZEaBqIj.jpg"" /><figcaption>Image Source - <a href=""http://www.japantravelplanning.com"">www.japantravelplanning.com</a></figcaption></figure><p>So as designers, we can confidently use color to communicate directly with the limbic system, influencing emotion and attention on a biological level but we must also remain aware of cultural context when using color as a symbol, such as the familiar â€œtraffic light logicâ€ so often applied in interface design. For example, until the 20th century, the Japanese language had no separate word for â€œgreen.â€ All hues between blue and green were described by the same word é’ã„ (aoi), meaning both â€œblueâ€ and â€œgreenâ€, which has led some lights to be a bluer shade ofÂ green.</p><h3>Why every designer should start with color psychology</h3><p>Iâ€™m sure these theories form the essential foundation every designer should enter the profession with and keep exploring throughout their career. Because in the end, we are learning to speak emotions with our users, and color is what speaks directly to their emotions.</p><p>In my opinion, many of these principles shouldnâ€™t be treated merely as hypotheses that demand constant validation, but as axioms we can confidently build upon. No matter what you test or how you test it, red will always attract more attention than blue, as I wrote earlier, some things are universal.</p><p>Itâ€™s important to remember that unless you plan to conduct research on hundreds, maybe thousands, of participants using brain-scanning equipment, youâ€™re unlikely to reinvent the wheel or to prove, through ordinary user testing, a new universal psychological truth about color that hasnâ€™t already been explored by scientists.</p><p>And yet, thatâ€™s exactly where I find beauty in being a designer. Because we work with people, not with algorithms. Our role is to ask, to listen, and to adapt, to consider the socio-cultural context, the personal story, and the environments that shape how your user group perceives both color andÂ design.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e5e6556919da"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-color-reflex-psychology-that-fires-before-you-think-e5e6556919da"">The color reflex: Psychology that fires before you think</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/designing-for-brain-rot-figma-accessibility-neo-robot-10-easy-ui-fixes-ae1bf815f4ca?source=rss----138adf9c44c---4,1762771213,"Designing for brain rot, Figma accessibility, Neo Robot, 10 easy UI fixes","Designing for brain rot, Figma accessibility, Neo Robot, 10 easy UI fixes

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://uxdesign.cc/are-we-creating-brain-rot-dad9e947ba5c?sk=b8c5e21680a3df7a3b775638a3f9742b""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*MvZX-VNMky7_y0za.png"" /></a></figure><p>â€œHow much time do you think you spend on your phone everyday? The survey gives an average of 5 hours and 16 minutes each day. Thatâ€™s almost enough time to watch all three of the original Jurassic Park movies. You can fly from New York to Los Angeles in about the sameÂ time.â€</p><p><a href=""https://uxdesign.cc/are-we-creating-brain-rot-dad9e947ba5c?sk=b8c5e21680a3df7a3b775638a3f9742b""><strong>Are we designing for brain rot?</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/8ab653ea27a6"">DaleyÂ Wilhelm</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/is-figma-in-its-accessibility-era-c87c831b1393""><strong>Is Figma in its accessibility era?</strong></a><strong> â†’</strong><br />Figmaâ€™s inclusive design updates.<br />By <a href=""https://medium.com/u/b2f44e1879c9"">AllieÂ Paschal</a></li><li><a href=""https://uxdesign.cc/how-grocery-store-layouts-manipulate-your-shopping-behavior-aa3cd59e8fc0?sk=f0913d96e3013d8c65e17ac0ae1b0dd7""><strong>How grocery store layouts manipulate you</strong></a><strong> â†’</strong><br />If you overspend, youâ€™re shopping exactly as designed.<br />By <a href=""https://medium.com/u/46ebaf4ad998"">ElvisÂ Hsiao</a></li><li><a href=""https://uxdesign.cc/how-ai-writing-tools-fail-to-speak-to-writers-1bab97d0fa98""><strong>How AI writing tools fail to speak to writers</strong></a><strong> â†’</strong><br />Design insights from taking Grammarly ads (too) seriously.<br />By <a href=""https://medium.com/u/ab6d2e727ca5"">DanielÂ Buschek</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://www.wired.com/ai-issue/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*Ei407fGFTC9JlXEL.png"" /></a></figure><p><a href=""https://www.wired.com/ai-issue/?ref=sidebar""><strong>AI of a thousand faces: deep report by Wired</strong></a><strong>Â â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://ethanmarcotte.com/wrote/against-stocking-frames/""><strong>Against the protection of stocking frames</strong></a><strong> â†’</strong><br />â€œIn fact, I think describing the technology as a thing that has failed can be helpful in elevating what does actually work about it. Heck, maybe itâ€™ll even help us build a better alternative toÂ it.â€</li><li><a href=""https://mikegallagher.org/posts/design-principles-for-healthcare/?ref=sidebar""><strong>Design principles for teams working in healthcare</strong></a><strong> â†’</strong><br />â€œDefining what â€œgoodâ€ means when it comes to user experience design is difficult. In NHS England, all our work is measured against the NHS service standard and we use the NHS design principles to help make decisions about how to align our work with ourÂ values.â€</li><li><a href=""https://www.chrbutler.com/the-fundamentals-problem?ref=sidebar""><strong>The fundamentals problem</strong></a><strong> â†’</strong><br />â€œAnyone can make something that looks designed, but that doesnâ€™t mean that design has happened.â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/material-3-expressive-building-on-the-failures-of-flat-design-d7a9bb627298""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*yGZyufGceIfSPlA-.png"" /></a></figure><p><a href=""https://uxdesign.cc/material-3-expressive-building-on-the-failures-of-flat-design-d7a9bb627298""><strong>Material 3 Expressive: Building on the failures of flat design</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/21edd2d82a10"">Benjamin C.J.Â W</a></p><figure><a href=""https://uxdesign.cc/a-hippocratic-oath-for-tech-with-teeth-4498fb64ea84""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*l-8vLfdiGV2Aoit0.png"" /></a></figure><p><a href=""https://uxdesign.cc/a-hippocratic-oath-for-tech-with-teeth-4498fb64ea84""><strong>A Hippocratic Oath for techâ€¦ with teeth</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/cad7b803aca3"">EleanorÂ Howe</a></p><figure><a href=""https://uxdesign.cc/neo-robot-and-the-role-of-design-in-selling-unfinished-dreams-53e5b0f61e2b?sk=b68959582514436b95874faca8287b3b""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*8d-uHiIA5mbP7G3x.png"" /></a></figure><p><a href=""https://uxdesign.cc/neo-robot-and-the-role-of-design-in-selling-unfinished-dreams-53e5b0f61e2b?sk=b68959582514436b95874faca8287b3b""><strong>Neo Robot and the role of design in selling unfinished dreams</strong></a> â†’<br />By <a href=""https://medium.com/u/fb680b9a4cb0"">FilipeÂ Nzongo</a></p><h3>Tools and resources</h3><ul><li><a href=""https://medium.com/design-bootcamp/10-tiny-ui-fixes-that-make-a-big-difference-c5922c0ef6ab""><strong>10 tiny UI fixes that make a big difference</strong></a><strong> â†’</strong><br />You donâ€™t always need a massive redesign.<br />By <a href=""https://medium.com/u/92299f562789"">RyanÂ Almeida</a></li><li><a href=""https://uxdesign.cc/the-hidden-structure-of-digital-products-6b7ab408f31f?sk=b832097f7e1a9b35137a1a5d6cab057e""><strong>The hidden structure of digital products</strong></a><strong> â†’</strong><br />Bridging the gap between atomic design and conceptual models.<br />By <a href=""https://medium.com/u/6e211b28ed59"">DaleenÂ Rabe</a></li><li><a href=""https://medium.com/design-bootcamp/design-for-glanceable-interfaces-how-preattentive-vision-shapes-intuitive-interactions-d2042b119280""><strong>Design for glanceable interfaces</strong></a><strong> â†’</strong><br />How pre-attentive vision shapes intuitive interactions.<br />By <a href=""https://medium.com/u/3ad9b9b26b8c"">JulianÂ Scaff</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-div10"">this weekâ€™s sponsor</a> to support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ae1bf815f4ca"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/designing-for-brain-rot-figma-accessibility-neo-robot-10-easy-ui-fixes-ae1bf815f4ca"">Designing for brain rot, Figma accessibility, Neo Robot, 10 easy UI fixes</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/we-cant-predict-the-future-but-we-can-design-for-it-079b60bf3bac?source=rss----138adf9c44c---4,1762770177,"We canâ€™t predict the future, but we can design for it","We canâ€™t predict the future, but we can design for it

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/we-cant-predict-the-future-but-we-can-design-for-it-079b60bf3bac?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*RKYwZzN9vMojXz2fm6EWiQ.jpeg"" width=""3840"" /></a></p><p class=""medium-feed-snippet"">How decentralisation is reshaping innovation, and what the possible futures of adaptability might look like.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/we-cant-predict-the-future-but-we-can-design-for-it-079b60bf3bac?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/synthetic-developer-the-solo-designers-best-friend-947ec304c9f4?source=rss----138adf9c44c---4,1762770070,"Synthetic developer, the solo designerâ€™s best friend?","Synthetic developer, the solo designerâ€™s best friend?

<h4>Ever tried scoping a real project with AI to simulate developers expertise? I did. Here are theÂ results.</h4><figure><img alt=""A woman sits behind her desk, discussing with an AI named Tim on her computer. A second screen shows a Figma file."" src=""https://cdn-images-1.medium.com/max/1024/1*EXco2iPy1e1CNAeaQvGaKQ.png"" /><figcaption>Drawing by Anna Lefour, rendered withÂ ChatGPT</figcaption></figure><p>If youâ€™re a solo designer in the team, then you probably feltâ€¦ well,Â lonely.</p><p>At least I did, sometimes. Not that my developers colleagues werenâ€™t helpful. But in a fast paced environment, where delivery is key and discovery is secondary, developers arenâ€™t always available.</p><p>During my thesis research about AIsâ€™ impact on dev/designer collaboration, I interviewed designers that had the same experience. That, or they worked in an environment where developers and designers never interacted: everything went through the ProductÂ manager.</p><figure><img alt=""A schema simplifying collaboration dynamics between dev, design and a third party, from no communication to continuous communication."" src=""https://cdn-images-1.medium.com/max/773/1*N9Skk1lFu6dDoX_De5zdhQ.png"" /><figcaption>These are examples of the collaboration dynamics between the development and design teams that I encountered during my thesis research. Credit: AnnaÂ Lefour</figcaption></figure><p>Thatâ€™s when I decided to test an idea that wandered in my head for some time: <strong>the synthetic developer</strong>.</p><h3>From synthetic user to synthetic dev</h3><p>The first time I heard about a synthetic user was through <a href=""https://medium.com/@lwowa.creator/synthetic-users-a-tool-for-progress-or-a-step-too-far-2db4e95ebb4c"">a classmateâ€™s article</a>. The idea was simple: instead of interviewing real people, you generate a user with AI and run research onÂ them.</p><p>This simple presentation got me to think: <strong>If we can fake users feedbacks, could we fake colleagues expertise too? </strong>After some research,<strong> </strong>Iâ€™ve stumbled across very interesting perspectives on synthetic colleagues, going as far as creating <a href=""https://medium.com/%40popov.anatolii.it/the-synthetic-department-working-with-ai-colleagues-24e77cd2fd1d"">a â€œsynthetic departmentâ€</a>.</p><p>Fast forward a few months. I was thrown into a project mid-flight. No kickoff, no discovery, no user research. Only an oral briefing, a vague description of the clientâ€™s expectations, and the pressure toÂ deliver.</p><p>Normally, this is when I would turn to developers, to help me clarify whatâ€™s feasible, whatâ€™s risky, what needs prioritizing. But I used this opportunity to test the value of AI as a substitute: I tried working with a synthetic expert, and createdÂ Tim.</p><p>And thatâ€™s when you may be wondering: <strong>Is this designer suggesting we replace developers with AI? </strong>The answer is no.<strong> </strong>What I wanted to understand was whether a LLM could<strong> replicate the kind of reasoning developers use</strong> when making trade-offs and spotting risks. Not to take their place, but to help designers explore technical constraints when no human counterpart is immediately available.</p><h3>The experiment: building a synthetic developer</h3><p>Tim was a developer persona powered by ChatGPT, my â€œsynthetic devâ€. I chose ChatGPTÂ because:</p><ul><li>It has unlimited use (unlike Claude) which was important at the time for my thesis research.</li><li>Itâ€™s the designers most used LLM, according to Designlabâ€™s <a href=""https://designlab.com/blog/the-state-of-ai-in-ux-and-product-design-insights-expertise"">State of AI in UX and ProductÂ Design</a>.</li></ul><p>Timâ€™s job was to act as if he were my colleague, ready to discuss scenarios, constraints, and the structure of the interface.</p><figure><img alt=""A screen capture of the details of the persona called Tim."" src=""https://cdn-images-1.medium.com/max/1024/1*9KjqsGBGoFuUbT1E9LIkew.png"" /><figcaption>I built a persona for Tim, my synthetic dev. Credit; AnnaÂ Lefour.</figcaption></figure><p>I gave Tim a detailed persona (experience level, tech stack expertise, communication style) blending the experience of my two colleagues: one senior engineer, one junior developer. I fed him the project brief, including tech stack, user roles, core CRUD features, and industry-specific constraints. Then I ran a structured design discussion, asking him to help meÂ on:</p><ul><li>Generation of typical use scenarios for the 3 main screens detailed in theÂ briefing</li><li>Specific technical constraints depending on the sector the product will beÂ used</li><li>Hypothetical zoning ofÂ screens</li></ul><p>Later, I ran the exact same exercise with the two actual developers from my team. Same questions, same format, same projectÂ brief.</p><p>The contrast was striking.</p><h3>What the synthetic dev got right (andÂ wrong)</h3><p>Tim excelled at certain tasks. He helped me structure three Jobs To Be Done when I was struggling to articulate user needs clearly. He proposed a data model that anticipated change logs requirements I hadnâ€™t considered (<em>example 1, see image below</em>). He explained complex technical concepts in designer-friendly language. And he was instantly available. But his limitations became clear when context matteredÂ most.</p><figure><img alt=""A set of three examples that have been made confidential and are drawn from the conversation the writer had with the synthetic developer."" src=""https://cdn-images-1.medium.com/max/1024/1*UD3EPe2iiIGS5aBq3oDGsg.png"" /><figcaption>Due to confidentiality, I canâ€™t share the exact details of my conversation with Tim. However, I share here some examples. CreditÂ : AnnaÂ Lefour</figcaption></figure><p>He also sounded too generic, too polished, too â€œChatGPTâ€ (<em>example 2</em>). At times, the responses felt more like â€œhelpful AI assistantâ€ than â€œTim the developerâ€â€¦ Especially when offering solutions rather than asking clarifying questions. The persona worked best when I explicitly framed questions as developer-to-designer exchanges, but would drift toward generic helpfulness otherwise.</p><p>More critically, Tim occasionally hallucinated, most notably when he invented industry-specific project experience to justify his choices about the workflows (<em>example 3</em>). But the real issue wasnâ€™t frequent fabrication; it was premature consensus. Tim would propose technically sound solutions without first questioning whether the underlying problemÂ existed.</p><p>He was working from general developer knowledge, not our teamâ€™s knowledge.</p><h3>What real developers brought to theÂ table</h3><p>The real developers brought something Tim couldnâ€™t: <strong>skeptical curiosity</strong>. Where Tim would propose solutions, theyâ€™d ask â€œBut have you checked with the client if they actually work this way?â€ Where Tim suggested optimization patterns, theyâ€™d question â€œDo we even have that problemÂ yet?â€</p><p>Users with multiple roles, need of in-app authentication for some features, further development of the productâ€¦ They pointed out infrastructure context, security concerns, feasibility trade-offs, things Tim simply couldnâ€™t know. They also brought institutional knowledge.</p><p>At times, they went too deep, drifting into implementation details that werenâ€™t immediately relevant, but that richness was what anchored the project inÂ reality.</p><p>The conversation didnâ€™t end with answers. It led to relationship-building. We created a dedicated Slack channel for ongoing design-dev exchanges. The collaboration deepened beyond that singleÂ project.</p><h3>The real insight: synthetic as scaffolding, not structure</h3><p>What this test taught me about the nature of collaboration itself: AI can help us simulate collaboration, but not replaceÂ it.</p><p>Working with Tim showed me the potential of synthetic colleagues as preparation tools. TheyÂ can:</p><ul><li>Help structure thinking before human discussions</li><li>Generate first-draft solutions to stress-test</li><li>Provide on-demand expertise when humans arenâ€™t immediately available</li><li>Act as a rehearsal tool for complex conversations</li><li>Help us cover any angles we may haveÂ missed</li></ul><p>But theyÂ also:</p><ul><li>Miss context-specific constraints</li><li>Hallucinate with confidence</li><li>Canâ€™t build relationships</li><li>Donâ€™t challenge assumptions the way humansÂ do</li><li>Lack the messiness that leads to breakthrough insights</li></ul><p>The real developers gave me more than expertise. They gave me relationship, institutional knowledge, and collaborative momentum that extended far beyond our initial conversation.</p><h3>How to use synthetic developers effectively</h3><p>Itâ€™s important to take into consideration that my observations are based on this one test, as I couldnâ€™t replicate it with another LLM or for another projectÂ (yet).</p><p>Nonetheless, based on my experiment and broader research, hereâ€™s my recommendation: adopt a hybrid approach that leverages AI preparation while protecting human collaboration.</p><figure><img alt=""A schema with three blocks connected with arrows, showing a simplified version of the framework to use AI in briefs collaboration."" src=""https://cdn-images-1.medium.com/max/1024/1*14f33NCwtlixaaJYzEhftw.png"" /><figcaption>AI-assisted scoping requires expert validation. The hybrid approach gradually improves both AI outputs and team relationships. Credit: AnnaÂ Lefour.</figcaption></figure><h3>This framework has three interconnected phases:</h3><h4>Phase 1: preparation withÂ AI</h4><p>Use synthetic developers as thinking partners to structure your approach before human discussions. The biggest limitation? They donâ€™t know what they donâ€™t know. Timâ€™s hallucinations mostly came from lack ofÂ context.</p><p>To make this phase effective:</p><ul><li>Document your project context exhaustively (industry, tech stack, existing architecture)</li><li>Ask a real developer to help you craft that context, theyâ€™ll know what detailsÂ matter</li><li>Use AI to generate edge case scenarios, identify potential constraints, draft initial taxonomies</li><li>Formalize concepts you havenâ€™t articulated clearly (in my experiment, Tim helped me structure Jobs To Be Done that became foundation for richer conversations later)</li></ul><p>Making AI useful requires human collaboration upfront. Treat AI outputs as conversation starters that help you ask better questions.</p><h4>Phase 2: e<strong>xpert validation</strong></h4><p>Always validate and enrich AI outputs with real humans. My test showed that Tim could provide useful initial framing, but the real developers brought context, nuance, and ideas no LLM could generate.</p><p>This isnâ€™t about AI replacing 30 minutes of developer time. Itâ€™s about making those 30 minutes exponentially more valuable by arriving prepared with structured questions and preliminary solutions to stress-test.</p><p>Expert validation teaches you how to improve your synthetic colleague. What did the AI miss? What context mattered most? Use these insights to refine your prompts and evolve your persona. The goal isnâ€™t perfection, itâ€™s a framework that improves and adapts with eachÂ project.</p><h4>Phase 3: collaborative momentum</h4><p>Hereâ€™s the critical part: the ease of AI creates a dangerous temptation. When you can get â€œgood enoughâ€ answers instantly, itâ€™s easy to skip the messier, slower human conversation. Especially under deadline pressure.</p><p>That shortcut erodes exactly what makes collaboration valuable: relationship-building, institutional knowledge transfer, creative friction that leads to breakthrough insights.</p><p>Set a rule for yourself: If you use AI for preliminary exploration, commit to following up with humans. Even if AI â€œworkedâ€.</p><p>The Slack channel that emerged from my real developer conversations became infrastructure for future collaboration and documentation of our progress and choices. No amount of synthetic dev efficiency could createÂ that.</p><h3>Final thought</h3><p>Back to my main question: is a synthetic dev the solo designerâ€™s bestÂ friend?</p><p>Well, not really. The designerâ€™s best friends are still <strong>the colleagues who bring the expertise she or he lacks</strong>. But the synthetic dev can help bridge the gap: a facilitator to learn the developersâ€™ language, a thinking partner to explore ideas. This experiment proved to me that synthetic actors (devs, users, PMs) arenâ€™t about replacing, but about filling the gaps where communication or collaboration becomeÂ harder.</p><p>Still,<strong> scaffolding isnâ€™t a house</strong>. A synthetic dev isnâ€™t a colleague.</p><p><strong>The goal was never to replace developers, but to explore how much of their reasoning AI can truly emulate.</strong> The future of design wonâ€™t be about choosing between humans and AI. It will be about weaving them together, making the most of whatâ€™s fast and scalable without losing whatâ€™s human and irreplaceable.</p><p>What about you? <strong>Do you use LLMs to extend your teamâ€™s skills or simulate an unavailable colleague?</strong></p><p><em>This article is part of my thesis research on AIâ€™s impact on product team collaboration. Read the full </em><a href=""https://uxdesign.cc/ai-in-designer-developer-collaboration-beyond-individual-productivity-701ec92ce60e""><em>researchÂ article</em></a><em>.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=947ec304c9f4"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/synthetic-developer-the-solo-designers-best-friend-947ec304c9f4"">Synthetic developer, the solo designerâ€™s best friend?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/from-design-to-direction-bridging-product-design-and-ai-thinking-1d372707472d?source=rss----138adf9c44c---4,1762705500,From design to direction: Bridging product design and AI thinking,"From design to direction: Bridging product design and AI thinking

<h4><strong>The shift in product design with the advent of AI and a potential generative experiential future</strong></h4><blockquote>This short essay explores how core concepts in AI can reframe how product designers think about feedback, intent, and the future of ourÂ role.</blockquote><p>A lot has been written about the evolution of user experience since before I ever sat in a Barnes &amp; Noble for hours, trying to understand what the letters â€œH, C, and Iâ€ even meant. In the twelve years since that moment, the tools we use have matured, the rules for interaction have solidified, and the role of design has expanded. We have become a bridge connecting users, businesses, and the technologies that serveÂ them.</p><p>Now, with artificial intelligence entering the public mainstream, a new question emerges: <em>where do we go fromÂ here?</em></p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/767/1*l9X1bG4711j9SH6efndG5g.png"" /></figure><p>I am not here to push anyone toward <a href=""https://medium.com/@jacquelynyakira/thoughts-on-the-future-of-product-design-in-an-ai-first-world-621be208bfa5"">vibe coding</a>, <a href=""https://uxdesign.cc/figma-make-the-biggest-shift-in-ux-ui-since-sketch-5483e18f76d7"">Figma Mak</a>e, or any particular path. Instead, I want to share an idea that came to me while learning the basics of how large language models work. It is a way to start connecting core concepts across domains and help product designers bridge toward the next era of technology. As we move beyond conversational interfaces, we will need new ways of thinking about how to interact with this emerging intelligence.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/451/1*4Psy0Mc7Nh5fyPS89nz9HA.png"" /></figure><p>At the top, I want to recognize that, for the purposes of this article, the term <em>product design</em> can mean many things. Even <a href=""https://www.figma.com/resource-library/what-is-product-design/"">Figmaâ€™s own definition</a> lists responsibilities that extend far beyond â€œpushing pixels.â€ Product designers excel when they have a deep understanding of how technology works and how the business measures success. Whether supporting key metrics or shaping strategy, our work brings together different domains.</p><p>To do that well, we already think in systems, frameworks, research, and telemetry to influence metrics and drive better outcomes. If we take that same mindset and apply it to concepts from AI such as <strong>training corpus, loss, gradients, and intent</strong>, we can start to see a future where design is not just about arranging interfaces but about understanding <em>how systems learn</em>. That is the bridge I want toÂ explore.</p><h3><strong>What AI teaches us about feedback andÂ learning</strong></h3><p>In almost every conversation about technology today, one word keeps surfacing: <em>data.</em> It shapes the experiences we design, the decisions businesses make, and the intelligence that powers modern systems. For this section, I want to focus on how data in AI can teach us something about our own design process, specifically how we learn andÂ iterate.</p><figure><img alt=""Generic graph showing points as if plotted on an x- and y-axis."" src=""https://cdn-images-1.medium.com/max/627/1*5IW-t0Tmhfn0pJTGytGu4w.png"" /><figcaption>Letâ€™s pretend we have a bunch of data at our disposal.</figcaption></figure><p>In user experience, we often work with two types of data: qualitative, which describes what people say, and quantitative, which describes what they do or how often they do it. Letâ€™s focus on the quantitative side for a moment. Imagine plotting the results of a usability study on a simple x and y axis, showing effort versus success rate. Now imagine doing something similar with the data an AI model learns from, whatâ€™s called its <strong><em>training corpus</em></strong><em> </em>(<a href=""https://www.fastcompany.com/90916291/what-is-a-corpus-ai-corpora-chatgpt"">FastCompanyâ€™s article â€œWhat is a â€˜corpusâ€™â€</a>)<em>.</em></p><figure><img alt=""Sample graphs, showing hypothetical data points along an x- and y-axis, one depicting sample usability data and the other training data for an LLM."" src=""https://cdn-images-1.medium.com/max/823/1*YWP-fStx1-W9Jfr1rHGFWQ.png"" /><figcaption>Letâ€™s imagine plotting our data, once for a usability study and another for our trainingÂ data.</figcaption></figure><p>Of course, an LLMâ€™s data isnâ€™t really this simple, but as a metaphor it helps. Once both sets of data are visualized, we can imagine drawing a line that represents our average user response on one chart and the AIâ€™s predicted understanding on the other. The distance between those lines represents something that exists in both worlds: the gap between what we <em>expect</em> and what weÂ <em>observe.</em></p><figure><img alt=""Hypothetical graphs with data points and an overlayed line on each showing average user response and the other illustrating an LLMâ€™s prediction understanding from training data."" src=""https://cdn-images-1.medium.com/max/823/1*NKc49UaujgiY5KKwqm2xOQ.png"" /><figcaption>Now letâ€™s visualize what, as a green line, the average user response or an LLMâ€™s prediction might lookÂ like.</figcaption></figure><p>In design, we call that <em>friction.</em> In AI, itâ€™s called <strong><em>loss</em></strong><em>.</em> Both terms describe the cost of being wrong. When we iterate on a flow or redesign a feature to remove friction, we are, in a sense, minimizing loss. Each round of testing gives us more data to adjust our model of the userâ€™s mental model, just as machine learning systems adjust their internal weights to better predict outcomes (<a href=""https://www.ibm.com/think/topics/loss-function"">IBM: What is Loss Function</a>).</p><figure><img alt=""Two graphs showing difference between average lines and data points, illustrating the connected concept(s) of user friction and loss."" src=""https://cdn-images-1.medium.com/max/795/1*W-btC1pdHsjJgBsaIvK-nA.png"" /><figcaption>Difference between our predictions and reality impact our work exponentially irregardless if it is for an experience or an LLM we are creating.</figcaption></figure><p>Consider an onboarding flow where users repeatedly abandon a form at the â€œCompany Nameâ€ field. Once identified, we might re-label the field or make it optional, reducing friction and improving completion rates. That adjustment mirrors how an AI system corrects its parameters after identifying anÂ error.</p><figure><img alt=""Image illustrating data points towards desired average path to highlight how iteration and optimization are key for usability and LLM performance."" src=""https://cdn-images-1.medium.com/max/333/1*XD_oG9iPScZzYRwO7Vjy7w.png"" /><figcaption>Tweaking an LLMâ€™s parameters, or iterating on an experience, helps us optimizeÂ both.</figcaption></figure><p>This is where the concept of <strong><em>gradients</em></strong> comes in. In machine learning, a gradient measures the direction and magnitude of change needed to reduce loss. Think of it like rolling a ball down a landscape toward the lowest point (<a href=""https://www.ibm.com/think/topics/gradient-descent"">IBM: What is Gradient Descent?</a>). The slope tells the model how to adjust its parameters to improve performance. In product design, we do something similar every time we interpret usability data or customer feedback to decide what to change next. Our gradient is directional insight, the sense of where to move to make the experience smoother.</p><figure><img alt=""Graphic illustrating a curved line representing a downward slope, a gradient descent, with a data point at the bottom showing zero loss or friction."" src=""https://cdn-images-1.medium.com/max/563/1*qHoM1I0rStyKAZN37XXCng.png"" /><figcaption>By tweaking parameters, of an LLM or an experience, we should see a reduction of friction and loss until they, ideally, disappear.</figcaption></figure><p>The iterative process that defines good design is, in many ways, a form of gradient descent. We identify where users struggle, adjust our assumptions, and measure again. Over time, our understanding converges toward what users need. It is not perfect, but neither are machine learning models; both are approximations refined through feedback.</p><p>If thereâ€™s one takeaway from this parallel, itâ€™s that feedback, whether from people or from data, is not an afterthought. Itâ€™s the learning mechanism that keeps systems aligned with reality. And just as models can overfit to their training data, teams can overfit to internal assumptions or stakeholder preferences. In both cases, the cure is the same: structured, ongoing feedback loops that balance exploration with correction.</p><h3>Design as a system of optimization</h3><p>Now that we understand the shared language of feedback and learning between design and AI, it helps to zoom out and look at how these loops exist across every layer of our work. Most senior product designers already know that the interfaces we craft are only one piece of a much larger system. As noted in <a href=""https://www.nngroup.com/articles/ux-maturity-model/"">Nielsen Normanâ€™s levels of UX maturity</a>, mature groups and practitioners move beyond pixels to build frameworks, strategic models, and alignment structures. Even at these higher levels, tight loops of feedback and iteration guide what weÂ do.</p><p>If learning and iteration exist at every level, our role is to understand how those levels connect. Each one has its own kind of <em>loss</em> to minimize and its own signals to optimize. We can roughly think of three layers atÂ play:</p><ul><li><strong>Designers optimizing interfaces</strong>: reducing friction and improving micro-interactions (<em>micro Jobs to BeÂ Done</em>).</li><li><strong>Interfaces optimizing user journeys</strong>: helping people complete the key <em>Jobs to Be Done (JTBD)</em> that deliver productÂ value.</li><li><strong>Organizations optimizing outcomes</strong>: aligning those journeys to business metrics such as adoption, retention, andÂ revenue.</li></ul><figure><img alt=""Image illustrating three key levels in enterprise product design design and various focuses and example intents."" src=""https://cdn-images-1.medium.com/max/582/1*u_7UvtufIi01PV66ZQC8RA.png"" /><figcaption>Product designers working strategically naturally optimize across three key layers in their work. Leveraging key signals across each level, alongside the goals (or intents), lets us understand the loss and how we can iterate to eliminate loss.</figcaption></figure><p>At the first level, designers focus on immediate signals like click rates or error events to reduce friction and guide users toward small but meaningful completions. At the next level, we expand our view to higher-order goals, such as â€œusers complete their profile within thirty days.â€ These are composite outcomes that indicate whether our product fulfills its promises. Finally, at the organizational level, we zoom out again to see how entire journeys and feature sets contribute to larger KPIs and OKRs. Each level informs the others, forming a continuous loop of optimization from micro-interaction to business strategy.</p><figure><img alt=""Graphic illustrating simplified click-path and sample metrics across three optimization levels."" src=""https://cdn-images-1.medium.com/max/964/1*sjffZcAXhKJXXoqAhS5v7g.png"" /><figcaption>Mapping optimization cycles in traditional experiential design, with accompanying signals, might look something likeÂ this.</figcaption></figure><p>As product designers, our work is shifting away from static interfaces and toward orchestrating these systems of <strong><em>intent</em></strong> which I mentally still hold in the same place as a JTBD. With the looming advent of more generative experiences, our influence lies less in deciding where each pixel goes and more in defining the <em>direction</em> a system should learn toward. Our task becomes identifying the goals for each layer, ensuring the feedback flowing through them is meaningful, and guiding the system to reduce its loss at everyÂ scale.</p><figure><img alt=""Simple graphic illustrating how a simple set of activities could change with inclusion of generative UI elements and their potential new signals for measurement."" src=""https://cdn-images-1.medium.com/max/964/1*8sMLLbyQ0JBSwfxSUin98g.png"" /><figcaption>Signals become more about accuracy of identifying user needs (intent) and correlating actions an LLM takes towards supporting desired outcomes (such as delivering most impactful copy to encourage someone to purchase a product).</figcaption></figure><p>Doing that requires data and this is where many organizations struggle. In my experience at both small and large enterprise companies, few have mature instrumentation strategies that connect in-product signals to their KPIs or OKRs. The result is a blind spot: teams canâ€™t see how user intent translates to business outcomes, especially in environments increasingly shaped by AI. When instrumentation is thoughtfully designed, those signals become the gradients we follow. They allow us to see where experiences fall short, measure how far off the mark they are, and iteratively align the product, the user, and the business.</p><p>Directionally similar to other schools of thought, such as from Claudia Canalesâ€™ <a href=""https://medium.com/user-experience-design-1/beyond-the-model-a-systems-approach-to-ai-product-design-fd9917750993"">Beyond the Model: a systems approach to AI product design</a>, positioning design as a system, I see it as one of optimization and not creating perfect screens. Itâ€™s about cultivating feedback systems that learn alongside users. When product designers learn to interpret intent, orchestrate signals, and balance the goals of each layer, we build the foundation for truly adaptive, AI-infused experiences.</p><h3>From control toÂ guidance</h3><p>As product designers, many of us are used to controlling every element of the experience. But as generative systems begin composing parts of the interface for us, our value shifts from crafting the final form to defining the conditions that shape it. We move from being <em>the maker</em> to being <em>the guide</em>â€Šâ€”â€Šdesigning how intent, data, and feedback interact to keep the system aligned with humanÂ goals.</p><p>Imagine opening your design tool and seeing a generative prototype already built around inferred intent. You donâ€™t redraw components; you evaluate signals: <em>Did the model understand the job correctly? Did the feedback loop close?</em> That shift, from crafting to curating, is one direction our craft might be headed. Our influence doesnâ€™t disappear; itÂ evolves.</p><p>When we see design as a system of optimization, we stop treating AI as a separate discipline, or the latest tool to use, and start seeing it as a mirror. It reflects how we already work: learning, adjusting, and seeking balance between human intent and technical possibility. The next evolution of design isnâ€™t about replacing what we do, but about scaling how weÂ learn.</p><p>In the next article of this series, Iâ€™ll explore how instrumentation and <em>Jobs to Be Done</em> can serve as the connective tissue between intent and measurementâ€Šâ€”â€Šthe practical levers we can use to steer generative systems toward meaningful outcomes.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1d372707472d"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/from-design-to-direction-bridging-product-design-and-ai-thinking-1d372707472d"">From design to direction: Bridging product design and AI thinking</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/the-invisible-gap-designing-for-users-who-reconstruct-not-just-read-deae09b93a93?source=rss----138adf9c44c---4,1762619140,"The invisible gap: Designing for users who reconstruct, not just read","The invisible gap: Designing for users who reconstruct, not just read

<h4>Understanding the hidden cognitive work behind every interaction with yourÂ content</h4><figure><img alt=""A graphic illustration shows how a digital screen is taken apart and put back together. At the top is an iPad-like screen with an arrow labelled decode pointing down to smaller pieces. Another arrow labelled reorder points right to a rearranged screen. The final arrow labelled rebuild points up to the original screen."" src=""https://cdn-images-1.medium.com/max/1024/1*zYZTPyhARpMMjBuUMMKo7A.jpeg"" /></figure><p>This article focuses on individuals who use products in English, despite their native language being differentâ€Šâ€”â€Šthose who reconstruct the context when perceiving information inÂ English.</p><p>About 1.19 billion people use English as an additional language, <a href=""https://www.icls.edu/blog/most-spoken-languages-in-the-world"">compared with</a> 390 million native speakersâ€Šâ€”â€Šleaving 810 million non-native English users worldwide.</p><p>Since English content accounts for roughly <a href=""https://www.isocfoundation.org/2023/05/what-are-the-most-used-languages-on-the-internet/"">55% of all websites</a>, while only about 16 % of the worldâ€™s population speak Englishâ€Šâ€”â€Šincluding both native and non-native speakersâ€Šâ€”â€Ša large share of those users navigate the web in a language they learned later inÂ life.</p><h3>What is context reconstruction and why itÂ matters</h3><h4>How non-native English speakers perceive information</h4><p>When users interact with content in a non-native language, they donâ€™t just readâ€Šâ€”â€Šthey reconstruct. Context reconstruction is a three-step, non-linear loop where users decode unfamiliar words or syntax, translate them inwardly, then rebuild the intended meaning before deciding how to act. Itâ€™s not a passive process but an active, effortful one.</p><p><a href=""https://files.eric.ed.gov/fulltext/EJ1214282.pdf"">Studies on second-language comprehension</a> show that readers use strategies like translation, paraphrasing, and contextual inference to reconstruct meaning. <a href=""https://www.mdpi.com/2226-471X/8/1/86"">Research on bilingual reading</a> confirms this processâ€Šâ€”â€Šusers draw on background knowledge and context to bridge linguistic gaps.</p><p>In digital interfaces, <a href=""https://www.digitalstudies.org/article/id/9608"">this reconstruction extends beyond reading</a>: multilingual users interpret layout, structure, and tone through the same active meaning-making loop, as UX research on multilingual personas highlights.</p><p>When users process content in a second language, the reconstructive loop <a href=""https://etheses.whiterose.ac.uk/id/eprint/15502/1/A.E.Schweitzer%20PhD%20Thesis%20November%202016.pdf"">increases cognitive load</a>. Native speakers usually integrate syntax and meaning almost automatically. For non-native speakers, this integration slows downâ€Šâ€”â€Šthe brain weighs <a href=""https://www.sciencedirect.com/science/article/abs/pii/S0022537179903554"">multiple interpretations before resolving the right one</a>â€Šâ€”â€Ševen when the surrounding context favours onlyÂ one.</p><p>This pauseâ€Šâ€”â€Šinvisible but measurableâ€Šâ€”â€Šis where comprehension frictionÂ begins.</p><h4>How reconstruction principles apply to nativeÂ speakers</h4><p>The cognitive load described in multilingual users isnâ€™t unique to them. Similar friction appears for people with <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC10036960/?utm"">lower literacy levels or certain cognitive disabilities</a>. Comprehension challenges like decoding, restructuring, and inferring meaning are shared <a href=""https://developer.mozilla.org/en-US/docs/Web/Accessibility/Guides/Cognitive_accessibility?utm"">across many cognitive differences</a>. Design patterns that reduce this gap benefit everyone, not only international usersâ€Šâ€”â€Šaccessibility and language clarity go hand inÂ hand.</p><p>The term â€˜native speakerâ€™ itself <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC8517917/"">oversimplifies</a> how people use and learn languages. It combines factors like identity, exposure, and cultural background into a binary label that hides real proficiency differences and often reinforces bias. Instead of defining audiences by birth language, teams can describe them through language exposure and functional fluency.</p><p>Setting writing targets around those needs is more practicalâ€Šâ€”â€Šfor example, aiming for B1â€“B2 readability levels on the <a href=""https://readable.com/readability/readability-formulas/"">Flesch-Kincaid scale</a> supports broad comprehension across audiences.</p><p>Looking ahead, the line between native and non-native is already blurring. Trans-languagingâ€Šâ€”â€Šthe natural mixing of languagesâ€Šâ€”â€Šis common in global teams. UX copy isnâ€™t just read by non-native speakers, itâ€™s often <a href=""https://spotify.design/article/were-spilling-the-tea-spotify-ux-writing-questions-answered"">written by them</a>. Inclusive language isnâ€™t just good UXâ€Šâ€”â€Šitâ€™s sound <a href=""https://medium.com/user-experience-design-1/content-design-practices-for-sustainable-communication-in-tech-cbfc679be0cc"">workplace practice</a>.</p><h4>Business perspective on theÂ topic</h4><p>For global products, English source copy should work like a blueprintâ€Šâ€”â€Šclear, structured, and easy to adapt. When itâ€™s written in plain language, localisation teams can translate the meaning without losing intent. That clarity travels: it reduces rework, speeds up releases, and makes products easier to use in any language.</p><p>Plain content also saves money. Teams that act on clear copy often see fewer support requests and faster resolutionsâ€Šâ€”â€Š<a href=""https://arxiv.org/pdf/2201.02737"">in some studies</a>, ticket volume dropped by up to 25 % after improving languageÂ clarity.</p><p>The same practices that make content easier to translate also make it <a href=""https://link.springer.com/article/10.1007/s10209-023-00986-z"">more accessible</a>. Structured, readable text reduces cognitive load for people with learning or attention differencesâ€Šâ€”â€Šand helps non-native speakers too. Poor localisation <a href=""https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/6942735"">does the opposite</a>: it confuses users, adds cost, and quietly blocks conversions.</p><p>Language clarity isnâ€™t just a UX winâ€Šâ€”â€Šitâ€™s a business one. Aligned copy, culture, and layout turn communication into scale, making products more inclusive and more efficient at the same timeâ€Šâ€”â€Šwhether users are solving a problem, completing a task, or looking for quick answers inside aÂ product.</p><h3>Designing for reconstruction</h3><h4>Quality benchmarks</h4><p>Making content reconstruction-ready takes small but deliberate shiftsâ€Šâ€”â€Šacross language, structure, process, and testing. The checklist below helps teams spot risks early and build toward equity atÂ scale.</p><p><strong>Plain language: </strong><a href=""https://digital.gov/guides/plain-language"">Use plain verbs and avoid idiomatic phrasing</a>: â€˜Create accountâ€™ or â€˜Registerâ€™ instead of â€˜Sign upâ€™, â€˜Start trial periodâ€™ rather than â€˜Get startedâ€™. This reduces parsing complexity and helps meaning travel better across languages.</p><p><strong>Consistency:</strong> Collect key terms in a <a href=""https://uxdesign.cc/product-glossary-simple-tool-for-consistent-content-960f8ea1b94f"">product glossary</a> and use them consistently. Avoid synonyms that fragment meaningâ€Šâ€”â€Šif you use â€˜planâ€™ in one screen, donâ€™t switch to â€˜packageâ€™ or â€˜bundleâ€™ elsewhere. Consistency keeps terms stable across journeys and translations.</p><p><strong>Structure: </strong>Clear structureâ€Šâ€”â€Šone of content designâ€™s core principlesâ€Šâ€”â€Š<a href=""https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1305134/full"">improves comprehension</a> for non-native readers and supports accessibility forÂ all.</p><p>Start with information architecture: make navigation transparent and logical. Let users move back, pause, or finish a task midway. Use bullet lists to clarify choices and keep headings, buttons, and labels predictable. This saves time and makes content easy to scan and actÂ on.</p><p>Good structure also supports fast problem-solvingâ€Šâ€”â€Šusers should find answers where they expect them, without scanning or guessing.</p><p><strong>Accessibility:</strong> Plain, well-structured content also boosts accessibility. Around <a href=""https://www.allaccessible.org/blog/web-accessibility-statistics-the-impact-of-disabilities-on-web-use"">16 % of the worldâ€™s population</a> live with some form of disability, and small design choices determine whether they can use products effectively.</p><p>Avoid embedding text in images, and always provide alt-text that adds missing context rather than repeating labels.</p><p>Clear hierarchy and scannable sections also make self-help content and automated responses easier to use for people under cognitive load.</p><p><strong>Localisation: </strong>Consider localisation from the wireframe stage. Write source copy that can stand on its own, so meaning stays clear when removed from layout for translation. Even a short phrase like â€˜Info updatedâ€™ can be misinterpretedâ€Šâ€”â€Šreflexive in one context, passive in another. For example, translators may not know if it means â€˜The system updated the infoâ€™ or â€˜The user updated theÂ infoâ€™.</p><figure><img alt=""A split illustration compares two versions of a screen with the text Info updated. On the left, a blue background shows a paper-like character pressing its own button labelled Updated. On the right, a purple background shows a hand pressing the same button. The image shows how the phrase Info updated can mean either the system updated the information or the user did."" src=""https://cdn-images-1.medium.com/max/1024/1*AxBc9ygNg7C1OaiZL2e6Pg.jpeg"" /></figure><p>Integrate continuous-localisation tools early to prevent late copy freezes andÂ rework.</p><p><strong>Test and research:</strong> Include non-native speakers in every usability round. Ask them to pause and explain what they think a piece of copy meansâ€Šâ€”â€Šyouâ€™ll quickly see where reconstruction fails.</p><p>Testing this way exposes issues that standard metrics often miss and helps build empathy across teams. Include tasks that mirror real support interactionsâ€Šâ€”â€Šfinding help, clarifying messages, or following troubleshooting stepsâ€Šâ€”â€Što reveal hidden friction.</p><h4>Reconstruction blocks</h4><p>When users reconstruct meaning, language and layout can either support or block that process. Even small mismatches can escalate into task failure. Beyond well-known localisation issues like <a href=""https://m2.material.io/design/usability/bidirectionality.html#mirroring-layout"">directionality</a> and <a href=""https://medium.com/@finnclark/designing-for-localisation-what-you-could-be-thinking-about-320184be10a9"">text expansion</a> there are recurring but less obvious tensions.</p><p>These patterns create friction in comprehension and task completionâ€Šâ€”â€Šaddressing them early reduces errors, rework, and user frustration.</p><p><strong>Phrasal verbs: </strong>Phrases like â€˜Sign upâ€™ or â€˜Sign inâ€™ <a href=""https://riyajawandhiya.medium.com/figuring-out-when-to-use-sign-up-vs-register-vs-join-while-looking-at-principles-of-ux-writing-26d299f514dc"">often confuse users</a>â€Šâ€”â€Ševen native speakers. The difference feels small but delays action, especially when both appear on the sameÂ screen.</p><p>Use clear, literal verbs that describe the action. These forms translate more reliably and reduce hesitation. Test them with users to confirm comprehension.</p><p><strong>Idioms: </strong>Colloquial phrases like â€˜Heads upâ€™ or â€˜Kick things offâ€™ rely on cultural metaphors that donâ€™t carry across languages. Replace them with phrasing that makes action explicit. Literal phrasing keeps intent clear and prevents cultural distortion.</p><p><strong>Cultural assumptions: </strong>Error messages like â€˜Oops, something went wrongâ€™ may sound casual in English but dismissive elsewhere. In languages with layered politeness, such as Korean or Japanese, <a href=""https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?referer=&amp;httpsredir=1&amp;article=5350&amp;context=lkcsb_research#:~:text=Abstract%20A%20very%20prominent%20feature,and%20directions%20for%20future%20research"">tone directly shapesÂ trust</a>.</p><p>Write clear, neutral guidance insteadâ€Šâ€”â€Šâ€˜We couldnâ€™t load your details. Please refresh or try againâ€™. Matching tone to user expectations builds reliability andÂ respect.</p><p><strong>Gendered grammar: </strong>English verbs are neutral, but many languages inflect for gender. In Spanish or French, mismatched gender agreement <a href=""https://linguistics.washington.edu/sites/linguistics/files/documents/research/language_learning.pdf"">slows reading</a> and can sound awkward. Translators often have to choose gendered forms even when the English source isÂ neutral.</p><p>Avoid phrasing that forces this choiceâ€Šâ€”â€Šuse â€˜Confirmâ€™ instead of â€˜I agreedâ€™ or â€˜Iâ€™m readyâ€™. Check how target languages express gender early in localisation to keep translations inclusive.</p><p><strong>Auto-generated alt-text and captions: </strong>Machine-generated captions and alt-text <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC9395872/"">often miss nuance or context</a>. When captions run faster than about <a href=""https://dcmp.org/learn/601-captioning-key---presentation-rate"">160 words per minute</a>, comprehension dropsÂ sharply.</p><p>Review all accessibility copy manually for clarity, neutrality, and pacing. Treat it as part of the user experience, not metadata.</p><p><strong>Split attention: </strong>When instructions appear far from the fields they describeâ€Šâ€”â€Šfor example, password rules above an input boxâ€Šâ€”â€Šusers must hold information in working memory. That extra effort <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC12366468/"">increases cognitive load</a>.</p><p>Keep related information close together in both layout and flow. Memory should not have to carryÂ UX.</p><p><strong>Choice overload: </strong>Too many visible options overwhelm users, especially non-native speakers. Studies show that greater menu complexity increases <a href=""https://www.researchgate.net/publication/357695637_An_Analysis_on_the_Impact_of_Choice_Overload_to_Consumer_Decision_Paralysis"">decision paralysis</a>, while simplified layouts improve task speed by about <a href=""https://arxiv.org/abs/2005.01292"">25Â percent</a>.</p><p>Apply <a href=""https://www.interaction-design.org/literature/topics/progressive-disclosure?srsltid=AfmBOooR-h3xZ1WJIY52UypnK4QcAYctQ_n6DXzch7p3qOg1Ya6RZB-Q"">progressive disclosure</a> and group related items logically. Fewer, clearer decisions reduce drop-offs and support comprehension.</p><p>Reconstruction fails when copy or layout forces users to infer too much. To avoid this, designers must go beyond surface fixes and invest in understanding how language and culture shape perception.</p><p><a href=""https://medium.com/design-bootcamp/how-does-knowledge-of-other-languages-impact-your-perspective-as-a-ux-designer-1ecb6bf99690"">Language and design are inseparable</a>: learning how different languages structure thought and communication broadens a designerâ€™s perspective and leads to more inclusive solutions. Awareness of cultural and linguistic diversity helps anticipate preferences, avoid stereotypes, and create source copy that is clearer, more adaptable, and easier to localise.</p><h3>Final thought &amp; firstÂ step</h3><p>Design is what people get, not what weÂ write.</p><p>To get information, hundreds of millions of people who use English as a second or additional language reconstruct what they readâ€Šâ€”â€Šdecoding, reordering, and rebuilding intent beforeÂ action.</p><p>Awareness of this effort changes how we design. It makes us notice the friction that usually stays invisibleâ€Šâ€”â€Šwhere meaning slips or clarity fades. Non-native content designers and UX writers experience this every day, and their insight helps reveal those hiddenÂ gaps.</p><p>When we design with that awareness, content starts to speak across languagesâ€Šâ€”â€Šclearer for non-natives, smoother for everyone.</p><p>The first step is noticing how people get meaningâ€Šâ€”â€Šand designing fromÂ there.</p><h4>Checklist for designing with reconstruction inÂ mind</h4><ul><li>Use verbs that make it clear what users can doÂ next</li><li>Skip idioms and culture-bound phrasing that donâ€™t translate well</li><li>Use hierarchy, lists, and consistent patterns so users can see how information connects</li><li>Ensure copy stays clear when removed from its visual context or translated</li><li>Test with multilingual users to uncover hiddenÂ friction</li><li>Bring in non-native content designersâ€”they experience reconstruction first-hand</li><li>Focus on how users build meaning, not how design presentsÂ it</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=deae09b93a93"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-invisible-gap-designing-for-users-who-reconstruct-not-just-read-deae09b93a93"">The invisible gap: Designing for users who reconstruct, not just read</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/what-the-marble-machine-can-teach-us-about-design-automation-and-creativity-a394ba1563ff?source=rss----138adf9c44c---4,1762619035,"What the Marble Machine can teach us about design, automation, and creativity","What the Marble Machine can teach us about design, automation, and creativity

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/what-the-marble-machine-can-teach-us-about-design-automation-and-creativity-a394ba1563ff?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1920/1*WmocKxRx4pfUVR3qWzlZ6A.jpeg"" width=""1920"" /></a></p><p class=""medium-feed-snippet"">Even in an automated world, creativity needs imperfection.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/what-the-marble-machine-can-teach-us-about-design-automation-and-creativity-a394ba1563ff?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>",
rss,uxdesign.cc,https://uxdesign.cc/material-3-expressive-building-on-the-failures-of-flat-design-d7a9bb627298?source=rss----138adf9c44c---4,1762509359,Material 3 Expressive: Building on the failures of flat design,"Material 3 Expressive: Building on the failures of flat design

<h4>The newest changes to Googleâ€™s influential design system are reviving some very oldÂ lessons.</h4><figure><img alt=""A collection of buttons of various sizes and varied corner radii, with various blue/purple colours and different icons and/or labels"" src=""https://cdn-images-1.medium.com/max/1024/1*lC_hYYT0be6KqpYWNzSVjg.png"" /><figcaption>A whimsical cloud of Expressive buttons. (<em>Google Design</em>,Â 2025)</figcaption></figure><blockquote><em>â€œ</em>Life is too short to click on things you donâ€™t understand.<em>â€â€Šâ€”â€Š</em><a href=""https://www.nngroup.com/articles/clickable-elements/""><em>JakobÂ Nielsen</em></a></blockquote><p>On May 13, 2025 Google unveiled â€œMaterial 3 Expressiveâ€ (M3E), a refresh to its Material Design (MD) design system built on top of the last big update, Material 3Â (M3).</p><p>Chock full of big buttons, stylised text, and passionate colour, M3E is, at first glance, an update primarily championing experimentation with form, colour and shape, a new, artistic approach to productÂ design.</p><p>Indeed, itâ€™s been widely billeted as a young, fresh and hip refresh, and most coverage thus far has accepted this. But UX should never be reduced to just trendy visuals, and it would be a mistake to see M3E as simply a refresh to MDâ€™s aesthetic sensibilities.</p><p>M3E is at its core speaking to the problems that a large plurality of users, particularly older age groups, have experienced to varying degrees with the dominant UI design paradigm of the last decade or soâ€Šâ€”â€Šâ€˜flatâ€™ UI design. These overly-simplified designs showed a lack of <strong>clear interaction signifiers</strong>, leading to <strong>click uncertainty</strong>, and <strong>barriers to quick scanning</strong>.</p><p>Digging into the guidelines, the research, and the changes Google has pushed thus far, itâ€™s clear that M3E represents the MD teamâ€™s attempt to address these limitations of flat UI design, applying the conclusions of UX researchers over the years, now supported by Googleâ€™s own usability studies.</p><figure><img alt=""A collection of 10 phone screen mockups on a pastel purple background, showing various concept designs that showcase the standout aesthetic features of Material 3 Expressive: experimentation with varied button sizes, lots of colour, and bohemian font choices"" src=""https://cdn-images-1.medium.com/max/1024/1*QzkU3a_Pelfur_EvQnjNrQ.jpeg"" /><figcaption>Some promo material for Googleâ€™s M3E update. Iâ€™m not sure what an â€˜athleisure but elevatedâ€™ fit is either. (<em>Start building</em>, 2025)</figcaption></figure><h3>Flat vs. skeuomorphic design</h3><p>Coincidentally as I write this very paragraph, we can (but you probably wonâ€™t!) celebrate fifteen years since the worldwide release of Windows Phone 7â€Šâ€”â€ŠOctober 21st,Â 2010.</p><p>Although I think itâ€™s safe to say that Windows Phone is nowadays remembered more for its failure than anything else, Windows Phone 7 is today perhaps most important for its influence on the realm of interface design. From perhaps the earliest days of consumer computing, UIs relied on a set of principles known as <strong>skeuomorphism</strong>â€Šâ€”â€Štaking physical cues from the real-world, like shadows, depth, and imagery, to communicate the functionality of an interface.</p><p>This methodology is today most fondly remembered from Appleâ€™s early iOS apps, especially the ones which took skeuomorphism to an almost pantomime degree by imitating the functionality and look of real, traditional objects or devices. A notebook became a notes app with a yellow paper background and ruled margins; a newsagentsâ€™ cabinet carried over into the newsstand app, with digitally articulated oak wood-texture shelves.</p><p>Skeuomorphism was essentially a very complex set of <strong>signifiers</strong>â€Šâ€”â€Š<a href=""https://jnd.org/signifiers-not-affordances/"">cues that an object uses to communicate how to use it</a>â€Šâ€”â€Šwhich communicated functionality to the user by relying on our real-world knowledge. Eventually, once interaction paradigms became <a href=""https://jnd.org/affordances-and-design/"">cultural convention</a>, skeuomorphic flourishes became visual flair and noise, distracting as it was no longer necessary to teach functionality by relating the real to theÂ digital.</p><h4>Flat design</h4><p>By 2014, digital interfaces no longer seemed constrained by the usersâ€™ presumed greater familiarity with the physical world. Cue <strong>flat design</strong>. Windows 8 went full brutalist minimalism; iOS 7 stripped away all the Steve Jobs gloss; and Android Lollipop brought Material Design to the party. Material was always a little different, basing itself off a series of stacked-paper metaphors which included a healthy dose of drop shadows (<a href=""https://www.nngroup.com/articles/flat-design/"">NN/g called it â€˜Flat 2.0â€™</a>), but it was still, at its core, a flat approach.</p><figure><img alt=""A side-by-side comparison of two versions of the iPhone calendar app"" src=""https://cdn-images-1.medium.com/max/1024/1*xHNivWuKzFhnGfhAzU_5VQ.png"" /><figcaption>When Apple adopted flat design: the calendar appâ€™s skeuomorphic look in iOS 6 (left) vs. iOS 7 (right). (Moss,Â 2013)</figcaption></figure><p>Flat designâ€™s philosophy, in the great modernist tradition, was exceedingly simple: <strong>remove everything thatâ€™s notÂ needed</strong>.</p><p>Retreating from the overtly heavy visual ornamentation that skeuomorphism had become infamous for was a step in the right direction. But along with the trend toward simplification, researchers found that many flat design implementations also harboured a worrying tendency to go to far, to <strong>oversimplify</strong>, leaning too hard on assumptions of user familiarity with common layouts. In the name of minimalism, these flat UIs stripped away too many visual cues, leaving interactable elements without signifiers and creating interfaces that produced hesitation rather thanÂ harmony.</p><p>In the name of minimalism, these flat UIs stripped away too many visual cues, leaving interactable elements without signifiers and creating interfaces which produced hesitation rather thanÂ harmony</p><p>Ever since flat design emerged researchers, particularly those at the Nielsen Norman Group (NN/g), have been hard at work studying these usability challenges. In the interests of time and space, mine and yours, a short guide to some of the best research is presented below, although I recommend you take the time to read each article for yourself.</p><h3>Flat design &amp; click uncertainty: The 22 percentÂ problem</h3><p>In 2017, Kate Moran and the NN/g team ran an extensive eyetracking study into the then-emerging flat design. They presented 71 users with 9 different pairs of website designs: one with strong visual signifiers (colour, shading, and/or depth); and one with weak or non-existent signifiers (utilising reduced contrast and/or containment). Participants were presented with simple real-world tasks, such as â€œ<em>You will see a page from a hotel website. Reserve this hotelÂ room.</em>â€</p><figure><img alt=""Side-by-side closeup of two different text treatments"" src=""https://cdn-images-1.medium.com/max/1024/1*CP4f35b11kmr2tzYZWr0Dg.png"" /><figcaption>A closeup of a jewellery website target link tested by NN/g, strong-signifier (left) and weak-signifier (right) versions. (Moran,Â 2017a)</figcaption></figure><p>The results were revealed in one <a href=""https://www.nngroup.com/articles/response-criticisms-flat-design/"">much-discussed</a> article, â€˜<a href=""https://www.nngroup.com/articles/flat-ui-less-attention-cause-uncertainty/"">Flat UI Elements Attract Less Attention and Cause Uncertainty</a>â€™, from which two damning statistics emerge:</p><ul><li>Users spent<strong> 22 percent more time completing tasks</strong> on pages with weak signifiers.</li><li>They also had <strong>25 percent more page fixations</strong> on the weak-signifier pages, i.e. their eyes spent more time scanning the page before they found what theyÂ needed.</li></ul><figure><img alt=""Side-by-side comparison of heatmaps"" src=""https://cdn-images-1.medium.com/max/1024/1*RcCFcwUXVrnLjXhkPCGpNA.png"" /><figcaption>The heatmap of the jewellery website pair shows stronger fixations on the strong-signifier interface (left) versus the weak-signifier version (right). The user task was to find the pearl jewellery. (Moran,Â 2017a)</figcaption></figure><p>I should note here that the NN/g study was not embarking on a tirade against the whole of flat design. However, the core tenet of flat design is <strong>simplification</strong> of an interface, and the point of the study was to discover how the extent to which this principle is applied affects usability. Many flattened interfaces suffer from these exact pitfalls, and the stimuli pairs that Moran et al. tested were in fact sourced from real websiteÂ pages.</p><p>(Just the other day I actually ran into an e-commerce website which shared the same button styling, or lack thereof, as in the weak-signifier version of the jewellery website aboveâ€Šâ€”â€Ševidently the studyâ€™s lessons remain relevant to this veryÂ day)</p><h4>Click certainty vs. uncertainty</h4><p>NN/gâ€™s heatmaps revealed what Moran labelled â€œclick uncertainty.â€ On the strong-signifier pages, user attention was more often than not far more focused and confident on than on the flat pages. Because the flat versions of each page had stripped away certain cues that users rely on to differentiate whatâ€™s clickable and whatâ€™s not, they had to spend more time scanning the page, expending more cognitive load to locate the UI element which would complete the task given toÂ them.</p><p>Itâ€™s the opposite of what good UX aims for. To quoteÂ Moran:</p><blockquote><em>â€œ</em>We want our users to have experiences that are easy, seamless, and enjoyable. Users need to be able to look at a page, and understand their options immediately. They need to be able to glance at what theyâ€™re looking for and know instantly, â€˜Yep, thatâ€™sÂ it.â€™<em>â€</em></blockquote><p>But although it was a significant, extensive piece of research, Moranâ€™s study was not the firstâ€Šâ€”â€Šand would not be the lastâ€Šâ€”â€Što sound the alarm on the potential pitfalls of flatÂ design.</p><h3>Further UXÂ research</h3><p>One of the earliest studies addressing the usability drawbacks of flat UI designs focused on an early progenitor of the trend: Windows 8. NN/gâ€™s â€˜<a href=""https://www.nngroup.com/articles/windows-8-disappointing-usability/"">Windows 8â€Šâ€”â€ŠDisappointing Usability for Both Novice and Power Users</a>â€™ (2012) strongly rejected the overtly flat changes Windows 8 had touted: poorly signposted buttons, hardly distinguishable from text labels or info cards, and icons that were â€œ<em>flat, monochromatic, and coarsely simplified,</em>â€ falling into the background of the overall information architecture.</p><figure><img alt=""Screenshot of a dark-blue settings menu with a 3x3 grid of white menu link buttons"" src=""https://cdn-images-1.medium.com/max/344/1*vmQRRzsnFVoXEXYOb37ylQ.png"" /><figcaption>A disturbingly flat settings menu in Windows 8. (Nielsen, 2012)</figcaption></figure><p>And similar conclusions to the Windows 8 article were noted in two other studies inÂ 2015:</p><p><strong>LÃ¼cken et al.</strong> published â€˜<a href=""https://doi.org/10.1515/9783110443929-039"">Evaluation of buttons in the context of the Flat Design style</a>,â€™ which found that stripping away strong visual affordances from a button exponentially raises user hesitation time, and decreases the chance it actually getsÂ clicked.</p><p>In <strong>Burmistrov et al.</strong>â€™s â€˜<a href=""https://doi.org/10.1007/978-3-319-22668-2_10"">Flat Design vs Traditional Design</a>,â€™ the task of identifying clickable objects created a higher cognitive load and rate of error in flat website designs than in â€˜traditionalâ€™ site designs. Scanning in a grid of flat icons also took twice as long as scanning in a grid of skeuomorphic ones.</p><p>Stripping away strong visual affordances from a button exponentially raises user hesitation time, and decreases the chance it actually getsÂ clicked.</p><p>An NN/g study from 2015, â€˜<a href=""https://www.nngroup.com/articles/flat-design-long-exposure/"">Long-Term Exposure to Flat Design: How the Trend Slowly Decreases User Efficiency</a>,â€™ was one of the earliest to note that young adult users were more effective at identifying clickable elements in flat interfaces, while also pointing out that flat design had trained users to spend more time hesitating before clicking. But despite younger usersâ€™ superior performance with flat UIs, the study noted that â€œ<strong><em>young adult users donâ€™t enjoy click uncertainty </em></strong><em>any more than other userÂ groups</em>.â€</p><p>More recently, in 2022â€™s â€˜<a href=""https://doi.org/10.1080/0144929X.2020.1814867"">From skeuomorphism to flat design</a>,â€™ <strong>Urbano et al.</strong> delineated and tested three interface design styles: flat, skeuomorphic, and â€˜skeuominimalistâ€™. The researchers created mockups reflecting the differences between the three styles, incorporating their approaches to colour and shading, adding varying degrees of visual signifiers for interactable elements. Their findings revealed that purely flat designs significantly increase click error rates across <em>all</em> age groups, and <strong>for older users, task completion time was notably sabotaged</strong>.</p><p>One common thread runs through the research: flat designâ€™s tendency to strip away visual signifiers from interfaces inevitably impairs usability. It made interfaces harder to use, especially for older users. Rather than focusing user attention on what matters, making UIs <strong>too clean</strong>, <strong>too white</strong>, <strong>too flat</strong> has the opposite effect: users can lose the ability to discern what they should be paying attention to at all, generating click hesitation and increasing scanningÂ time.</p><p>While our humble UX researchers have been studying these issues for many years, not many companies have actually noticed and followed suitâ€Šâ€”â€Šbut with M3E, Google has bucked theÂ trend.</p><h3>From flat design to Material 3 Expressive</h3><p>The example below is a screenshot from <a href=""https://m3.material.io/blog/building-with-m3-expressive"">one of Googleâ€™s new M3E guideline articles</a>, and it perfectly demonstrates how Google has brought the weight of UX research to bear on their design philosophy:</p><figure><img alt=""A side-by-side comparison showing two versions of a financial app home screen"" src=""https://cdn-images-1.medium.com/max/1024/1*JfALVeLBXkvIRgLVss7BOw.png"" /><figcaption>Doâ€™s and donâ€™tâ€™s from Googleâ€™s new guidelines. (<em>Start building</em>, 2025)</figcaption></figure><p>The flat design (left) uses implicit whitespace and section labels to enable users to understand the structure, requiring extra cognitive effort and potentially introducing click hesitancy.</p><p>The expressive design (right), by contrast, has instant visual structure:</p><ul><li><strong>Containment</strong> using contrasted shades is used to signify important interactive elements.</li><li><a href=""https://www.nngroup.com/articles/common-region/""><strong>Common region</strong></a> boundariesâ€Šâ€”â€Šstronger than proximity or similarity aloneâ€Šâ€”â€Šseparate distinct groups of elements in a rounded container. The subtle corner shape between each element in the container, background colour dividers between the contained buttons, makes each a distinctÂ element.</li><li><strong>Stronger colours</strong> make buttons more obvious against the light background.</li></ul><p>Colour and shade are used not for visual flair, but to <strong>efficiently</strong> <strong>signal key interactive elements</strong> and <strong>instantly communicate visual structure</strong>, ensuring the user doesnâ€™t get lost in whitespace.</p><h4>The changes soÂ far</h4><p>We havenâ€™t seen full overhauls of apps that resemble the bold and experimental mockups shown in M3Eâ€™s initial load of promo material. But since June of this year, Google has begun rolling out design refreshes to their roster of apps, implementing changes that take cues from the new Expressive guidelines:</p><figure><img alt=""A side-by-side comparison showing two versions of the Gmail email app inbox screen"" src=""https://cdn-images-1.medium.com/max/1024/1*8snae9amX10NThLf8tBn3A.png"" /><figcaption>The Gmail inbox, before (left) and after (right) M3E. (Simons &amp; AssembleDebug, 2025)</figcaption></figure><figure><img alt=""A side-by-side comparison showing two versions of the Google One settings screen"" src=""https://cdn-images-1.medium.com/max/1024/1*yy3wgo3TaEsXjypxEB2aEQ.png"" /><figcaption>The settings page of the Google One app, before (left) and after (right) M3E. (Li,Â 2025)</figcaption></figure><p>Again, <strong>containment </strong>(each settings link and each email get their own containers), <strong>common region </strong>(related settings and emails list explicitly grouped) and <strong>stronger colours </strong>(see the M3E Gmailâ€™s compose button) are all strategically implemented, adding important signifiers to critical interactions, and creating immediately clear structure.</p><p>We were lucky enough to get a large amount of the research behind these changes published by Google. And itâ€™s clear from their findings that these changes were aimed at solving the problems with flat design that weâ€™ve seen in the research so farâ€Šâ€”â€Šlack of clear signifiers leading to click uncertainty and barriers to scanning.</p><h3>Googleâ€™s researchÂ findings</h3><p>In the snappy article which explained the research behind the update, â€˜<a href=""https://design.google/library/expressive-material-design-google-research"">Better, Easier, Emotional UX</a>,â€™ the MD design team waxed lyrical about the origins ofÂ M3E:</p><blockquote><em>â€œ</em>Back in 2022, our research intern was studying user sentiment toward Material Design in Google apps. After mentioning her initial findings to colleagues in a Munich beer hall, she sparked a team-wide design debate: Why did all these apps look so similar? So boring? Wasnâ€™t there room to dial up the <em>feeling</em>?<em>â€</em></blockquote><figure><img alt=""A collection of 9 phone screen mockups on a pastel purple background, showing various concept designs that showcase the standout aesthetic features of Material 3 Expressive: experimentation with varied button sizes, lots of colour, and bohemian font choices"" src=""https://cdn-images-1.medium.com/max/1024/1*uyMRWpPABImhPv35gGbyuQ.png"" /><figcaption>Dial up the FEELING! (<em>Start building</em>, 2025)</figcaption></figure><p>The results of this debate speak for themselves. Instead of just redesigning based on designerly intuition, Google embarked on a massive three-year-long, 18,000 participant-strong research study, testing hundreds of design variations across 46 different research studies and conducting surveys and focus groups to gather emotional responses.</p><p>Material 3 Expressive was the result, and Googleâ€™s findings validate everything that UX researchers have been pointing out about flat design for years: click uncertainty, barriers to scanning, and ageÂ gaps.</p><h4>4x faster discovery</h4><p>Using the latest eye-tracking equipment to analyse where users attention was focused, Google had participants interact with 10 different apps pairs: one in current M3 style, and a new M3EÂ version.</p><p>One example was that of an email app: where the current M3 Gmail design relied on whitespace alone to contain the key action (sending the email), hiding it in the top app bar next to other secondary buttons, the M3 Expressive design heightened the visual signifiers, making the primary interaction a large, explicitly contained and contrasted button, placed just above the keyboard.</p><p>Users discovered the send button <strong>four times faster</strong> in the Expressive redesign.</p><figure><img alt=""A side-by-side comparison showing two versions of an email drafting screen"" src=""https://cdn-images-1.medium.com/max/1024/1*dVScxiHpXmmBY9qok8LKTA.png"" /><figcaption>Two versions of a concept email app Google used in its testing. (<em>Better, Easier</em>,Â 2025)</figcaption></figure><p>Thatâ€™s a significant improvement, and it demonstrates just how much more of an additional cognitive load was added by the flatter information architecture and reduced visual signifiers that flat design boasted. The benefits also extended beyond fixation time: across all the Expressive design apps tested, the time users took to tap on the key action actually <strong>decreased byÂ seconds</strong>.</p><p>The key takeaway isnâ€™t only that Googleâ€™s M3E designs are better, but that the research was right: flattening an interface too much results in decreased ease of scanning, and hesitancy about where toÂ click.</p><h4>Age gaps flattened</h4><p>As weâ€™ve seen, digital products usually exhibit a measurable performance difference between younger and older users. Older age groups take longer to identify key UI elements, while <a href=""https://www.nngroup.com/articles/flat-design-long-exposure/"">younger users can often pick up on subtle design cues</a> which allow them to identify key actions muchÂ faster.</p><p>So perhaps the most important finding from Googleâ€™s research is that their Expressive design tactics have resulted in a dramatic <strong>erasure of this gap in performance</strong>:</p><figure><img alt=""Line graph showing that UI elements were spotted faster (in seconds) in expressive designs across all age groups"" src=""https://cdn-images-1.medium.com/max/1024/1*BIhWwgmrSZaIy_RXziyExA.png"" /><figcaption>Chart of M3 vs M3E fixation times per age group. (<em>Better, Easier</em>,Â 2025)</figcaption></figure><p>Yet M3E not just about trying to help older users become digital natives. With this update, the Google Design team has acknowledged that visual signifiers do cognitive work that benefits all users. Strategically applied shading, borders and containment are hallmarks of good design, not just visual flair for the sake of visualÂ flair.</p><p>Strategically applied shading, borders and containment are hallmarks of good design, not just visual flair for the sake of visualÂ flair.</p><h3>Conclusion: The return ofÂ colour</h3><p>The MD team obviously arenâ€™t high on nostalgia for skeuomorphism. They arenâ€™t bringing back wood panelling, glass sheen or yellow note paper texturesâ€Šâ€”â€Štheyâ€™re bringing back <strong>functional signifiers</strong>, the visual cues that help users identify interactive elements and allow them to understand the information architecture at a glance. M3E is a data-driven correction to the problems of flat design that researchers have noted for more than aÂ decade.</p><p>Mind you, the update isnâ€™t perfect. The two new wavy progress indicators, while a lovely idea, do look a bit like a shuffling worm and a wobbly intestinal tract. You be theÂ judge:</p><figure><img alt=""Animation of linear and circular purple progress indicators showing determinate progress and indeterminate progress"" src=""https://cdn-images-1.medium.com/max/1024/1*ZiKNgUuDmjx51fRYhCkxLw.gif"" /><figcaption>M3Eâ€™s new earthworm &amp; human intestine indicators. (<em>Progress indicators</em>, 2025)</figcaption></figure><p>Itâ€™s probably not a coincidence that M3 Expressive comes at a time when it seems like the whole world is retreating from minimalism: style, buildings, design everywhere, just look around! Vogue Australiaâ€™s <a href=""https://www.vogue.com.au/vogue-living/design/decor-trends-2025/image-gallery/8a0c4e8a1db9042a17cd6a8eec7e9112"">guide to 2025â€™s interior design trends</a> even reads like it could be a pitch for M3Eâ€Šâ€”â€Šâ€˜<em>express yourself</em>,â€™ â€˜<em>bolder is better</em>,â€™ â€˜<em>the return ofÂ colour</em>.â€™</p><p>This is the line us UX designers must tread. Trends, to a certain extent, allow us to identify what users are familiar with, what they might find the most â€˜modernâ€™ or appealing.</p><p>But an app isnâ€™t a house. Itâ€™s a 2D tool, projected on a crystalline display, that solves a problem for a user, and I would argue the aesthetic choices of our 2D tools may have far more of a knock-on effect on usability scores than aesthetic interior design choices do. Perhaps itâ€™s because we interact with our apps with the minutia of fingers and eyes alone, rather than the full-body experience of a house. Or perhaps itâ€™s just discipline tunnelÂ vision.</p><p>The researchâ€Šâ€”â€Šfrom NN/gâ€™s heatmaps to Googleâ€™s 18,000-person studiesâ€Šâ€”â€Šhas definitively shown that blindly following popular trends (i.e. flat design) without studying the utility impact can do far more harm thanÂ good.</p><p>As designers, we should never have let ourselves be satisfied with the assumption that, since many users have become familiar with general interface patterns, we can afford to go totally minimalist in our approach to content, layout and signifiers. Conventions are a powerful and necessary tool, and designers should always aim to leverage a usersâ€™ existing knowledge. But there are limits to every law. UI design, particularly for products used by a broad range of ages like Android, should be able to articulate itself for every user, offering <strong>clarity of function</strong> as well as simpleÂ form.</p><p>Rather than let their design guidelines enter a phase of <a href=""https://www.nngroup.com/articles/liquid-glass/"">rampant design cacophony</a>, Google have chosen to build on the years of usability research accumulated since flat designâ€™s inception. Itâ€™s an incredibly encouraging development.</p><p>On one last pointâ€Šâ€”â€Šalthough this article is primarily about the research trail from the earliest flat design studies to M3Eâ€Šâ€”â€Šit would be remiss of me not to note M3Eâ€™s exciting new aesthetic possibilities. In a culture when users are becoming increasingly bored with minimalist trends, interfaces injected with additional artistic intent and emotional appeal have the potential to stand out from the bland, unexciting competition.</p><p>The keywords of M3 Expressiveâ€Šâ€”â€Šdelight, joy, playfulness, modernityâ€Šâ€”â€Šare exciting for designers and users alike, but these touches must be applied with intent, skill and strategy, always testing with that age-old question, so often lost in translation: â€˜<em>does this improve the end user experience?</em>â€™</p><h3>Sources</h3><p><em>Better, Easier, Emotional UX</em>. (2025, May). Google Design. <a href=""https://design.google/library/expressive-material-design-google-research"">https://design.google/library/expressive-material-design-google-research</a></p><p>Budiu, R. (2025, October 10). <em>Liquid Glass Is Cracked, and Usability Suffers in iOS 26</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/liquid-glass/"">https://www.nngroup.com/articles/liquid-glass/</a></p><p>Burmistrov, I., Zlokazova, T., Izmalkova, A., &amp; Leonova, A. (2015). Flat Design vs Traditional Design: Comparative Experimental Study. In M. Fetter, P. Palanque, T. Gross, J. Abascal, M. Winckler, &amp; S. Barbosa (Eds.), <em>Human-Computer Interactionâ€Šâ€”â€ŠINTERACT 2015</em> (Vol. 9297, pp. 106â€“114). Springer International Publishing AG. <a href=""https://doi.org/10.1007/978-3-319-22668-2_10"">https://doi.org/10.1007/978-3-319-22668-2_10</a></p><p>Google Design. (2025, May 14). <em>Introducing: Material 3 Expressive</em>. YouTube. <a href=""https://www.youtube.com/watch?v=n17dnMChX14"">https://www.youtube.com/watch?v=n17dnMChX14</a></p><p>Li, A. (2025, July 31). Google One Material 3 Expressive redesign drops the graphics. <em>9To5Google</em>. <a href=""https://9to5google.com/2025/07/31/google-one-material-3-expressive/"">https://9to5google.com/2025/07/31/google-one-material-3-expressive/</a></p><p>Loranger, H. (2015, March 8). <em>Beyond Blue Links: Making Clickable Elements Recognizable</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/clickable-elements/"">https://www.nngroup.com/articles/clickable-elements/</a></p><p>LÃ¼cken, M., Bruder, G., Steinicke, F. (2015). Evaluation von Buttons im Kontext des Gestaltungsstils Flat Design [Evaluation of Buttons in the Context of the Flat Design Style]. In M. Pielot, S. Diefenbach &amp; N. Henze (Ed.), <em>Mensch und Computer 2015â€Šâ€”â€ŠTagungsband</em> (pp. 307â€“310). Berlin, MÃ¼nchen, Boston: De Gruyter. <a href=""https://doi.org/10.1515/9783110443929-039"">https://doi.org/10.1515/9783110443929-039</a></p><p>Moran, K. (2015, September 27). <em>Long-Term Exposure to Flat Design: How the Trend Slowly Decreases User Efficiency</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/flat-design-long-exposure/"">https://www.nngroup.com/articles/flat-design-long-exposure/</a></p><p>Moran, K. (2015, September 27). <em>Flat Design: Its Origins, Its Problems, and Why Flat 2.0 Is Better for Users</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/flat-design/"">https://www.nngroup.com/articles/flat-design/</a></p><p>Moran, K. (2017, September 3). <em>Flat UI Elements Attract Less Attention and Cause Uncertainty</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/flat-ui-less-attention-cause-uncertainty/"">https://www.nngroup.com/articles/flat-ui-less-attention-cause-uncertainty/</a></p><p>Moran, K. (2017, October 15). <em>Response to Criticisms of Flat-Design Eyetracking Study</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/response-criticisms-flat-design/"">https://www.nngroup.com/articles/response-criticisms-flat-design/</a></p><p>Moss, C. (2013, September 18). <em>23 Side-By-Side Comparisons Of How Appleâ€™s New iPhone Software Will Change Your Favorite Apps</em>. Business Insider. <a href=""https://www.businessinsider.com/ios-6-versus-ios-7-apps-2013-9"">https://www.businessinsider.com/ios-6-versus-ios-7-apps-2013-9</a></p><p>Nielsen, J. (2012, November 19). <em>Flat Design: Its Origins, Its Problems, and Why Flat 2.0 Is Better for Users</em>. Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/windows-8-disappointing-usability/"">https://www.nngroup.com/articles/windows-8-disappointing-usability/</a></p><p>Norman, D. (2008, November 17). Affordances and Design. <em>JND</em>. <a href=""https://jnd.org/affordances-and-design/"">https://jnd.org/affordances-and-design/</a></p><p>Norman, D. (2008, November 17). Signifiers, not affordances. <em>JND</em>. <a href=""https://jnd.org/signifiers-not-affordances/"">https://jnd.org/signifiers-not-affordances/</a></p><p><em>Progress indicators</em>. (2025). Material 3 Components. <a href=""https://m3.material.io/components/progress-indicators/guidelines"">https://m3.material.io/components/progress-indicators/guidelines</a></p><p>Sassall, Y. (2024, November 14). The 15 design trends youâ€™ll be in seeing in 2025 and beyond. <em>Vogue Australia</em>. <a href=""https://www.vogue.com.au/vogue-living/design/decor-trends-2025/image-gallery/8a0c4e8a1db9042a17cd6a8eec7e9112"">https://www.vogue.com.au/vogue-living/design/decor-trends-2025/image-gallery/8a0c4e8a1db9042a17cd6a8eec7e9112</a></p><p>Simons, H. &amp; AssembleDebug. (2025, June 30). <em>Gmail is getting even more Material 3 Expressive UI changes (APK teardown)</em>. <a href=""https://www.androidauthority.com/gmail-expressive-redesign-apk-teardown-3572169/"">https://www.androidauthority.com/gmail-expressive-redesign-apk-teardown-3572169/</a></p><p>Spiliotopoulos, K., Rigou, M., &amp; Sirmakessis, S. (2018). A Comparative Study of Skeuomorphic and Flat Design from a UX Perspective. <em>Multimodal Technologies and Interaction</em>, <em>2</em>(2), 31. <a href=""https://doi.org/10.3390/mti2020031"">https://doi.org/10.3390/mti2020031</a></p><p><em>Start building with Material 3 Expressive</em>. (2025, May 13). Material 3 Blog. <a href=""https://m3.material.io/blog/building-with-m3-expressive"">https://m3.material.io/blog/building-with-m3-expressive</a></p><p>Thornley, N., Simpson, B., Feldman, J., Gilbert, M. (2024, May 13). <em>What does your UI say to your users?</em>. Material 3 Blog. <a href=""https://m3.material.io/blog/testing-material-3"">https://m3.material.io/blog/testing-material-3</a></p><p>Urbano, I. C. V. P., Guerreiro, J. P. V., &amp; Nicolau, H. M. A. A. (2022). From skeuomorphism to flat design: age-related differences in performance and aesthetic perceptions. <em>Behaviour &amp; Information Technology</em>, <em>41</em>(3), 452â€“467. <a href=""https://doi.org/10.1080/0144929X.2020.1814867"">https://doi.org/10.1080/0144929X.2020.1814867</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d7a9bb627298"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/material-3-expressive-building-on-the-failures-of-flat-design-d7a9bb627298"">Material 3 Expressive: Building on the failures of flat design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
rss,uxdesign.cc,https://uxdesign.cc/we-wanted-superman-level-ai-instead-we-got-bizarro-ce6d4ba04f64?source=rss----138adf9c44c---4,1762431746,"We wanted Superman-level AI. Instead, we got Bizarro.","We wanted Superman-level AI. Instead, we got Bizarro.

<h4>The illusion of intelligence is the new frontier of deception.</h4><figure><img alt=""Animated character with pale skin, scraggly black hair, and an eerie expression. Wears a distorted Superman logo on a purple suit. Dark, vibrant background."" src=""https://cdn-images-1.medium.com/max/1024/1*UD88HUJXrf-IcJHasqUqNg.png"" /><figcaption>Image source: <a href=""https://dcau.fandom.com/wiki/Bizarro"">dcau.fandom.com/wiki/Bizarro</a></figcaption></figure><p>I was a huge Superman fan as a kid. In fact, my first tattoo was of the Superman symbolâ€Šâ€”â€ŠI know, cheesy. But there was something about that idea of strength guided by purpose that stuck with me. However, one character that truly captured my imagination was Supermanâ€™s failed copyâ€Šâ€”â€Š<a href=""https://dcau.fandom.com/wiki/Bizarro"">Bizarro</a>.</p><p>Bizarro is a botched experiment by the genius villain <a href=""https://superman.fandom.com/wiki/Lex_Luthor"">Lex Luthor</a> to replicate Superman. He sort of looks like the hero we know, has his powers, and even tries to do goodâ€Šâ€”â€Šbut everything he does comes out wrong. He saves people by endangering them, speaks in twisted opposites, and mistakes harm for help. He isnâ€™t evilâ€Šâ€”â€Šjust reversed. That inversionâ€Šâ€”â€Šan imitation of greatness that misunderstands its essenceâ€Šâ€”â€Šis a fitting metaphor for modernÂ AI.</p><p>But this metaphor isnâ€™t just poeticâ€”Appleâ€™s 2025 paper <a href=""https://machinelearning.apple.com/research/illusion-of-thinking""><em>The Illusion of Thinking</em></a> backs it up. In the study, Apple researchers tested a class of models they called â€œLarge Reasoning Models,â€ essentially Large Language Models (LLMs) retuned for reasoning, using puzzles like the <a href=""https://en.wikipedia.org/wiki/Tower_of_Hanoi"">Tower of Hanoi</a>. At first the models performed well, but as the puzzles grew more complex, their reasoning began toÂ fail.</p><p>Instead of increasing their effort, the models produced shorter and less coherent thought chains, often stopping even when more computation time was available. The researchers observed that their reasoning degraded, revealing that the systems were matching patterns that appeared like reasoning rather than genuinely reasoning.</p><p>As complexity increased, their logic collapsed into pure prediction. The models recognized the shape of thought without ever truly thinking. The result sounded intelligent but feltÂ hollow.</p><p>At the end of the day, these â€œintelligentâ€ machines are little more than glorified autocorrect systemsâ€Šâ€”â€Špredicting, not thinking. Thatâ€™s dangerous, because it blurs the line between intelligence and imitation.</p><p>Itâ€™s a false illusion sold by powerful tech companies as they rake in billions. If I didnâ€™t know better, Iâ€™d call the entire <a href=""https://www.library.hbs.edu/working-knowledge/ai-schemes-could-make-bernie-madoffs-fraud-look-trivial-eugene-soltes"">AI movement a modern Ponzi scheme</a>â€Šâ€”â€Šbut thatâ€™s a discussion for anotherÂ day.</p><p>Anyone whoâ€™s used tools like ChatGPT knows the frustration of arguing with a machine that doesnâ€™t know itâ€™s wrong. And yes, I say â€œarguingâ€ because I often catch myself yelling (with colorful language) at these conversational AI toolsâ€Šâ€”â€Ša fact Iâ€™m not proudÂ of.</p><p>I know itâ€™s foolish to yell at a machine, but in my defense, maybe it should act more like a machine instead of a compulsive liar.</p><p>Just the other day, I asked it to debug a JavaScript snippet it had written. When I said it wasnâ€™t working, it replied, â€œYouâ€™re absolutely correct! The code appears to be flaky.â€ Code it had just given me. I was actually more surprised by the use of the word flakey than the fact that it gave me brokenÂ code.</p><p>That moment perfectly captured the essence of modern AIâ€Šâ€”â€Šconfident errors, fluent nonsense, and zero accountability. This is where weâ€™ve landed as a society. Weâ€™ve traded honesty for efficiency.</p><p>To understand why a model would confidently call its own code â€œflaky,â€ we need to look at how we have historically defined intelligence in machines, and how that definition hasÂ shifted.</p><p>The earliest approach in AI, <a href=""https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/"">symbolic intelligence</a>, encoded human-knowledge in explicit rules and logic. It relied on structured reasoningâ€Šâ€”â€Šif-then statements, symbol hierarchies, and clear inference paths. The advantageâ€”every conclusion is transparent and traceable.</p><p>But the disadvantageâ€”when faced with messy, real-world inputs (such as image recognition or natural language), the rule-based system struggles to scale or cope with ambiguity.</p><p>Following the limitations of rule-based symbolic methods, the field shifted to <a href=""https://www.aaas.org/taxonomy/term/9/heuristic-and-statistical-artificial-intelligence"">statistical artificial intelligence</a>. Instead of encoding explicit logic, this approach relies on probability, large datasets and pattern recognition.</p><p>The system doesnâ€™t â€œreasonâ€ in human termsâ€Šâ€”â€Šit correlates. It learns statistical relationships between inputs and outcomes, then uses those to predict. The trade-offâ€”high scalability and flexibility, but weak transparency and little genuine â€œunderstanding.â€</p><p>And then thereâ€™s todayâ€™s g<a href=""https://research.ibm.com/blog/what-is-generative-AI"">enerative artificial intelligence</a>â€Šâ€”â€Šthe kind behind text, images, and music. Large Language Models (LLMs) like ChatGPT are trained on massive datasets scraped from the internet, learning statistical patterns across billions of examples.</p><p>LLMs use <a href=""https://www.ibm.com/think/topics/transformer-model"">transformer networks</a> to learn contextual relationships by predicting the next word across billions of parameters, creating language that feels coherent but remains purely probabilistic.</p><p>Meanwhile, <a href=""https://www.ibm.com/think/topics/diffusion-models"">diffusion models</a> generate images by gradually denoising random noise into structured visuals, guided by patterns learned from vast datasets.</p><p>Both systems learn correlations, not conceptsâ€Šâ€”â€Šthey model likelihoods, notÂ meaning.</p><p>The trajectory is clearâ€Šâ€”â€Šthe further weâ€™ve moved from the transparency of logic (symbolic AI) toward the fluency of prediction (generative AI), the more convincingly human the output appearsâ€Šâ€”â€Šand the more fundamentally alien the process behind itÂ becomes.</p><p>This is the paradox of modern AI. In our quest to build reliable intelligence, we created its flawed reflectionâ€Šâ€”â€Ša brilliant mimic whose fluency guarantees imitation, but whose lack of reasoning prevents the very understanding and accountability we need to trustÂ it.</p><p>But maybe itâ€™s not entirely bad. Generative AI feeds on what already exists, which means originality still belongs to us. That gives creators a chance to stand apartâ€Šâ€”â€Što make what the machine can onlyÂ imitate.</p><p>The more I learn about AI, the less I fear it taking our jobsâ€Šâ€”â€Šand the more I fear its power to distort truth. These systems donâ€™t thinkâ€”they replicate. They strip away context until meaning becomes optional.</p><p>In that sense, Big Tech has become our Lex Luthorâ€Šâ€”â€Šbrilliant, self-assured, and convinced itâ€™s saving humanity while quietly trying to own it. Its creations mirror its ambitionâ€”powerful, profitable, and fundamentally indifferent to theÂ truth.</p><p>Thatâ€™s the real dangerâ€Šâ€”â€Šnot that AI will outthink us, but that it will outproduce us, flooding the world with fluent illusions that sound right but arenâ€™t. Itâ€™s our own version of Bizarroâ€Šâ€”â€Šexcept this time, thereâ€™s no Superman coming to saveÂ us.</p><p><strong><em>Donâ€™t miss out! </em></strong><a href=""https://micbuckcreative.medium.com/subscribe""><strong><em>Join my email list</em></strong></a><strong><em> and receive the latestÂ content.</em></strong></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce6d4ba04f64"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/we-wanted-superman-level-ai-instead-we-got-bizarro-ce6d4ba04f64"">We wanted Superman-level AI. Instead, we got Bizarro.</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
gnews,news.google.com,https://news.google.com/rss/articles/CBMidEFVX3lxTE5GelVQVGR6MEVYLXpCS3I3WmdrZy0ycUVyNXNDX21udUMyVjBGZzQ5TEFFODk3SlFzbmdOMVY1YmRxaEt6c00zbDhraVB3NVhDX05NWnVsb0FFOEw4QjVWN3FQVlVwM296cTVWMlJXemNXTzBf?oc=5,1762336560,Stunning parallax scrolling web designs that make you never want to stop scrolling - Creative Bloq,Stunning parallax scrolling web designs that make you never want to stop scrolling - Creative Bloq,web design trend
youtube,,https://www.youtube.com/watch?v=tYo76aTdPEc,1762846230,Explore unique dress saree design ideas for womenâ¤ï¸,women dress /wedding dress #Shorts Discover Stunning Dress Designs for Women! âœ¨ Want to elevate your style? In this quick ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=9OR9xoC1zc8,1762837218,Are Graphic Designers Just Professional Thieves?,"Picasso once said, â€œGood artists copy, great artists steal.â€ It wasn't just a quote, it was a warning. Because every great designer, ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=f2rcZ3P28OY,1762829699,Fashion Trends: Learn How to Match Your Style To Your Customers! #shorts,"Understanding graphics, expressions, and fashion trends is crucial for thriving in the clothing business. Niche knowledge + ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=k1GWrD0_wN8,1762812093,How Can Graphic Design Influence Future Movements? - Marketing and Advertising Guru,How Can Graphic Design Influence Future Movements? Have you ever wondered how visual elements can shape social ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=LGTileqyVTs,1762811381,How Did Graphic Design Shape Historical Movements? - Marketing and Advertising Guru,How Did Graphic Design Shape Historical Movements? Have you ever wondered how visual styles influence marketing and ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=0MSM32XcA6c,1762780500,Photoshop Tips 2026 - Create Love Motion Blur Gradient Text  #skvidz #graphicdesign,"In this video, I break down the top Photoshop tips and tricks ......... Photoshop tips 2026, graphic design trends 2026, Photoshop ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=hJpeqH0_UAs,1762779694,A ModernizacÌ§aÌƒo da UltraGaÌs,ConheÃ§a o trabalho do Moura Studio https://mattheusmoura.com Acompanhe nas redes Instagram: ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Q5UDYm3TtDs,1762755202,Mid - Level Graphic Designer #graphicdesigner #delhijobs #corporatedesign #designerinspiration,Position: Graphic Designer Job ID: 009DEL-GD-AL Join a multidisciplinary design studio with 28+ years of experience in crafting ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=F_I2vYs46eA,1762752572,Google Chrome logo design|| Google Chrome ka logo kaise banaye #tranding #viral #shorts #google,"Google Chrome, Chrome logo design, logo design, graphic design, branding, design secrets, Google logo, logo history, web ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=xa98oKhSgQo,1762742748,What Were The Key Illustrative Design Trends Of The 1950s? - Im a 50s Baby,What Were The Key Illustrative Design Trends Of The 1950s? Ever wondered what made graphic design in the 1950s so ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=UqGewluwEac,1762718893,ğŸ¨ 2025 Design Trends Alert! ğŸš€,The visual landscape is transforming. Here are 15 game-changing design trends dominating this year: âœ¨ AI-Augmented Design ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=AG98DTWTVGo,1762715865,These Design Trends Are Going to EXPLODE in 2026,Try Kittl for FREE and start designing today! â†’ https://www.ecomlegendsacademy.com/kittl1 Get 25% OFF with code ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=5NRLoDIuQVg,1762708032,PS 2025 Tutorial HDR 4K | Efecto de Texto Dorado | Photoshop Editing | CC + BP Drop #A380F N.D YT,English (EN): Discover the latest video editing and graphic design trends! From new trending glowing effect video editing to ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=oH0Ec8QSRuQ,1762693313,Suraiya crafts HD. Graphic design trends 2025 . Interior design trends .  Border Designs,Suraiya crafts HD. Graphic design trends 2024 . Interior design trends . Border Designs / Border design for project / Project work ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=aOcdJ76cTZU,1762692560,Dark Humor Design: When Art Gets Laughably Evil,"Explore the fascinating world of dark humor design, where art gets laughably evil and pushes the boundaries of what is ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=qKFueEKRFo8,1762692612,How Can You Predict The Next Big Graphic Design Trend? - Graphic Design Nerd,How Can You Predict The Next Big Graphic Design Trend? Are you curious about how to stay ahead in the ever-evolving world of ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=hMQhOkwW6ZE,1762689997,How Do Graphic Designers Spot Future Trends Early? - Graphic Design Nerd,How Do Graphic Designers Spot Future Trends Early? Are you curious about how graphic designers identify upcoming trends ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=JNSE48h_FeY,1762687907,What Will Be The Next Major Graphic Design Trends? - Graphic Design Nerd,What Will Be The Next Major Graphic Design Trends? Are you curious about what the future of graphic design holds? In this video ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=TDb1UtdoGlc,1762683298,How to make a youtube thumbnail | Graphic design full course | youtube thumbnail banane ka tarika,How to make a youtube thumbnail | Graphic design full course | youtube thumbnail banane ka tarika Background music YouTube ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=oUCxUgKsRY0,1762683305,Photoshop Tips 2026 - Create Debossed Cardboard Effect #skvidz #graphicdesign,"In this video, I break down the top Photoshop tips and tricks ......... Photoshop tips 2026, graphic design trends 2026, Photoshop ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=Zg77tAoI-as,1762682191,Top 5 Digital Marketing and Graphics Design Trends You Can&#39;t Ignore in 2025,"Welcome to my channel! In this video, I'll reveal the Top 5 Digital Marketing and Graphic Design Trends for 2025 that every ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=UOVzV5s_dlU,1762680982,Are Current UI/UX Trends Creating Fundamental Design Shifts? - Graphic Design Nerd,Are Current UI/UX Trends Creating Fundamental Design Shifts? Are you curious about how modern design trends are ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=z5nk7RfccEs,1762677656,What UI/UX Trends Represent Fundamental Shifts In Design? - Graphic Design Nerd,What UI/UX Trends Represent Fundamental Shifts In Design? Are you curious about how modern design is evolving in the digital ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=8QG2I91N6Aw,1762676943,"How Can Graphic Designers Spot Impactful Trends, Not Fads? - Graphic Design Nerd","How Can Graphic Designers Spot Impactful Trends, Not Fads? Are you curious about how graphic designers identify which visual ...",graphic design trends
youtube,,https://www.youtube.com/watch?v=GqyBmyW3WuA,1762676233,How Are UI/UX Design Trends Fundamentally Shifting Today? - Graphic Design Nerd,How Are UI/UX Design Trends Fundamentally Shifting Today? Are you curious about how modern UI and UX design are ...,graphic design trends
youtube,,https://www.youtube.com/watch?v=Q8v5LCSpcp4,1762841048,How to Create Image Overlay in Webflow [2025 Guide],"How to Create Image Overlay in Webflow [2025 Guide] In today's video, we cover webflow tutorial, image overlay, web design tips, ...",web design trends
youtube,,https://www.youtube.com/watch?v=VAB-cvDDje4,1762833846,Emerging trends and future of AI in UI/UX Design,"Welcome to Bagxinet Productions â€“ your hub for UI/UX design tutorials, tips, and creative insights. Learn how to design stunning ...",web design trends
youtube,,https://www.youtube.com/watch?v=VXnI2M5N0Ok,1762822941,Web design trends since 1990 be like,webdesign #y2k #frutigeraero #neubrutalism #memphis #design #digital #wojak #belike #liquidglass Evolution of digital devices ...,web design trends
youtube,,https://www.youtube.com/watch?v=wHlAwXE0BPU,1762755826,How to Create 3D Website Designs Webflow [2025 Guide],"How to Create 3D Website Designs Webflow [2025 Guide] In today's video, we cover 3D website design, Webflow tutorial, website ...",web design trends
youtube,,https://www.youtube.com/watch?v=wG3Sd6WlhYw,1762741850,Unbelievable Liquid Fill Form Animation! ğŸ’§âœ¨ #HTML #CSS #JavaScript #WebDesign #CodingMagic,"Unbelievable Liquid Fill Form Animation using HTML, CSS & JavaScript! This stunning form design flows like real liquid â€” smooth ...",web design trends
youtube,,https://www.youtube.com/watch?v=IXSy6116YQE,1762708752,REST API vs GraphQL Explained in 60 Seconds | Web Development Cheat Sheet 2025,"Confused between REST API and GraphQL? In this short, we break down the key differences between REST and GraphQL ...",web design trends
youtube,,https://www.youtube.com/watch?v=GLBLafoH6Jo,1762659012,WUI Kit Explained in 60 Seconds! ğŸ”¥,"In this video, we'll explore what a UI Kit is and how it helps designers save time and maintain consistency in their projects.",web design trends
youtube,,https://www.youtube.com/watch?v=4D3nC-ISHPI,1762651803,How to Build a Website for Your Business (2025)#viral#freelancing,How to Build a Website for Your Business (2025)#viral#freelancing web design website design web development digital ...,web design trends
youtube,,https://www.youtube.com/watch?v=ke0usk0cvKI,1762529205,ğŸ”¥ Neumorphism Button â€” Soft Shadow UI Design with Pure CSS! | Modern Web Design Trick ğŸ’¡ #shorts,Learn how to create a Neumorphism (Soft UI) button using only HTML & CSS! This clean and minimal soft shadow effect gives ...,web design trends
youtube,,https://www.youtube.com/watch?v=Ttp9GUp6Juw,1762519586,#34 - Webdesign-Trends 2025: Was Solo-SelbststÃ¤ndige wirklich brauchen,"Der Style-Check: Was bringt's, was nervt, was bringt Kunden Auch im Webdesign gibt es jedes Jahr neue Modetrends â€“ aber ...",web design trends
youtube,,https://www.youtube.com/watch?v=nTWY2M6-6sc,1762518666,How to Create Text Masks in Wix (Wix Web Design Tutorial),"In this Wix Web Design Tutorial, I'll show you how to create Text Masks in Wix, a powerful design feature that lets you fill text with ...",web design trends
youtube,,https://www.youtube.com/watch?v=5RIePeOTfaQ,1762490679,"ğŸš€ The future of web design is here - bold, minimal &amp; smarter than ever!","From sleek layouts to intuitive interactions, every detail is crafted to create an unforgettable user experience. Drop a if you're ...",web design trends
youtube,,https://www.youtube.com/watch?v=9HViIP26YU8,1762450273,Why Are Resource-intensive Design Trends Hard To Use? - Graphic Design Nerd,Why Are Resource-intensive Design Trends Hard To Use? Have you ever wondered why some design trends are difficult to ...,web design trends
youtube,,https://www.youtube.com/watch?v=7MNumyS05xM,1762415615,Modern Website Design Inspiration ğŸ”¥ | Smooth UI/UX Scroll Animation Showcase #uidesignlearning,"Discover one of the most beautiful modern website designs â€” clean layout, smooth scroll effects, and stunning color palette!",web design trends
youtube,,https://www.youtube.com/watch?v=-scodGlwN7w,1762414542,2025 Web Design Trends Explained | How Deeva PayOn Leads the Future,"Discover how Deeva PayOn is shaping the future of web design in 2025 â€” from 3D UI and AI integration to fast, SEO-optimized ...",web design trends
youtube,,https://www.youtube.com/watch?v=NBdfB2DjQOs,1762367423,#uiux #uidesignlearning #designtrends #webdesign #food #userexperiencedesign #figma #shortvideo #ui,,web design trends
youtube,,https://www.youtube.com/watch?v=pOYV8tKWYAE,1762345010,Web design company,"Applicontech offers excellent web design services that mainly focus on the creative aspect, the use, and the brand identity.",web design trends
youtube,,https://www.youtube.com/watch?v=FaDaNf7gUkM,1762315266,ĞšĞ°Ğº Ğ²ĞµĞ± Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€Ñƒ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾Ñ…Ğ¾Ğ´ Ñ‡ĞµÑ€ĞµĞ· ÑÑ‚Ğ¸Ğ»ÑŒ #Ğ¼Ğ¾Ğ´Ğ° #ÑÑ‚Ğ¸Ğ»ÑŒ #Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ #ÑÑ‚Ğ¸Ğ»Ğ¸ÑÑ‚,,web design trends
youtube,,https://www.youtube.com/watch?v=HBBiy76tSoU,1762309822,Mind-Blowing 3D Website Design ğŸ”¥ #Shorts,"Discover the future of web design with this stunning 3D website UI! This 3D website animation showcases modern design, smooth ...",web design trends
youtube,,https://www.youtube.com/watch?v=EosHwcJmSiY,1762304421,Dynamic Doodles: The Secret Trends Reshaping 2025 Branding,"An informative look at emerging graphic design trends blending AI, motion, and inclusive branding. Practical tips and real case ...",web design trends
youtube,,https://www.youtube.com/watch?v=EefEeTDRVQ0,1762271364,ğŸŒˆCRAZY Colorful Cursor Effect ğŸ¤¯JavaScript UI Animation Tutorial #coding #trends #shorts #viral,Colorful Cursor Animation using JavaScript ğŸ–±ï¸ This stunning UI trick makes your website feel ALIVE Created with: ...,web design trends
youtube,,https://www.youtube.com/watch?v=4CEmMys0zCI,1762259406,How to create Simple Website Using HTML &amp; CSS |Tutorial  for Beginners | Fast Code,How to create Simple Website Using HTML & CSS |Tutorial for Beginners | Fast Code Content gaps Keywords: - food ordering ...,web design trends
youtube,,https://www.youtube.com/watch?v=nzVYdQJA-Lo,1762229957,Modern E-Commerce Website Design,"In this video, I showcase a modern and clean website design concept created with a focus on minimalism and smooth user ...",web design trends
youtube,,https://www.youtube.com/watch?v=11ixIV656X0,1762186500,New UX/UI Tools You Need to Try! + AI Design Tools,"Today we're looking at some amazing new UX/UI design tools that you must try. These also include some exciting AI design tools, ...",web design trends
youtube,,https://www.youtube.com/watch?v=Dun_NOJrhQg,1762174823,ĞšĞ°Ğº Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ ÑĞ°Ğ¹Ñ‚ Ğ² 2025 Ğ³Ğ¾Ğ´Ñƒ: Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ² Ğ²ĞµĞ±-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğµ,ĞšĞ°Ğº Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ ÑĞ°Ğ¹Ñ‚ Ğ² 2025 Ğ³Ğ¾Ğ´Ñƒ: Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ² Ğ²ĞµĞ±-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğµ ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑˆĞ¸ÑÑŒ Ğ½Ğ° Ğ½Ğ°Ñˆ Ğ¢Ğ“ https://t.me/runoitdesign â€” Ğ·Ğ´ĞµÑÑŒ Ğ¿Ñ€Ğ¾ IT Ğ¸ ...,web design trends
youtube,,https://www.youtube.com/watch?v=NUfwSlAbGJQ,1762779651,Top 5 UI Design Trends You Can&#39;t Ignore in 2025,"Top 5 UI Design Trends You Can't Ignore in 2025 top 5 design trends you can't ignore in 2025, top 5 machine learning trends in ...",typography trends
youtube,,https://www.youtube.com/watch?v=Zg77tAoI-as,1762682191,Top 5 Digital Marketing and Graphics Design Trends You Can&#39;t Ignore in 2025,"Welcome to my channel! ğŸ‘‹ In this video, I'll reveal the Top 5 Digital Marketing and Graphic Design Trends for 2025 that every ...",typography trends
youtube,,https://www.youtube.com/watch?v=ORLtUdliD2I,1762563629,Cutting-Edge Graphic Design Trends 2025 Episode: Tools Tactics and Tales,A visually engaging dive into emerging graphic design trends with practical tips and real-world case studies. Perfect for designers ...,typography trends
youtube,,https://www.youtube.com/watch?v=u8DGyZQIAVA,1762176499,Typography Secrets That Will Transform Your 2026 Designs,"Welcome to the Future of Typography! In this 2.5-hour live workshop, I'll take you deep into modern typography trends that are ...",typography trends
youtube,,https://www.youtube.com/watch?v=uE5GiBWRdXE,1762171320,Top 9 Graphic Design TRENDS in 2026 | You Canâ€™t Miss! Explained in Tamil,"2026-la graphic design world romba fast-a evolve aagudhu ! Intha video-la, naan ungalukku top 9 design trends, tools, solluren ...",typography trends
youtube,,https://www.youtube.com/watch?v=mM51YQY84Q0,1762047833,Which Current Design Trends Should Graphic Designers Know? - Graphic Design Nerd,Which Current Design Trends Should Graphic Designers Know? Are you curious about the latest movements in the world of ...,typography trends
youtube,,https://www.youtube.com/watch?v=X6figa2r7rY,1761436846,Sonic Data: Designing with Sound in Graphic Trends,This episode explores ambient storytelling through data sonification with practical workflows and a real case study. Learn how ...,typography trends
youtube,,https://www.youtube.com/watch?v=xZ7chP3FTHQ,1761372052,Typography Made Easy! | Best Typography Inspiration Website for Designers! | UI/UX &amp; Graphic Design,"Looking for the perfect typography for your next UI/UX or graphic design project? ğŸ¨ In this short, I'm sharing one of the best ...",typography trends
youtube,,https://www.youtube.com/watch?v=TRCjGEwO-pA,1761205120,day 5,Day [5] of the challenge! ğŸ¬ Today's video is all about what's hot and what's not in the world of graphic design. I'm sharing the ...,typography trends
youtube,,https://www.youtube.com/watch?v=XFbbhC7T7b8,1761033112,2026 Design Trends | Design Tips &amp;  Tricks by Pexel Fusion,,typography trends
youtube,,https://www.youtube.com/watch?v=lOn7vq607MA,1760963452,Trends of Typography Part 1,Trends of Typography Part 1.,typography trends
youtube,,https://www.youtube.com/watch?v=YNUgACOjnSU,1760962512,"Design Entrance Exams 2026 Key Trends and Tips for NIFT, NID, and UCEED Aspirants","Are you preparing for NIFT, NID, or UCEED 2026? Discover the top design trends shaping portfolios and exams, from Typography ...",typography trends
youtube,,https://www.youtube.com/watch?v=id4WgA3YpCI,1760961369,"Design Entrance Exams 2026: Key Trends and Tips for NIFT, NID Aspirants","Are you preparing for NIFT, NID, or UCEED 2026? Discover the top design trends shaping portfolios and exams, from Typography ...",typography trends
youtube,,https://www.youtube.com/watch?v=CVMTDqUQBV0,1760792432,The Art of Ransom Note Typography,"Discover the fascinating world of ransom note typography, a unique blend of graphic design and creative fonts that has become a ...",typography trends
youtube,,https://www.youtube.com/watch?v=A9eXPvwtf3o,1760529630,10 Inspiring Brand Style Guide Examples That Actually Work (2025 Design Trends),"Want to make your brand look more consistent, professional, and unforgettable? ğŸ’¡ In this video, we explore 10 real brand style ...",typography trends
youtube,,https://www.youtube.com/watch?v=eSxtfqM6iTw,1760522169,Top 5 Web Design Trends to Follow in 2025 | Future-Ready Websites,Want your website to stand out in 2025? ğŸš€ Here are the top 5 web design trends you can't ignore: 1ï¸âƒ£ Bold typography ...,typography trends
youtube,,https://www.youtube.com/watch?v=OcOQQlfDVsI,1760104843,2026 Graphic Design Trends You Should Know,Check Out Our Trend Report: https://kit.tl/designtrendreport2026 ğŸ‘‡ Kittl Design Templates Shown In The VideoğŸ‘‡ â†ªï¸Naive: ...,typography trends
youtube,,https://www.youtube.com/watch?v=a5OkhdUrWsI,1760054400,Neon Futures: Fresh Frontiers in Graphic Design Trends,"A concise exploration of cutting-edge techniques, tools, and case studies shaping modern graphic design. Practical insights ...",typography trends
youtube,,https://www.youtube.com/watch?v=HR5H3_zFteY,1759708818,PixselPulse Nova Frontiers in Digital Design 2025,"Concise insights on graphic design trends, photography tips, animation techniques, and social storytelling for Instagram and ...",typography trends
youtube,,https://www.youtube.com/watch?v=43rvdglwIs8,1759536007,Tactile Data Typography Live Trends,"Exploring the cutting edge of graphic design through tactile data visualization and live typography. A practical, case study-driven ...",typography trends
youtube,,https://www.youtube.com/watch?v=bbXBNm1h_nI,1759536047,Pixel Pulse Creative Toolkit 2025 Trends and Quick Visual Techniques,A concise rundown of new graphic design trends and practical tips for photography and animation. Includes platform-ready ...,typography trends
youtube,,https://www.youtube.com/watch?v=a91Y6rgW2hk,1759494488,Crafting the Perfect Roofing Logo: Tips and Trends,Recommended Links: Contractor Directory Website: https://www.bighomeprojects.com/ Join the Community: ...,typography trends
youtube,,https://www.youtube.com/watch?v=n4WwqC_VkaY,1759190455,Pulse of 2025 Visual Trends for PixelPulse Creators,"A quick, engaging look at 2025 graphic design trends, photography tips, and animation techniques. It also covers visual ...",typography trends
youtube,,https://www.youtube.com/watch?v=Ubaj7jXhTWQ,1759104036,Pixel Alchemy 2025 Trends for Bold Design and Quick Motion,"Discover five fresh takes on design, photography, animation, and social storytelling with PixelPulse. This short breaks down ...",typography trends
youtube,,https://www.youtube.com/watch?v=VaDokz4Rcdk,1759054682,He Sold Custom Fonts to Designers II Typography Digital Product,"Dive into the fascinating world of typography with our latest video, ""He Sold Custom Fonts to Designers II."" Discover the art and ...",typography trends
