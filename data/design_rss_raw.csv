source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/css-scope-alternative-naming-conventions/,1770278400,CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions,"CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions

Prescriptive class name conventions are no longer enough to keep CSS maintainable in a world of increasingly complex interfaces. Can the new `@scope` rule finally give developers the confidence to write CSS that can keep up with modern front ends?"
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/combobox-vs-multiselect-vs-listbox/,1770112800,Combobox vs. Multiselect vs. Listbox: How To Choose The Right One,"Combobox vs. Multiselect vs. Listbox: How To Choose The Right One

Combobox vs. Multi-Select vs. Listbox vs. Dual Listbox? How they are different, what purpose they serve, and how to choose the right one. Brought to you by <a href=""https://ai-design-patterns.com"">Design Patterns For AI Interfaces</a>, **friendly video courses on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/desktop-wallpaper-calendars-february-2026/,1769850000,"Short Month, Big Ideas (February 2026 Wallpapers Edition)","Short Month, Big Ideas (February 2026 Wallpapers Edition)

Let’s make the most of the shortest month of the year with a new collection of desktop wallpapers that are sure to bring a smile to your face — and maybe spark your creativity, too. All of them were designed with love by the community for the community and can be downloaded for free. Happy February!"
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/practical-use-ai-coding-tools-responsible-developer/,1769778000,Practical Use Of AI Coding Tools For The Responsible Developer,"Practical Use Of AI Coding Tools For The Responsible Developer

AI coding tools like agents can be valuable allies in everyday development work. They help handle time-consuming grunt work, guide you through large legacy codebases, and offer low-risk ways to implement features in previously unfamiliar programming languages. Here are practical, easy-to-apply techniques to help you use these tools to improve your workflow."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/unstacking-css-stacking-contexts/,1769508000,Unstacking CSS Stacking Contexts,"Unstacking CSS Stacking Contexts

In CSS, we can create “stacking contexts” where elements are visually placed one on top of the next in a three-dimensional sense that creates the perception of depth. Stacking contexts are incredibly useful, but they’re also widely misunderstood and often mistakenly created, leading to a slew of layout issues that can be tricky to solve."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking “Pixel Perfect” Web Design,"Rethinking “Pixel Perfect” Web Design

Amit Sheen takes a hard look at the “Pixel Perfect” legacy concept, explaining why it’s failing us and redefining what “perfection” actually looks like in a multi-device, fluid world."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designer’s Career Paths In 2026,"UX And Product Designer’s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI that’s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,Pivoting Your Career Without Starting From Scratch,"Pivoting Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, “Is this still what I want to be doing?” This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as you’re reading this or you’re still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? We’ve got you covered."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,uxdesign.cc,https://uxdesign.cc/the-natural-design-process-a4af7605ab90?source=rss----138adf9c44c---4,1770730885,The natural design process,"The natural design process

<h4><strong>Exploration of the essence of what we do and how we do it</strong></h4><figure><img alt=""Photo of mosaic tile decoration depicting eyes. One of them fully open, the other one partly squinted."" src=""https://cdn-images-1.medium.com/max/1024/0*jTmH4G75uMi1nmp7"" /><figcaption>Photo by <a href=""https://unsplash.com/@jontyson?utm_source=medium&amp;utm_medium=referral"">Jon Tyson</a> on <a href=""https://unsplash.com?utm_source=medium&amp;utm_medium=referral"">Unsplash</a></figcaption></figure><p>It might be a sign of changing of the times and of our industry, it might be a marketing push from the companies betting big on AI. I don’t know. But there seems to be a sort of a urgency for something new. For speed. For freedom. For paving a new path. For simplicity. For flexibility. <strong>A push for something else rather than Design Thinking as the standard design process.</strong></p><p>I am talking about the new wave of <a href=""https://uxdesign.cc/the-return-of-the-intuitive-designer-in-the-age-of-ai-6f0ea728d1d0"">intuitive design</a> and <a href=""https://www.youtube.com/watch?v=4u94juYwLLM&amp;t=864s"">not trusting the design process</a>, of taste and craft as the only ways to do exceptional design, of <a href=""https://x.com/ryolu_/status/2000557301695226265"">jumping straight into code / material</a>. While some parts of those ideas resonate, not all of us are positioned or experienced to do that. Also, processes exist for a reason — usually to make sure we take our users into account, to avoid blindspots, to be sure we are solving the right problem and to meet high bars of quality.</p><p>Before coming across as a big saviour / defender of Design Thinking, I need to come clean: I think we often fall into the trap of wrapping design in bloated processes, frameworks, and mystical terminology, producing unnecessary artefacts and wasting time along the way. And I think that design doing is equally important as the design thinking part.</p><p>So what is my thesis here?</p><p><strong>We need to go back to what’s <em>essential</em> and what’s <em>natural</em>.</strong></p><h4>In pursuit of the essence</h4><p>In my first attempt to shape my perspective, I wrote a think piece on the <a href=""https://medium.com/design-bootcamp/1000-questions-1000-answers-2eeaf01dcb50"">1000 Questions and Answers of design</a>. It’s basically a snapshot of design as I know it and practice, outside of methodologies and tools.</p><p>Even though I believe the article still makes sense, I started questioning my thinking. Can it be simpler? Can it be shorter? Can it be more natural and stripped down to the essence?</p><p>If you strip it down, I started to see the design process as two simple steps:</p><p><strong>&lt;&gt; &lt;&gt; Open your eyes.</strong></p><p><strong>— — Squint your eyes.</strong></p><p>We all do these steps already, with or without realising it. With or without Design Thinking.</p><h4>Huh?</h4><p>Maybe I simplified it way too much. Sometimes I can err in the other direction — making things too abstract.</p><p>This is what I mean:</p><p><strong>Open your eyes to get information. Squint your eyes for focus.</strong></p><p><em>When your eyes are open</em>, you observe. You look around. You absorb. You listen. You think. You notice things you’d otherwise miss — the way people use a product, the frustrations in their tone, something beautiful that inspires a new direction, a design pattern that solves your problem. You are in consuming mode and in a pursuit for new information and perspectives. You are in search for inspiration, references, sparks for your ideas. Along the way, you might become an expert in something and you will start to empathise with your users.</p><p><em>When you squint your eyes</em>, you focus. You tune out the noise and work with what you’ve gathered. You sketch, you build, you make decisions. You bring something into being. You roll up your sleeves and produce with this newfound focus, clarity and intention. The background gets blurry and you just create. Time also gets blurry, you are in the flow and designs materialise.</p><p>That’s how the eyes work. That’s how the mind works — expanding and present when immersed into something new, focused on execution and on auto pilot once having all information. <a href=""https://www.nikon.nl/nl_NL/learn-and-explore/magazine/tips-and-tricks/what-is-aperture?srsltid=AfmBOor-FBxrbfqFoy56R6qsVvcZZDv_3AsIXYyZMh7-_j3SNNo49iFd"">Even cameras work this way </a>— wide open to take in light and to focus all the way up to the horizon in the distance, then tightened up to sharpen focus and capture the detail in front of the lens. It’s the natural way of seeing, thinking, and doing.</p><h4>In practice</h4><p>You can open and squint your eyes as many times as you like to or need to. Just don’t do it at the same time. That’s call winking. Or multitasking. Both are quite useless while designing.</p><p>Here’s an example of how this “process” might work:</p><ol><li><strong>Open your eyes</strong> → absorb, get inspired, ask questions, explore.</li><li><strong>Squint your eyes</strong> → focus, design, make, refine.</li><li><strong>Open again</strong> → test, show, share, watch reactions.</li><li><strong>Squint your eyes</strong> → polish, detail, finalise.</li></ol><p>Repeat until something good emerges. Add activities that you need at the moment.</p><p>At the end, or in between: <strong>fully close your eyes</strong> → <a href=""https://medium.com/design-bootcamp/rest-why-it-is-important-for-designers-66b539a7c5dd"">rest</a>, let ideas simmer, gain distance. Also a natural and essential part of the process.</p><h4>Zoom out</h4><p>Zooming out (or while squinting your eyes) you might see double diamonds in the eye picture above. You might also see the concepts of diverge &amp; converge. Your eyes might be seeing right.</p><p>We might be back to square (or diamond) one. But we are free and back to our nature. We know why we do what we do and do it with confidence. We block out the noise.</p><p>We don’t need to kill the Double Diamond, but we can admit it’s just a dressed-up version of something our brains already know how to do. The danger with process-heavy design thinking is that it can become an end in itself. Design becomes the artefacts <em>about</em> design, rather than the <em>design itself</em>. We need to be careful about that, while respecting and following a <em>natural</em> process, with the necessary steps and activities for our problem and users.</p><p>The next time you’re overthinking your process, just remember: open your eyes, squint your eyes. The rest is abstraction and decoration.</p><p>And don’t forget to fully close your eyes from time to time. The best ideas come after some good rest and distance. Practice it now… closing in 3, 2, 1.</p><p><strong>References and extra resources</strong></p><ul><li><a href=""https://medium.com/design-bootcamp/1000-questions-1000-answers-2eeaf01dcb50"">1000 Questions, 1000 Answers</a></li><li><a href=""https://arnevanoosterom.medium.com/design-thinking-is-dead-again-e48bb1b17b7c"">Design Thinking is dead... again</a></li><li><a href=""https://medium.com/@Tirdad/design-thinking-is-not-dead-but-are-we-extracting-its-full-potential-85342d291bea"">Design thinking is not dead, but are we extracting its full potential?</a></li><li><a href=""https://medium.com/@tufred/design-thinking-is-dead-or-not-d151376ab9ce"">Design Thinking Is Dead. Or Not.</a></li><li><a href=""https://uxdesign.cc/the-return-of-the-intuitive-designer-in-the-age-of-ai-6f0ea728d1d0"">The return of the intuitive designer in the age of AI</a></li></ul><a href=""https://medium.com/media/3df61fc6f744d5cfddcd2da4ac62907e/href"">https://medium.com/media/3df61fc6f744d5cfddcd2da4ac62907e/href</a><p><a href=""https://medium.com/design-bootcamp/rest-why-it-is-important-for-designers-66b539a7c5dd"">Rest: why it is important for designers</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a4af7605ab90"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-natural-design-process-a4af7605ab90"">The natural design process</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/embrace-the-mess-how-to-tell-honest-ux-stories-that-help-you-grow-df666212cb91?source=rss----138adf9c44c---4,1770722814,Embrace the mess: how to tell honest UX stories that help you grow,"Embrace the mess: how to tell honest UX stories that help you grow

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/embrace-the-mess-how-to-tell-honest-ux-stories-that-help-you-grow-df666212cb91?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/640/1*oSdn3l4h9CStnmWOY__vog.jpeg"" width=""640"" /></a></p><p class=""medium-feed-snippet"">How trying to hide the mess of design projects caps your career</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/embrace-the-mess-how-to-tell-honest-ux-stories-that-help-you-grow-df666212cb91?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/useful-ads-7899e1711157?source=rss----138adf9c44c---4,1770722612,Designing useful ads,"Designing useful ads

<h4>Redefining the relationship between AI utility and digital advertising.</h4><figure><img alt=""Black-and-white banner image with the words ‘Useful ads’ on the left and a bright roadside billboard on the right. The billboard text reads, ‘Driver in the red Camry: your left headlight is out. Take Exit 12 for Redline Autoshop, typical fix for $75–$120,’ illustrating a hyper‑contextual, genuinely helpful advertisement."" src=""https://cdn-images-1.medium.com/max/1024/1*gKGVP8mqh_cBzjUa7PsXzQ.jpeg"" /><figcaption>(AI disclaimer: billboard asset produced with AI assistance; the billboard copy, and rest of the banner are my own design) Banner for “Useful Ads,” showing a nighttime billboard warning a specific driver about a broken headlight and pointing them to nearby repair shops.</figcaption></figure><p><strong>AI usage disclaimer</strong>: <em>AI tools were used for editing visual assets, writing feedback, assistance in locating relevant sources, &amp; Chicago-style citation formatting; all early drafts, ideas, arguments, &amp; experiences in this article are my own.</em></p><h4>Taxing advertising</h4><p>I have a good friend &amp; mentor at work, and we’ve been exploring new AI trends in tech and design. He brought up the news that OpenAI recently announced that it would begin testing ads in the free and Go tiers of ChatGPT in the U.S., with the promises that ads will be clearly labeled &amp; won’t influence answers.¹ ² We’ve both fought against needless promotional content before and lamented that frontier AI platforms are falling into the same pattern. As designers and users, we’ve learned that “free” usually means putting up with interruptive, slightly creepy ads that feel more like a tax than a benefit — a frustration tax that now colors how we approach free‑tier services and now AI tools. However, we started chatting through it a bit more, and explored whether there might actually be some good that can come out of it.</p><p>While advertisements in free services like ChatGPT risk frustrating users &amp; harming brand trust, frontier AI models have a unique opportunity to replace the traditional “Sponsored” tag with promotional features that genuinely enhance the utility of threads &amp; responses instead of undermining them. Before exploring how digital ads might actually do this, I want to briefly revisit how ads evolved on TV and YouTube, then look at the unique opportunities frontier AI platforms have, and finally ground it in a simple electrician problem to show how ads could enhance an AI chat thread.</p><h4>New platform, same commercial</h4><p>Billboards, cable TV commercials, and radio ads typically felt like a jarring distraction — pulling me out of driving, the show I was watching, or the song I was listening to. Further, the commercials themselves were usually irrelevant to whatever I was interested in. But since there was less focused demographic targeting on TV, aside from specific channels that entertained a certain subject like <em>Comedy Central</em>, Nickelodeon, TV Land, etc., it made sense that you would see a wide variety of advertisements ranging from uplifting prescription drug commercials to wacky toy ads for kids. And I remember when I started seeing that same pattern begin on YouTube videos and feeling frustrated by that since it just felt like TV commercials were coming to this new platform.</p><p>YouTube used to feel like a ‘free expression’ platform for anyone &amp; everyone to make videos on the internet. It gave people the means to show off talented, creative, weird, strange, hilarious, and odd content that we used to expect from YouTube and the TV shows that would curate its content like <em>Tosh.0</em> or <em>Ridiculousness</em>. Even though ads came onto the scene just a year later, YouTube’s CEO Chad Hurley put his ad approach this way:</p><blockquote>We think there are better ways for people to engage with brands than forcing them to watch a commercial before seeing content. You could ask anyone on the net if they enjoy that experience and they’d probably say no. <br /> — <em>Chad Hurley ³</em></blockquote><p>But when YouTube was acquired by Google, ads started to function like commercials on TV by the end of 2007, and at first they were annoying, but at least they were short, skippable, and rarely shown.⁴ Today, however, ads can last over 90 seconds if the user allows it, run multiple ads in basically what is a <em>de facto</em> commercial break, and not all ads offer the option to skip until the timer cools down.</p><p>But YouTube ads felt more targeted, which was both helpful and creepy at times. If I started watching skateboarding videos, I might see advertisements for things skaters are interested in (e.g., skate decks, certain clothing brands, <em>X Games</em> announcements, and so on). With data sharing, I’d start seeing ads based on things I searched for online or just after I made an online purchase for a similar item — the latter of which always felt odd to me since I already bought it. Still, it was better in a sense and more dialed in to relevant audiences than traditional TV or radio commercials.</p><p>All of this has taught us to expect that “free‑tier” experience means interruptive, slightly creepy, and rarely on our terms. That’s the mental model users will bring to free‑tier plans with ads in AI tools, and it functions like a frustration tax: “free” feels less like a gift and more like a tax you pay in attention. The opportunity for frontier AI is to break that pattern by making promotional content feel like a feature that even paid‑tier accounts may want to keep, so paid plans can focus on adding capabilities rather than simply removing frustration taxes.</p><h4>Strengths of the AI pioneer</h4><p>Shifting over to ChatGPT and other frontier AI platforms, the obvious risk is that ads will simply adopt the same look and feel they have on search engines — those “sponsored” results at the top of the page — but these tools are capable of much more than that. While I don’t have the exact data in front of me, I often wonder how frequently people scroll past those sponsored results to reach the first “organic” link and how often accidental clicks leave them feeling misled instead of helped. One recent roundup of digital ad research found that around 86% of users report banner blindness (effectively ignoring banner‑like advertising) and that average banner engagement rates hover around 0.06%.⁵</p><p>If frontier AI platforms adopt a similar pattern, I imagine the analytics data won’t change much. However, these platforms aren’t doing the same things as search engines are either — they do a lot more, obviously. They’re great at synthesizing content from a variety of sources based on the content of the user’s prompt. And they’re quickly doing more and more. For instance, I’m continuously impressed with Perplexity’s updates and new features it adds.</p><p>Advertisements can also be better with AI platforms. If search engines, YouTube, and other digital platforms can have more relevant ads just based on the search query, content of the video, or knowing the target audience, they can do all the more with a user’s prompt &amp; chat thread. Even a basic prompt contains far more data than a general search query, and users are far more likely to write in natural language to AI platforms than to traditional search boxes. This can include nuanced details, context, and specificity that wasn’t as easy to do with a search engine — even with advanced search tools. Further, users no longer have to necessarily scan through each webpage result in a response to figure out what’s relevant to what they’re looking for. Whether or not they ought to is another question, but the sources in the response are very likely to be on topic with the prompt anyway.</p><h4>Discovering marketed electricity</h4><p>A month or so ago, several outlets in our kitchen stopped working after a GFCI outlet tripped, and a quick do-it-yourself (DIY) attempt led to a small spark behind the outlet. At that point, the problem moved from “easy DIY project” to “I need a professional who won’t overcharge me or cut corners. So imagine I turn to an AI assistant and type something like:</p><blockquote>I have three outlets that went out in our kitchen. I replaced a GFCI outlet, but when I pulled it back out to check the wiring I saw a small spark behind the outlet. I’m comfortable with basic DIY, but I don’t want to risk an electrical fire or make the problem worse. I’m looking for an electrician near me who is thorough, is transparent about pricing, and won’t pressure me into unnecessary work. Give me a few options and explain which one you’d choose for this situation.</blockquote><p>This is a perfect example of the kind of urgent, high‑anxiety scenarios where ads could either quietly undermine trust — or actually help. In the rest of this section, I’m treating my electrical experience as a small test case for this idea: what happens if we replace a thin “sponsored” tag with richer promotional features like coupons, adjacent follow-up content, even a contextual panel that doesn’t distract from the main thread so much?</p><p>So, how might ads be smartly introduced from a prompt like this? Well, maybe there are a few ways. First, imagine a fairly conventional AI response: a ranked list of three electricians with one of them labeled “Sponsored.”</p><figure><img alt=""Screenshot mock of an AI chat response listing three electricians in a vertical comparison, with one option marked by a small ‘Sponsored’ tag, illustrating the default search-style ad pattern."" src=""https://cdn-images-1.medium.com/max/792/1*XRKhqWoRxsWNgaDi0cu_HA.png"" /><figcaption>Conventional AI response: a comparison list of electricians with a tiny “Sponsored” tag.</figcaption></figure><p>This is the default pattern we’ve inherited from search: a solid comparison list with a tiny “Sponsored” tag bolted onto one option. It technically discloses the ad, but it also quietly introduces doubt for the whole recommendation about whether you’re getting the best fit or just the company with the highest advertising budget.</p><p>In my actual experience, my AI chat included a local map view with some content cards for each electrical company in my area. So let’s take that card UI and use it as our starting point and ask a few ‘what ifs’:</p><ul><li>What if the ‘sponsored’ card showed the typical cost of the exact service I need, based on what other customers actually paid?</li><li>What if there were coupons, discounts, or perks that directly benefit me if I contact a particular company?</li><li>What if some of the “ads” weren’t just more electricians, but alternative routes like payment plans or DIY tutorials?</li></ul><p>Now compare that conventional response to one that uses smartly integrated ads: the same electrician options, but with richer promotional features and a contextual panel that lives alongside the main thread instead of inside it.</p><figure><img alt=""Mock AI response showing three electrician cards side by side, each with price, reviews, a short description, and buttons for actions like ‘Read reviews’ and ‘Compare GFCI troubleshooting costs,’ illustrating a richer sponsored card layout."" src=""https://cdn-images-1.medium.com/max/792/1*Q9WcYea2yv8d2gceOu2M6w.png"" /><figcaption>Smartly integrated ad cards with costs, perks, and follow‑up CTAs.</figcaption></figure><p>Under the hood, this card layout is doing a few specific things. First, I kept the familiar basics — company name, review rating, a link to the website, a call-to-action (CTA) to get in touch, and a short description. Second, it uses information grouping: cost, reviews, and perks live together inside each card, so you don’t have to mentally stitch them across the interface.</p><figure><img alt=""Close-up of a single electrician card showing company name, star rating, description, price, cost explanation, and action buttons stacked together, demonstrating information grouping within the card."" src=""https://cdn-images-1.medium.com/max/1024/1*4f2VaxhBFG_jZ60QMbJ-cA.png"" /><figcaption>Electrician card layout with grouped details for one company.</figcaption></figure><p>Where it begins to differ is in the cost row: instead of a vague price range, the card shows the average amount customers actually reported paying for the specific service I’m asking about, plus a link to the reviews that generated that cost amount. That turns the “ad” element into a concrete expectation‑setting tool, not just a badge.</p><figure><img alt=""Zoomed-in view of the price section on an electrician card, with a bold dollar amount and a line explaining that the cost is based on similar customer reviews, plus a link to detailed reviews."" src=""https://cdn-images-1.medium.com/max/1024/1*_Mi_H53mh0PEXi-WeGfj2g.png"" /><figcaption>Cost row highlighting typical customer‑reported price and linked reviews.</figcaption></figure><p>There’s also a clearly labeled coupon or perk add‑on that directly benefits the user as a form of promotional content, much like scouting through <em>RetailMeNot</em> or <em>Groupon</em> for a promo code to paste in at checkout, except the value is surfaced in context, before you ever hit a checkout page.</p><figure><img alt=""Zoomed-in view of an electrician card showing a ‘Free inspection coupon’ badge next to the action buttons, representing a user-benefiting promotional perk embedded in the card."" src=""https://cdn-images-1.medium.com/max/1024/1*z1ZPnOWDHTT6AuaSTSmwQg.png"" /><figcaption>Sponsored perk: a clearly labeled coupon for a free inspection.</figcaption></figure><p>Last, it strengthens information scent by labeling actions in the user’s own language (“Reliable DIY tutorials,” “Electricians with payment plans,” etc.) instead of generic ad copy, which makes them feel like relevant next steps rather than distractions. Together, these tweaks improve the overall signal‑to‑noise ratio by making sure every sponsored element either clarifies trade‑offs or opens a concrete, optional path you might actually want to take.</p><figure><img alt=""Mock of three pill-shaped buttons beneath the main electrician recommendation labeled ‘Compare GFCI troubleshooting costs,’ ‘Electricians with payment plans,’ and ‘Reliable DIY tutorials,’ showing opt‑in sub‑search routes."" src=""https://cdn-images-1.medium.com/max/1024/1*-joPf8gZZKPSZrqVr_lEZA.png"" /><figcaption>Optional CTAs launching focused sub‑threads for costs, payment plans, and DIY.</figcaption></figure><p>Each predetermined CTA launches a focused sub‑thread where the AI can surface related content or even sponsored resources, without hijacking the main answer. This is where the “smartly integrated ads” pattern really shows up: the promotion lives in a side‑path you choose, rather than inside the core explanation you came for.</p><figure><img alt=""AI response displaying a list of DIY electrical resources — video, article, and blog cards — with short descriptions and ‘Add to thread’ or ‘Watch now’ buttons, illustrating a sponsored side-thread of helpful content."" src=""https://cdn-images-1.medium.com/max/1024/1*E2x93DDHTJNlP9iG5Oz00A.png"" /><figcaption>DIY tutorial thread with sponsored videos, articles, and blogs the user can add to the chat.</figcaption></figure><p>For the overall layout, all of this can be contained in a contextual, right‑aligned panel that fights banner blindness by keeping the promotional content inside a clearly related, text‑heavy space rather than in a noisy strip at the margins. It’s still clearly promotional, but it behaves like a helpful feature stitched to your thread instead of a banner shouting from the edge of the screen and avoids the frustration tax of random, off-topic ads.</p><figure><img alt=""Full-page mockup of an AI chat interface with the conversation on the left and a right-aligned ‘Thread insights’ panel on the right containing electrician cards, costs, and action buttons, demonstrating a dedicated ad space that updates with the thread."" src=""https://cdn-images-1.medium.com/max/1024/1*szASXnWFl8Jdcd3XRWak1w.jpeg"" /><figcaption>Contextual right‑hand panel showing electrician cards and insights alongside the main thread.</figcaption></figure><p>Cards like these are probably the “maximal” version for a high‑stakes case, but even one or two of these ideas would give users a real sense of reciprocity and incentive to interact with the advertised picks. Companies willing to pay for ad space could compromise by allowing more transparency — e.g., showing the specific average amount customers paid, offering concrete perks and coupons, or sponsoring alternative routes like clearly labeled DIY content that gives the user more autonomy.</p><p>Compared to the tiny “Sponsored” tag next to <em>BrightSpark Electrical</em> in the earlier version, this card makes the advertising work much more in my favor. The promoted content is still an ad, but it’s wrapped in concrete information about cost, clear perks, and optional side paths that match my concerns, all reusing the same thoughtful pattern instead of casting doubt on the recommended services. That makes it more likely I’ll actually engage with it, instead of scrolling past it as just another banner or quietly wondering if the whole recommendation is spurious.</p><h4>Mapping out the new frontier</h4><p>Free‑tier AI platforms with ads don’t have to inherit the same frustration tax we’ve learned from YouTube commercials and sponsored search results. The electrician example is small, but it shows how promotional content can be reshaped into something that actually helps in a stressful, high‑stakes moment instead of quietly eroding trust.</p><p>Structurally, the move is simple: treat ads as enhancing features, not just paid recommendations. Smartly integrated cards, natural sub‑thread CTAs, and contextual panels give advertised content visibility while adhering to good principles like information grouping, strengthening information scent, and protecting the signal‑to‑noise ratio of the thread — which in turn counters banner blindness rather than fighting against it. At their best, these patterns also line up with the TRAP virtues I’ve argued for elsewhere: they make sponsorship transparent, offer real reciprocity in the form of perks and clearer information, and preserve user autonomy by keeping every sponsored path optional.⁶</p><p>As more frontier AI platforms roll out free‑tier advertising, the real question isn’t whether to show ads at all, but which patterns we normalize. Do we copy the flimsy “Sponsored” tag and hope users still engage with it, or invest in ad experiences that users would actually miss if we took them away? If you work on these products — as a designer, PM, or engineer — now is the moment to decide which pattern AI platforms ship.</p><h3>References</h3><p>[1] Simo, Fidji. “Our Approach to Advertising and Expanding Access to ChatGPT.” <em>OpenAI</em>. January 16, 2026. <a href=""https://openai.com/index/our-approach-to-advertising-and-expanding-access"">https://openai.com/index/our-approach-to-advertising-and-expanding-access</a>.​</p><p>[2] Capoot, Ashley. “OpenAI to Begin Testing Ads on ChatGPT in the U.S.” <em>CNBC</em>, January 16, 2026. <a href=""https://www.cnbc.com/2026/01/16/open-ai-chatgpt-ads-us.html"">https://www.cnbc.com/2026/01/16/open-ai-chatgpt-ads-us.html</a>.</p><p>[3] QQTube (Terri Pinyerd). “When Did YouTube Start Ads? | A History of Video Advertising.” <em>QQTube Blog</em>, October 6, 2025. Accessed February 9, 2026. <a href=""https://www.qqtube.com/blog/when-did-youtube-start-ads"">https://www.qqtube.com/blog/when-did-youtube-start-ads</a>.</p><p>[4] Holmes, Gareth. “A Brief History of Video Advertising.” <em>New Digital Age</em>, 2026. <a href=""https://newdigitalage.co/technology/a-brief-history-of-video-advertising"">https://newdigitalage.co/technology/a-brief-history-of-video-advertising</a>.</p><p>[5] GrowthSRC Team. “Banner Blindness Statistics &amp; Studies You Need to Know in 2025.” <em>GrowthSRC</em>. Last modified 2026. <a href=""https://growthsrc.com/banner-blindness-statistics-studies"">https://growthsrc.com/banner-blindness-statistics-studies</a>.</p><p>[6] Walsh, Tanner. “Eudaimonistic-Centered Design: The Virtues of UX.” <em>UX Collective</em> (Medium). February 16, 2022. <a href=""https://medium.com/user-experience-design-1/eudaimonistic-centered-design-92b69654ee25"">https://medium.com/user-experience-design-1/eudaimonistic-centered-design-92b69654ee25</a>.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7899e1711157"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/useful-ads-7899e1711157"">Designing useful ads</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/can-you-run-out-of-creativity-64b47fe76af0?source=rss----138adf9c44c---4,1770722594,Can you run out of creativity?,"Can you run out of creativity?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/can-you-run-out-of-creativity-64b47fe76af0?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1536/1*jeqiwA1Kf1GSNAKF6DlapQ.png"" width=""1536"" /></a></p><p class=""medium-feed-snippet"">There&#x2019;s a particular kind of panic that hits when you&#x2019;re facing a creative problem, and the well just feels&#x2026; empty. Every idea seems stale&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/can-you-run-out-of-creativity-64b47fe76af0?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/what-design-leaders-must-unlearn-to-lead-in-an-ai-first-world-f131652f828d?source=rss----138adf9c44c---4,1770722577,What design leaders must unlearn to lead in an AI-first world,"What design leaders must unlearn to lead in an AI-first world

<h4>The path to designing for AI is in questioning the fundamentals of what design stands for</h4><figure><img alt=""A designer shedding the past design artifacts and embracing the future of emerging tech"" src=""https://cdn-images-1.medium.com/max/1020/1*LE0BFPSuq6HxhmN7zt2pAQ.png"" /><figcaption>Image Credit: AI Generated Image</figcaption></figure><p>I admire artists and industrial designers who challenge assumptions. Ross Lovegrove is one of them. If you’ve never heard of him, he is one of the most visionary creators in the world, and designs all sorts of devices, including door handles, computers, fragrance bottles, and concept cars.</p><p><a href=""https://www.wallpaper.com/design-interiors/ross-lovegrove-on-working-with-ai""><strong>In an article in the popular design magazine Wallpaper</strong></a>, he claims that the potential of working with AI is utopian. That says a lot coming from someone considered by many as a futurist.</p><p>Lovegrove admits that most people in his generation, including design leaders, are skeptical of AI’s use in design. He doesn’t belong to that group, as he says that “AI is complementary, like having a conversation with a very intelligent friend.” He even built a Carrara marble sculpture in collaboration with a robot!</p><p>After reading Lovegrove’s take on AI, I asked myself: Are design leaders prepared for this new AI era? Or, more precisely, what do they need to unlearn to stay relevant and lead their teams in a world where AI is reshaping how we create?</p><p>Here’s what I’m unlearning, and what I think other design leaders should consider letting go of too.</p><h4>#1. “AI enablement is (just) a tooling decision”</h4><figure><img alt=""Chart showing AI code-generation success rates for novices and experts. Novices show 79% success, while experts show 90% success. Purple represents success and orange represents failure, displayed over a background of a person viewing multiple computer screens."" src=""https://cdn-images-1.medium.com/max/1024/1*_B-jLlsLe5dcH5q-4u4JYg.png"" /></figure><p>This might be a hard pill to swallow for some design leaders and any business leaders in general.</p><p>Before we entered what we now call an AI-first world, AI felt like a frontier that was approaching slowly. Leaders could afford to experiment, pilot a few tools, let teams test them out, see what stuck… It was like a free buffet where everyone could try the new shiny thing without much risk.</p><p>The problem now is how your team uses it, because the consequences of this free-for-all approach can be the opposite of what you expect: AI tools expose the talent gap in your team.</p><p>A 2025 study titled<strong><em> </em></strong><a href=""https://arxiv.org/html/2509.21890v1""><strong>Not Everyone Wins with LLMs: Behavioral Patterns and Pedagogical Implications in AI-assisted Data Analysis</strong></a>, sheds some light on this. In it, researchers tracked 36 students as they used an LLM to complete programming and data analysis tasks. Everyone had equal access to the same AI tools.</p><p>The study found that students with strong data &amp; coding foundations used AI to extend their thinking, explore alternatives, and debug more quickly. Those with weaker fundamentals often copy pasted outputs, misread results, or got overwhelmed by verbose explanations.</p><p>Now extrapolate this to your design team. If you just democratize the use of AI without paying attention to core fundamentals like systems thinking, experimentation, and evaluating AI output, your best performers will become even better at their craft, but junior designers may fall behind and become too dependent on AI.</p><p>Choosing the right tools is still and will remain relevant for years to come, but it’s equally important to build capability from the ground up so your team can use AI to extend their thinking. Today, AI enablement is a talent strategy decision.</p><h4>#2. “Designers (only) design interfaces, researchers (only) provide insights”</h4><p>There was a time when a designer had a very specific role, and so did researchers. And it was easy to assign them tasks, goals, and projects because everything worked like a well-oiled machine.</p><p>AI has changed the way we box these positions in. Can we already say we are on the verge of seeing more hybrid roles in design teams? J.M. Downey, Director of Design Strategy &amp; Research at AT&amp;T, thinks so.</p><p>Downey is one of the design leadership voices interviewed in the 2025 report<strong> </strong><a href=""https://cdn.prod.website-files.com/65b848447e935c9f1f8e6ec5/68357bcd7d7740446815dbba_The%20AI%20Shift.pdf""><strong>The AI Shift: Transforming How We Discover, Imagine, and Design</strong></a>, conducted by the Design Executive Council (DXC). He sees his team as design strategists as much as he sees them as researchers. “That’s the future of this discipline,” he claims.</p><p>Most leaders interviewed for DXC’s report agreed that the old boundaries between design and research no longer work. For example, Dave Brown, who leads design for AI services at Amazon Web Services, says, “Design and research now need to look across the whole stack.” He’s talking about understanding how data flows, how models make decisions, and how those decisions show up in the user experience.</p><p>My perspective aligns with what they all say. Design leaders must adapt to what’s coming and upskill their teams for new challenges. Your designer needs to understand what the AI is optimizing for, why it’s making certain recommendations, and how to design friction when users need transparency or control. Your researcher can’t just deliver insights and walk away. They need to shape how those insights get embedded into product decisions, AI training, and business strategy.</p><p>An AI-first world demands strategic builders. Your team needs them, starting with yourself.</p><h4>#3. “Polish, craft, and aesthetics are what make design good”</h4><figure><img alt=""Statistics showing 52% of respondents believe design is more important in AI-powered products than in traditional digital products, displayed over a background of a person sketching an interface on a tablet."" src=""https://cdn-images-1.medium.com/max/1024/1*cENQNgrjZtPySAfi9nmTKQ.png"" /></figure><p>When you read this headline, it might sound like an oversimplification. I’m not arguing that design leaders have ever cared only about how a product looks, but I do include myself among those who have, at times, over-indexed on polished prototypes, pixel-perfect interfaces, and visual refinement as proxies for quality.</p><p>In AI-powered products, that definition of quality isn’t enough. Designing with AI introduces additional layers of responsibility and complexity. Beyond aesthetics and usability, which remain essential, quality now also includes:</p><ul><li><strong>Trust:</strong> Can users rely on the system’s outputs over time?</li><li><strong>Transparency:</strong> Do users understand why the system made a recommendation or took an action?</li><li><strong>Graceful degradation:</strong> Does the product communicate uncertainty and fail safely when it doesn’t know something, rather than confidently producing wrong results?</li></ul><p>In this context, a visually polished interface can mask deeper issues: unreliable outputs, opaque decision-making, brittle behavior at the edges… Design leaders must therefore stop measuring quality just by surface-level polish and instead treat trust, clarity, and reliability as first-class design outcomes.</p><p>According to <a href=""https://cdn.sanity.io/files/599r6htc/regionalized/d4e0b1140b4d4d32c004e442bdb3e9f136fd3657.pdf""><strong>Figma’s 2025 AI Report</strong></a>, more than half of designers and AI builders believe design has become more important for AI-powered products, precisely because users now depend on design to interpret, evaluate, and trust intelligent systems.</p><p>For the design leaders of the future, great design will be defined by how confidently users can understand a system and rely on it in real-world conditions.</p><h4>#4. “Speed equals progress”</h4><figure><img alt=""Statistic showing 89% of designers say AI has improved their workflow, displayed over a background of a computer screen with AI interface windows and connected data elements."" src=""https://cdn-images-1.medium.com/max/1024/1*HXZAT1UYCqpYw8qJ-Tq4Rg.png"" /></figure><p>I’ve heard many times in my career things like “moving faster is always the right move” or “if we ship faster, we win.” Well, these assumptions may be wrong today. Although I agree that for certain companies, especially startups, speed is a virtue, for the most part, we should stay vigilant when hearing such claims.</p><p>There’s one thing we all love about AI: it makes us faster. It can accelerate good work, there’s no doubt about it, but it can also accelerate mistakes. I recently read an article in <a href=""https://www.cio.com/article/4076280/why-ai-initiatives-fail-the-costly-mistakes-it-leaders-make-and-how-you-can-avoid-them.html""><strong>CIO magazine</strong></a> on why AI initiatives fail, and one of the reasons mentioned was, indeed, ‘rushed pilots.’</p><p>Often, when pressured by stakeholders, business leaders may feel the need to deploy products without clear goals or proper processes, just to release them as quickly as possible. And design teams fall into the trap, mistaking speed and novelty for progress.</p><p>As per the <a href=""https://www.stateofaidesign.com/""><strong>State of AI in Design Report 2025</strong></a>, 89% of designers say AI has improved their workflow in some way. Your team may already be benefiting from this. They are more productive, and you get tangible results. Everything works faster, and everyone’s celebrating that. But is the work truly <em>better</em>?</p><p>The best design leaders know when to slow down, validate, and ensure that what they’re building is worth shipping.</p><h4>Closing thoughts</h4><p>One day, not too far away, we won’t talk about an “AI-first world”, just <em>our </em>world, much like we no longer say we’re in an “Internet-driven world”. AI will be embedded in everything, just as the internet is now.</p><p>Until then, design leaders have time to build and, apologies for the redundancy, ‘design’ this new reality. That means unlearning some of the universal truths we all took as sacred, as set in stone.</p><p><strong><em>Want to see how we’re putting these principles into practice? Explore SAP’s approach to human-centered design at </em></strong><a href=""https://www.sap.com/design""><strong><em>www.sap.com/design.</em></strong></a></p><p><a href=""https://www.linkedin.com/in/arinb""><em>Arin Bhowmick</em></a><em> (</em><a href=""https://twitter.com/arinbhowmick""><em>@arinbhowmick</em></a><em>) is Chief Design Officer at SAP, based in San Francisco, California. The above article is personal and does not necessarily represent SAP’s positions, strategies or opinions.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f131652f828d"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/what-design-leaders-must-unlearn-to-lead-in-an-ai-first-world-f131652f828d"">What design leaders must unlearn to lead in an AI-first world</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/intuitive-designer-ai-delegation-matrix-the-new-ux-toolkit-2f2edb0e10a1?source=rss----138adf9c44c---4,1770640855,"Intuitive designer, AI delegation matrix, the new UX toolkit","Intuitive designer, AI delegation matrix, the new UX toolkit

<h4><em>Weekly curated resources for designers — thinkers and makers.</em></h4><figure><a href=""https://uxdesign.cc/the-return-of-the-intuitive-designer-in-the-age-of-ai-6f0ea728d1d0""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*3XdPzKwms1TNiRYv.png"" /></a></figure><p>“You likely know, or at the very least know of, a designer who just gets it. I’m talking about the designer who solves complex problems with elegant, user-centered, buildable solutions without breaking a sweat. Or maybe that designer who turns everything they touch into something genuinely beautiful. Or even the one who gets up on a stage and says what we’re all thinking more clearly and eloquently than we can. Maybe all three. Love or irrationally hate them, there they are, making the things that you struggle with daily look easy. You look skyward and wonder, What is it they have that I don’t?”</p><p><a href=""https://uxdesign.cc/the-return-of-the-intuitive-designer-in-the-age-of-ai-6f0ea728d1d0""><strong>The return of the intuitive designer in the age of AI</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/356e883b7572"">James Harrison</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/design-careers-in-the-age-of-ai-specialize-or-generalize-b99e0f573f2b""><strong>Specialize or generalize?</strong></a><strong> →</strong><br />Design careers in the age of AI.<br />By <a href=""https://medium.com/u/26e889d3b8a9"">Matheus Cervo</a></li><li><a href=""https://uxdesign.cc/why-your-brain-rebels-against-redesigns-even-good-ones-263a75915c86""><strong>Why your brain rebels against redesigns</strong></a><strong> →</strong><br />The redesign tested well. Users hate it anyway.<br />By <a href=""https://medium.com/u/3c3654a6ac8"">Dora Cee</a></li><li><a href=""https://uxdesign.cc/the-safest-decision-is-rarely-the-right-one-a07360337dd8""><strong>The safest decision is rarely the right one</strong></a><strong> →</strong><br />Trusting judgement without ignoring evidence.<br />By <a href=""https://medium.com/u/698547972de4"">Simon Mauro Guido</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about their work.</em></p><figure><a href=""https://alttextselfies.net/welcome/""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*8loy1sov00STk2QI.png"" /></a></figure><p><a href=""https://alttextselfies.net/welcome/""><strong>Alt text selfies</strong></a><strong> →</strong></p><h3>Make me think</h3><ul><li><a href=""https://unsung.aresluna.org/how-to-shoot-a-screen-using-a-board-of-keys/?ref=sidebar""><strong>How to shoot a screen using a board of keys</strong></a><strong> →</strong><br />“Everybody who routinely takes screenshots on a Mac knows very well the motor memory heaven and hell that are the screenshotting shortcuts: ⌘⇧3 to grab the whole screen, ⌘⇧4 to grab part of it, hold ⌃ ahead of time to put the result in the clipboard, press space at the right moment to select a window, hold ⌥ at a different time to remove a shadow, and so on. (Yes, there’s more.)”</li><li><a href=""https://peterboeckel.com/writing/displacementofpurpose?ref=sidebar""><strong>The displacement of purpose</strong></a><strong> →</strong><br />“When work begins to vanish, what disappears first is not income — it is rhythm. The small rituals that gave shape to a day — waking, commuting, exchanging fragments of conversation — are not merely logistical. They are choreography, a social heartbeat that affirms one’s current place in the collective. Even unfulfilling work provides orientation; it punctuates time.”</li><li><a href=""https://terriblesoftware.org/2026/02/02/why-am-i-doing-the-thinking-for-you/?ref=sidebar""><strong>Why am I doing the thinking for you?</strong></a><strong> →</strong><br />“I got a Slack message the other week, just “What do you think?” with a link to a Notion document. No context or indication of what this person actually believed. Just a link and a question mark. I stared at it for a minute, trying to decide if I was annoyed or just tired (both, probably). What’s this message is actually saying is: “I haven’t figured this out yet and I’d like you to do the thinking for me.”</li></ul><h3>Little gems this week</h3><figure><a href=""https://uxdesign.cc/lost-for-words-why-text-in-ai-images-still-goes-wrong-b5232c39bd11""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*YiQo4_c6dDzbbh1E.png"" /></a></figure><p><a href=""https://uxdesign.cc/lost-for-words-why-text-in-ai-images-still-goes-wrong-b5232c39bd11""><strong>Lost for words: why text in AI images still goes wrong</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/3c3654a6ac8"">Dora Cee</a></p><figure><a href=""https://uxdesign.cc/nothing-is-certain-not-even-the-right-design-process-f323bb2d426b?sk=ed6cb7c589dba9968041590e3fca01b9""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*oojH2yEWpG8UlYFJ.png"" /></a></figure><p><a href=""https://uxdesign.cc/nothing-is-certain-not-even-the-right-design-process-f323bb2d426b?sk=ed6cb7c589dba9968041590e3fca01b9""><strong>Nothing is certain — not even the “right” design process</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/af434fd67626"">Ian Batterbee</a></p><figure><a href=""https://uxdesign.cc/the-art-of-unnecessary-story-45c9c7ccfdb4?sk=7061f87e43912ae12ed6562b038649b1""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*knbCPNScD8JluQKB.png"" /></a></figure><p><a href=""https://uxdesign.cc/the-art-of-unnecessary-story-45c9c7ccfdb4?sk=7061f87e43912ae12ed6562b038649b1""><strong>The art of unnecessary story</strong></a> →<br />By <a href=""https://medium.com/u/b95d4ccb538e"">Rita Kind-Envy</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/the-new-ux-toolkit-data-context-and-evals-9bd09fea466d""><strong>The new UX Toolkit</strong></a><strong> →</strong><br />Data, context, and evals.<br />By <a href=""https://medium.com/u/d66c8bb38139"">Paz Perez</a></li><li><a href=""https://uxdesign.cc/test-smart-how-to-solve-dilemmas-as-qa-29673df6c51b""><strong>Test smart</strong></a><strong> →</strong><br />How to navigate through dilemmas as QA?<br />By <a href=""https://medium.com/u/5de316912dba"">Julia Kocbek</a></li><li><a href=""https://uxdesign.cc/the-ai-delegation-matrix-what-parts-of-your-ui-shouldnt-exist-f4b97f9c4491""><strong>The AI delegation matrix</strong></a><strong> →</strong><br />What parts of your UI shouldn’t exist?<br />By <a href=""https://medium.com/u/498aec590e1b"">Taras Bakusevych</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, here’s how you can support us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-mob1"">this week’s sponsor</a> and support their work too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor an edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2f2edb0e10a1"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/intuitive-designer-ai-delegation-matrix-the-new-ux-toolkit-2f2edb0e10a1"">Intuitive designer, AI delegation matrix, the new UX toolkit</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/emotional-design-lets-design-for-silence-f2e3181d246f?source=rss----138adf9c44c---4,1770639217,Emotional design: let’s design for silence,"Emotional design: let’s design for silence

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/emotional-design-lets-design-for-silence-f2e3181d246f?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/660/0*5gyJrHgCxkYseDkI"" width=""660"" /></a></p><p class=""medium-feed-snippet"">The most powerful communication happens before language. And there are psychoneurological reasons.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/emotional-design-lets-design-for-silence-f2e3181d246f?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/ais-text-trap-moving-towards-a-more-interactive-future-7035bbc4aaa5?source=rss----138adf9c44c---4,1770639175,AI’s text-trap: Moving towards a more interactive future,"AI’s text-trap: Moving towards a more interactive future

<h4>AI assistants don’t have to communicate in paragraphs. They can communicate through interfaces.</h4><figure><img alt=""A paper cutout illustration showing an AI assistant chat interface on the left connected to a design system library on the right."" src=""https://cdn-images-1.medium.com/max/1024/1*Ec6csH34-8uaTEWIkXZ6Gg.png"" /><figcaption>Generated using Google Gemini</figcaption></figure><p>LLMs have made AI assistants a standard feature across SaaS. AI assistants allow users to instantly retrieve information and interact with a system through text-based prompts. Mathias Biilmann, in his article “<a href=""https://biilmann.blog/articles/introducing-ax/"">Introducing AX: Why Agent Experience Matters</a>,” discusses two distinct approaches to building AI assistants. The Closed Approach involves a conversational assistant embedded directly within a single SaaS product. Examples include Zoom’s AI Companion, Salesforce CRM’s Einstein, and Microsoft’s Copilot. The Open Approach involves external conversational assistants, such as Claude, ChatGPT, and Gemini, which are being supercharged via protocols like MCP (Model Context Protocol). This protocol allows the AI assistants to connect to and interact with various third-party SaaS products, effectively making a company’s product accessible to external assistants and agents.</p><h3>The risk of commoditization</h3><p>Both approaches are powerful. They offer users flexibility they’ve never had. However, they also reduce the carefully crafted user experience to a purely text-based interface. When the interaction is text-only and detached from your product, the user experience is no longer a differentiator, and your <a href=""https://www.pragmaticcoders.com/blog/saas-is-dead-how-ai-agents-reduced-saas-to-just-an-api"">product is at risk of becoming a commodity</a>.</p><p>Text-only interfaces also limit interactions to simple information retrieval and basic CRUD operations, making complex workflows difficult. This <a href=""https://artium.ai/insights/beyond-chat-how-ai-is-transforming-ui-design-patterns"">creates limitations</a> as users attempt to consume large amounts of information and execute complex operations solely through text prompts. Andrej Karpathy, in his recent piece<a href=""https://karpathy.bearblog.dev/year-in-review-2025/""> 2025 LLM Year in Review</a>, noted that while text is the favored format for computers and LLMs, it is not for humans. We humans prefer information visually. Similarly, Maximillian Piras in 2024, argued that <a href=""https://uxmag.com/articles/when-words-cannot-describe-designing-for-ai-beyond-conversational-interfaces"">chat is often a poor fit for complex interaction patterns</a>.</p><h3>The temptation of generative UI</h3><p>One answer gaining traction is generative UI where the AI autonomously creates interfaces based on the user’s prompts. While this capability is likely to improve significantly, it also presents a risk of delivering generic experiences. Without designer input, AI-generated UX defaults to the generic average of its training data. Every product starts looking the same. There is no differentiation. Dorian Tireli describes how <a href=""https://poplab.io/commoditization-saas-design-ai/"">AI is reinforcing mediocrity</a> due to training data coming from common design platforms that are optimized for visual appeal.</p><h3>The case for design system integration</h3><p>As a result, we need to examine an alternate approach, one where the AI assistants have knowledge of a product’s unique design system — its components, patterns, and guidelines. Any time the user prompts, instead of displaying text blocks and paragraphs, what if the assistant could render rich interfaces supplied by the product’s design system? This transforms the chat from a static text box into a dynamic viewport with rich interactive elements. The <a href=""https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps/"">latest developments</a> in the MCP protocol are making this approach possible.</p><figure><img alt=""Flow diagram showing a user prompting the AI assistant which then communicates with the Design System that returns a UI component. The UI component is then rendered to the user as a response."" src=""https://cdn-images-1.medium.com/max/714/1*jRw1B92fdpVGV7Tw_D_DLA.png"" /><figcaption>Designed using Figma</figcaption></figure><h3>Three modes for richer AI experiences</h3><p>To create richer and differentiated experiences, I have considered three different design modes that can help us move beyond the text-trap.</p><h4>Mode 1: Rich output</h4><p>In complex business applications, users consume data, not just answers. Large blocks of text create cognitive load. The challenge is to move beyond text and towards a richer UI output. For example, when a user prompts “Merge the two John Smith records flagged yesterday,” the AI doesn’t ask “Which one should be primary?” Instead, it displays two contact cards side-by-side with metadata, enabling the user to make a decision through the UI. This approach maximizes scannability and allows the user to instantly grasp the situation and prioritize follow-up.</p><figure><img alt=""AI assistant displaying two contact cards for the user to choose between using visual cues."" src=""https://cdn-images-1.medium.com/max/872/1*M0bgD1X-TCn5hFBfSC4coQ.png"" /><figcaption>Designed using Figma Make</figcaption></figure><h4>Mode 2: UI as input</h4><p>The differentiated experience must start at the point of input, not just output. Rather than forcing users to craft precise text prompts and requiring them to know the exact parameters to provide, imagine if the AI assistant could replace the text box with a structured input component. For example, when a user wants to retrieve a record, instead of typing “Show me California leads with high activity” and then requiring the user to re-prompt every time they want to add more parameters, the AI assistant simply displays a query builder.</p><figure><img alt=""AI assistant displaying a filter UI, making it easier for the user to choose parameters as opposed to having to type a detailed query."" src=""https://cdn-images-1.medium.com/max/872/1*qXe8NrqwVlPjifV34woP3g.png"" /><figcaption>Designed using Figma Make</figcaption></figure><p>This shift from text to high-fidelity input removes ambiguity, reduces back-and-forth, and makes the overall interaction faster and more precise.</p><h4>Mode 3: Co-creation</h4><p>Modes 1 and 2 represent single interactions. But real-world scenarios are rarely this simple. In SaaS applications, high-value tasks are multi-step workflows. Creating a marketing automation campaign. Building a complex report. Configuring an integration. These aren’t things you accomplish in one prompt, rather they unfold over a conversation where the user and AI assistant refine the work together.</p><p>To support this, the AI assistant needs to become more than a responder. <strong>It needs to become a workspace.</strong></p><p>Let’s see how this plays out through a single scenario: a user creating a marketing automation campaign. The user prompts: “Create a campaign for trial users who haven’t activated yet.” The AI responds by rendering a flow builder component showing a draft campaign.</p><figure><img alt=""The image shows a flow generated by the AI assistant based on the user’s prompt. The user asked the AI assistant to create campaign for trial users who haven’t activated yet."" src=""https://cdn-images-1.medium.com/max/1024/1*pJjd37QJ5eFZNFj_L8ektA.png"" /><figcaption>Made using Figma</figcaption></figure><p>From here, <strong>four capabilities</strong> transform a back-and-forth conversation into a co-creation model.</p><p><strong>Fluid modality switching<br /></strong>When the user wants to update a block, they shouldn’t be forced back to the text prompt. The AI assistant should allow users to move fluidly between text and direct manipulation. For example, rather than prompting “change the wait time to 5 days,” the user simply adjusts the wait component directly in the flow builder. The AI validates the change and updates dependent elements automatically.</p><figure><img alt=""The image shows the flow components rendered by the AI assistant. The user directly interacts with the UI elements and updates the flow as opposed to asking the AI assistant to make changes."" src=""https://cdn-images-1.medium.com/max/1024/1*3W3npKqeOz42lXXqZf1JNw.png"" /><figcaption>(Made using Figma)</figcaption></figure><p><strong>Proactive cross-tool suggestions<br /></strong>Complex workflows often span multiple tools and users need information from various sources to take better decisions. Rather than forcing the user to start a new conversation or open a new tab, the AI assistant can bring data from connected tools directly into the workflow. Better yet, it can surface insights proactively.</p><p>In our example, once the flow has been created, the AI notices that most unactivated users are on mobile, while the email templates are desktop-focused. Without being prompted, it pulls usage data from the connected analytics tool and surfaces a brief insight within the flow builder: “68% of your unactivated trial users are on mobile, but your email templates aren’t mobile-optimized.”</p><figure><img alt=""The GIF shows the AI assistant proactively displaying insights from relevant tools and sources. As the user is updating the flow, the AI assistant pulls data from an analytics tool and informs that user that most of the unactivated users are on mobile whereas all the email templates in the flow are web based."" src=""https://cdn-images-1.medium.com/max/1024/1*8GVVr2klWv6iLVqViVYPWg.gif"" /><figcaption>(Created using Figma and Figma Make)</figcaption></figure><p>For this to work, the AI assistant needs the right level of access to the data. But access alone isn’t enough. The judgment layer needs to be designed to know when an insight is worth surfacing and when silence is the better choice.</p><p><strong>Delegation of discrete subtasks<br /></strong>At some point in a multi-step workflow, the user may want to hand off a contained piece of work entirely. Based on the mobile optimization insight, the user prompts the AI assistant to update the template. The AI assistant then takes on the content work while the user continues refining the campaign’s structural logic. When ready, the AI surfaces the updated template for review. This is <strong>co-creation as division of labor</strong>, not just turn-taking.</p><figure><img alt=""Once the user accepts the AI assistant’s recommendation, the assistant goes to work on this sub-task while the user can continue to do their work. The assistant keeps the user informed on the progress and the user can take an informed decision."" src=""https://cdn-images-1.medium.com/max/1024/1*ggzbqGj4XsiUp5r3gbaJgQ.gif"" /><figcaption>(Made using Figma and Figma Make)</figcaption></figure><p><strong>Contextually refine with text<br /></strong> The text-based input doesn’t have to live in the prompt box — it can be contextual to the UI elements. For example, the user hovers over a connector in the flow and prompts, “Send a survey asking about their biggest challenge, then route them to different content tracks based on their answer.” In response, the AI inserts a new survey block before the final reminder email block, creates conditional branches based on common responses, and shows the multi-path workflow.</p><p>Because the prompt was anchored to a specific component rather than being in the generic prompt box, the AI understands where in the workflow the user is acting, not just what they’re saying. The library, Shape of AI by Emily Campbell highlights <a href=""https://www.shapeof.ai/patterns/inline-action"">Inline action</a> as way for user to adjust or respond to a small part of a larger piece of content.</p><figure><img alt=""This image shows the user prompting the AI assistant in context of the UI. The user clicks one of the nodes in the flow and asks the AI assistant to update the flow."" src=""https://cdn-images-1.medium.com/max/1024/1*_q961WZJ3qbWUVUl5VF_Sg.gif"" /><figcaption>(Made using Figma and Figma Make)</figcaption></figure><p>In Mode 3, rather than forcing users into turn-by-turn conversations, the AI assistant becomes an added modality for the product’s experience. It holds context across tools so the user doesn’t have to. It creates <strong>a shared workspace for co-creation</strong> so the user and AI assistant can work together.</p><h3>The craft hasn’t changed</h3><p>While designing for AI assistants and AI agents may sound daunting at first, the good news is that the <a href=""https://www.salesforce.com/blog/ai-design-skills/"">skills required to succeed aren’t novel</a>. They’re the same fundamentals that have always distinguished exceptional designers.</p><p>You need a deep understanding of users and jobs-to-be-done to identify which tasks actually benefit from conversational AI. Systems thinking is quickly becoming one of the most important skills as highlighted in these articles from <a href=""https://www.salesforce.com/blog/ai-jobs-to-be-done-designers/#h-five-ways-design-work-is-shifting-and-how-to-respond"">Salesforce</a> and <a href=""https://adobe.design/stories/leading-design/six-human-skills-that-will-future-proof-your-design-career"">Adobe</a>. You need systems thinking, because these assistants cross boundaries, within your product’s IA and beyond it into other tools. And you need technical literacy: data models, APIs, backend logic. When users can query any data the system touches, you’d better understand what that data looks like.</p><p>AI assistants and agents are only going to keep increasing. The question isn’t whether your product will have one, it’s whether the experience will be differentiated or commoditized.</p><p>The text-trap is real, but it’s not inevitable.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7035bbc4aaa5"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ais-text-trap-moving-towards-a-more-interactive-future-7035bbc4aaa5"">AI’s text-trap: Moving towards a more interactive future</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/how-to-make-any-text-scannable-36f4db67ee77?source=rss----138adf9c44c---4,1770559238,How to make any text scannable,"How to make any text scannable

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-to-make-any-text-scannable-36f4db67ee77?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2560/1*FXKZRwHgvXObhdNHjRy_eg.png"" width=""2560"" /></a></p><p class=""medium-feed-snippet"">9 science-backed ways to get people to read your stuff (any stuff).</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-to-make-any-text-scannable-36f4db67ee77?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-design-vibeshift-894001f64fa8?source=rss----138adf9c44c---4,1770559229,The Design Vibeshift,"The Design Vibeshift

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-design-vibeshift-894001f64fa8?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2400/0*YsooRVxSp3gJ0wA7.png"" width=""2400"" /></a></p><p class=""medium-feed-snippet"">A change is happening&#x2026; for a lot of designers, code is becoming our new canvas</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-design-vibeshift-894001f64fa8?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
