source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI thatâ€™s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,PivotingÂ Your Career Without Starting From Scratch,"PivotingÂ Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, â€œIs this still what I want to be doing?â€ This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as youâ€™re reading this or youâ€™re still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? Weâ€™ve got you covered."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/giving-users-voice-virtual-personas/,1766484000,Giving Users A Voice Through Virtual Personas,"Giving Users A Voice Through Virtual Personas

Turn scattered user research into AI-powered personas that give anyone consolidated multi-perspective feedback from a single question."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/,1766138400,How To Measure The Impact Of Features,"How To Measure The Impact Of Features

Meet TARS â€” a simple, repeatable, and meaningful UX metric designed specifically to track the performance of product features. Upcoming part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today)."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/smashing-animations-part-7-recreating-toon-text-css-svg/,1765965600,Smashing Animations Part 7: Recreating Toon Text With CSS And SVG,"Smashing Animations Part 7: Recreating Toon Text With CSS And SVG

In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk) shows his techniques for creating [Toon Text titles](https://stuffandnonsense.co.uk/toon-text/index.html) using modern CSS and SVG."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/accessible-ux-research-ebook-release/,1765296000,"Accessible UX Research, eBook Now Available For Download","Accessible UX Research, eBook Now Available For Download

Weâ€™ve got exciting news! eBook versions of â€œAccessible UX Research,â€ a new Smashing Book by Michele A. Williams, are now available for download! Which means soon the book will go to the printer. Order the eBook for instant download now or <a href=""https://www.smashingmagazine.com/printed-books/accessible-ux-research/"">reserve your print copy at the presale price.</a>"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/state-logic-native-power-css-wrapped-2025/,1765274400,"State, Logic, And Native Power: CSS Wrapped 2025","State, Logic, And Native Power: CSS Wrapped 2025

CSS Wrapped 2025 is out! Weâ€™re entering a world where CSS can increasingly handle logic, state, and complex interactions once reserved for JavaScript. Here is an unpacking of the standout highlights and how they connect to the bigger evolution of modern CSS."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-ux-professionals-can-lead-ai-strategy/,1765180800,How UX Professionals Can Lead AI Strategy,"How UX Professionals Can Lead AI Strategy

Lead your organizationâ€™s AI strategy before someone else defines it for you. A practical framework for UX professionals to shape AI implementation."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/beyond-black-box-practical-xai-ux-practitioners/,1764946800,Beyond The Black Box: Practical XAI For UX Practitioners,"Beyond The Black Box: Practical XAI For UX Practitioners

Explainable AI isnâ€™t just a challenge for data scientists. Itâ€™s also a design challenge and a core pillar of trustworthy, effective AI products. Victor Yocco offers practical guidance and design patterns for building explainability into real products."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/masonry-things-you-wont-need-library-anymore/,1764669600,Masonry: Things You Wonâ€™t Need A Library For Anymore,"Masonry: Things You Wonâ€™t Need A Library For Anymore

CSS Masonry is almost here! Patrick Brosset takes a deep dive into what this long-awaited feature means for web developers and how you could make use of it in your own work."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/desktop-wallpaper-calendars-december-2025/,1764493200,A Sparkle Of December Magic (2025 Wallpapers Edition),"A Sparkle Of December Magic (2025 Wallpapers Edition)

With December just around the corner, how about some new desktop wallpapers to welcome the last month of the year â€” and the holiday season, if youâ€™re celebrating? Our latest edition of monthly wallpapers has got you covered. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/accessibility-problem-authentication-methods-captcha/,1764237600,The Accessibility Problem With Authentication Methods Like CAPTCHA,"The Accessibility Problem With Authentication Methods Like CAPTCHA

CAPTCHAs were meant to keep bots out, but too often, they lock people with disabilities out, too. From image classification to click-based tests, many â€œhuman checksâ€ are anything but inclusive. Thereâ€™s no universal solution, but understanding real user needs is where accessibility truly starts."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/design-system-culture/,1764093600,Design System Culture: What It Is And Why It Matters (Excerpt),"Design System Culture: What It Is And Why It Matters (Excerpt)

Weâ€™re so happy to announce that â€œMaturing Design Systemsâ€â€”a Smashing book by Ben Callahan &mdash; will soon be joining the Smashing Library! Benâ€™s insights and advice are so powerful, we thought you might like to read an excerpt from the book. <a href=""https://www.smashingmagazine.com/the-smashing-newsletter/"">Subscribe to our Smashing newsletter</a> to be notified when orders are open."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/designing-for-stress-emergency/,1763989200,Designing For Stress And Emergency,"Designing For Stress And Emergency

Practical guidelines on designing time-critical products that prevent errors and improve accuracy. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today). With a <a href=""https://smashingconf.com/online-workshops/workshops/vitaly-friedman-impact-design/"">live UX training</a> starting next week."
rss,uxdesign.cc,https://uxdesign.cc/post-covid-user-research-needs-a-revised-safeguarding-plan-1eba94e4d03a?source=rss----138adf9c44c---4,1767822091,Postâ€‘COVID user research needs a revised safeguarding plan,"Postâ€‘COVID user research needs a revised safeguarding plan

<h4>A story from the field: the day safeguarding becameÂ real</h4><figure><img alt=""Laptop, phone and book chained together, symbolising safeguarding and data security in user research fieldwork. Source: Pexels."" src=""https://cdn-images-1.medium.com/max/1024/1*pt1NxJUSAWyMb06YrmA_Zg.jpeg"" /><figcaption>Laptop, phone and book chained together, symbolising safeguarding and data security in user research fieldwork. Source:Â Pexels.</figcaption></figure><p>During a discovery project, I was visiting education settings across England to run inâ€‘person research. That meant working inside real-world constraints: safeguarding processes, visitor protocols, staff availability, young people moving through corridors, rooms that suddenly became unavailable, and the constant awareness that youâ€™re a guest in someone elseâ€™s environment.</p><p>At one site, we were told (almost casually) that more than half the staff were off sick with COVID, and another bug was doing the rounds. The cherry on top was that we were crammed into a small basement room that was colder than the rest of the building, so no ventilation, and a very high chance of catching whatever was circulating.</p><p>Two days later, I was ill. I stayed ill for weeks. I couldnâ€™t take sick leave due to tight deadlines and stakeholders picking on any leave taken as â€œdelaying the projectâ€.</p><p>That was my reminderÂ that:</p><blockquote>Safeguarding isnâ€™t only about what happens <strong>in</strong> the session. Itâ€™s also about what happens <strong>around</strong> the session: infection risk, travel load, lone working, fatigue, access, and the logistics nobody puts on the Gantt chart, including allowance for sickÂ leave.</blockquote><p>And if you think thatâ€™s â€œjust wellbeingâ€Â â€¦well, it isnâ€™t. Itâ€™s research quality. When researchers are depleted, rushed, anxious about getting to the next site, or taking avoidable health risks, the work gets worse. Decision-making gets shakier, debriefs get skipped, boundaries blur, and the conditions for ethical, high-quality research quietlyÂ erode.</p><p>The safeguarding plan template I share with you (at the end of this article) is informed by what I now call â€œinterestingâ€ field notes (though at the time, they were mildly psychosisâ€‘inducing events!). Iâ€™m sharing 7 field notes to set the stage for why (and I cannot emphasise this enough) a safeguarding plan reallyÂ matters.</p><h4>Field note #1: the invisible entrance</h4><p>On one visit, I arrived at what looked like a massive establishment, but couldnâ€™t find the entrance. Construction work, temporary buildings, and exactly zero signposting added to the pain. I spent the first 15 minutes convincing myself Iâ€™d come to the wrong place, while my Uber driver (now a distant memory) had left me in what felt like a no-manâ€™s-land.</p><p>I rechecked Google Maps like 50 times, reread my emails and tried contacting the reception by calling but noÂ luck.</p><p>Eventually, a stranger appeared, also going to the same place, pointed me to the entrance like a human â€œyou are hereâ€ sign. It was like going through aÂ maze!</p><p>No one had done anything malicious in this case. Iâ€™d sent confirmation emails. Theyâ€™d replied. Weâ€™d all behaved like professionals. But nobody had thought toÂ say:</p><blockquote>â€œEntrance is currently around the back, follow the temporary fencing and come through the metal gates where all the clinical waste bins are lined up, and ignore the sign thatÂ lies.â€</blockquote><p>It wasnâ€™t their â€œfaultâ€. It was the assumption that got me. I did not treat basic navigation and access as part of safeguarding. The fix, is boring and brilliant:</p><blockquote>Ask for <strong>photos of the entrance</strong>, a <strong>named contact with a mobile number</strong>, and a plan for what happens if you canâ€™t get in within 10Â minutes.</blockquote><figure><img alt=""Building entrance hidden behind construction work (scaffolding) and confusing signage. Source: Pexels."" src=""https://cdn-images-1.medium.com/max/1024/1*piNKrKky26yMF_HpnN0qnA.jpeg"" /><figcaption>Building entrance hidden behind construction work (scaffolding) and confusing signage. Source:Â Pexels.</figcaption></figure><h4>Field note #2: the loneÂ working</h4><p>When I was a PhD researcher, my office was in what was called â€œthe Pink Building.â€ A large, lightâ€‘pink shed on campus. It had the architectural charm of a storage unit and the safety profile of, letâ€™s say, â€œoptimisticâ€.</p><p>One evening, we were preparing for a large-scale randomised controlled trial. We were printing and packing hundreds of consent forms, participant information sheets, and supporting documentation (ethical approval, what you need to know etc.). The kind of admin tasks that convinces you that your PhD is mainly an advanced qualification in stapling and packing envelopes.</p><p>Due to the looming deadline, I stayed late. A few others stayed lateÂ too.</p><p>At some point, without noticing, I became the last person in the building. And for some reason the main door would not open. I was stuck, and it was way past loneâ€‘working hours. There were no CCTV cameras inside the building, and the dread of my supervisor finding out (and then them getting in trouble) was doing a lovely little duet with my panic response.</p><p>I called a friend who lived nearby. Luckily, they were home and they came and got meÂ out.</p><p>Weeks later, I found out a different office in that same building had caught fire because a student smoked inside a wooden shed and left a stillâ€‘lit cigarette butt in a bin full of paper. The fire alarm did its job (thankfully). However, the final-year PhD studentâ€™s work couldnâ€™t beÂ rescued.</p><p>Iâ€™m sharing this because itâ€™s the most predictable safeguarding lesson in academia (andÂ beyond):</p><blockquote>Lone working isnâ€™t a badge of honour. Itâ€™s a risk that needs aÂ plan.</blockquote><h4>Field note #3: the reâ€‘traumatisation</h4><p>Now for the one that still makes my eyeÂ twitch.</p><p>There was an opening event for a trial involving eating disorders. An influencer with lived experience was invited (paid to attend by public funding!). A media presence was expected. The senior investigator bragged about having â€œuseful connectionsâ€ in high places (because nothing says â€œscientific rigourâ€ like nameâ€‘dropping your ministerÂ cousin).</p><p>Thank goodness the broadcaster didnâ€™t show up, and neither did the â€œvery important cousinâ€.</p><p>But what did happen was worse in a quieter way: there were clearly people in the room being impacted by the choices made around food, messaging, and the theatre of it all. It was a masterclass in how a team can be so focused on â€œPRâ€ that they lose sight of basic emotional safety.</p><p>Putting large quantities of food and drinks in front of people (including the influencer herself) was not thoughtful. It was triggering for many because they were there due to lived experience of battling severe eating disorders that included <strong>anorexia, bulimia and so on</strong>â€¦ and then you have staff enthusiastically eating and drinking through itÂ all.</p><p>That experience sharpened a point I now say out loud in project kick-offs:</p><blockquote>You can have all the ethics paperwork in the world. If your team culture treats reâ€‘traumatisation as an abstract risk rather than a real human outcome, you donâ€™t have safeguarding, you have compliance cosplay.</blockquote><p>And if the most senior person is the risk, you need a pre-agreed speakâ€‘up route (not just â€œbe braveâ€). A stop rule. A named escalation contact outside the immediate hierarchy, and a culture where safeguards are rehearsed, not improvised. In academia, the ethics board that approved the study is one route of escalation.</p><figure><img alt=""Measuring tape wrapped around an apple symbolising diet and eating disorders. Source: Pexels."" src=""https://cdn-images-1.medium.com/max/1024/1*KJa9JR13BTMWpbfRFc0Ybg.jpeg"" /><figcaption>Measuring tape wrapped around an apple symbolising diet and eating disorders. Source:Â Pexels.</figcaption></figure><h4>Field note #4: the day the institution-to-institution relationship collapsed</h4><p>Hereâ€™s a scenario I wish more safeguarding plans covered: governance collapse.</p><p>I once travelled across the country for fieldwork in a healthcare setting. Everything looked â€œapprovedâ€ on paper. Then I arrived, and suddenly I had no access. Nobody would speak to me and I was told to wait in reception for hours. Doors that should have opened didnâ€™t. The relationship between the university and the partner organisation had fractured at a senior level, and Iâ€™d been left out of theÂ loop.</p><p>So there I was with wasted travel cost, time, energy, preparation and a hard stop. This is safeguarding too.</p><blockquote>Because safeguarding is also about protecting the <strong>work</strong> and the <strong>researcher</strong>. If a breakdown in institutional comms can strand you physically, professionally, and emotionally (and sometimes financially), then it needs to sit in the risk register like any other operational risk.</blockquote><p>The question we rarely ask is who covers what? Before I now travel for fieldwork, I confirm insurance/indemnity and cancellation rules:</p><ul><li>who covers travel costs if access collapses,</li><li>whether professional indemnity/public liability applies (especially if contracting), and</li><li>who has authority to pause/stop fieldwork if safety conditions change.</li></ul><h4>Field note #5: families as a riskÂ variable</h4><p>In social care settings, thereâ€™s another layer that rarely makes it into tidy templates:</p><blockquote>Families can be protective and brilliant, and they can also be chaotic, accusatory, and sometimes activelyÂ harmful.</blockquote><p>During my time working in social care and in an NHS rehab service, Iâ€™ve seen families raise serious concerns that were absolutely legitimate and neededÂ action.</p><p>Iâ€™ve also seen families create issues where there were none. And Iâ€™ve seen situations where family members were taking money from someone in care, then implying it was the settingâ€™s fault or that the staff â€œdidnâ€™t do their job properlyâ€ and attempting to escalate formally.</p><p>As researchers, we donâ€™t prosecute. But we do need to planÂ for:</p><ul><li>thirdâ€‘party risk,</li><li>allegations and counterâ€‘allegations,</li><li>reputational volatility,</li><li>and the possibility that â€œwhatâ€™s trueâ€ is not always clear in theÂ moment.</li></ul><h4>Field note #6: when the VPN and firewall are so safe they break theÂ research</h4><p>In one organisation, we assumed the laptops provided would seamlessly connect to Wiâ€‘Fi on sites being visited. Trust me when I say: they did not. The firewall and VPN were so secure that even the host IT team couldnâ€™t troubleshoot the connection.</p><p>The result was that MS Teams wouldnâ€™t run, recording didnâ€™t work, and there was no builtâ€‘in audio recording on the laptop. I also didnâ€™t have a dedicated work mobile, so using my personal phone to capture audio would have breachedÂ policy.</p><p>We defaulted to note-taking, but even that became an issue because uploads to the analysis tool kept failing. We ended up with an incomplete dataset and analysis that relied far too much onÂ memory.</p><p>Safeguarding lesson here is that you need a preâ€‘agreed offline plan (confirming Wiâ€‘Fi access arrangements and device/VPN constraints in advance of the visit, approved recording routes, secure note templates, and a contingency for when tech fails), especially in high-stakes/high-security settings.</p><p>Another important thing to note is that in high-security settings like prisons, secure mental health hospitals, and immigration environments, safeguarding escalates because power imbalance is built into the setting. Recording may be prohibited altogether, device access may be restricted or denied, staff may be present in the session impacting what is said and shared, and â€œvoluntary participationâ€ can be complicated. For such settings, your safeguards need to be even more robust and explicit like having a paired working and no lone-working atÂ all.</p><h4>Field note #7: not everyone is willing to participate</h4><p>One of the biggest lessons I learned is that not everyone will participate, even when your intentions are good and your paperwork is flawless. In some communities, trust is not easy toÂ earn.</p><p>Iâ€™ve turned up at settings where I simply couldnâ€™t access the voices I came to hear. Some communities have rational reasons for being cautious: history, extraction, misrepresentation, and previous â€œresearchâ€ that didnâ€™t translate intoÂ change.</p><p>This taught me that refusal is data too, not a failure. Safeguarding hereÂ means:</p><blockquote>Designing for cultural safety and voluntariness which may look like working through trusted community connectors, using culturally appropriate facilitators where needed, offering different modes of participation, and being explicit that saying â€œnoâ€ to participation has no consequences.</blockquote><figure><img alt=""Human holding a banner saying â€˜Noâ€™ against a yellow background. Source: Pexels."" src=""https://cdn-images-1.medium.com/max/1024/1*UBLuSXVuMISnYk3u6COCnA.jpeg"" /><figcaption>Human holding a banner saying â€˜Noâ€™ against a yellow background. Source:Â Pexels.</figcaption></figure><h3>Soâ€¦ what is safeguarding, really?</h3><p><a href=""https://user-research.education.gov.uk/standards/participant-safeguarding"">Safeguarding</a> is a delivery operating model, captured as a plan (or an agreement) that clarifies:</p><ul><li>who is responsible for what (and who makes decisions when conditions change),</li><li>how consent and power dynamics are handled in realÂ time,</li><li>what we do if participant becomes distressed or discloses aÂ risk,</li><li>how we keep researchers safe (physical safety,<a href=""https://www.hse.gov.uk/lone-working/employer/index.htm?utm_source=chatgpt.com""> lone working</a>, travel, wellbeing),</li><li>how we protect third parties (because research stories often include other people who havenâ€™t consented),</li><li>how we protect data, so insights donâ€™t become unintended identifiers.</li></ul><p>And crucially, how we execute the plan in real environments where everything isÂ messy.</p><h3>There are a few things that make a safeguarding plan comprehensive and failâ€‘safe</h3><h4>1) A traumaâ€‘informed lens</h4><p><a href=""https://skilledwork.org/an-introduction-to-trauma-informed-research/"">Traumaâ€‘informed approaches</a> arenâ€™t â€œextra sensitivityâ€. Theyâ€™re pragmatic. They improve safety, choice, and trust, which tends to improve the quality of what people are able (and willing) toÂ share.</p><p>In research terms, a traumaâ€‘informed lens pushes you to design sessions where participants:</p><ul><li>know whatâ€™sÂ coming,</li><li>have meaningful control,</li><li>can opt out withoutÂ penalty,</li><li>and arenâ€™t pushed into disclosure â€œfor the sake of insightâ€.</li></ul><p>It also forces a professional acknowledgement that researchers can be impacted too by vicarious trauma, fatigue, stress, and the physical reality of operating in highâ€‘pressure systems.</p><h4>2) Factoring in incentives (as a safeguarding decision, not justÂ admin)</h4><p><a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC9631331/"">Incentives can reduce barriers to participation</a>, but they can also create pressure, bias, orÂ risk.</p><p>I treat incentives as part of safeguarding:</p><ul><li>It must never be framed as â€œpayment for disclosureâ€.</li><li>It should not be conditional on answering every question or completing the session fully (especially in the digital world where 45 minutes into a 60 minute session, the connection breaks, or a participant faces issues when re-joining the session).</li><li>It must be safe and discreet to deliver (cash can create risk; digital delivery can create privacy issues where emails, bank account details areÂ shared).</li><li>It <a href=""https://info.lse.ac.uk/staff/divisions/research-and-innovation/research/Assets/Documents/PDF/ethics-incentives-reimbursement-etc-v5.pdf"">should be equitable</a>: if we pay for time, we should consider expenses and participation costs (travel, childcare, foodÂ etc.).</li></ul><p>And yes, incentives can attract misrepresentation. People may tell you what they think gets them â€œinto the studyâ€, or what they think will please you. Thatâ€™s not a reason to remove incentives; itâ€™s a reasonÂ to:</p><ul><li>design screening carefully and thoughtfully,</li><li>avoid recruitment through coercive gatekeepers,</li><li>and be clear that incentives are not linked to â€œperformingâ€ as a good participant.</li></ul><h4>3) Consent and assent (done properly, not performatively)</h4><p>This is the part that matters most, especially when vulnerable people are involved.</p><p><a href=""https://www.hra.nhs.uk/planning-and-improving-research/best-practice/informing-participants-and-seeking-consent""><strong>Consent</strong></a><strong> for adults with capacity</strong> must be informed, freely given, specific, and ongoing (reconfirm at key moments).</p><p><strong>Children: </strong><a href=""https://www.hra-decisiontools.org.uk/consent/principles-children.html#:~:text=Consent%20is%20a%20legally%20defined,their%20capacity%20when%20seeking%20assent.""><strong>consent +Â assent</strong></a></p><ul><li>Parental/guardian consent may be required (depending on policy andÂ age).</li><li>Child assent should still be sought even when an adult has consented on theirÂ behalf.</li></ul><p>Assent is not a tick-box. Itâ€™s the childâ€™s affirmative agreement, expressed in age-appropriate ways. And hereâ€™s what it may lookÂ like:</p><ul><li>If the child does not want to take part, verbally or nonâ€‘verbally, weÂ stop.</li><li>If the child wants to stop partway through, weÂ stop.</li><li>If the child wants to skip a question, we skipÂ it.</li></ul><p>No negotiation. No persuasion. No â€œjust one more question.â€</p><p><strong>Vulnerable adults/adults who may lack capacity: </strong><a href=""https://www.cqc.org.uk/guidance-regulation/providers/regulations-service-providers-and-managers/health-social-care-act/regulation-11""><strong>supported decisionâ€‘making +Â assent</strong></a></p><ul><li>Use supported decision-making (plain language, time, breaks, visuals, accessible formats).</li><li>Check understanding by asking them to explain back (in their own words) what will happen, what will be recorded, and that they canÂ stop.</li></ul><p>If a person cannot understand/retain/weigh the information or communicate a decision even withÂ support:</p><ul><li>you cannot rely on their consentÂ alone,</li><li>you may need a legally authorised representative process (depending on jurisdiction/policy),</li><li>and you should still seek the personâ€™s assent and monitor for distress orÂ dissent.</li></ul><p>And again: if they show they donâ€™t want to continue, weÂ stop.</p><p><strong>Gatekeepers (who protect voluntariness)</strong><br />Teachers, carers, clinicians, managers, and yes, prison staff, can enable access and unintentionally pressure participation. BuildÂ in:</p><ul><li>a private optâ€‘outÂ route,</li><li>clear â€œno consequenceâ€ language,</li><li>and a cooling-off window where appropriate.</li></ul><h3>5 things I now do before I enter any setting (andÂ why)</h3><p>These are the â€œunsexyâ€ steps that make fieldwork safer, and prevent heroics from becoming theÂ plan:</p><h4>1) Map safeguarding on both sides (and confirm clearance)</h4><ul><li>Identify the host settingâ€™s safeguarding lead and read their safeguarding policy before youÂ arrive.</li><li>Identify your organisationâ€™s safeguarding lead and escalation route.</li><li>Make sure both ends know how to reach each otherÂ quickly.</li><li>Confirm clearance requirements early (e.g., enhanced DBS, prison/security vetting, NHS site rules). If clearance wonâ€™t land in time: pivot methodÂ early.</li></ul><h4>2) Build a fieldwork tracker (treat it like an asset, notÂ admin)</h4><p>Document:</p><ul><li>where youâ€™re going (exact building location),</li><li>photos of the entrance if itâ€™s a complexÂ site,</li><li>who youâ€™re meeting (names where appropriate, roles, agreed contact details),</li><li>a named contact with a mobileÂ number,</li><li>timings, checkâ€‘in/out times, contingency routes,</li><li>language requirements (do participants communicate in English; do you need an interpreter).</li><li>Inform the setting that youâ€™ll need to access their network and ask for WiFi and device connectivity early on so you avoid delays on theÂ day.</li><li>Create a separate tracker for your participants where you use participant IDs but keep participant contact details separate.</li><li>Have a tracker for research work where you keep a record of what was recorded, with whom, who conducted the session, who took notes, who observed, what supplementary material was provided, if you upload the material and notes etc. For online research, you can adapt this tracker (links, time zones, backup numbers, â€œwhat if the platformÂ failsâ€).</li><li>For data security, upload to secure storage promptly, and donâ€™t rely on â€œIâ€™ll sort it laterâ€ when youâ€™re travelling.</li></ul><h4>3) Treat public health as part of safeguarding (postâ€‘COVID reality)</h4><p>Before inâ€‘person work:</p><ul><li>ask the site about outbreaks or visitor restrictions,</li><li>confirm PPE expectations (even if â€œoptionalâ€),</li><li>decide in advance what triggers a reschedule or a switch toÂ remote.</li></ul><h4>4) Plan reset capacity like itâ€™s a delivery constraint (because itÂ is)</h4><ul><li>Cap the number of intensive visits perÂ week.</li><li>Build half-day resets into schedules whereÂ needed.</li><li>Protect debrief time as nonâ€‘negotiable (not a â€œnice toÂ haveâ€).</li></ul><p>People who havenâ€™t done fieldwork often only see the interview hour. They donâ€™t see the off-stage work: ethics, documentation, travel (and all the drama of delays and connectivity), relationship management, safeguarding alignment, the emotional labour of holding space, and the operational coordination required to get usable data without harmingÂ anyone.</p><p>So if your team asks for frequent check-ins or expects you to do additional work, ensure that you set their expectations by walking them through all the off stage workÂ needed.</p><h4>5) Run a dynamic risk assessment on the day (including semiâ€‘public spaces)</h4><p>Conditions change fast: staffing, space, local incidents, illness levels, travel disruption. Your plan needs a mechanism for responding withoutÂ stress.</p><p>And if youâ€™re observing in semiâ€‘public spaces (corridors, waiting rooms, receptions): plan for bystanders who didnâ€™t consent. Decide what you record, how you protect privacy, and when you pause or reposition.</p><h3>My template (use it and adaptÂ it)</h3><p>Iâ€™m sharing the template I now use as a default for discovery projects, user research and service design work across education, health, social care, pharmaceutical, justice, and other highâ€‘stakes environments.</p><p>Itâ€™s intentionally written as a template: youâ€™ll need to tailor it to your organisationâ€™s safeguarding policy, ethics process, and the host settingâ€™s local requirements.</p><p>If youâ€™re working with children or vulnerable adults, you should always align the plan with the host organisationâ€™s safeguarding lead and your own organisational safeguarding lead before fieldwork starts.</p><h3>Safeguarding plan template for research (andÂ design)</h3><h3>1. DocumentÂ control</h3><p>Table 1 shows the data fields that you can use for documentÂ control.</p><figure><img alt=""Screenshot of a table showing document control data fields."" src=""https://cdn-images-1.medium.com/max/1024/1*TanZZ_EDe27dSYWzyrZ7gg.png"" /><figcaption>Document control data fields. Screenshot by theÂ author.</figcaption></figure><h3>2. Purpose andÂ scope</h3><p>This plan sets out how we prevent harm, recognise distress or risk, respond to concerns (including disclosures), and learn from incidents. ItÂ covers:</p><ul><li>Participant safeguarding (physical, psychological, cultural, and digitalÂ safety)</li><li>Researcher safeguarding (physical safety, psychological wellbeing, and lone-working)</li><li>Safeguarding of third parties (people mentioned during research, bystanders, or dependents)</li><li>Data governance and reporting practices that reduce risk and re-identification</li><li>Decision-making for consent, capacity, and involving guardians or gatekeepers</li><li>How participants raise concerns/complaints after participation (include contact details on information sheets and at sessionÂ close)</li></ul><h3>3. Principles (proposed by</h3><p>We adopt a <a href=""https://www.gov.uk/government/publications/working-definition-of-trauma-informed-practice/working-definition-of-trauma-informed-practice"">trauma-informed approach</a> and embed these principles into recruitment, consent, session design, data handling, analysis, and reporting:</p><ul><li>Safety (physical and psychological)</li><li>Accessibility (physical andÂ remote)</li><li>Trustworthiness</li><li>Collaboration</li><li>Choice and transparency</li><li>Empowerment</li><li>Cultural considerations (including gender responsiveness)</li><li>Recognising where there may be a potential for reâ€‘traumatisation, and preventing it</li></ul><h3>4. Governance, roles and escalation</h3><p>Define clear accountability and an escalation path so researchers can act quickly and consistently.<br />Roles (tailor):</p><ul><li>Safeguarding Lead/Designated Safeguarding Lead (DSL): receives concerns, decides next steps, liaises with statutory services</li><li>Research Lead: ensures this plan is implemented, approves risk mitigations, overseesÂ training</li><li>Fieldwork Lead/Moderator (researcher on the ground): runs sessions, monitors distress, logs incidents</li><li>Data Lead/Data Protection Officer (DPO): ensures secure handling, minimisation, and accessÂ control</li><li>Partner/Gatekeeper Liaison: coordinates with schools/care settings/community organisations withoutÂ coercion</li></ul><p>Table 2 provides a worked example of an escalation map you can adapt and complete.</p><figure><img alt=""Screenshot of an escalation map."" src=""https://cdn-images-1.medium.com/max/1024/1*ckbc6eqQZuR9bwltcZGefQ.png"" /><figcaption>Escalation map. Screenshot by theÂ author.</figcaption></figure><h3>5. Risk assessment (before fieldwork)</h3><p>Complete a safeguarding risk assessment for the topic, participant group, methods, and setting (in-person/remote). Use the risk matrix in AppendixÂ A.</p><p><strong>At minimum,Â assess:</strong></p><ul><li>Sensitivity of topic and likelihood of triggering content</li><li>Participant vulnerability (age, disability, trauma exposure, dependency, power imbalance)</li><li>Setting risks (home visits, public spaces, care settings, online sessions)</li><li>Researcher exposure (secondary trauma, lone-working, travel, hostility)</li><li>Observers/note takers: their needs, triggers, and responsibilities (theyâ€™re part of the safeguarding environment too)</li><li>Data risks (identifiers, recordings, storage access, retention)</li><li>Thirdâ€‘party risks (information about children/dependents/others)</li><li>Language and culture as barriers to participation; plan accordingly</li></ul><p><strong>Additional in-person fieldwork risks (especially postâ€‘COVID):</strong></p><ul><li>Public health/infection-control risks (outbreaks, PPE/visitor rules, ventilation, handÂ hygiene)</li><li>Clinical/biohazard risks where applicable (follow site infection-control protocols/training)</li><li>Travel and fatigue risks (long days, commute safety, late finishes)</li><li>Environmental/neighbourhood risks (area safety, transport availability, accessibility, lone travel afterÂ dark)</li></ul><p><strong>High-security settings (prisons/secure hospitals):</strong></p><ul><li>restricted devices/recording, staff presence of in the sessions, coercion risk, emergency procedures, lockdown/incident response.</li></ul><p>Plan for a dynamic risk assessment on theÂ day.</p><h3>6. Recruitment, screening, and participation support (including incentives)</h3><p>Recruitment must be voluntary, proportionate, and designed to avoid coercion.</p><ul><li>Use plain-language invitations and information sheets</li><li>Avoid recruiting via a person with direct power over the participant where possible (manager, teacher, clinician, prison staff). If unavoidable, add safeguards to protect voluntariness.</li><li>Screen for immediate risk: if a participant is in acute crisis, signpost support and do notÂ proceed.</li><li>Plan accessible formats (easy-read, large print, multiple languages, captions)</li></ul><p>Incentives, reimbursement, and participation costs:</p><ul><li>Equity: consider reimbursement for expenses and costs of participation (including for staff, service users, or people in custody, subject toÂ policy).</li><li>Document: amount, rationale, delivery route, timing, and what personal data is required to payÂ it.</li><li>Confirm host policies: e.g., whether staff can accept gifts, and prison rules on incentives.</li><li>Document potential issues: undue influence, misrepresentation, and how youâ€™ll mitigate (neutral framing, ethical screening, optâ€‘out preserved).</li></ul><h3>7. Consent and capacity (adults, vulnerable adults, children)</h3><p>Consent is ongoing, informed, and freely given. Use staged consent for recordings, artefact review, and attribution. Reconfirm at keyÂ moments.</p><p>Operational note: donâ€™t assume digital consent will work. Bring printed packs for in-person sessions, or allow time at the start of remote sessions to complete consent. Confirm verbally and record confirmation; have a second team member witness if required.</p><p>Table 3 shows a worked example of a decision pathway that you canÂ adapt.</p><figure><img alt=""Screenshot of a decision pathway for consent and assent."" src=""https://cdn-images-1.medium.com/max/1024/1*mxrX5ynibKw3U7Cq3kghDw.png"" /><figcaption>Decision pathway for consent and assent. Screenshot by theÂ author.</figcaption></figure><p>Capacity checks (use appropriate local framework):</p><ul><li>Explain in a way the person can understand (visuals/easy read asÂ needed)</li><li>Check understanding (ask them to describe what will happen and their right toÂ stop)</li><li>If they cannot understand/retain/weigh/communicate a decision even with support, do not take consent from themÂ alone</li></ul><p>Provide complaints/concerns contact details on the info sheet and repeat atÂ close.</p><h3>8. Participant safeguarding duringÂ sessions</h3><p>Build â€œsafety by designâ€ into every touchpoint.</p><p><strong>Baseline safeguards:</strong></p><ul><li>Content warnings and a plain-language roadmap</li><li>â€œMenu of participationâ€ (topics, depth, mode, anonymity)</li><li>Choice throughout (breaks, camera off, written chat, skip questions)</li><li>Use redacted/synthetic artefacts byÂ default</li><li>Normalise opting out without explanation</li><li>Support signposting at start andÂ end</li><li>Avoid leading and probing language; also avoid pathologising terms</li><li>Close with a grounding option ifÂ useful</li></ul><p><strong>Remote-session enhancements:</strong></p><ul><li>Confirm participant is in a safe/private space; offer â€œswitch topicâ€ / â€œstop nowâ€Â phrase</li><li>Collect emergency contacts only whereÂ needed</li><li>Use secure platforms; lock meetings; manage screen-sharing/chat safely</li><li>If using an AI tool to record for later notes and analysis, inform the participant. Build that into your consentÂ forms</li><li>If remote observation is allowed, inform the participant. Itâ€™s unethical to allow a session to be watched by 10 observers via tools such as <a href=""https://info.heymarvin.com/marvin-ai-research-software-fe?utm_campaign_id=&amp;utm_term=marvin%20software&amp;utm_campaign=gs_cpc_brand_maxconv_kwds_marvin&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=2315755094&amp;hsa_cam=23058402392&amp;hsa_grp=186754625740&amp;hsa_ad=787418153179&amp;hsa_src=g&amp;hsa_tgt=kwd-344036103553&amp;hsa_kw=marvin%20software&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gad_source=1&amp;gad_campaignid=23058402392&amp;gbraid=0AAAAApcRwVqn4UhpUqzsCm0IRRpNJaX_3&amp;gclid=Cj0KCQiAgvPKBhCxARIsAOlK_EqA5zmRIA3LuPAbVm0AL8IK5ScvprJuNTXpcqAO_6Juxk3zpnMLJg4aAqxCEALw_wcB"">Marvin</a> etc, while you introduced only one observer visible to the participant on MS Teams meeting. Build this into your consent materials and consentÂ process</li></ul><h3>9. Managing distress, disclosures and safeguarding concerns</h3><p><strong>Distress script:</strong><br />â€œLetâ€™s pause here. We can take a break or switch topic. Youâ€™re in control, and itâ€™s okay to skip anything. Here are support options if youâ€™d likeÂ them.â€</p><p><strong>Disclosure script:</strong><br />â€œIâ€™m concerned this may relate to someoneâ€™s safety. I need to pass this to the safeguarding lead/DSL. Iâ€™ll note only whatâ€™s necessary and can help you contact themÂ now.â€</p><p><strong>Incident recording</strong>: minimum necessary facts, no interpretation, store securely.</p><h3>10. Researcher wellbeing andÂ safety</h3><ul><li>Pre-brief on trauma cues and de-escalation; rehearseÂ scripts</li><li>Buddy system for higher-risk sessions/field visits</li><li>Time-box sessions; cap daily exposure; rotate facilitators</li><li>Structured debriefs; document lessonsÂ learned</li><li>Access to supervision/Employee Assistance Programme (EAP); encourage micro-breaks and recoveryÂ routines</li><li>Lone-working check-in/out protocol and incident reporting</li></ul><h3>11. Data governance and reporting</h3><ul><li>Collect minimum necessary detail; avoid identifiable case narratives</li><li>Anonymise promptly; separate identifiers from researchÂ data</li><li>Use quotes and video sparingly; approve sensitive quotes where appropriate</li><li>Avoid sensational detail; focus on patterns and systemÂ insights</li><li>Secure storage; limit access on a need-to-know basis</li><li>Complete a <a href=""https://ico.org.uk/for-organisations/law-enforcement/guide-to-le-processing/accountability-and-governance/data-protection-impact-assessments/#:~:text=A%20data%20protection%20impact%20assessment%20(DPIA)%20is,The%20measures%20envisaged%20to%20address%20those%20risks"">Data Protection Impact Assessment (DPIA)</a>/privacy assessment where required and ensure <a href=""https://www.gov.uk/government/publications/accessing-ukhsa-protected-data/approval-standards-and-guidelines-privacy-notice"">privacy notice</a> is provided.</li><li>Include a data breach escalation route (lost/stolen device, accidental sharing, unauthorised access).</li></ul><h3>12. Operating rhythm: before, during, after fieldwork</h3><p><strong>Before:</strong></p><ul><li>Map triggers and design mitigations</li><li>Prepare scripts for distress and disclosure; rehearse as aÂ team</li><li>Prepare referrals pathways/support signposting</li><li>Prepare accessible materials; test with lived-experience reviewer whereÂ feasible</li></ul><p><strong>During:</strong></p><ul><li>Begin with a grounding check-in; set norms (breaks, skip-anything, stop anytime).</li><li>Monitor signs of distress; pause to check consent andÂ comfort.</li><li>If a disclosure relates to harm/risk, follow the incidentÂ pathway.</li><li>Avoid rapid-fire questioning; allow silence andÂ pacing.</li></ul><p><strong>After:</strong></p><ul><li>Offer debrief and optional follow-up</li><li>Provide support resources again</li><li>Log incidents securely; confirmÂ handover</li><li>Build in team decompression and lessons learned. Have a researchÂ retro.</li></ul><h3>13. Monitoring, review and continuous improvement</h3><p>Track adverse events and near-misses; review and update mitigations as the project evolves. Document learning for futureÂ studies.</p><h3>Appendix A: Traumaâ€‘informed riskÂ matrix</h3><p><strong>Risk entry</strong></p><ul><li><strong>Risk/trigger:</strong></li><li><strong>Who is affected:</strong> (participant/researcher/third party/organisation)</li><li><strong>Where it applies:</strong> (in-person/remote hybrid/specific setting)</li><li><strong>Likelihood:</strong> Low/Medium/High</li><li><strong>Impact:</strong> Low/Medium/High</li><li><strong>Early warningÂ signs:</strong></li><li><strong>Mitigation (before):</strong></li><li><strong>Mitigation (during):</strong></li><li><strong>Mitigation (after):</strong></li><li><strong>Owner:</strong></li><li><strong>Escalation route:</strong></li><li><strong>Residual risk:</strong></li><li><strong>Review date:</strong></li></ul><h3>Appendix B: Session startÂ scripts</h3><h4>B1) 1:1 session start script (copy/paste)</h4><p>â€œThanks for joining. Before weÂ start:</p><ul><li>You can skip any question, take a break, or stop at anyÂ time.</li><li>What you share will be treated confidentially, unless we become concerned about someoneâ€™s safety, in which case we may need to escalate via our safeguarding process. We will tell you if thatÂ happens.</li><li>With your permission, weâ€™d like to [record/take notes only]. You can change your mind at anyÂ time.</li><li>If youâ€™re receiving a thank-you for your time and participation incentive, itâ€™s not linked to what you share or whether you complete theÂ session.</li></ul><p><strong>If you have any concerns afterwards</strong>, you canÂ contact:</p><ul><li>[Research Lead name + email +Â phone]</li><li>Independent route (if available): [Ethics contact/host organisation contact]</li></ul><p>Any questions before weÂ begin?â€</p><h4>B2) Group session start script (copy/paste)</h4><p>â€œThanks for joining. Before weÂ start:</p><ul><li>You can step out, skip any question, or stop at anyÂ time.</li><li>Weâ€™ll ask everyone to respect privacy, but we canâ€™t guarantee confidentiality in a group, please share only what youâ€™re comfortable sharing.</li><li>Weâ€™ll agree group norms to keep this respectful andÂ safe.</li><li>With your permission, weâ€™d like to [record/take notes only]. You can change your mind at anyÂ time.</li></ul><p><strong>If you have concerns afterwards</strong>, you canÂ contact:</p><ul><li>[Research Lead name + email +Â phone]</li><li>Independent route (if available): [Ethics contact/host organisation contact]â€</li></ul><h3>Appendix C: Incident and nearâ€‘miss logÂ fields</h3><p><em>(Facts-first. Minimum necessary detail.)</em></p><ul><li><strong>Date/time:</strong></li><li><strong>Mode:</strong> in-person/remote /hybrid</li><li><strong>Setting label:</strong> (non-identifying name)</li><li><strong>Reported by:</strong>Â (role)</li><li><strong>What happened:</strong> (factsÂ only)</li><li><strong>Immediate actionsÂ taken:</strong></li><li><strong>Safeguarding decisionÂ made:</strong></li><li><strong>Escalation route used:</strong> (who was informed +Â when)</li><li><strong>People involved:</strong> (roles only where possible)</li><li><strong>Follow-up actions +Â owner:</strong></li><li><strong>Closure date +Â notes:</strong></li><li><strong>Learning captured/change toÂ plan:</strong></li></ul><h3>Appendix D: Fieldwork checklists</h3><h4>D1) Preâ€‘visit checklist</h4><p><strong>Safeguarding and governance</strong></p><p>â˜ Host safeguarding lead/DSL identified; host safeguarding policyÂ reviewed</p><p>â˜ Your organisationâ€™s safeguarding lead confirmed + escalation routeÂ shared</p><p>â˜ Speakâ€‘up route confirmed (including stop rule if safety is undermined)</p><p>â˜ Participant complaints/concerns route prepared (printed +Â digital)</p><p><strong>Clearance/access</strong></p><p>â˜ DBS/enhanced disclosure/vetting confirmed where required (schools, NHS, social care,Â prisons)</p><p>â˜ Insurance/indemnity confirmed for fieldwork (travel cancellation, liability, authority to pause/stop)</p><p>â˜ Site security rules confirmed (badges, escorts, prohibited items, lockdown procedures if relevant)</p><p><strong>Public health andÂ safety</strong></p><p>â˜ Ask about outbreaks/visitor restrictions/PPE expectations</p><p>â˜ Decide go/noâ€‘go threshold (when youâ€™ll reschedule orÂ pivot)</p><p><strong>Method +Â consent</strong></p><p>â˜ Consent and information pack materials prepared and sent (plain language, accessible formats, translations)</p><p>â˜ Plan for consent capture issues: include printed packs for in-person; time in-session forÂ remote</p><p>â˜ Recording/photography rules confirmed (especially in education/prisons/clinical settings)</p><p><strong>Incentives/participation support</strong></p><p>â˜ Incentive + reimbursement approachÂ approved</p><p>â˜ Host rules checked (staff gift restrictions; prison rules; voucher/cash constraints)</p><p>â˜ Delivery method + minimum data required confirmed</p><p><strong>Tech + dataÂ security</strong></p><p>â˜ Test Wiâ€‘Fi/VPN implications if on-site devices are restricted</p><p>â˜ Offline contingency ready (secure note template, approved recording route, backupÂ plan)</p><p>â˜ Device security: encryption, screen lock, storage route, deletionÂ policy</p><p><strong>Logistics</strong></p><p>â˜ Entrance details confirmed (photo/map); named contact with mobileÂ number</p><p>â˜ Travel plan + contingency (late arrival rules, cancellation trigger)</p><p>â˜ Lone-working/buddy arrangements and check-in/out timesÂ set</p><p>â˜ Interpreter booked if needed (and briefed on confidentiality + safeguarding)</p><h4>D2) On the day checklist</h4><p>â˜ Sign in; wear ID; confirm where safeguarding lead/DSL is; fire/firstâ€‘aid rules</p><p>â˜ Dynamic risk assessment completed (staffing changes, room changes, illness, incidents)</p><p>â˜ Reconfirm consent + recording rules</p><p>â˜ Restate ground rules: skip/stop anytime; confidentiality limits; complaints route</p><p>â˜ Monitor distress; pause and re-checkÂ consent</p><p>â˜ If concern arises: <strong>Stop â†’ Listen â†’ Record â†’ Report</strong> (per escalation map)</p><p><strong>High-security environments (add if applicable)</strong></p><p>â˜ Confirm escort requirements and privacy limitations</p><p>â˜ Confirm what you can/canâ€™t bring in (devices/chargers/notebooks)</p><p>â˜ Confirm whether staff presence may affect voluntariness; add opt-outÂ route</p><h4>D3) Postâ€‘visit checklist</h4><p>â˜ Securely upload notes/media to approved storage; remove local copies asÂ required</p><p>â˜ Log incidents/nearâ€‘misses; inform safeguarding lead/DSL as appropriate</p><p>â˜ Team debrief (participant wellbeing + researcher wellbeing + lessonsÂ learned)</p><p>â˜ Update risk register and safeguards based on what changed on theÂ day</p><p>â˜ Deliver incentive/reimbursements within agreed timeframe</p><p>â˜ Send participant follow-up (thanks + signposting + complaints route reminder if appropriate)</p><h3>Appendix E: Fieldwork trackerÂ fields</h3><p><em>(One entry per visit/session.)</em></p><ul><li>Date:</li><li>Setting label:</li><li>Full address (internal only):</li><li>Entrance instructions + photoÂ link:</li><li>Onâ€‘site contact (name/role) +Â mobile:</li><li>Host safeguarding lead/DSL (name/role) +Â mobile:</li><li>Who youâ€™re meeting (rolesÂ only):</li><li>Method (interview/group/observation):</li><li>Participant vulnerability flags (high-level only):</li><li>Interpreter required? (Y/N)</li><li>Recording allowed?Â (Y/N)</li><li>Device restrictions? (Y/N +Â details)</li><li>PPE/outbreak status confirmed? (Y/N +Â notes)</li><li>Travel plan + contingency:</li><li>Check-in time/check-out time:</li><li>Buddy/escalation contact:</li><li>Notes/risk flags:</li></ul><h3>Appendix F: Safety planningÂ grid</h3><p><em>(Pre-plan your â€œif this happens â†’ we do thisâ€ responses.)</em></p><ul><li><strong>If this happens:</strong> participant distressed<br /><strong>We will:</strong> pause; offer break/skip/stop; signpost; document nearâ€‘miss ifÂ needed</li><li><strong>If this happens:</strong> disclosure indicates risk of harm<br /><strong>We will:</strong> explain confidentiality limits; record minimum facts; escalate toÂ DSL</li><li><strong>If this happens:</strong> researcher feels unsafe<br /><strong>We will:</strong> end session; exit safely; buddy check-in; incidentÂ log</li><li><strong>If this happens:</strong> outbreak/illness risk escalates<br /><strong>We will:</strong> follow site rules; apply PPE; reschedule/pivot toÂ remote</li><li><strong>If this happens:</strong> tech prevents secure recording<br /><strong>We will:</strong> use approved backup plan (secure notes/approved device/reschedule)</li></ul><h3>Further resources:</h3><ul><li><a href=""https://www.tnlcommunityfund.org.uk/media/insights/documents/Trauma-informed-social-research-A-practical-guide-2021.pdf""><strong>Trauma-informed social research: a practical guide</strong></a><strong>. Fulfilling Lives South East Partnership. </strong>Great<strong> </strong>for running trauma-informed interviews, focus groups, and observations.</li><li><strong>HMPPS, </strong><a href=""https://apply-for-hmpps-research.service.justice.gov.uk/Introduction-and-Guidance""><strong>Conducting research in prisons/probation/HMPPS</strong></a><strong> (National Research Committee guidance). </strong>Practical entry point to prison research governance and application routes</li><li><strong>DfE, </strong><a href=""https://user-research.education.gov.uk/guidance/ethics-and-safeguarding/research-with-children-and-young-people""><strong>User Research Manual, Research with children and young</strong></a><strong> people. </strong>Practical, research-specific guidance on planning and running research safely with under-18s, including incentives, consent, and safeguarding.</li><li><a href=""https://www.taylorfrancis.com/books/mono/10.4324/9781003510536/practical-guide-trauma-sensitive-research-ayhan-alman""><strong>A practical guide to trauma-sensitive research: integrating trauma-informed frameworks into the qualitative research lifecycle</strong></a><strong> (2024)</strong><br /> Very on-point on how to design, run, analyse, and report qualitative research in ways that reduce re-traumatisation, including supervision and researcher wellbeing.</li><li><a href=""https://www.ncbi.nlm.nih.gov/books/NBK614417""><strong>WHO Research Ethics Online, Guideline 15: Research involving vulnerable persons</strong></a><strong>. </strong>Clear, global framing of protections without exclusion.</li><li>Also look at <strong>safeguarding plans/policies created by various universities</strong> like the ones by <a href=""https://www.london.ac.uk/about/policies/research-governance/safeguarding-policy-procedures"">University of London</a>, <a href=""https://www.imperial.ac.uk/human-resources/operational-services/compliance-and-immigration/safeguarding/safeguarding-for-research-projects"">Imperial College London</a>Â etc.</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1eba94e4d03a"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/post-covid-user-research-needs-a-revised-safeguarding-plan-1eba94e4d03a"">Postâ€‘COVID user research needs a revised safeguarding plan</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/when-your-best-work-gets-tossed-79f2e7d59c8b?source=rss----138adf9c44c---4,1767800686,When your best work gets tossed,"When your best work gets tossed

<h4>We have decades of data proving designâ€™s business value. So why do we still lose every budgetÂ fight?</h4><figure><img alt=""Abstract geometric illustration in Mondrian style with overlapping rectangles in red, blue, yellow and black, representing design frameworks and business structure"" src=""https://cdn-images-1.medium.com/max/1024/1*_wRdyx0G_yje4RDYTxkNFw.png"" /><figcaption>Generated using Midjourney</figcaption></figure><p>Iâ€™ve watched it happen too many times. You spend weeks researching, prototyping, testing. The users love it. The data backs it. Then someone in the room says â€œI donâ€™t like blueâ€ or â€œmy wife thinks this is confusingâ€ and suddenly everythingâ€™s back on the table. Design decisions get discarded like theyâ€™re optional decorations, not strategic choices backed by evidence.</p><p>In most companies Iâ€™ve worked with, design is an afterthought. Something you add after the important decisions get made. Which means when budget cuts come, when timelines compress, when stakeholders disagreeâ€Šâ€”â€Šdesign goes first. And the worst part? We stand there unable to articulate why thatâ€™s a mistake in terms anyone will listenÂ to.</p><p>Hereâ€™s what makes this infuriating: <strong>the evidence that design creates business value is unambiguous</strong>. McKinsey studied 300 publicly listed companies over five years and found that top-quartile design performers achieved <a href=""https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-business-value-of-design"">32% points higher revenue growth and 56% points higher total returns to shareholders</a>. The Design Management Institute tracked design-led companies for a decade and found they <a href=""https://fortune.com/2017/08/31/the-design-value-index-shows-what-design-thinking-is-worth/"">outperformed the S&amp;P 500 byÂ 211%</a>.</p><p>Yet design teams get cut disproportionately during layoffs. We lose budget allocation fights. We remain stuck in service organization roles while marketing and product management sit at the strategic table making decisions about what weâ€™llÂ build.</p><p>The problem isnâ€™t that design lacks value. The problem is that weâ€Šâ€”â€Šas a professionâ€Šâ€”â€Šnever learned how to prove it in language that organizations understand.</p><p>And this isnâ€™t about individual designers being bad at business. This is systemic. This is about how design professionalized, how design education evolved, and how the industry systematically failed to build business articulation capability into our DNA from theÂ start.</p><p>John Maedaâ€™s annual <a href=""https://designintech.report/"">Design in Tech reports</a> have tracked designâ€™s rise in Silicon Valley for over a decade, documenting the evolution from â€œclassical designâ€ to â€œcomputational design.â€ His 2024 report carried an urgent warning: â€œWork Transformation Is Coming FASTâ€ for design careers. Yet even as designâ€™s technical capabilities expanded, its business legitimacy remained precarious.</p><h3>We inherited a philosophy that actively opposed commercial thinking</h3><p>The roots go deeper than youâ€™d think. When Walter Gropius established the Bauhaus in 1919, he deliberately positioned design as an artistic and technical pursuit <em>opposed to</em> commercial concerns. The curriculum emphasized â€œform follows functionâ€ and workshop-based learning, but <a href=""https://novedge.com/blogs/design-news/design-software-history-the-influence-of-the-bauhaus-movement-on-the-evolution-of-design-software-and-its-lasting-legacy-in-modern-design-practices"">explicitly excluded business, history, and commercial context</a>.</p><p>This wasnâ€™t neutral. It established a professional identity centered on craft excellence and creative autonomyâ€Šâ€”â€Švalues that positioned designers as separate from commercial enterprise. When LÃ¡szlÃ³ Moholy-Nagy founded the New Bauhaus in Chicago in 1937 and Josef Albers joined Black Mountain College, they carried this DNA into American design education. The pattern replicated through Ulm, RISD, and eventually into the academic design programs that produce most professional designers today.</p><p>Mike Monteiro frames this inheritance bluntly in <a href=""https://www.designisajob.com""><em>Design Is a Job</em></a>: designers must understand theyâ€™re â€œrunning a business, not a hobby.â€ Yet this framing contradicts the very foundation of modern design education, which positioned commercial concerns as antithetical to craft excellence. While marketing departments in the 1950s-70s were learning to speak the language of ROI and revenue attribution, design schools were teaching students that commercial thinking corrupted creative integrity.</p><p>Nigel Crossâ€™s influential 1982 paper <a href=""https://en.wikipedia.org/wiki/Nigel_Cross"">â€œDesignerly Ways of Knowingâ€</a> cemented this separation by establishing design as a â€œthird cultureâ€ distinct from both sciences and humanities. While this legitimized design academically, it also reinforced our distance from business disciplines. Cross positioned design cognition as fundamentally different from analytical thinkingâ€Šâ€”â€Švaluable insight that inadvertently made cross-functional translation harder.</p><p><strong>Compare this to other professions</strong>. The <a href=""https://www.carnegiefoundation.org/about/who_we_are/our-legacy/"">Flexner Report of 1910</a> transformed medical education by standardizing training and establishing clear professional standards. The <a href=""https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1908453"">Carnegie Foundationâ€™s subsequent studies</a> of law, medicine, and engineering identified a pattern: successful professional education combines technical skill with professional identity formation that includes service, responsibility, and yesâ€Šâ€”â€ŠbusinessÂ reality.</p><p>Design education never underwent equivalent transformation. There was no Flexner Report for design. No moment of standardization that required business competency as part of becoming a professional designer.</p><p>So we learned to make beautiful things, thoughtful things, user-centered things. But nobody taught us how to defend them when someone asks â€œWhatâ€™s theÂ ROI?â€</p><p>Design educationâ€™s failure to incorporate business competency isnâ€™t new criticism. <a href=""https://jnd.org/why-design-education-must-change/"">Don Norman</a>â€Šâ€”â€Šformer Apple VP and author of The Design of Everyday Thingsâ€Šâ€”â€Šhas spent decades advocating for educational reform. In his influential 2010 essay â€œWhy Design Education Must Change,â€ Norman observed that designers often lack â€œrequisite understandingâ€ of behavioral sciences, technology, and business: â€œDesign schools do not train students about these complex issues, about the interlocking complexities of human and social behavior.â€ His 2019 <a href=""https://www.futureofdesigneducation.org/about"">Future of Design Education</a> initiative with IBMâ€™s Karel Vredenburg brought together 600+ volunteers to address the gap between <a href=""https://www.fastcompany.com/90669651/inside-don-normans-herculean-quest-to-fix-design-education"">design education</a> and professional demands. Yet as Norman noted, â€œthe vast majority of schools [remain] incredibly resistant, unable toÂ change.â€</p><figure><img alt=""Timeline comparing professionalization paths: Marketing (1950s-2010s), Product Management (1931â€“1998), Design (ongoing gap in business education)"" src=""https://cdn-images-1.medium.com/max/1024/1*9VCLeyxHTdJjROHLjdWUBw.png"" /><figcaption>Source: Author</figcaption></figure><h3>Meanwhile, marketing and product management learned the language ofÂ power</h3><p>Understanding why design gets marginalized requires looking at how other functions earned their strategic seats. The histories of marketing and product management reveal paths we havenâ€™t followed.</p><p>Marketingâ€™s strategic ascent took decades. In the 1950s, marketing existed primarily as advertising coordination. By the 1970s, marketers at companies like Procter &amp; Gamble had assumed profit-and-loss responsibilityâ€Šâ€”â€Ša critical legitimizing move that forced financial accountability. The CMO title appeared in the 1990s, and by the 2010s, <a href=""https://hbr.org/2017/07/the-evolution-of-the-cmo"">marketing led digital activities in 92% of companies</a>.</p><p>The key transition? Marketers learned to speak in revenue attribution, customer acquisition cost, lifetime valueâ€Šâ€”â€Šthe language finance already understood.</p><p>Product managementâ€™s rise is even more instructive. The role started with Neil McElroyâ€™s 1931 â€œBrand Manâ€ memo at Procter &amp; Gamble, defining someone responsible for tracking sales and driving business outcomes. When Bill Hewlett and David Packard adapted this at HP in the 1940s, they created the modern product manager as â€œvoice of the customer internally.â€</p><p>But the decisive framing came from <a href=""https://hbr.org/2017/07/the-evolution-of-the-cmo"">Ben Horowitzâ€™s 1998 memo â€œGood Product Manager/Bad Product Manager,â€</a> which positioned PMs as â€œCEO of the productâ€â€Šâ€”â€Šexplicitly claiming strategic accountability rather than coordination responsibility.</p><p>Sociologist Andrew Abbottâ€™s â€œThe System of Professionsâ€ (1988) provides the framework for understanding these trajectories. Abbott argues that professions compete over â€œjurisdictionsâ€â€Šâ€”â€Šclaims of ownership over expert knowledge. A profession gains legitimacy through diagnosis (classifying problems), inference (applying knowledge), and treatment (implementing solutions).</p><p>Marketing claimed the customer relationship jurisdiction. Product management claimed product success jurisdiction.</p><p>What jurisdiction has design claimed that executives recognize as strategically essential?</p><p><a href=""https://journals.aom.org/doi/10.5465/amr.1995.9508080331"">Mark Suchmanâ€™s legitimacy research</a> (Academy of Management Review, 1995) identifies three forms: pragmatic (â€œWhat can you do for me?â€), moral (normative approval), and cognitive (taken-for-grantedness). Cognitive legitimacy is most powerful butÂ rarest.</p><p>Marketing and product management have achieved cognitive legitimacy in most organizationsâ€Šâ€”â€Štheir presence at strategic discussions is assumed. Design remains trapped at pragmatic level, constantly having to prove immediate utility.</p><figure><img alt=""Comparison table showing Marketing, Product Management, Engineering, and Design across jurisdiction claims, metrics used, and legitimacy status"" src=""https://cdn-images-1.medium.com/max/1024/1*YZA01jEzLvsDqEuM6shK5w.png"" /><figcaption>Source: Author</figcaption></figure><h3>The metrics we use donâ€™t connect to decisions executives make</h3><p>Hereâ€™s where the disconnect gets concrete. Designers measure experience quality: task completion rates, System Usability Scale scores, Net Promoter Score, user satisfaction surveys.</p><p>These metrics measure something real. But as <a href=""https://businessofsoftware.org/talks/design-metrics-matter-jared-spool/"">Jared Spool observed</a>: â€œThe metrics out of the box didnâ€™t help us one little bit. They just created confusion.â€</p><p>The problem isnâ€™t that NPS or SUS are invalid. Itâ€™s that they exist in a different causal chain than executive decision-making. Look at the structure:</p><p><strong>Marketing:</strong> Revenue attribution â†’ Direct (clicks â†’ purchases)<br /><strong>Engineering:</strong> Delivery metrics â†’ Direct (code â†’ features)<br /><strong>Design:</strong> Experience quality â†’ <strong>Indirect</strong> (experience â†’ satisfaction â†’ loyalty â†’ <em>maybe</em>Â revenue)</p><p>Marketing demonstrates that campaign X generated Y dollars through clear attribution. Engineering demonstrates that sprint Z delivered features A, B, C. Design demonstrates that usability improved by some percentageâ€Šâ€”â€Šand then <em>hopes</em> executives connect this to business outcomes.</p><p>Design leader <a href=""https://www.petermerholz.com/blog/design-leadership-truisms/"">Peter Merholz</a> captured this fundamental tension in his Design Leadership Truisms: â€œYOU CANNOT CALCULATE AN ROI FOR DESIGN.â€ This isnâ€™t defeatismâ€Šâ€”â€Šitâ€™s acknowledgment that designâ€™s impact is diffuse, systemic, and resistant to the neat attribution models that executives expect.</p><p>Research from behavioral economics explains why this indirection kills influence. <a href=""https://www.ncbi.nlm.nih.gov/books/NBK593518/"">Kahneman and Tverskyâ€™s prospect theory</a> established that people weigh losses approximately twice as heavily as equivalent gains. <a href=""https://www.behavioraleconomics.com/resources/introduction-behavioral-economics/"">Thalerâ€™s mental accounting research</a> showed that people categorize money into different mental buckets with different decisionÂ rules.</p><p>The implication: design investments positioned as abstract improvements compete poorly against investments positioned as loss prevention or direct revenue generation.</p><p>The <a href=""https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-business-value-of-design"">McKinsey Design Index study</a> quantified this disconnect: <strong>over 40% of surveyed companies donâ€™t talk to end users during development</strong>, and <strong>less than 5% reported that their leaders could make objective design decisions</strong>. Design isnâ€™t measured with the same rigor as time and costsâ€Šâ€”â€Šand designers â€œhave not always embraced design metrics or actively shown management how their designs tie to meeting businessÂ goals.â€</p><p>Even NPS itself is crumbling. According to <a href=""https://www.cmswire.com/customer-experience/wasnt-nps-supposed-to-be-all-but-gone-this-year/"">CMSWireâ€™s 2025 analysis</a>, NPS fell from second-most popular CX metric in 2023 to eighth place in 2024. Only 23% of U.S. enterprise CX leaders now use it. The metricâ€™s critics note weak correlation to actual behavior, lack of diagnostic capability, and score volatilityâ€Šâ€”â€Šproblems that make it unreliable for executive decisions even when designers treat it asÂ gospel.</p><p>Weâ€™re speaking a language executives donâ€™t use to make decisions. And then weâ€™re surprised when our arguments donâ€™tÂ land.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*hHL2Akev5ssuu-DcrsPrPA.png"" /><figcaption>Created using Midjourney.</figcaption></figure><h3>Real layoffs reveal the cost of not knowing how to defend ourÂ worth</h3><p>The consequences manifest most visibly during organizational stress. <a href=""https://www.quarterinchhole.com/p/how-the-layoffs-have-impacted-ux"">Lawton Pybusâ€™s analysis of 2022â€“2024 tech layoffs</a>, tracking 5,521 laid-off employees across 12 companies, found that while engineers made up the largest share of layoffs in absolute numbers, <strong>when adjusted for team size</strong>, designers were cut at 1.7 times the expected rate, and researchers at three times the expected rate. In other words: design and research teams were disproportionately targeted.</p><p>The UX Collectiveâ€™s 2024 State of UX report, authored by <a href=""https://uxdesign.cc/the-state-of-ux-in-2024-enter-late-stage-ux-e9b403b67667"">Fabricio Teixeira</a> and <a href=""https://uxdesign.cc/why-designers-quit-2023-report-24dae87d7896"">Caio Braga</a>, identified what they call â€œlate-stage UXâ€â€Šâ€”â€Šcomparing the current industry state to late-stage capitalism. Their analysis of over 1,000 articles from 2023 found design characterized by â€œmarket saturation, heavy focus on financial growth, commoditization, automation, and increased financialization.â€ Designers can now only push so far when advocating for user needs against corporate influence. Matej Latinâ€™s 2023 survey of 293 designers found that 14.3% were laid offâ€Šâ€”â€Ša staggering increase from 2022, when layoffs werenâ€™t significant enough toÂ track.</p><p>Indeedâ€™s job posting data showed UX Research positions decreased <strong>89%</strong> from their 2022 peak to JanuaryÂ 2024.</p><p><a href=""https://uxdesign.cc/why-is-the-ux-job-market-such-a-mess-right-now-a-comprehensive-explanation-97d5588696fd"">Jared Spool</a>, in his January 2024 analysis â€œWhy is the UX job market such a mess right now?â€, pushed back on the myth that UX was disproportionately targeted: â€œThereâ€™s no evidence to support this. When Meta laid off 21,000 people in 2022 and 2023, a few hundred were UX peopleâ€¦ UX people were never more than a small proportion of the total people let go.â€ Yet this statistical nuance provides cold comfortâ€Šâ€”â€Šwhether designers were targeted specifically or caught in broader cuts, the result remains: design teams shrinking, roles disappearing, and a profession unable to articulate why this is strategically catastrophic.</p><p>Google Cloudâ€™s October 2025 layoffs cut 100+ design-related positions, with some design teams reduced by half. The pattern repeats: when cost-cutting pressures intensify, design becomes expendable because its contribution remains unquantified.</p><p>Iâ€™ve seen this up close. Talented designers with years of institutional knowledge, cut because nobody could articulate their business value in the thirty seconds it took finance to scan the headcount spreadsheet.</p><p><strong>Intuitâ€™s 2007 Design for Delight launch</strong> illustrates how articulation failures play out even with executive support. Founder Scott Cook invited Intuitâ€™s top 300 managers to an off-site to introduce design thinking. He delivered a five-hour PowerPoint presentation. The result: â€œPolite, yet unengaged response.â€</p><p>Then Stanfordâ€™s Alex Kazaks presented for one hour using hands-on exercises. Two-thirds of participants said most of what they learned occurred in Kazaksâ€™Â session.</p><p>The lesson: even well-intentioned design advocacy fails when it relies on abstract arguments rather than experiential demonstration and financial connection.</p><p><a href=""https://fortune.com/2017/03/20/pepsico-design-chief-mauro-porcini/"">PepsiCoâ€™s Chief Design Officer Mauro Porcini</a> (2012â€“2025) identified three phases design leadersÂ face:</p><h3><strong>Denial</strong> (â€œThe company doesnâ€™t understand that they needÂ youâ€),</h3><h3><strong>Hidden Rejection</strong> (â€œEverybodyâ€™s nice in meetings, then as soon as youâ€™re out, theyâ€™re like, â€˜Okay, letâ€™s go back to realÂ lifeâ€™â€),</h3><h3>and <strong>Occasional Leap of Faith</strong> (â€œYou find some people, the co-conspirators, that decide to bet onÂ youâ€).</h3><p>Porcini built a 400-designer team and won 1,800+ design awardsâ€Šâ€”â€Šbut only after finding executive â€œco-conspiratorsâ€ willing to champion designâ€™s strategic role.</p><p>This pattern of organizational resistance isnâ€™t unique to PepsiCo. <a href=""https://www.petermerholz.com/blog/design-leadership-is-change-management/"">Peter Merholz</a>, in his â€œFinding Our Wayâ€ podcast interviewing senior design executives, identified a consistent theme: â€œDesign leadership is change management.â€ As Katrina Alcorn, GM of Design for IBM, told him: â€œWeâ€™re change agents because all of us doing this are still part of a movement to change how businesses work, how theyÂ run.â€</p><p><strong>Appleâ€™s post-Ive trajectory</strong> reveals what happens when design loses its executive champion. After Jony Iveâ€™s 2019 departure, nearly his entire 24-person design team leftâ€Šâ€”â€ŠEvans Hankey, Tang Tan, Duncan Kerr, Jody Akana, and <a href=""https://apple.gadgethacks.com/news/apple-loses-key-ui-designer-to-meta-design-exodus-reveals/"">more than a dozen others</a>. Designâ€™s strategic position at Apple depended on Jobsâ€™s protection and Iveâ€™s access; remove those, and organizational gravity pulled design back toward service function.</p><h3>Weâ€™re speaking different languages and donâ€™t even realizeÂ it</h3><p>The communication divide operates at multiple levels. <a href=""https://www.diva-portal.org/smash/get/diva2:1671890/FULLTEXT01.pdf"">Carlileâ€™s 2002 research on knowledge boundaries</a> identifies â€œsyntactic boundariesâ€ from differences in vocabulary and protocols between professional groups. When designers say â€œuser pain pointsâ€ and executives hear vague qualitative concerns rather than quantifiable friction costs, both sides are speaking accurately from their own frameworksâ€Šâ€”â€Šand neither is communicating.</p><p>Recent data quantifies the scope: <a href=""https://fullscale.io/blog/cross-functional-collaboration-development-product-design/"">78% of organizations report significant barriers between technical departments</a>, 65% of project failures stem from poor communication between teams, and 82% of companies lack unified success metrics across departments.</p><p>Designâ€™s articulation problem exists within this broader organizational communication failureâ€Šâ€”â€Šbut weâ€™re uniquely disadvantaged because our native vocabulary diverges most sharply from financial language.</p><p><a href=""https://www.mindtheproduct.com/how-can-we-build-human-centred-products-by-kim-goodwin/"">Kim Goodwin</a>, who spent decades teaching designers stakeholder communication at Cooper, observed the deeper problem: â€œItâ€™s not about just doing great design; thatâ€™s maybe half the problem. I think thatâ€™s actually less than half the problem.â€ The other half? Understanding how decisions actually get made in organizationsâ€Šâ€”â€Šand speaking that language fluently.</p><p>Research on <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC9873534/"">boundary spanners</a> defines effective cross-functional communicators as those â€œfamiliar with the various professional vernacular and routines of different organizations.â€ This capability is learnable. But design education doesnâ€™t teachÂ it.</p><p><a href=""https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/bias-busters-when-the-question-not-the-answer-is-the-mistake"">Framing research from behavioral economics</a> explains why the direction of translation matters. Tversky and Kahnemanâ€™s work shows that identical information presented differently leads to different decisions. Loss framing proves more persuasive for action than gainÂ framing.</p><p>The implication: â€œWe improved usability by 15%â€ loses to â€œWeâ€™re losing $500K annually to poor checkout UXâ€â€Šâ€”â€Šsame reality, radically different executive response.</p><p>I learned this the hard way. Early in my career, Iâ€™d walk into stakeholder meetings armed with beautiful research findings, usability scores, user quotes. I thought the quality of the work would speak forÂ itself.</p><p>It didnâ€™t. What worked was translating those findings into their terms: â€œThis redesign will reduce support tickets by 40%, saving approximately $200K annually in customer service costs.â€ Suddenly, people listened.</p><p>The work didnâ€™t change. The languageÂ did.</p><h3>Where design actually wins shows us whatâ€™s missing everywhere else</h3><p>The counterexamples prove instructive. <a href=""https://www.hbs.edu/faculty/Pages/item.aspx?num=60141""><strong>IBMâ€™s design thinking transformation</strong></a> (2012â€“2020) under Phil Gilbert demonstrates what systematic change requires: $100+ million investment, growth from ~100 to 3,000 designers, <a href=""https://fortune.com/2017/12/22/ibm-design-thinking/"">100,000 employees certified</a> in design thinking, and product time-to-market reduction ofÂ 50%.</p><p>But Gilbertâ€™s insight was strategic positioning, not just capability building. He <a href=""https://designobserver.com/making-change-the-product-phil-gilbert-on-transforming-ibm-from-the-inside-out/"">created internal â€œbrandâ€</a> by avoiding preconceived terms: â€œI could either change 400,000 minds, or create a concept that meant nothing at IBM and define it ourselves.â€</p><p>He made design services something teams paid for, creating demand rather than mandating adoption. He secured CEO sponsorship (Ginni Rometty). He created measurement frameworks connecting to business outcomes (<a href=""https://medium.com/design-ibm/a-new-study-on-design-thinking-is-great-news-for-designers-593f71b40627"">Forrester documented 300% ROI</a>). He built organizational structures that institutionalized design influence.</p><p><strong>Airbnbâ€™s design influence</strong> stems from structural advantage: cofounders Brian Chesky and Joe Gebbia are RISD-trained designers. Design DNA existed from inception. But even Chesky admitted at Config 2023: â€œGetting design in the boardroom wasnâ€™t easyâ€¦ For 10 years, I was apologizing about how I wanted to run the company because how I really wanted to run the company was as a designer, but I didnâ€™t have theÂ nerve.â€</p><p><a href=""https://blog.experiencepoint.com/design-thinking-transforming-customer-experience-finance""><strong>Capital Oneâ€™s 2014 acquisition of Adaptive Path</strong></a> represented a different approach: acquiring external legitimacy rather than building it internally. The combination enabled systematic design integration producing measurable outcomesâ€Šâ€”â€Šincluding <a href=""https://blog.experiencepoint.com/design-thinking-transforming-customer-experience-finance"">eliminating overdraft fees</a> after user research revealed customer frustration patterns.</p><p>Industries where design holds obvious strategic position share characteristics: consumer electronics (where experience IS the product), automotive (where design commands premium pricing), luxury goods (where aesthetic value is explicitly monetized), and digital products with network effects (where engagement drives the businessÂ model).</p><p>In these contexts, designâ€™s contribution requires no translation because the causal chain is self-evident.</p><p>For the rest of us? We need frameworks.</p><figure><img alt=""A screenshot of the articleâ€Šâ€”â€Šhttps://review.firstround.com/how-design-thinking-transformed-airbnb-from-failing-startup-to-billion-dollar-business/ How Design Thinking Trasnformed AirBnB from a Failing Startup to a Billion Dollar Business."" src=""https://cdn-images-1.medium.com/max/1024/1*ciHmlRwLo6-482WAT_GZUw.png"" /><figcaption>Source: <a href=""https://review.firstround.com/how-design-thinking-transformed-airbnb-from-failing-startup-to-billion-dollar-business/"">https://review.firstround.com/how-design-thinking-transformed-airbnb-from-failing-startup-to-billion-dollar-business/</a></figcaption></figure><h3>The frameworks that actuallyÂ work</h3><p>Several approaches have emerged to bridge designâ€™s measurement gap, each with documented effectiveness.</p><p><a href=""https://www.appcues.com/blog/google-improves-user-experience-with-heart-framework""><strong>Googleâ€™s HEART framework</strong></a> structures UX measurement around <strong>H</strong>appiness, <strong>E</strong>ngagement, <strong>A</strong>doption, <strong>R</strong>etention, and <strong>T</strong>ask Successâ€Šâ€”â€Šcombined with Goals-Signals-Metrics process to connect product goals to measurable outcomes. Kerry Rodden, Hilary Hutchinson, and Xin Fu developed HEART in their 2010 CHI conference paper â€œ<a href=""https://research.google/pubs/measuring-the-user-experience-on-a-large-scale-user-centered-metrics-for-web-applications/"">Measuring the User Experience on a Large Scale: User-Centered Metrics for Web Applications</a>,â€ specifically to fill the gap between small-scale qualitative observations and large-scale automated measurement.</p><p>Google uses it internally across products. The Gmail â€œundo sendâ€ feature emerged from <a href=""https://www.lyssna.com/blog/google-heart-framework/"">happiness metrics tracking</a>.</p><p>Jared Spoolâ€™s outcome-driven metrics, detailed in his famous â€œ<a href=""https://articles.centercentre.com/three_hund_million_button/"">$300 Million Button</a>â€ case study, focus on â€œproblem-value metricsâ€â€Šâ€”â€Šquantifying UX obstacles in dollar terms. An e-commerce company identified checkout failures through usability testing, created a custom metric (â€œunrealized shopping cart value from password issuesâ€), implemented guest checkout, and recovered $300 million annually.</p><p>The metric framing transformed â€œregistration causes frictionâ€ into financial language executives understood. Spoolâ€™s principle: â€œSurface the cost of not removing obstaclesâ€Šâ€”â€Šthis gives executives a perspective about UX theyâ€™ve never hadÂ before.â€</p><p><a href=""https://www.nngroup.com/articles/calculating-roi-design-projects/""><strong>Nielsen Norman Groupâ€™s ROI framework</strong></a> attempts direct financial calculation, though they appropriately note that â€œROI calculations are strategic exercises to help you conceptualize the relative value of design projects. They are not financial projections.â€</p><p>The methodology: identify specific business metrics affected (revenue, cost savings, productivity), establish baseline and target values, calculate investment cost, project time to achieve targets, and computeÂ ROI.</p><p><strong>Les Binet and Peter Fieldâ€™s advertising effectiveness research</strong> offers lessons from a discipline that solved its measurement problem. Analyzing nearly 1,000 advertising case studies spanning 30+ years, they established frameworks that created evidential infrastructure design currently lacks.</p><p>Advertisingâ€™s effectiveness awards, shared databanks for meta-analysis, and common measurement frameworks built the credibility that designÂ needs.</p><figure><img alt=""A screenshot of Googleâ€™s Heart Framework."" src=""https://cdn-images-1.medium.com/max/1024/1*n3gKKb3K2fenolM-jZjUqA.png"" /><figcaption>Source: <a href=""https://www.appcues.com/blog/google-improves-user-experience-with-heart-framework"">https://www.appcues.com/blog/google-improves-user-experience-with-heart-framework</a></figcaption></figure><h3>What needs to change (and who needs to changeÂ it)</h3><p>The research points toward structural interventions, not individual heroism. This problem is systemic. Solutions must beÂ too.</p><p><strong>Design education must incorporate business competency as core requirement.</strong> The <a href=""https://carey.jhu.edu/explore-carey-mba/design-leadership"">Johns Hopkins/MICA Design Leadership MA/MBA</a> and <a href=""https://id.iit.edu/graduate-school/master-of-design-mba/"">IIT Institute of Design MDes/MBA</a> programs exist because the market recognizes this gap. But such programs remain exceptions.</p><p>Mainstreaming business literacy into undergraduate and bootcamp design education would address the problem atÂ source.</p><p><strong>Professional organizations must build measurement infrastructure.</strong> Shared databases of design effectiveness case studies, common metrics frameworks, longitudinal research programs would provide the evidential base we currently lack. The <a href=""https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-business-value-of-design"">McKinsey Design Index</a> and <a href=""https://fortune.com/2017/08/31/the-design-value-index-shows-what-design-thinking-is-worth/"">DMI Design Value Index</a> demonstrate the conceptâ€™s power.</p><p><strong>Designers must learn to speak both languages</strong> without abandoning native expertise. This isnâ€™t about becoming business people who do some design. Itâ€™s about developing boundary-spanning capability that research identifies as critical for cross-functional influence.</p><p><strong>Organizations investing in design must create structural legitimacy.</strong> IBMâ€™s transformation worked because Gilbert built organizational infrastructureâ€Šâ€”â€Šnot just because IBM hired designers. Design Program Offices, certification programs, embedded teams, executive sponsorship.</p><p>And for those of us in the trenches rightÂ now?</p><p>Start translating. Every design recommendation you make, every research finding you presentâ€Šâ€”â€Šask yourself: â€œHow would I frame this in terms of revenue, cost reduction, or risk mitigation?â€</p><p>It feels reductive at first. It feels like weâ€™re reducing craft to spreadsheets.</p><p>But hereâ€™s the thing: the alternative is watching your best work get discarded because someone in the room didnâ€™t like the colorÂ blue.</p><h3>The paradox we need toÂ resolve</h3><p>Jodi Rae, when creating the Design Value Index, captured designâ€™s fundamental challenge: â€œPeople who are convinced of the value of design are not interested in quantifying it. The CEOs in all of the DVI companies already understand the power of designâ€¦ Those most interested in quantifying the value of design are the financial people, which shows they donâ€™t really understand the power ofÂ design.â€</p><p>This paradox isnâ€™t inevitable. Itâ€™s the predictable outcome of a profession that built exceptional craft capability while neglecting business articulation capability.</p><p>The good news? This problem is structural, not inherent.</p><p>Marketing learned to prove ROI. Product management learned to claim strategic accountability. HR learned to speak in financial terms. Data science learned to demonstrate decisionÂ impact.</p><p>Each discipline underwent professionalization transitions that design has yet to complete.</p><p>The research suggests this transition is achievableâ€Šâ€”â€Šbut requires coordinated action: education reform, professional infrastructure, organizational change, individual development.</p><p>Weâ€™re not the cause of this problem. But weâ€™re positioned to catalyze its solution.</p><p>Designâ€™s business value is empirically demonstrated. The task now is building the professional infrastructure to articulate itâ€Šâ€”â€Što translate craft excellence into language that organizational decision-making recognizes andÂ rewards.</p><p>Because the alternative is watching another generation of talented designers get laid off while someone in finance looks at a spreadsheet and decides design is optional.</p><p>Itâ€™s not. And itâ€™s time we learned how to proveÂ it.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=79f2e7d59c8b"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/when-your-best-work-gets-tossed-79f2e7d59c8b"">When your best work gets tossed</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/same-same-but-new-ux-research-in-the-age-of-llms-36285d007845?source=rss----138adf9c44c---4,1767788015,"Same, but new: UX Research in the age of LLMs","Same, but new: UX Research in the age of LLMs

<h4>How researchers can define quality, guide prompts, and shape the value of AIÂ outputs.</h4><p>AI agents, synthetic users, deep research, staying relevant as a UX researcher can feel like a challenge that resets every week. Teams across product, design, and engineering are moving faster than ever, often powered by the same underlying AI technologies. <a href=""https://medium.com/user-experience-design-1/human-machine-responsible-ai-workflows-for-ux-research-22a5c39ac0ec"">Prompt engineering and system design have quickly become central topics across disciplines</a>, raising a familiar, and uncomfortable, question: <em>where does UX research fitÂ now?</em></p><p>My experience building LLM-based products over the past two years has led me to a clear conclusion. This moment is not the end of UX research. It is the same work we have always done, understanding people, defining value, but applied to a new class of systems. And for researchers willing to adapt, it creates an opportunity to move upstream and become more strategic than ever. As products become cheaper to build and AI spreads across nearly every workflow, teams now face a new foundational decision: how much AI should this featureÂ contain?</p><p><a href=""https://uxdesign.cc/is-your-ai-use-case-idea-really-going-to-work-7718c695e7c0"">When the answer is â€œyesâ€, and it is not always</a>, the work does not stop there. A second, equally important question follows: <em>what form should that AI take?</em> One of the most prescient frameworks in this space comes from <a href=""https://www.emcap.com/thoughts/your-success-with-generative-ai-may-come-down-to-these-ux-decisions"">Jake Saper and Jessica Cohen at Emergence Capital, who describe AI products along a spectrum</a>. On one end are pure chat-based systems that maximize flexibility. On the other are AI-enhanced features that trade flexibility for simplicity. Most production features live closer to the latter. The product defines the prompt, sometimes with light user input, and delivers the output in a predetermined format. Every â€œsummarize,â€ â€œrewrite,â€ or â€œgenerateâ€ button we encounter today reflects this tradeoff.</p><p>Delivering value with AI enhanced features means having a solid understanding of what the user is attempting to achieve within the context of their workflow both for the actual output and the design of how it is delivered. Take for example, a summarize feature. A summary can mean many different things depending on where it is being delivered. A â€œSummarizeâ€ button offered in Gmail likely needs punchy and bulleted contents. The same within Adobe acrobat for a large PDF could mean a multi paragraph executive summary. It is all about context and the actual need in the moment. The same we have always been doing butÂ new.</p><figure><img alt=""Adobe buttons for taking AI Actions"" src=""https://cdn-images-1.medium.com/max/774/1*lYL-7x1LLVuJ-LBP0ey62w.png"" /><figcaption>Adobe buttons for taking AIÂ Actions</figcaption></figure><p>NotebookLM offers a compelling example of this shift. The product began as a chat-based, retrieval-augmented system. It gained widespread attention with its audio overview feature, which generated a podcast-style summary of a userâ€™s materials, no prompting required. That feature delivered immediate, differentiated value by meeting a specific user need in a novel format. While the initial novelty has faded, subsequent updates have reinforced NotebookLMâ€™s position as a model for AI-enhanced productivity.</p><figure><img alt=""A screenshot of the NotebookLM feature including sources, the overview page, and the studio feature."" src=""https://cdn-images-1.medium.com/max/1024/1*5e0Ox6q7MpceIhZjBBiXBw.png"" /><figcaption>A screenshot of the NotebookLM feature including sources, the overview page, and the studioÂ features</figcaption></figure><p>The Studio feature set within NotebookLM illustrates the pattern particularly well. Users are presented with a set of structured options that guide them toward generating reports, briefs, or analyses. The real power lies not in unrestricted chat, but in the ability to lightly customize a pre-generated prompt. In Emergence Capitalâ€™s terms, this is a true copilot: a system that helps users provide the right input in order to receive a valuable output. When a user asks NotebookLM to generate a report, success is not defined by grammatical correctness or factual accuracy alone. Success is whether the output fits the userâ€™s actual need, whether it advances their task, supports their workflow, or deepens their understanding.</p><p>This is where the role of UX research begins to changeâ€¦ not in kind, but inÂ scope.</p><h3>A New Way to CreateÂ Value</h3><p>Creating value with LLM-based features is not about writing the cleverest prompt. It is about defining the right instructions so the system produces something that is genuinely useful to the user in that moment. Prompt quality matters, but prompts do not exist in a vacuum. They sit at the intersection of engineering, design, and, critically, research.</p><p>NotebookLMâ€™s opening chat response is a useful example. As a user logs in, the chat window is filled with an overview of all contents that helps users make sense of their materials as soon as they open a notebook, reducing the cognitive cost of re-orienting themselves. Engineering work was required to craft prompts that reliably surface the right insights. Design work was required to decide how that information should appear on the page. But neither of those efforts can succeed without first understanding what users actually need at the moment of entry. That understanding is where research does its most important work, informing both what the system should generate and how that output should be presented.</p><figure><img alt=""NotebookLM opens with a summary of the Notebooks"" src=""https://cdn-images-1.medium.com/max/1024/1*Hk912CHJxIPta3jysWeUEg.png"" /><figcaption>NotebookLM opens with a summary of the Notebooks</figcaption></figure><p><a href=""https://uxdesign.cc/ai-ux-design-for-intelligent-interfaces-bc966e96107d"">Design guidance for displaying AI-generated content is relatively well covered.</a> <a href=""https://medium.com/user-experience-design-1/search?q=ai+in+product"">Many strong frameworks already exist for structuring text, surfacing key information, and presenting outputs in ways that are readable and actionable.</a> What has received far less attention is the upstream work of shaping the instructions that guide generation in the first place. Ensuring a prompt is directionally correctâ€Šâ€”â€Šaligned to real user needs rather than abstract capabilities, was always important. With LLMs, it becomes foundational.</p><p>This is where UX research creates new leverage. By engaging early, researchers can help teams anchor feature development in what is actually possible given both the state of the technology and the userâ€™s needs in context. In my experience, this approach consistently opens up more promising product directions. Instead of retrofitting research onto an already-defined solution, teams start with a shared understanding of value, giving design and engineering a clearer target to aim for as theyÂ build.</p><h3>A New Process for Defining Quality inÂ Outputs</h3><p>For decades, UX research has focused on identifying the user needs a product must satisfy. That part of the work is unchanged. What <em>is</em> new is the nature of the systems we are designing. With large language models, teams no longer have complete control over outputs. These systems are inherently non-deterministic, we can guide them, but we cannot fully dictate what they willÂ produce.</p><p>In traditional product design, many needs could be satisfied with deterministic solutions. When Apple realized people were using their iPhones as flashlights, the solution was straightforward: a single button that produced a single, predictable outcome. One tap, immediate value. No ambiguity, no interpretation required. That model works well when the need is simple and the desired outcome isÂ clear.</p><figure><img alt=""iPhone flashlight buttons that is placed on the Lock Screen for ease of use"" src=""https://cdn-images-1.medium.com/max/1024/0*WDyogOfVTb78FQwo"" /><figcaption>iPhone flashlight buttons that is placed on the Lock Screen for ease ofÂ use</figcaption></figure><p>As needs become more complex, so does the solution. Uber faced a different problem: passengers felt anxious while waiting for their ride. The company could not control the behavior of individual drivers, so instead it designed an experience to manage uncertainty. <a href=""https://www.wired.com/story/uber-algorithm-fake/?utm_source=chatgpt.com"">A live map showed the driverâ€™s progress (although not always truthfully)</a>. Messaging explained potential delays. Contact options gave users a sense of agency. Each element addressed the same underlying issue, negative sentiment during the wait, even though the core system remained unpredictable.</p><figure><img alt=""A screen grab of a car moving toward a destination on Uber App"" src=""https://cdn-images-1.medium.com/max/800/0*SrfQbAaDBqm8Gh6H"" /><figcaption>A screen grab of a car moving toward a destination on UberÂ App</figcaption></figure><p><a href=""https://medium.com/ai-ux-designers/ai-is-breaking-free-an-emerging-ai-ux-pattern-26894a915d93"">Working with LLMs is similar, but amplified</a>. An LLM behaves less like a traditional interface and more like a human collaborator: responsive, capable, and inconsistent. It may produce insightful results one moment and confident-sounding nonsense the next. This unpredictability is not a flaw; it is a property of the technology. The challenge, then, is not eliminating variability, but maximizing output quality despiteÂ it.</p><p>That challenge requires a different approach. Rather than treating quality as an after-the-fact judgment, teams must define what â€œgoodâ€ looks like in advance, and do so in a way that acknowledges uncertainty. This is where UX research plays a central role: translating user needs into clear quality signals that can guide generation, evaluation, and ongoing refinement, even when outputs cannot be fully controlled. Here is how I got aboutÂ it.</p><h4>Surfacing QualityÂ Signals</h4><p>The first step is establishing a shared understanding of what constitutes a high-quality experience. When a user requests a briefing document in NotebookLM, what are they actually expecting to see? The answer is inherently subjective. Different users bring different expectations, shaped by their goals, context, and prior experience.</p><p>This is why qualitative research is essential. In-depth interviews allow teams to understand not just <em>what</em> users say they want, but <em>how</em> they judge AI-generated outputs in practice. I start by asking users to share what they expect to see as an output. Afterwards, I walk them through examples, either outputs they already use or ones I introduce, and have them describe what they mean when they say something â€œinforms,â€ â€œsummarizes,â€ or â€œprovides direction.â€ These conversations reveal the mental models users bring to AI systems and the tradeoffs they are willing toÂ make.</p><p>As classic Jobs to Be Done research has shown, people are rarely asking for features in the abstract, they are trying to make progress in a specific situation. The same principle applies here. With that mindset, research becomes a game of identifying the main themes in what users are asking for in theÂ output.</p><p>In the case of NotebookLM, early qualitative work might surface themes such as trust, cognitive relief, contextual relevance, and actionability. Users may not articulate all of these dimensions explicitly, but patterns emerge across interviews. A useful heuristic here is the 80/20 rule: a relatively small set of research-derived criteria can account for the majority of usersâ€™ expectations.</p><p>For example, a high-quality briefing report in Notebook might be judged on whetherÂ it:</p><ul><li>Feels trustworthy</li><li>Demonstrates understanding across multipleÂ sources</li><li>Reflects the userâ€™s currentÂ context</li><li>Connects insights to realistic nextÂ actions</li></ul><h4>Validation and Refinement</h4><p>Once core quality themes are identified, the next step is validation and refinement at scale. Surveys are particularly effective here. They allow teams to translate high-level themes into more specific, testable factors and to understand how consistently those factors matter across users and contexts. When designing these studies, I ask participants to evaluate outputs that closely resemble what the product would actually generate. Users are then asked to rate and critique those outputs, providing nuance around what makes them useful, orÂ not.</p><p>Take trust as an example. Users frequently say they want AI outputs they can trust, but trust is not a single, universal attribute. At a minimum, it implies factual correctness. Beyond that, trust is shaped by tone, length, structure, and framing, all of which vary by context. <a href=""https://medium.com/%40mariamargarida/designing-with-ai-ux-considerations-and-best-practices-5c6b69b92c4c"">An email summary should be concise and direct. An executive briefing should surface key themes and unexpected insights.</a> A call recap should highlight action items and mention relevant stakeholders. When an output matches what users expect in that situation, trustÂ follows.</p><p>Surveys help teams refine these distinctions. In the NotebookLM case, researchers might explore when users feel a pre-created executive briefing demonstrates contextual awareness and when it does not. For example, users may respond positively when recent meetings or emails are incorporated appropriately, and negatively when outdated or irrelevant documents are surfaced. This level of specificity is critical, it directly informs how prompts should be written and constrained.</p><h4>Creating a QualityÂ Rubric</h4><p>With qualitative depth and survey validation in place, the next step is synthesizing insights into a shared quality rubric. There is an immediate opportunity for the engineering team to create refinement, yet as previously suggested, it is not just about the actual output but how it is designed. As such, this rubric can become the centering focus for the entireÂ team.</p><p>A well-designed rubric defines each quality factor clearly, illustrates what good and poor outputs look like, and makes tradeoffs explicit. It allows designers, product managers, and engineers to align on what success means and how it should be evaluated. Importantly, it translates research insights into something actionable.</p><p>For prompt engineers, the rubric serves as a definition of the <strong>global maximum</strong>, the set of characteristics the system should optimize for overall. Prompt iteration can then focus on finding local maxima within that boundary, confident that improvements are aligned with real user needs rather than proxyÂ metrics.</p><figure><img alt=""Example of Metric Rubric for NotebookLM"" src=""https://cdn-images-1.medium.com/max/1024/1*r0e7MNnSxTo_jHMxDAVlug.png"" /><figcaption>EXAMPLE: NotebookLM Summary Output QualityÂ Rubric</figcaption></figure><h4>Continued Refinement</h4><p>Even with a strong rubric and well-crafted prompts, the work does not end. Many teams now rely on AI-based testing and automated evaluation to refine LLM outputs over time. Companies such as <a href=""https://www.braintrust.dev/"">BrainTrust</a> have built extensive platforms that allow product teams to test the output of their prompts at scale, across models. Leveraging these tools are far more effective when grounded in research-defined quality criteria.</p><figure><img alt=""Screenshot of the Braintrust app, showing evals at scale."" src=""https://cdn-images-1.medium.com/max/1024/1*ci85QVqGfpeeBUbeWFYSlw.png"" /><figcaption>Braintrust has an extensive automated evaluation system</figcaption></figure><p>A solid rubric ensures that synthetic user testing, automated scoring, and iterative refinement are anchored in metrics that matter to real people. Rather than optimizing loosely connected signals, teams can focus on outcomes that genuinely improve the user experience.</p><p>This ongoing refinement is especially important in a fast-moving market. User expectations are evolving quickly as the Overton window of what is possible with AI continues to shift. A bullet-point summary that felt impressive yesterday may be table stakes today, replaced by audio, visual, or personalized formats tomorrow. Quality rubrics must be revisited and updated as expectations change, creating a sustained, strategic role for UX research in keeping AI systems aligned with humanÂ value.</p><h3>UX Research as the Interpreter of HumanÂ Value</h3><p>The science of UX research has not changed. People are still complex, contextual, and inconsistent, and understanding what they need remains the core of the work. The methods have not changed either. UX researchers are still experts at learning from users, identifying patterns, and translating insight intoÂ action.</p><p>What <em>has</em> changed is the nature of the systems we are shaping. With LLM-based products, outputs are no longer guaranteed, and a new stakeholder, the prompt engineer, has entered the room. <a href=""https://uxdesign.cc/a-practitioners-journal-on-navigating-ux-in-the-age-of-ai-97f0a11e8319"">Research now has a direct line into how AI systems are instructed, evaluated, and scaled.</a> Insights no longer stop at informing interfaces or features; they define the criteria by which machine-generated work is judged as successful.</p><p>This process is not foreign to UX research, but the leverage it creates is new. By defining quality up front, researchers can shape how intelligence itself is tuned, guiding optimization, grounding automation, and ensuring that faster iteration does not come at the expense of human value. In my own work, this shift has made the field feel more relevant and more exciting than it has inÂ years.</p><p>Done well, UX research can become the discipline that defines what people want from AI systems, and holds those systems accountable to real outcomes. AI will continue to do more of the work. That is not changing. What can change is whether that work actually matters. UX research is uniquely positioned to make sure itÂ does.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=36285d007845"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/same-same-but-new-ux-research-in-the-age-of-llms-36285d007845"">Same, but new: UX Research in the age of LLMs</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4,1767702176,"If your confidence is at an all-time low in design, try this","If your confidence is at an all-time low in design, try this

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*b7RqqzAQSJn18pNskWDBXQ.jpeg"" width=""4085"" /></a></p><p class=""medium-feed-snippet"">How writing can help tackle self-confidence issues in design</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/beyond-conversations-natural-language-as-interaction-influencer-8b39ed123c39?source=rss----138adf9c44c---4,1767702078,Beyond conversations: natural language as interaction influencer,"Beyond conversations: natural language as interaction influencer

<h4>From chat to canvas to control panel: Understanding natural language interaction patterns</h4><figure><img alt=""Soft, misty background with a blurred human face profile on the right and the heading â€œNatural Language Interaction Patternsâ€ on the left, accompanied by pill-shaped labels reading Intent, Action, and Orchestration."" src=""https://cdn-images-1.medium.com/max/1024/1*GNkosiM1Eioj63cPsN-qMg.png"" /></figure><p>For much of the history of software, users had to build a mental model of the system before they could use it effectively. You learned where things lived like which menu contained which action, which screen held which information, how different parts of the interface connected to eachÂ other.</p><p>Interaction followed a structured pattern: navigate screens by clicking buttons, type into fields, scroll through content, use gestures, menus, or keyboard shortcuts to move between states. Every action required first understanding the systemâ€™s organizational logic, then locating the right control, and finally performing the correct interaction on it. Users translated what they wanted into a series of UI interactions the system understood.</p><p>While <em>affordance</em> was explicit, <em>intent</em> was indirect.</p><h3>When systems begin to understand intent</h3><p>As natural language based interaction to machine evolves, they didnâ€™t just change how we express intent, they fundamentally compress entire workflows into single expressions.</p><p>For instance, Google search transformed how we find information precisely because it eliminated the directory-browsing model of early webÂ portals.</p><figure><img alt=""Image comparing two navigation approaches. At the top, a hierarchical categories flow shows stacked panels moving left to right: Technology â†’ Software â†’ Operating System â†’ Linux, with each selection highlighted in blue and arrows indicating deeper navigation. At the bottom, a single search bar labeled â€œDirect Natural Language Searchâ€ shows the query â€œlatest news on linux OS,â€ illustrating direct access without navigating categories."" src=""https://cdn-images-1.medium.com/max/1024/1*4CH_JqrSYUIkVUtYkLu8DQ.png"" /></figure><p>The system becomes responsible for translating that intent into the underlying sequence of actions, queries, and transformations.</p><p>This transformation fundamentally changes the contract between user and tool. Traditional interfaces required users to learn the systemâ€™s language, its navigation patterns, its terminology, its organizational logic. Natural language interfaces require the system to learn the userâ€™s languageÂ instead.</p><h4>The Agent Shift: From understanding intent to executing work</h4><p>Modern AI interfaces extend this principle even further. Where Google compressed <em>navigation</em>, AI systems compress <em>action</em>, as Ben Shneiderman explores in his work on <a href=""https://dl.acm.org/doi/10.1145/3419764"">bridging the gap between ethics and practice in human-centered AI</a>.</p><p>Plus, typing into a message box in natural language to converse with a system is straightforward, much like sending a text message. This familiarity lowers the entry barrier dramatically, making powerful AI tools immediately accessible to non-experts. And made tools like ChatGPT, Claude, Gemini, Perplexity, Microsoft Copilot etc achieved mainstream adoption with remarkable speed.</p><h4>The conversation feed overloadÂ problem</h4><p>These conversation feed-based AI tools excel at expressing intent and getting relatively straightforward answers with better multi-turn controls. But the conversation feed can become overloaded when tasks involve multiple subsequent actions, require human intervention at various steps, or produce persistent artifacts that need to remain visible or outcomes become duplicative and longer. The linear nature of conversation thread often struggles to accommodate these complexities.</p><figure><img alt=""Animated GIF showing a user scrolling through a ChatGPT conversation feed in dark mode, revealing structured sections with headings, bullet points, and to convey longer message chains."" src=""https://cdn-images-1.medium.com/max/1024/1*0vGE_GTPNE1cECtP1Y2xNw.gif"" /></figure><p>Different tools are responding to thisÂ tension:</p><ul><li>Some keep everything in the chat thread, treating code and documents as just anotherÂ message</li><li>Others split the experience entirely, placing all output in a dedicated canvas</li><li>A few blend both approaches, using conversation for steering while the canvas holds theÂ work</li></ul><p>This question of AI placement in UI design, which Sharang Sharma explored in his <a href=""https://uxdesign.cc/where-should-ai-sit-in-your-ui-1710a258390e"">article</a>, becomes increasingly critical as these tools mature. The rest of this article covers observations from industry AI tools using different natural language-based interaction patterns, how they align with key aspects of interaction elements, and what we can learn if we want to build natural language-driven features, products, orÂ systems.</p><h3>Natural language as an interaction medium</h3><p>When examining natural language interfaces through the lens of interaction design, Don Normanâ€™s concept of the <a href=""https://mitpress.mit.edu/9780262525671/the-design-of-everyday-things/"">Gulf of Execution and Gulf of Evaluation</a> provides a powerful framework for understanding how interaction loop with natural language work in theseÂ tools.</p><p><em>The Gulf of Execution</em> represents the gap between what a user intends to do and the actions required to execute it in the interface.</p><p><em>The Gulf of Evaluation </em>represents the gap between what the system does and the userâ€™s understanding of thatÂ outcome.</p><figure><img alt=""Diagram illustrating Normanâ€™s action cycle with two loops. From â€œUser Goal,â€ the top execution path flows through Identify Intention â†’ Identify Actions â†’ Execute in Interface â†’ Interface. The bottom evaluation path flows from Interface Output â†’ Interpretation â†’ Evaluation back to User Goal, labeled as the Gulf of Execution (top) and Gulf of Evaluation (bottom)."" src=""https://cdn-images-1.medium.com/max/1024/1*jK0bzL1YdrRarBHK55o7nA.png"" /></figure><p>For natural language driven interaction, instead of manually identifying and executing interface actions, users express intent directly through language. The system handles the translation from intention to action to execution. Instead of piecing together what happened from interface changes, users receive feedback in natural language, visual outputs, or a combination of both, making interpretation and evaluation moreÂ direct.</p><p>However, the effectiveness of this approach depends on how the interface distributes these interactions across different spaces.</p><p>Across existing tools that Iâ€™ve come across, I notice several patterns in how natural language bridges these gulfs. Iâ€™ve summarized three of them based on where execution happens and where evaluation takesÂ place.</p><h4><strong>Pattern 1: Natural language interface as primary workspace</strong></h4><p>This pattern makes the <em>conversation itself the main workspace</em>, where the user expresses intent entirely in natural language and the system generates outputs in the same thread. It treats the chat as the central place for input, execution, and results along with persistent messageÂ history.</p><figure><img alt=""Four-panel comparison of AI assistant interfaces displayed in a grid, each showing long-form, structured responses in dark mode, including bullet points, headings, tables, and search-based results. Order of tools (top left to bottom right): ChatGPT, Gemini, Microsoft Copilot, Perplexity"" src=""https://cdn-images-1.medium.com/max/1024/1*8tCUXqcI03M3zRrcAYIrpQ.png"" /><figcaption>Side-by-side view of AI assistants: <a href=""https://chatgpt.com/"">ChatGPT</a>, <a href=""https://gemini.google.com/app"">Gemini</a>, <a href=""https://copilot.microsoft.com/"">Microsoft Copilot</a>, and <a href=""https://www.perplexity.ai/"">Perplexity</a></figcaption></figure><p>Both gulfs are bridged entirely within the same conversational space. You express what you want in the chat, the system executes, and you evaluate the results all in the same thread. The entire interaction loop lives in the conversation. Your journey can end there, or you move forward into a different tool to continue theÂ work.</p><p><strong><em>Things to be aware of</em>: </strong>Users can express broad intent easily, but they have <em>limited fine-grained control</em> over how outputs are produced, and refining results still relies on more natural language rather than precise edits. Also Piras documents <a href=""https://www.smashingmagazine.com/2024/02/designing-ai-beyond-conversational-interfaces/"">how conversational interfaces, while seemingly intuitive, introduce usability challenges</a> designers solved decades ago in GUI design. The â€œblank page problemâ€ remains acute: users often donâ€™t know what to type to get ideal output, and the burden of articulating intent shifts entirely to theÂ user.</p><h4><strong>Pattern 2: Natural language interface as contextual actionÂ block</strong></h4><p>Contextual input area, not a full chat interface. A natural language input component appears near your selection or as a menuÂ option</p><figure><img alt=""Four-panel grid showing AI-assisted creation across different tools: Figma with an â€œDescribe your editâ€ prompt, Notion with inline AI writing suggestions, Photoshop with a generative image fill prompt over a blurred image, and Wispr Flow displaying voice dictation converting speech into text."" src=""https://cdn-images-1.medium.com/max/1024/1*64GJWusQ_N1eIgdBjb3aXw.png"" /><figcaption>AI-assisted workflows across <a href=""https://www.linkedin.com/feed/update/urn:li:activity:7373707174193156096/"">Figma</a>, <a href=""https://www.notion.com/help/guides/notion-ai-for-docs"">Notion</a>, <a href=""https://www.adobe.com/products/photoshop/generative-fill.html"">Photoshop</a>, and <a href=""https://wisprflow.ai/"">WisprÂ Flow</a></figcaption></figure><p>Gulf of execution happens through language interface, but gulf of evaluation happens visually on the canvas. Thereâ€™s typically no conversation history in this space (can be stored and displayed in different interface seciton), each prompt is a fresh, contextual interaction. The canvas remains the primary work surface; natural language is just another input method within your existing workflow. This pattern often references context implicitly, bundling related information into single commands which Tang terms â€œ<a href=""https://uxdesign.cc/emerging-interaction-patterns-in-generative-ai-experiences-8c351bb3392a"">context bundling</a>â€ to reduce typing burden while preserving</p><p><strong><em>Things to be aware of</em>: </strong>Pattern 2 treats each language prompt as a discrete action command tied to the workspaceÂ . For example, â€œsummarize this selectionâ€ or â€œgenerate chart from this tableâ€. This mean the pattern often reference context implicitly. it often struggles to integrate rich external context (like files, multiple references, or tool chains) and doesnâ€™t naturally support deep follow-up refinement through languageÂ alone.</p><h4>Pattern 3: Natural language interface as controlÂ panel</h4><p>Having a persistent conversational panel alongside a workspace helps with iterative refinement and visibility of results. This dedicated chat composer provides a full, persistent conversational interface with message history. The system interprets the request, plans a sequence of actions from the converstation panel and executes them in a separate workspace</p><figure><img alt=""Four-panel screenshot showing an AI-assisted development workflow: Cursor AI editing a React/TypeScript codebase with inline suggestions, and OpenAI ChatGPT Atlas in agent mode executing tasks"" src=""https://cdn-images-1.medium.com/max/1024/1*aA7XTemjn2iJ5Hzlw80cHg.png"" /><figcaption>Agent-driven workflows using <a href=""https://cursor.com/agents"">Cursor AI </a>and OpenAI <a href=""https://chatgpt.com/atlas/"">ChatGPTÂ Atlas</a></figcaption></figure><p>Gulf of execution and gulf of evaluation are bridged across separate spaces. You execute through conversation in one space, but you evaluate by watching both the external workspace and reading feedback in the chat. This creates a supervisory relationship where the natural language interface is your control mechanism while work happens elsewhere. Users must monitor both spaces to fully understand what happened. Design principle from <a href=""https://uxdesign.cc/ai-ux-design-for-intelligent-interfaces-bc966e96107d"">article written by Basu</a> emphasize how to provide clear indicators of what the agent is doing in the background, so users feel in control even when the system is proactive. Interpretation requires synthesizing information from the workspace (seeing what changed) and the chat (reading what the system did and why). The control panel enables iteration that you can refine, redirect, or build on previous turns while the agent continues working.</p><p>Agent Advancements like Anthropicâ€™s <a href=""https://www.anthropic.com/news/3-5-models-and-computer-use"">Computer Use</a>, OpenAIâ€™s <a href=""https://openai.com/index/introducing-operator/"">Operator</a>, Googleâ€™s <a href=""https://blog.google/technology/google-deepmind/gemini-computer-use-model/"">Computer Space</a>, operates an entire computer or browser interface while you supervise from the chat panel. You provide high-level instructions (â€œbook a restaurant reservation for Fridayâ€), and the agent navigates websites, fills forms, and completes multi-step tasks. As these agents become more autonomous, the tension between letting them work and maintaining meaningful control becomes more acute, echoing the classic debate between direct manipulation and interface agents that <a href=""https://pienso.com/blog/direct-manipulation-vs-interface-agents-revisiting-the-classic-debate-decades-later"">Pienso</a> revisited in their 2024 analysis.</p><figure><img alt=""Diagram comparing three natural language interface patterns. Pattern 1 shows a single full-screen conversation area. Pattern 2 displays a canvas with a contextual input field and separate workspace. Pattern 3 illustrates a split view with a chat panel on the right and workspace on the left"" src=""https://cdn-images-1.medium.com/max/1024/1*5W0gVWTy1weWjKlAYZvXBg.png"" /></figure><p>Interaction loop can be summarized asÂ follows:</p><a href=""https://medium.com/media/dc5ca7d1bc382799e7d95e1b194822c9/href"">https://medium.com/media/dc5ca7d1bc382799e7d95e1b194822c9/href</a><p>While the three patterns above represent the primary ways natural language functions as an active interaction medium, two other common approaches exist but fall outside this framework. <em>Dedicated intent capture pages</em> like homepage or AI tool template galleries serve as short-lived entry points that help users articulate what they want before routing them to one of the three core patterns for actual work. <em>Promoted prompts as interface actions</em> like â€œImprove Writingâ€ or â€œSummarizeâ€ buttons embed common natural language instructions into traditional UI elements, removing the need for users to type. These approaches differ fundamentally because they either donâ€™t sustain the interaction (intent capture is just an entry point) or donâ€™t require active natural language input (the instruction is predefined in theÂ button).</p><h3>Reflections: How tools are built today and whatâ€™sÂ ahead</h3><p>Looking at tools launched in 2024â€“2025, most follow a familiar structure: <a href=""https://www.thirteen23.com/updates/the-prompt-box-paradox"">start with an intent capture page</a> (templates, starter prompts), then route users to either Pattern 1 for conversational tasks or Pattern 3 for agent-driven work. Pattern 2 appears as embedded features within existingÂ tools.</p><p>As tools mature, frequently-used prompts get â€œpromotedâ€ into buttons such as â€œImprove Writing,â€ â€œSummarize,â€ â€œTranslate.â€ Natural language coexists with traditional UI, reducing friction for common tasks while preserving flexibility for open-ended prompting.</p><p>This structure isnâ€™t entirely new, it mirrors how traditional software has been built for decades. Classic tools also started with an onboarding or template selection page, then moved users into the main workflow interface. The difference now is that within that workflow page, natural language acts as a new control layer, either as a control panel (Pattern 3) orchestrating work, or as an action bar (Pattern 2) augmenting existing canvas-based workflows.</p><h4>What patterns mightÂ emerge?</h4><p>As we move through 2026, one interesting question that strikes my mind is that, how will human intervention and interaction loop in these AI toolsÂ evolve?</p><figure><img alt=""Animated GIF showing a human finger and a robotic finger reaching toward each other against a cosmic sky background, symbolizing connection between humans and machines."" src=""https://cdn-images-1.medium.com/max/500/0*in9E65KC0ifJVc5V.gif"" /></figure><p>Many tools have started addressing intervention, but few experiences have become overwhelming with multiple pause points, confirmation dialogs, and approval gates. The challenge is making intervention intuitive and natural, not just possible. Also, the users need to develop an strong mental model for when to step in versus when to trust theÂ agent.</p><p>Also supervision isnâ€™t enough. The real challenge is understanding <em>how and why the agent made changes</em>, a concern central to <a href=""https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/"">Microsoft Researchâ€™s guidelines for human-AI interaction</a>.</p><blockquote>As agents become more capable, we risk creating dependency where users accomplish tasks but donâ€™t understand the underlying work.</blockquote><p>This is critical for people learning newÂ skills</p><p>When an agent generates code or modifies a design, users need to comprehend the reasoning: not just â€œlines 45â€“67 changed,â€ but â€œhereâ€™s why this approach, hereâ€™s the trade-off, hereâ€™s what else was considered.â€ Yet thereâ€™s a critical gap: agents can provide these explanations, but users still need foundational knowledge to fully grasp them. An explanation of why a particular code structure was chosen doesnâ€™t help if you donâ€™t understand fundamentals.</p><p>Without this understanding, users canâ€™t effectively intervene, correct, or extend the work. They become dependent on the agent to modify its own output.Aubergine (2025) calls this the â€œ<a href=""https://www.aubergine.co/insights/designing-for-ai-agents"">learning arc</a>â€Â problem.</p><p>By designing systems that show learning progression, users experience agents as reliable collaborators that grow alongside them, not opaque blackÂ boxes.</p><p>The next generation of interaction model needs to balance efficiency with transparency. The design goal shifts from â€œmake AI do the workâ€ to â€œhelp users understand whatâ€™s being done and how they could do it themselves,â€ addressing what researchers at CHI 2020 identified as the <a href=""https://dl.acm.org/doi/10.1145/3313831.3376301"">unique difficulties in designing human-AI interaction</a>.</p><p>As product builders, our task is to observe how these interaction patterns perform, understand where they succeed and struggle, and continue pushing toward interfaces that make powerful tools that leverages accessibility, learnability and humanÂ control.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8b39ed123c39"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/beyond-conversations-natural-language-as-interaction-influencer-8b39ed123c39"">Beyond conversations: natural language as interaction influencer</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4,1767647684,"Why you canâ€™t fix your iPhone, and how the entire tech industry learned to profit from it","Why you canâ€™t fix your iPhone, and how the entire tech industry learned to profit from it

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/822/1*swa7xccTQoC6ZAVy-MjNaA.png"" width=""822"" /></a></p><p class=""medium-feed-snippet"">What General Motors figured out in 1924, Apple perfected it with your smartphone</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4,1767615432,What good writing looks like,"What good writing looks like

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*XecumDv5a3um7nPZZzHs0w.jpeg"" width=""5668"" /></a></p><p class=""medium-feed-snippet"">The essential (micro) copy rules I used at Google.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4,1767615366,The Apple-Sony special relationship,"The Apple-Sony special relationship

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/600/0*lioyERWiSiHamScl.jpg"" width=""600"" /></a></p><p class=""medium-feed-snippet"">Getting to the bottom of why Apple products pair so naturally with Sony</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/how-the-tools-we-use-change-the-products-we-design-9117e021dac8?source=rss----138adf9c44c---4,1767615309,How the tools we use change the products we design,"How the tools we use change the products we design

<h4>â€œThe medium is the messageâ€â€Šâ€”â€ŠMarshallÂ McLuhan</h4><figure><img alt=""â€œHow the Tools We Use Change the Products we Designâ€â€Šâ€”â€Šbanner image."" src=""https://cdn-images-1.medium.com/max/1024/1*-H8x4axWhYP0QCL9rRws4w.png"" /><figcaption>Background art by Pierre-Auguste Renoir,Â 1876.</figcaption></figure><p>Every era of product design on the web brings with it new design tools, these tools change how we design websites and also influences the next generation of design tools toÂ come.</p><p>I know it seems like a novel idea for some of you reading this, you might think you design the websites you want to design and youâ€™re only limited by your imagination, but youâ€™re only half-right.</p><p>Thatâ€™s somewhat true but also youâ€™re human and all humans are lazy sometimes and we like to design websites that are easily designed and easily developed, we donâ€™t like friction, as any designer who studied UX alreadyÂ knows.</p><p>So as Marshall McLuhan once said â€œThe medium is the messageâ€, meaning that our ever-changing medium does box us into certain realities as we approach the tools for webÂ design.</p><p>In this article Iâ€™ll try to go over the different tools for designing the web as they were used in chronological order, of course some of these tools got used simultaneously so there is no cleanÂ cut.</p><p>But Iâ€™ll do my best to paint the history of web design tools in stages as I lived through them, so letâ€™sÂ begin.</p><p>First, we had plainÂ HTML.</p><h3>HTML</h3><p>Before any design tool ever existed, there was HTML, it was (and still is) the most fundamental building material of theÂ web.</p><p>When HTML was the only way to design websites we had WYSIWYG interfaces to better move around what was essentially just HTML tags like paragraphs, headings, tables andÂ images.</p><p>CSS didnâ€™t exist yet so all the styling was done inside of the actual HTML itself (remember <em>bgcolor</em>?) and the only way to center anything was to use tables and make their borders invisible.</p><p>In some ways simple HTML styling lives on today in email newsletters and passion projects but the web itself has moved on to betterÂ things.</p><p>Websites of this area were made to emphasis the tags and their aesthetics were unique with lots of GIFs, lots or background images that repeated themselves endlessly, and of course some background music to set theÂ mood.</p><p>The most well known offender in this category of early 90s websites was GeoCities, which did offer a WYSIWYG editor for everybody to use forÂ free.</p><figure><img alt=""GeoCities web editor was one of the first publicly available WYSIWYG editors."" src=""https://cdn-images-1.medium.com/max/640/0*YLJ_Xt0xreCr6UIh"" /><figcaption>GeoCities web editor was one of the first publicly available WYSIWYGÂ editors.</figcaption></figure><figure><img alt=""Netscape Composer live edits, image from Pier-Luc Braultâ€™s Blog."" src=""https://cdn-images-1.medium.com/max/1024/0*83CyO7vFFtTOROrC.png"" /><figcaption>Netscape Composer live edits, image from Pier-Luc Braultâ€™s BlogÂ (<a href=""https://plbrault.com/blog-posts/i-used-netscape-composer-in-2024/"">Link</a>)</figcaption></figure><p>Websites of that era were built for Netscape or later for Internet Explorer, nobody ever tried to make their websites cross compatible and they all just worked sometimes.</p><p>These compatibility issues often occurred while using specific tags (that arenâ€™t in use anymore) like lots of <em>marquee</em> tags, <em>framesets</em>, <em>blink</em> tags andÂ more.</p><p>Those were visually unique but ultimately were deprecated for accessibility and/ or security reasons, so we could only find them in early web designÂ relics.</p><p>Speaking of security concerns, then cameÂ Flash</p><h3>Flash</h3><p>When Macromedia Flash (laterâ€Šâ€”â€ŠAdobe Flash) became the standard tool everyone was both a designer and a developer, Flash had its own scripting language called <a href=""https://en.wikipedia.org/wiki/ActionScript""><em>ActionScript</em></a> and itâ€™s own animation-driven interface.</p><p>As a result people started replacing their entire websites with Flash sites, these sites were very animated and very tailored to their needs, no more templates and no more copying HTML tags from one another (Flash sites were nutritiously closed offâ€Šâ€”â€Šunlike HTML â€œ<em>view source</em>â€Â feature)</p><p>Flash transformed the web more than any other tool, it made the entire web dependent on its proprietary technology, it made us all developers and animators, and sometimes even game designers.</p><p>As a result those sites were often bloated, since optimization was optional, and they were very unfriendly to SEO, since it was all closedÂ off.</p><figure><img alt=""Newgrounds landing page from the early 2000s."" src=""https://cdn-images-1.medium.com/max/640/0*6Uw-fXM3AN3_hkeX.jpg"" /><figcaption>Newgroundsâ€Šâ€”â€ŠIf you know, youÂ know.</figcaption></figure><p>But the Flash era was the most creative the web had even been, Flash websites could do pretty much anything we could imagine, Flash games were also a big thing in the mid-2000s, see Newgrounds websiteÂ above.</p><p>Flash is still alive in the form of Adobe Animate, but today itâ€™s less geared towards websites, since the web had moved onâ€Šâ€”â€Špartly since the web moved to a mobile firstÂ web.</p><p>Flash websites were bloated and had security issues but above all else: they werenâ€™t responsive enough to survive in the mobile internet era, when screen real estate and battery life were much moreÂ scarce.</p><p>I encourage everyone to read â€œ<a href=""https://web.archive.org/web/20170615060422/https://www.apple.com/hotnews/thoughts-on-flash/"">Thoughts on Flash</a>â€ by Steve Jobs, it sums the problems with Flash on mobile devicesÂ nicely.</p><h3>Photoshop / Illustrator</h3><p>Photoshop and Illustrator are both Adobe products, they werenâ€™t new at this point but the industry defaulted to them when Flash was on its deathbed.</p><p>When Flash was no longer the dominant design tool for the web, nothing could really fill its place, so the industry moved on to the tools that were already proven to stickÂ around.</p><p>This era of web design felt especially static, as designers only designed Desktop and Mobile websites, with often nothing in between, keep in mind that iPads werenâ€™t a thing yet and/ or just cameÂ out.</p><figure><img alt=""An Illustrator-designed website, it was never great."" src=""https://cdn-images-1.medium.com/max/720/0*3aY-7j9JtQ37VdXa"" /><figcaption>An Illustrator-designed website, it was neverÂ great.</figcaption></figure><p>Everything was done manually using hard labor, no automation, no tools to make the process any easier, certainly no specialized toolsÂ yet.</p><p>Photoshop and Illustrator are general purpose softwareâ€Šâ€”â€ŠPhotoshop is for editing images and Illustrator is for editing vector shapes, none of them were made for web design specifically.</p><p>As a result they had many tools that were irrelevant to Product Design and many relevant tools wereÂ missing.</p><p>These relevant/ irrelevant tools were the blueprint for the next generation of tools, that built upon the workflow of Photoshop/ Illustrator and decided what tools to include and what tools toÂ exclude.</p><p>Photoshop and Illustrator as web design tools were never great tools for the job, but they were great at being placeholders until some more specialized toolsÂ arrived.</p><h3>Sketch</h3><p>Sketch, for many designers, was just thatâ€Šâ€”â€Ša new tool built from the ground up for Product Design (or UI Design, as it was called then). Sketch didnâ€™t have the bloat Photoshop and Illustrator had since it was purposeÂ built.</p><figure><img alt=""Sketch circa 2017, image from Newbird"" src=""https://cdn-images-1.medium.com/max/1024/0*LduuUHZW42-rfbQ5.jpeg"" /><figcaption>Sketch circa 2017, image from NewbirdÂ (<a href=""https://newbird.com/digital-design-tool-review-sketch-app/"">Link</a>)</figcaption></figure><p>The application itself and the tools in it were lean and were exactly what users wanted. I didnâ€™t get into Sketch although a lot of my friends and colleagues did. Sketch was (and still is) a Mac only application so I knew it canâ€™t be the tool of theÂ future.</p><p>There were entire industries built on Windows PCs and the Mac-only Sketch were making a lot of problems in their pipelines, for example: the gaming industry, the data security industry, AR &amp; VR (at the time), the banking industryÂ etc.</p><p>Sketch did a lot of things right but eventually the one thing it did was making the entire design industry reconsider the tools theyÂ use.</p><p>Sketch walked so Figma couldÂ run.</p><h3>Figma</h3><p>Figma wasnâ€™t just a cross-platform version of Sketch, Figma took the formula that Sketch made of lean and precise design tool specifically made for UI design and expanded uponÂ it.</p><figure><img alt=""Figma in 2019, image from OneSignal"" src=""https://cdn-images-1.medium.com/max/1024/0*bd9eOPG0mhlINjkR.jpg"" /><figcaption>Figma in 2019, image from OneSignal (<a href=""https://onesignal.com/blog/designing-with-figma/"">Link</a>)</figcaption></figure><p>It was a new kind of toolâ€Šâ€”â€Šit was an online first tool, Figma was available from your browser, without any installation (when it did that, it was all new and exciting, I know today itâ€™s moreÂ common).</p><p>Since it was all online, Figma files could also be shared and worked on together, Figma had the most advanced â€œmultiplayerâ€ tools Iâ€™ve ever seen, which meant designers can work together on the same design file and in the same time, since it was allÂ online.</p><p>Think of Google Docs, you can also edit the same file in Google Docs, or the same code in a Git repository, for example, but Figma brought the same philosophy into a design tool and since then many tools tried to do theÂ same.</p><p>Since Figma tried to be lean (much like Sketch before it), many tools were dropped in the process, no more photo editing tools, limited filters, limited Motion Design tools, no 3D toolsÂ etc.</p><p>On the other side many new tools were introduced, responsive design controls for every frame, a prototyping tool and auto-layout controlsâ€Šâ€”â€Šjust to name aÂ few.</p><figure><img alt=""An example of responsive design in Figma."" src=""https://cdn-images-1.medium.com/max/610/0*LTf-cs6mmbWU2up_.png"" /><figcaption>An example of responsive design inÂ Figma.</figcaption></figure><p>Still, Figma was very â€œflatâ€ looking by design and more detailed work was harder to achieve, many still used Adobe Illustrator or Photoshop for detail design and many just gave up and embraced the flatness.</p><p>Since advanced Motion, Animations or working with 3D elements is virtually impossible in Figma and as a result, those elements are very rare to see in the webÂ today.</p><p>I would argue that to this day, features like Motion Design and 3D work are still missing since they werenâ€™t present in the original catch-all tools Photoshop/ Illustrator and as a result they are still missing from FigmaÂ today.</p><p>Just to be clearâ€Šâ€”â€ŠI am not against any of it, I like flat design and I think intelligent design can be done in any style and in any medium, regardless of the rendered output, when I say â€œ<em>flat</em>â€ I donâ€™t mean it as a criticismâ€Šâ€”â€Šjust as a visual observation.</p><h3>Closing words</h3><p>From no tools for design, through WYSIWYG and Flash, Photoshop/ Illustrator, Sketch and of course Figma it was quite aÂ ride.</p><p>The tools change not only <strong>how</strong> we design interactive websites but <strong>what</strong> we design as well, including how they look, how they work and how the users experience them. No website is made in aÂ vacuum.</p><p>We can clearly see how the tools of each era influenced the design of the websites below, they are all promotional websites that were designed when the movie released.</p><figure><img alt=""Space Jam official movie website, 1996."" src=""https://cdn-images-1.medium.com/max/544/0*oGSAc-WnPMYG5AfQ.png"" /><figcaption>Space Jam official movie website,Â 1996.</figcaption></figure><figure><img alt=""What is The Matrixâ€Šâ€”â€Šofficial movie website, 1999."" src=""https://cdn-images-1.medium.com/max/830/1*vkyS5ePhZTj81kAdPnRkcw.png"" /><figcaption>What is The Matrixâ€Šâ€”â€Šofficial movie website,Â 1999.</figcaption></figure><figure><img alt=""John Wick official movie website, 2014."" src=""https://cdn-images-1.medium.com/max/1024/1*l9mstz6xGkAUQPbJUKETNA.png"" /><figcaption>John Wick official movie website,Â 2014.</figcaption></figure><p>The first example (Space Jam) used HTML and WYSIWYG tools and the result is a more fined version of GeoCities websites, with the repeated background image and the secluded elements.</p><p>The Matrix example was done in the era of Flash and it has many TVs showing small clips from the movie, notice how they donâ€™t really design a UI but they design a â€œworldâ€ you can goÂ visit.</p><p>The Last exampleâ€Šâ€”â€ŠJohn Wick is modern design that was probably done with Figma, it is highly reusable, probably using the same template as any other movie and it is a UI with text, titles, menu and even a video in a rectangular shape, how long have we comeÂ indeed.</p><p>It can be said that any creative industry is bound to change, the history of painting and art in general is full of these examplesâ€Šâ€”â€Šhow the invention of oil colors gave a way to the renaissance masters to shine, how watercolors freed the impressionists from their studio to go paint outside and soÂ on.</p><figure><img alt=""Finally out of the studio and into the bar. Ã‰douard Manet, 1882."" src=""https://cdn-images-1.medium.com/max/1024/1*rGPrXfoPO83Pq7RuSWsThg.jpeg"" /><figcaption>Finally out of the studio and into the bar. Ã‰douard Manet,Â 1882.</figcaption></figure><p>As Marshall McLuhan proclaimed more than 60 years ago: â€œThe medium is the messageâ€ and it is much more pronounced in any technological field since technological tools change all theÂ time.</p><p>No one can predict the future. However Iâ€™m pretty sure that the tools will keep evolving and Figma wonâ€™t be the end-all for ProductÂ Design.</p><p>Thank you for ReadingÂ ğŸ™</p><h3>Resources</h3><p><a href=""https://www.webdesignmuseum.org/web-design-history"">Web Design History Timeline</a> / Web DesignÂ Museum</p><p><a href=""https://edenvidal.medium.com/a-brief-history-of-web-design-tools-9a75aff2d861"">A Brief History of Web Design Tools and the Original Sin</a> / EdenÂ Vidal</p><p><a href=""https://www.digitalimpactmarketers.com/ahistoryofwebdesign"">A History of Web Design: From Notepad to AI (1998â€“2025)</a> / DigitalÂ Impact</p><p><a href=""https://www.webdesign-inspiration.com/blog/web-design-history-evolution"">The History and Evolution of Web Design (Timeline)</a> / WebDesign Inspiration</p><h4>Links in thisÂ article</h4><p><a href=""https://plbrault.com/blog-posts/i-used-netscape-composer-in-2024/"">I Used Netscape Composer in 2024</a> / Pier-LucÂ Brault</p><p><a href=""https://newbird.com/digital-design-tool-review-sketch-app/"">Sketch App Review</a> /Â Newbird</p><p><a href=""https://onesignal.com/blog/designing-with-figma/"">How to Design with Figma</a> / OneSignal</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9117e021dac8"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/how-the-tools-we-use-change-the-products-we-design-9117e021dac8"">How the tools we use change the products we design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/algorithmic-atelier-escaping-ai-sludge-vibe-code-for-pms-10-ux-shifts-for-2026-75d9d3d72a6c?source=rss----138adf9c44c---4,1767615241,"Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026","Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://uxdesign.cc/the-algorithmic-atelier-4f3db0837136""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*8QiJgXx_a2zv-cQB.png"" /></a></figure><p>â€œTo understand this moment, we must contextualise AI within the history of artistic tools and conceptual shifts, while simultaneously confronting the very real socio-economic and ethical challenges it poses to the creative ecosystem.â€</p><p><a href=""https://uxdesign.cc/the-algorithmic-atelier-4f3db0837136""><strong>The algorithmic atelier</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/3ae8d4237762"">JoshuaÂ Leigh</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/from-hcd-to-hcd-what-i-learned-from-don-norman-24a3cdf79c4c""><strong>What I learned from Don Norman</strong></a><strong> â†’</strong><br />From HCD to HCD+.<br />By <a href=""https://medium.com/u/17dab133f2ba"">DarrenÂ Yeo</a></li><li><a href=""https://uxdesign.cc/reliability-by-design-designing-trustworthy-ai-for-healthcare-products-13a078d53bb0""><strong>Reliability by design</strong></a><strong> â†’</strong><br />Designing trustworthy AI for healthcare products.<br />By <a href=""https://medium.com/u/594e163637c3"">AurÃ©lieÂ Radom</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*T50ZuGOMCqpSCILg.png"" /></a></figure><p><a href=""https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/?ref=sidebar""><strong>Vibe coding a bookshelf with Claude Code</strong></a><strong>Â â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://miguelcarranza.es/cto-year-8?ref=sidebar""><strong>My role as a founder CTO: year eight</strong></a><strong> â†’</strong><br />â€œThere are courses promising millions if you learn to build apps, turning app development into what drop shipping was a few years ago. We were forced to quickly adapt and expand our definition of developer. We went from helping developers make more money, to helping apps make more money, and eventually to helping vibe coders make moreÂ money.â€</li><li><a href=""https://alearningaday.blog/2025/12/27/fall-in-love-with-your-new-reality/?ref=sidebar""><strong>Fall in love with your new reality</strong></a><strong> â†’</strong><br />â€œSometimes our role in life isnâ€™t to judge somethingâ€Šâ€”â€Šit is to figure out how to fall in love with it, especially when it becomes part of our new reality. The other day, I was in a conversation where someone was describing their new commute. The question that came up was, â€˜Do you like it?â€™ And of course, the natural instinct is to evaluate it: I donâ€™t like this part, I donâ€™t like that part,Â etc.â€</li><li><a href=""https://www.smashingmagazine.com/2025/12/how-design-for-with-deaf-people/?ref=sidebar""><strong>How to design for (and with) Deaf people</strong></a><strong> â†’</strong><br />â€œDeafness spans a broad continuum, from minor to profound hearing loss. Around 90â€“95% of deaf people come from hearing families, and deafness often isnâ€™t merely a condition that people are born with. It frequently occurs due to exposure to loud noises, and it also emerges with age, disease, and accidents.â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*PfJxlbwdVQVY535w.png"" /></a></figure><p><a href=""https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458""><strong>Escaping AI sludge</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/e140b6f5f08a"">JamesÂ Skinner</a></p><figure><a href=""https://uxdesign.cc/design-for-the-nose-6c5037f67ed8?sk=fb275baca0f69180f0628bab15843ee4""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*HJNisIxxpJabO3E2.png"" /></a></figure><p><a href=""https://uxdesign.cc/design-for-the-nose-6c5037f67ed8?sk=fb275baca0f69180f0628bab15843ee4""><strong>Design for the nose</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/b95d4ccb538e"">Rita Kind-Envy</a></p><figure><a href=""https://medium.com/design-bootcamp/the-history-of-radial-menus-in-video-games-e6968bb1bac6""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*N9z9JH0beTquht1p.png"" /></a></figure><p><a href=""https://medium.com/design-bootcamp/the-history-of-radial-menus-in-video-games-e6968bb1bac6""><strong>The history of radial menus in video games</strong></a> â†’<br />ByÂ <a href=""https://medium.com/u/34ec66185b3"">Barbesz</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/how-pms-can-vibe-code-to-build-stronger-requirements-11faeedb5274""><strong>Vibe code for PMs</strong></a><strong> â†’</strong><br />Leveraging AI to build stronger product requirements.<br />By <a href=""https://medium.com/u/ba6349c9c628"">ChrisÂ Butler</a></li><li><a href=""https://uxdesign.cc/a-nano-banana-with-color-theory-da9608277e4e?sk=6bcc8c9a5863877eadf28d4ec5a6e513""><strong>A NanoBanana with color theory</strong></a><strong> â†’</strong><br />Using Gemini to build an Accessible Perceptual Uniform Triad.<br />By <a href=""https://medium.com/u/bac2b370b37f"">Theresa-Marie Rhyne</a></li><li><a href=""https://uxdesign.cc/10-ux-design-shifts-you-cant-ignore-in-2026-8f0da1c6741d""><strong>10 UX design shifts</strong></a><strong> â†’</strong><br />Trends you canâ€™t ignore in 2026.<br />By <a href=""https://medium.com/u/2bea45f96a95"">ArinÂ Bhowmick</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-lab4"">this weekâ€™s sponsor</a> to support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=75d9d3d72a6c"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/algorithmic-atelier-escaping-ai-sludge-vibe-code-for-pms-10-ux-shifts-for-2026-75d9d3d72a6c"">Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
