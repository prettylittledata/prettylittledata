source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/designer-guide-eco-friendly-interfaces/,1771840800,A Designerâ€™s Guide To Eco-Friendly Interfaces,"A Designerâ€™s Guide To Eco-Friendly Interfaces

Every high-resolution hero image, autoplay video, and complex JavaScript animation carries a cost. Sustainable UX challenges the era of â€œunlimited pixelsâ€ and reframes performance as responsibility. In 2026, truly sophisticated design is defined not by how much it adds, but by how thoughtfully it reduces its footprint."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/designing-streak-system-ux-psychology/,1771426800,Designing A Streak System: The UX And Psychology Of Streaks,"Designing A Streak System: The UX And Psychology Of Streaks

What makes streaks so powerful and addictive? To design them well, you need to understand how they align with human psychology. Victor Ayomipo breaks down the UX and design principles behind effective streak systems."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/building-empathy-centred-ux-framework-mental-health-apps/,1770994800,Building Digital Trust: An Empathy-Centred UX Framework For Mental Health Apps,"Building Digital Trust: An Empathy-Centred UX Framework For Mental Health Apps

Designing for mental health means designing for vulnerability. Empathy-Centred UX becomes not a â€œnice to haveâ€ but a fundamental design requirement. Hereâ€™s a practical framework for building trust-first mental health products."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/designing-agentic-ai-practical-ux-patterns/,1770814800,"Designing For Agentic AI: Practical UX Patterns For Control, Consent, And Accountability","Designing For Agentic AI: Practical UX Patterns For Control, Consent, And Accountability

Autonomy is an output of a technical system. Trustworthiness is an output of a design process. Here are concrete design patterns, operational frameworks, and organizational practices for building agentic systems that are not only powerful but also transparent, controllable, and trustworthy."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/css-scope-alternative-naming-conventions/,1770278400,CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions,"CSS <code>@scope</code>: An Alternative To Naming Conventions And Heavy Abstractions

Prescriptive class name conventions are no longer enough to keep CSS maintainable in a world of increasingly complex interfaces. Can the new `@scope` rule finally give developers the confidence to write CSS that can keep up with modern front ends?"
rss,smashingmagazine.com,https://smashingmagazine.com/2026/02/combobox-vs-multiselect-vs-listbox/,1770112800,Combobox vs. Multiselect vs. Listbox: How To Choose The Right One,"Combobox vs. Multiselect vs. Listbox: How To Choose The Right One

Combobox vs. Multi-Select vs. Listbox vs. Dual Listbox? How they are different, what purpose they serve, and how to choose the right one. Brought to you by <a href=""https://ai-design-patterns.com"">Design Patterns For AI Interfaces</a>, **friendly video courses on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/desktop-wallpaper-calendars-february-2026/,1769850000,"Short Month, Big Ideas (February 2026 Wallpapers Edition)","Short Month, Big Ideas (February 2026 Wallpapers Edition)

Letâ€™s make the most of the shortest month of the year with a new collection of desktop wallpapers that are sure to bring a smile to your face â€” and maybe spark your creativity, too. All of them were designed with love by the community for the community and can be downloaded for free. Happy February!"
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/practical-use-ai-coding-tools-responsible-developer/,1769778000,Practical Use Of AI Coding Tools For The Responsible Developer,"Practical Use Of AI Coding Tools For The Responsible Developer

AI coding tools like agents can be valuable allies in everyday development work. They help handle time-consuming grunt work, guide you through large legacy codebases, and offer low-risk ways to implement features in previously unfamiliar programming languages. Here are practical, easy-to-apply techniques to help you use these tools to improve your workflow."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/unstacking-css-stacking-contexts/,1769508000,Unstacking CSS Stacking Contexts,"Unstacking CSS Stacking Contexts

In CSS, we can create â€œstacking contextsâ€ where elements are visually placed one on top of the next in a three-dimensional sense that creates the perception of depth. Stacking contexts are incredibly useful, but theyâ€™re also widely misunderstood and often mistakenly created, leading to a slew of layout issues that can be tricky to solve."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking â€œPixel Perfectâ€ Web Design,"Rethinking â€œPixel Perfectâ€ Web Design

Amit Sheen takes a hard look at the â€œPixel Perfectâ€ legacy concept, explaining why itâ€™s failing us and redefining what â€œperfectionâ€ actually looks like in a multi-device, fluid world."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designerâ€™s Career Paths In 2026,"UX And Product Designerâ€™s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,uxdesign.cc,https://uxdesign.cc/ai-writes-the-code-and-humans-still-write-the-rules-a2058ca0734c?source=rss----138adf9c44c---4,1772032365,AI writes the code and humans still write the rules,"AI writes the code and humans still write the rules

<h4>How Lovable, Cursor, and Bolt are rewriting who gets to build softwareâ€Šâ€”â€Šand the hidden costs nobody is talkingÂ about.</h4><figure><img alt=""An infographic mapping the AI code platform landscape in 2026, showing seven tools including Cursor, Copilot, and Claude Code orbiting a central AI model, with market stats, user types, and a note that humans remain the source of everything AI can do"" src=""https://cdn-images-1.medium.com/max/1024/1*E4ologEpmBZBJICSFT2C7w.png"" /><figcaption>Lovable hit $100M revenue in 8 months (Source: <a href=""https://www.cbinsights.com/research/report/coding-ai-market-share-december-2025/""><strong>CB Insights</strong></a>).</figcaption></figure><figure><img alt=""Four key statistics displayed in a horizontal layout: â€œ82%â€Šâ€”â€ŠDevelopers using AI tools daily,â€ â€œ41%â€Šâ€”â€ŠOf all code is AI-assisted,â€ â€œ$7.4Bâ€Šâ€”â€ŠMarket size in 2025,â€ and â€œ130+â€Šâ€”â€ŠActive platforms globally.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*TvZQtM-C4oFxvhoGpQ17lQ.png"" /></figure><p>A quarter of all YC startups now ship code thatâ€™s 95% AI-written. And somewhere in Silicon Valley, a 22-year-old with no CS degree just launched an app used by 40,000 peopleâ€Šâ€”â€Šwithout writing a single line. Hereâ€™s the full, unfiltered story of whoâ€™s building the future, whatâ€™s working, whatâ€™s failing, and what it allÂ means.</p><h3>The vibe codingÂ uprising</h3><p>In February 2025, AI pioneer Andrej Karpathy coined a phrase that sent shockwaves through software communities worldwide: â€œvibe coding.â€ He described it as â€œfully giving in to the vibes, embracing exponentials, and forgetting that the code even exists.â€ At the time, many professional developers rolled their eyes. Six months later, they were using it themselves.</p><p>The term captured something genuinely unprecedented: a new generation of tools that let anyoneâ€Šâ€”â€Šdesigners, marketers, founders, studentsâ€Šâ€”â€Šdescribe an app in plain English and watch it get built in real time. No compiler knowledge. No debugging in terminals. No Stack Overflow. Just a conversation with a machine that buildsÂ things.</p><p>What happened next defied almost every prediction. Lovable, a Stockholm-based startup launched in early 2024, reached $100M in annual recurring revenue in under 8 monthsâ€Šâ€”â€Šone of the fastest ARR trajectories ever recorded in enterprise software history. <em>(Source: </em><a href=""https://www.cbinsights.com/research/report/coding-ai-market-share-december-2025/""><strong><em>CB Insights</em></strong></a><em>)</em></p><blockquote><strong>Replit</strong> went from $10M to $100M ARR in 9 months after launching its AI Agent. Cursorâ€™s parent company Anysphere crossed a $9.9 billion valuation by June 2025. The AI coding platform market was valued at $7.37 billion in 2025 alone, on track to hit nearly $24 billion byÂ 2030.</blockquote><h4>Timeline of the explosion</h4><p><em>(Source: </em><a href=""https://www.ycombinator.com/blog/""><strong><em>Y Combinator Blog</em></strong></a><em>)</em></p><blockquote><strong>Feb 2025â€Šâ€”â€ŠKarpathy invents â€œvibe codingâ€</strong> The term goes viral. Non-technical founders start flooding AI builder platforms. YC CEO Garry Tan calls it â€œthe dominant way toÂ code.â€</blockquote><blockquote><strong>March 2025â€Šâ€”â€ŠYC drops its bombshell</strong> 25% of Winter 2025 YC startups reveal 95% of their codebase is AI-generatedâ€Šâ€”â€Šby highly technical founders who could have coded it themselves. The industryÂ gasps.</blockquote><blockquote><strong>April 2025â€Šâ€”â€ŠGuardio Labs sounds the alarm</strong> Security researchers find critical â€œVibeScammingâ€ vulnerability: malicious prompt injection can trick AI builders into generating backdoors. 170 of 1,645 Lovable-created apps are found to have security vulnerabilities exposing userÂ data.</blockquote><blockquote><strong>May 2025â€Šâ€”â€ŠOpenAI acquires Windsurf for $3B</strong> The biggest signal yet that Big Tech is treating AI coding as a core battleground. Microsoft, Google, Amazon, and IBM all accelerate competing products.</blockquote><blockquote><strong>July 2025â€Šâ€”â€ŠThe METR study shocks developers</strong> A rigorous independent study finds experienced developers using AI tools took 19% longer to complete complex tasksâ€Šâ€”â€Šdespite believing they were 20% faster. The perception-reality gap isÂ stark.</blockquote><blockquote><strong>Dec 2025â€Šâ€”â€ŠThe $4B market crystallizes</strong> CB Insights confirms three playersâ€Šâ€”â€ŠGitHub Copilot, Claude Code, and Anysphereâ€Šâ€”â€Šnow hold 70%+ of the coding AI agent market. All have crossed $1BÂ ARR.</blockquote><h3>Meet the platforms: A fieldÂ guide</h3><p>There are now over 130 active players in the AI coding platform space. But the real action clusters around a handful of names that keep appearing in developer Slack channels, Reddit threads, and YC pitch decks. Here is what they actually are, who built them, and what their real numbers lookÂ like:</p><h4><strong>Lovable</strong>â€Šâ€”â€ŠNo-codeÂ king</h4><p>Stockholm-born. Built for non-technical founders. Describe your app in plain English; Lovable builds a full-stack React + Supabase app with shareable URL, GitHub sync, and one-click deploy. The go-to for solopreneurs validating startup ideas. The fastest-growing platform in the space. <br /><strong>$200M ARR</strong>â€Šâ€”â€Štargeting $1B by summerÂ 2026</p><h4><strong>Cursor</strong>â€Šâ€”â€ŠDev powerÂ tool</h4><p>Made by Anysphere. VS Code-based AI code editorâ€Šâ€”â€Šthe choice for professional developers. Supports Claude, GPT-4, and other models. Produces production-grade code with proper architecture. Required technical knowledge but unmatched depth. Valued at $9.9B. <br /><strong>$500M+ ARR</strong>â€Šâ€”â€Š2 years to getÂ there</p><h4><strong>Bolt.new</strong>â€Šâ€”â€ŠSpeedÂ demon</h4><p>Browser-based. Zero setup. Type what you want, get a shareable URL in under 30 minutesâ€Šâ€”â€Šthe fastest time-to-demo of any platform. Built on StackBlitz. Powered by Supabase backend. Best for hackathon prototypes and quick experiments, but code quality degrades over iterations.<br /><strong>Fast-growing</strong>â€Šâ€”â€Š$100M+ ARR threshold crossed</p><h4><strong>Replit</strong>â€Šâ€”â€ŠFull environment</h4><p>The cloud IDE with an embedded AI Agent. Educator-favored. Strong for collaborative team environments. Built-in databases, deployment, and real-time multiplayer coding. Most powerful â€œmiddle groundâ€ platformâ€Šâ€”â€Štoo complex for pure beginners but excellent for learning developers and startup teams.<br /><strong>$10M â†’ $100M ARR</strong>â€Šâ€”â€Šin under 9Â months</p><h4><strong>GitHub Copilot</strong>â€Šâ€”â€ŠEnterprise standard</h4><p>Microsoftâ€™s flagship. Integrates into VS Code, JetBrains, and more. The largest user base of any AI coding tool. 82% of developers surveyed use itâ€Šâ€”â€Šthe default entry point for enterprise teams. Code completion and inline suggestions rather than full app generation. $10â€“39/month.<br /><strong>$1B+ ARR</strong>â€Šâ€”â€Šmarket leader by userÂ count</p><h4><strong>Claude Code</strong>â€Šâ€”â€ŠTerminalÂ agent</h4><p>Anthropicâ€™s command-line AI engineer. Deep code understanding, multi-file reasoning, and agentic task execution. CB Insights named it the â€œrunaway market leaderâ€ among LLM providers for pure coding use cases. For developers who want maximum intelligence with full control. Crossed $1B ARR.<br /><strong>$1B+ ARR</strong>â€Šâ€”â€Štop 3 marketÂ position</p><h4><strong>Windsurf</strong>â€Šâ€”â€ŠAcquired byÂ OpenAI</h4><p>Formerly Codeium. IDE-based with deep code understanding and agentic â€œflowâ€ mode. Highest code quality scores in independent benchmarks (8.5/10). Acquired by OpenAI for $3 billion in May 2025â€Šâ€”â€Šthe biggest statement yet about where AI coding is heading.<br /><strong>$3B acquisition</strong>â€Šâ€”â€Šby OpenAI Â· MayÂ 2025</p><h4><strong>v0 by Vercel</strong>â€Šâ€”â€ŠUI specialist</h4><p>Vercelâ€™s AI-powered UI generator. Highest quality score in benchmarks (9/10). Specializes in component and UI generation using React + shadcn/ui. Not a full app builder but the best tool if you want beautiful, production-quality front-end components fast. Free tier available.<br /><strong>Free + pro tiers</strong>â€Šâ€”â€Špart of Vercel ecosystem</p><blockquote>â€œA year ago, they would have built their product from scratch. <br />But now 95% of it is built by an AI. You donâ€™t need a team of 50 <br />engineers anymore. Companies are reaching $10 million in revenue with <br />teams of less than 10.â€ - Garry Tan, CEO, Y Combinator, MarchÂ 2025</blockquote><h3>Who is actually using theseÂ tools?</h3><p>The data paints a picture that surprises most people. This isnâ€™t just developers upgrading their workflow. The user base of AI coding platforms is fundamentally different from what the software world has ever seenÂ before.</p><figure><img alt=""Developer adoption by segmentâ€Šâ€”â€Š2025 SegmentAdoptionEnterprise devs97%Full-stack devs90%Startup founders85%Frontend devs82%Non-technical47%Backend devs35%"" src=""https://cdn-images-1.medium.com/max/1024/1*wf-P4Ygqa9AEq5huJcdSdQ.png"" /><figcaption>(Source: <a href=""https://survey.stackoverflow.co/2025/ai/"">Stack Overflow Developer SurveyÂ 2025</a>)</figcaption></figure><p>Three distinct tribes are using these tools, each for very different reasons:</p><h4>Tribe 1: The non-technical founder</h4><p>The biggest story of the AI coding era isnâ€™t that developers got fasterâ€Šâ€”â€Šitâ€™s that the definition of â€œdeveloperâ€ has exploded. 47% of people now applying AI to coding do so for work or school, and 41% use it for personal projects, according to Menlo Venturesâ€™ 2025 State of Consumer AI report. These are designers, product managers, marketers, and domain experts who previously needed to hire engineers to build their ideas. With Lovable or Bolt, they donâ€™tÂ anymore.</p><p>Gartner predicts 70% of new applications will be built outside traditional IT departments by end of 2025. That is happening. Real estate agents are building property management tools. Teachers are building grading apps. Small business owners are building custom CRMs. The phrase you see repeated constantly in community forums:</p><blockquote>â€œLovable figured out what to build when I couldnâ€™t.â€</blockquote><h4>Tribe 2: The technical StartupÂ Founder</h4><p>This is the group that surprised everyoneâ€Šâ€”â€Šincluding YC. These arenâ€™t non-technical people using AI because they have no choice. Theyâ€™re highly skilled engineers using AI because itâ€™s <em>dramatically faster</em>. The YC Winter 2025 data is stunning: 25% of startups with 95% AI-generated code were <strong>fully capable</strong> of writing that code manually. They chose not to. This cohort grew at 10% per week collectivelyâ€Šâ€”â€Šthe fastest-growing YC batch ever recorded. Companies in this wave are reaching $10M revenue with teams of fewer than 10Â people.</p><h4>Tribe 3: The enterprise developer</h4><p>The 63% of the market held by large enterprises is quieter but massive. GitHub Copilot integration into existing IDE workflows. Amazon CodeWhisperer for AWS shops. Internal deployment of fine-tuned models for regulated industries. These teams arenâ€™t vibe codingâ€Šâ€”â€Štheyâ€™re using AI for code review, documentation, test generation, and completing specific functions. 61% of mid-to-large U.S. software enterprises have integrated AI pair-programming into their CI/CD pipelines as ofÂ 2025.</p><h4>Sector distributionâ€Šâ€”â€Šwho usesÂ it</h4><ul><li><strong>Saas products</strong>â€Šâ€”â€Š34%</li><li><strong>Fintech</strong>â€Šâ€”â€Š21%</li><li><strong>Healthtech</strong>â€Šâ€”â€Š15%</li><li><strong>E-commerce</strong>â€Šâ€”â€Š13%</li><li><strong>Other (Education / Government / Misc.)</strong>â€Šâ€”â€Š17%</li></ul><h3>The real problems nobody talksÂ about</h3><p>Every platform announcement shows beautiful demos. Every founder testimonial is glowing. But spend enough time in the trenchesâ€Šâ€”â€Šbuilding 47 applications across these tools as one reviewer didâ€Šâ€”â€Šand a very different picture emerges. Here are the seven critical issues users face globally, backed by real research:</p><h4><strong>01<br />SecurityÂ holes</strong></h4><p>A May 2025 study found 170 of 1,645 Lovable-built apps exposed personal user data. Guardio Labs discovered â€œVibeScammingâ€â€Šâ€”â€Šattackers can inject malicious prompts that cause AI to generate backdoors. No platform auto-audits for security. Human review is non-negotiable for production apps.</p><h4><strong>02<br />Code degrades overÂ time</strong></h4><p>Multiple independent studies confirm: the 50th prompt produces measurably worse code than the 5th. As projects grow, AI-generated code becomes inconsistent and difficult to maintain. The context window fills up, patterns break down, and the codebase becomes something â€œnobody fully understands.â€</p><h4><strong>03<br />The perception gap</strong></h4><p>The July 2025 METR study stunned the industry: experienced developers using AI tools took 19% longer on complex tasks despite feeling 20% faster. The illusion of speed is real. Code appears fastâ€Šâ€”â€Šbut debugging AI output, understanding what was generated, and fixing mistakes eats the timeÂ saved.</p><h4><strong>04<br />Runway tokenÂ costs</strong></h4><p>Consumption-based pricing is wildly unpredictable during iterative debugging. Bolt.new users have burned 2+ million tokens fixing a single bug. Some spent over $1,000 on a single project. Replit Agent credit depletion during active iteration regularly shocks users. Thereâ€™s no costÂ ceiling.</p><h4><strong>05<br />Compliance blindÂ spots</strong></h4><p>For regulated industriesâ€Šâ€”â€Šfinance, healthcare, governmentâ€Šâ€”â€Šnone of these platforms meet production compliance requirements. No SOC2. No HIPAA-ready default configurations. No audit trails. All platforms are explicitly prototyping tools. Trying to ship to production without human review in these sectors is genuinely dangerous.</p><h4><strong>06<br />VendorÂ lock-in</strong></h4><p>Bolt.new and Replit make migration painful. Your project becomes deeply tied to their infrastructure. v0 and Lovable are easiest to migrate away from. For startups choosing these platforms, the exit strategy is rarely considered upfrontâ€Šâ€”â€Šand becomes a serious problem atÂ scale.</p><h4><strong>07<br />The almost â€œ right â€œ frustration</strong></h4><p>Stack Overflowâ€™s 2025 survey found that 66% of developersâ€™ biggest AI frustration is â€œsolutions that are almost right but not quite.â€ This near-miss problem is uniquely maddening: the AI produces something that looks correct, passes casual inspection, but breaks at the edges. Debugging this is a new cognitive skill entirely.</p><h4><strong>08<br />Technical debit explosion</strong></h4><p>AI-assisted coding leads to 4x more code cloning, increasing maintenance effort over time. Googleâ€™s 2024 DORA report found AI use caused a 7.2% drop in delivery stability. 62.4% of developers cite technical debt as their top frustrationâ€Šâ€”â€Šand AI is accelerating its accumulation for teams without strong review practices.</p><h4><strong>09<br />No real production-ready code</strong></h4><p>Every benchmark study reaches the same conclusion: no AI coding platform produces code you can ship to production without significant manual finishing. The speed gains are genuine for prototypes. But the quality gap is equally real for anything that needs to last beyond aÂ demo.</p><h3>AI coding vs. Manual coding: The real comparison</h3><p>The debate â€œAI vs. human codingâ€ misframes the reality. The better question is: for what tasks, for what users, at what stage does AI coding deliver genuine valueâ€Šâ€”â€Šand where does it create hiddenÂ costs?</p><h4>Time to first prototype</h4><p><strong>AI Coding platforms</strong><br />Applications can be generated in 28â€“45 minutes. These tools provide dramatic gains for non-technical founders and small teams seeking rapid validation.</p><p><strong>Manual human coding</strong><br />Initial builds typically take hours to days depending on architecture, complexity, and stack decisions.</p><p><strong>Assessment:</strong> AI platforms provide a significant advantage in early-stage prototyping and rapid iteration.</p><h4>Code quality (Simple applications)</h4><p><strong>AI coding platforms</strong><br />Generally sufficient for MVPs and demos. Generated code is functional and often built on consistent starterÂ stacks.</p><p><strong>Manual human coding</strong><br />Quality depends entirely on developer skill level. Strong engineers can produce clean, extensible foundations from theÂ start.</p><p><strong>Assessment:</strong> For straightforward applications, AI-generated code is often adequate.</p><h4>Code quality (ComplexÂ systems)</h4><p><strong>AI coding platforms</strong><br />Code quality degrades over time. As projects expand, inconsistencies increase, architectural patterns fragment, and maintainability becomes challenging.</p><p><strong>Manual human coding</strong><br />Architectural integrity is intentionally designed and maintained. Technical decisions are deliberate and aligned with long-term systemÂ goals.</p><p><strong>Assessment:</strong> For complex or long-lived systems, manual engineering maintains structural coherence more effectively.</p><h4>Security</h4><p><strong>AI coding platforms</strong><br />Elevated vulnerability risk without manual auditing. Prompt injection risks and insecure defaults require active oversight.</p><p><strong>Manual human coding</strong><br />Security patterns are applied intentionally through training, experience, and established review processes.</p><p><strong>Assessment:</strong> Production-grade security still requires human review regardless of AI assistance.</p><h4>Speed (Senior developers)</h4><p><strong>AI coding platforms</strong><br />Studies indicate experienced developers may take longer on complex tasks when using AI tools, despite a perception of increased speed.</p><p><strong>Manual human coding</strong><br />Expert engineers often move faster on nuanced architectural and system-level decisions.</p><p><strong>Assessment:</strong> AI accelerates repetitive tasks but does not consistently outperform experienced developers on sophisticated work.</p><h4>Speed (Junior developers and non-technical users)</h4><p><strong>AI coding platforms</strong><br />Documented productivity gains of approximately 26% in certain studies. Enables non-coders to build functional applications.</p><p><strong>Manual human coding</strong><br />Requires months or years of training to achieve similarÂ output.</p><p><strong>Assessment:</strong> AI significantly lowers the barrier toÂ entry.</p><h4>Cost</h4><p><strong>AI coding platforms</strong><br />Subscription pricing combined with unpredictable token consumption. Costs can spike significantly during debugging cycles.</p><p><strong>Manual human coding</strong><br />Fixed salary costs. High per-hour expense but predictable for planning purposes.</p><p><strong>Assessment:</strong> AI lowers upfront cost but introduces variability.</p><h4>Startup viability</h4><p><strong>AI coding platforms</strong><br />Small teams can achieve meaningful revenue milestones with minimal engineering headcount. Rapid iteration supports aggressive growth experimentation.</p><p><strong>Manual human coding</strong><br />Requires larger teams to reach similar output velocity.</p><p><strong>Assessment:</strong> AI creates leverage in early-stage startups.</p><h4>Scalability</h4><p><strong>AI coding platforms</strong><br />Production systems often require significant refactoring. AI-generated code rarely scales without humanÂ rework.</p><p><strong>Manual human coding</strong><br />Systems can be designed for scale from inception when architected by experienced engineers.</p><p><strong>Assessment:</strong> Scalability depends heavily on human oversight.</p><h4>Learning and understanding</h4><p><strong>AI coding platforms</strong><br />Risk of using code that developers do not fully understand. May create â€œblack boxâ€ dependencies.</p><p><strong>Manual human coding</strong><br />Deep understanding compounds over time. Knowledge of system components strengthens architectural decision-making.</p><p><strong>Assessment:</strong> Long-term technical mastery requires active engagement beyond generated output.</p><p>AI coding platforms are powerful acceleration tools. They are highly effective for prototyping, validation, and enabling non-technical creators. However, long-term system stability, security, architectural integrity, and scalability still rely heavily on human engineering judgment.</p><p>The strategic question is not whether AI replaces developers. It is where AI meaningfully augments themâ€Šâ€”â€Šand where human expertise remains indispensable.</p><blockquote>The verdict isnâ€™t simple. â€œAI tools are genuinely transformative for prototyping, validation, and non-technical buildersâ€. Theyâ€™re genuinely problematic for production systems without human oversight. The â€œrightâ€ answer depends entirely on your position in the product lifecycle and your risk tolerance.</blockquote><h3>Where the money is: MarketÂ data</h3><figure><img alt=""Bar chart titled â€œPlatform Revenue Raceâ€Šâ€”â€Š2025 ARR Estimates (CB Insights)â€ showing GitHub Copilot and Claude Code at $1B+, Cursor at $500M+, Lovable at $200M, Replit at $100M, and Bolt.new at $100M+.Market Data"" src=""https://cdn-images-1.medium.com/max/1024/1*IuBZj12TfpG3JwVESJ4Geg.png"" /></figure><p>The total AI coding market is on a trajectory that analysts estimate will reach $99 billion by 2034. The combined equity funding raised by players in this space already exceeded $5.2 billion in 2025 aloneâ€Šâ€”â€Šmore than double the $2 billion raised the year before. Over 60 mergers, acquisitions, and partnerships occurred in the AI developer tools ecosystem in 2024â€“2025. This is not a niche software category anymore. It is a platform war <em>(Source: </em><a href=""https://www.cbinsights.com/research/ai-software-development-market-map/""><strong><em>CB Insights MarketÂ Map</em></strong></a><em>)</em></p><p>Geography matters too: North America holds 43% of the current market but Asia-Pacific is the fastest-growing region at a 27.4% CAGR. India, particularly, is seeing explosive growth in AI-assisted development across both enterprise adoption and startup formation. The IT and telecommunications sector leads usage at 29.4% of the marketâ€Šâ€”â€Šbut banking and financial services (BFSI) is the fastest-growing vertical at 28.13%Â CAGR.</p><h3>The human truth at theÂ core</h3><p>Here is the thing that gets buried under all the revenue numbers and platform wars: every AI coding platform in existence was built by humans. Trained by humans. Fed data by humans. Evaluated by humans. Corrected by humans. The â€œintelligenceâ€ that pops out a React app from a text prompt is the crystallized output of millions of hours of human code written by developers over decades, scraped from GitHub repositories, Stack Overflow answers, documentation pages, and technical blogs.</p><p>This isnâ€™t a criticismâ€Šâ€”â€Šitâ€™s a clarification. The AI doesnâ€™t â€œknowâ€ how to build software the way a senior engineer knows. It pattern-matches. It predicts what code should follow the tokens you gave it, based on what it saw in training.</p><p>That is why it fails in ways that feel eerily specific: it produces code that looks correct but has subtle logical errors. It follows conventions without understanding the reasoning behind them. It solves problems itâ€™s seen before brilliantly; it stumbles on genuinely novel architectural challenges.</p><figure><img alt=""Dark-themed code snippet explaining how AI generates code: tokenize prompt, attend to context, predict next tokens, repeatâ€Šâ€”â€Šwhile noting it doesnâ€™t truly understand business logic; ends with returning â€œcode that looks rightâ€ plus hidden complexity.71% of developers say they do not merge AI-generated code without manual review."" src=""https://cdn-images-1.medium.com/max/1024/1*yie8x0iI5YhOxWPXYB1Khg.png"" /></figure><p>This is why the most dangerous users of AI coding platforms are the ones who trust them completely. The safest users are those who treat AI output the way a senior developer treats a junior developerâ€™s pull request: read it carefully, understand it fully, question its assumptions, test its edge cases, and only then mergeÂ it.</p><p><strong>71% of developers say they do not merge AI-generated code without manual review. </strong>That number should be 100%. The 29% who skip review are accumulating technical debt faster than they realize, in a codebase increasingly full of code whose logic they donâ€™t fully understand.</p><p>The brilliant insight buried in the METR study is that AI doesnâ€™t make developers faster across the boardâ€Šâ€”â€Šit makes <em>less-experienced</em> developers faster, while potentially slowing down senior engineers on complex problems. This suggests the technology is doing something more interesting than pure acceleration: it is compressing the skillÂ gap.</p><p>A junior developer with <strong>AI tools can produce work that once required mid-level experience.</strong> A non-technical founder can now build what once required a small engineering team. That democratization is real and meaningful. But it comes with the risk of deploying systems built without the depth of understanding that comes from having built them the hardÂ way.</p><h3>Are people actually launching real products?</h3><p>Short answer: yes, but with important asterisks.</p><p>YCâ€™s Winter 2025 data is the most compelling evidence. Companies in that cohort growing 10% per week with sub-10-person teams and genuine customers are not demos or experimentsâ€Šâ€”â€Štheyâ€™re real businesses. YC CEO Garry Tan pointed to startups reaching $10M in revenue with fewer than 10 people. That would have been structurally impossible inÂ 2019.</p><p>The common pattern in communities like Reddit and Indie Hackers follows a â€œgraduate workflowâ€: prototype fast in Lovable or Bolt, validate with real users quickly, then either rebuild properly in Cursor or traditional development once the idea is provenâ€Šâ€”â€Šor hire an engineer to clean up the codebase for production. Start vibe, graduate toÂ code.</p><p>Lovable projects $1 billion in ARR by summer 2026â€Šâ€”â€Šfive times its current $200M run rate. That would make it one of the fastest-scaling B2C software products in history. Whether that reflects genuine product launches or churning users experimenting with prototypes is the key question. The honest answer: both. High-churn is a documented concern across all these platforms, precisely because the barrier to trying is so low that many users spin up projects they neverÂ finish.</p><p>The sectors where AI coding platforms are generating real-world product launches break down clearly: SaaS tools (34%), fintech applications (21%), healthtech prototypes (15%), and e-commerce storefronts (13%). The fintech and healthtech numbers are notable precisely because these are <em>regulated industries</em> where AI-generated code requires the most careful human review before shippingâ€Šâ€”â€Šand where the security vulnerabilities documented in 2025 represent the highest actualÂ risk.</p><h3>Final word</h3><p>So what does it allÂ mean?</p><p>We are in the middle of a genuine platform shiftâ€Šâ€”â€Šone that happens once or twice per generation in software. The printing press didnâ€™t replace writers; it made writing accessible to millions more people and changed what â€œwritingâ€ meant forever. The spreadsheet didnâ€™t replace accountants; it changed what accountants spent their time doing. AI coding platforms are doing something similar to software development.</p><p>The question is not whether to use these tools. <strong>82% of developers already do, daily.</strong> The question is whether youâ€™re using them with eyes openâ€Šâ€”â€Šunderstanding what they actually are (pattern-matching engines trained on human knowledge), what theyâ€™re good at (speed, scaffolding, prototyping, compressing the skill gap), and what theyâ€™re bad at (security, novel architecture, complex production systems).</p><h4>The realÂ win</h4><p>AI coding tools have genuinely democratized software creation. Millions of people who could not previously build software now can. That is a profound and real expansion of human capabilityâ€Šâ€”â€ŠnotÂ hype.</p><h4>The realÂ risk</h4><p>Production systems built with AI and not reviewed by experienced engineers are accumulating vulnerabilities, technical debt, and architectural problems that will surface at scale. The bill will comeÂ due.</p><h4>The uncomfortable truth</h4><p>AI doesnâ€™t know what it doesnâ€™t know. It generates plausible code, not correct code. The difference only becomes visible when the system fails under real-world conditions that the training data didnâ€™t anticipate.</p><h4>The biggerÂ picture</h4><p>Every model was built on human knowledge. AI is not a new form of intelligenceâ€Šâ€”â€Šitâ€™s the stored pattern of human intelligence, made instantly accessible. The humans who fed it that knowledge are still the source of everything it canÂ do.</p><p>The most honest summary: AI coding platforms are the best prototyping tools ever built and potentially dangerous production deployment tools if used without human oversight. Use them to go from zero to validated idea in a weekend. Use experienced engineers to take it from there. The future belongs to builders who understand both sides of that lineâ€Šâ€”â€Šand know precisely when theyâ€™re on the wrongÂ one.</p><blockquote>The code revolution isnâ€™t coming. Itâ€™s here. The question is whether youâ€™re building with itâ€Šâ€”â€Šor being swept along byÂ it.</blockquote><p><strong>References:</strong></p><p>[1] CB Insightsâ€Šâ€”â€ŠCoding AI market share december 2025 â†’ <a href=""https://www.cbinsights.com/research/report/coding-ai-market-share-december-2025/"">https://www.cbinsights.com/research/report/coding-ai-market-share-december-2025/</a></p><p>[2] Stack overflow developer survey 2025â€Šâ€”â€ŠAI section â†’ <a href=""https://survey.stackoverflow.co/2025/ai/"">https://survey.stackoverflow.co/2025/ai/</a></p><p>[3] METRâ€Šâ€”â€ŠMeasuring impact of early 2025 AI on developer productivity â†’ <a href=""https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/"">https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/</a></p><p>[4] Guardio labsâ€Šâ€”â€ŠVibescamming research â†’ <a href=""https://guard.io/labs/vibescamming-from-prompt-to-phish-benchmarking-popular-ai-agents-resistance-to-the-dark-side"">https://guard.io/labs/vibescamming-from-prompt-to-phish-benchmarking-popular-ai-agents-resistance-to-the-dark-side</a></p><p>[5] Y Combinator blog â†’ <a href=""https://www.ycombinator.com/blog/"">https://www.ycombinator.com/blog/</a></p><p>[6] CB Insightsâ€Šâ€”â€ŠAI Software development market map â†’ <a href=""https://www.cbinsights.com/research/ai-software-development-market-map/"">https://www.cbinsights.com/research/ai-software-development-market-map/</a></p><p>[7] Stack Overflow 2025 Surveyâ€Šâ€”â€ŠAI Tools â†’ <a href=""https://survey.stackoverflow.co/2025/ai/"">https://survey.stackoverflow.co/2025/ai/</a></p><p>[8] METR study academic paper â†’ <a href=""https://arxiv.org/abs/2507.09089"">https://arxiv.org/abs/2507.09089</a></p><p>ğŸ¬ <strong>Must Watch:</strong> â€œThe vibe coding mind virus explainedâ€ by FireshipÂ â†’</p><a href=""https://medium.com/media/0f1740eb50c77f880c4fc6a6cabc032c/href"">https://medium.com/media/0f1740eb50c77f880c4fc6a6cabc032c/href</a><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a2058ca0734c"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ai-writes-the-code-and-humans-still-write-the-rules-a2058ca0734c"">AI writes the code and humans still write the rules</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/how-complexity-accumulates-e222182a67f5?source=rss----138adf9c44c---4,1771936391,How complexity accumulates,"How complexity accumulates

<h4>How systems become risky without anyone noticing.</h4><figure><img alt=""A Painting of Alexander Cutting the Gordian Knot"" src=""https://cdn-images-1.medium.com/max/1024/1*urJTxEUxB1exhlGRMTz9tg.jpeg"" /><figcaption>Alexander Undoing the Gordian | Source: Knot 1st-art-gallery.com</figcaption></figure><p>No one decides to build a fragile system. No executive convenes a meeting to discuss how best to make operations inscrutable, unreliable, brittle. No engineer sets out to create software that no one can maintain or discern later on. No organization deliberately designs processes so convoluted that they guarantee failure.</p><p>Yet fragile, incomprehensible, unmaintainable, and failure-prone systems are everywhere. They are the norm. Systems that excel and are resilient are exceptional. So how come? Fragile systems didnâ€™t arrive through dramatic decisions or catastrophic errors. They evolved. Their fragility and brittleness were accumulated gradually, through a thousand small, locally rational choices that collectively created something unmanageable. Therein lies the importance of Systems Thinking. To understand the aggregate dynamics of individual choices.</p><p><a href=""https://openlearning.mit.edu/news/ask-mit-professor-what-system-thinking-and-why-it-important"">Systems Thinking </a>is the best defense we have against the complexity run amuck. Complexity is an emergent property of systems. It evolves not from reckless decision-making but from responding sensibly to immediate, localized needs. A new feature here, a workaround there, an exception to handle an edge case, a patch to fix an urgent problem. Each addition seems small. Each solves a real problem. Each is approved and implemented with good intentions.</p><p>But complexity isnâ€™t an additive attribute. It multiplies.</p><figure><img alt=""A diagram that demonstrates that the complexity of a system (connections) grows exponentially with the number of components in a system"" src=""https://cdn-images-1.medium.com/max/776/0*2MfYpvTLBmGK5aYk.jpeg"" /><figcaption>Source: Author</figcaption></figure><p>Take the image above. In the abstract it does a good job of demonstrating complexity. A system of 3 nodes has just 3 unique connections. A system with 1 more node, doubles the number of connections to 6. Double that system and the number of connections grows exponentially. Somewhere along the way the system crosses a threshold where the system becomes so fraught with complexity that it creates genuine risk. Like the emergence of complexity, the probability also increases exponentially.</p><p><strong>How Complexity Accumulates</strong></p><p>The first step in managing complexity is understanding how it sneaks into systems despite everyoneâ€™s best efforts to keep thingsÂ simple.</p><p>Feature Creep</p><p>Every user wants one more feature. Every stakeholder has a use case that isnâ€™t quite covered. Every competitive analysis reveals something rivals offer that you donâ€™t. The pressure to add is constant and multifaceted.</p><p>Individual feature requests seem reasonable. A customer needs the system to handle a specific edge case. A sales prospect will sign if you just add this one capability. An internal team needs special handling for their workflow.</p><p>Saying yes to each request improves the system for someone. But each addition increases the surface area of the system, manifesting in more code to maintain, more interactions to test, more documentation to write, more training to conduct, as well as an expanded Optimal Design Domain. The complexity grows with the factorial of features.</p><p>Procedural Layering</p><p>Organizations respond to problems <a href=""https://irb.northwestern.edu/compliance-education/corrective-and-preventive-action-capa-plans.html"">by adding procedures</a>. A mistake occurs; a new approval process is implemented. An audit finds gaps; a new compliance check is required. A risk materializes; a new control is instituted.</p><p>Each procedure makes sense in isolation. We should approve major purchases. We should verify compliance. We should control risk. But procedures accumulate faster than theyâ€™re removed. Organizations rarely ask, â€œWhat procedure can we eliminate now that weâ€™re adding thisÂ one?â€</p><p>The result is sedimentary layers of process, each representing a response to some past problem, many now obsolete but all still in force because no one has authority or incentive to removeÂ them.</p><p><a href=""https://www.tocinstitute.org/theory-of-constraints.html"">The Theory of Constraints</a> (ToC) identifies this as policy constraintsâ€Šâ€”â€Šrules and procedures that become bottlenecks themselves. <a href=""https://www.tocinstitute.org/eliyahu-goldratt.html"">Goldratt </a>(the creator of ToC) observed that organizations often implement policies to optimize local efficiency but never revisit them when conditions change, creating system-level dysfunction.</p><p>Informal Complexity, WorkÂ Arounds</p><p>When formal systems donâ€™t serve user needs well, people create workarounds. They copy data manually between systems. They use spreadsheets to track what the official system should track but doesnâ€™t. They develop informal communication channels because formal ones are tooÂ slow.</p><p>In my experience as an engineer, systems designer, and consultant, this is actually the norm of how business gets done. People are very entrepreneurial by nature. Thereâ€™s never a formalized meeting to figure out how business operations ought to be completed, they just figure out what works, and that becomes the best practice. This is great for getting things done, but it also means that there is usually lots of low-hanging fruit to optimize these systems, usually at lowÂ cost.</p><p>Workarounds are innovations at the edges. They represent localized problem-solving that keeps work flowing. But theyâ€™re also a key driver of hidden complexity. The formal system looks simple on paper, but the actual operating system includes dozens of undocumented workarounds that only certain people knowÂ about.</p><p>When those people leave, their workarounds break. When systems change, workarounds that depended on specific quirks stop working. When new people join, they donâ€™t know the workarounds exist and make errors because the formal system doesnâ€™t match operational reality.</p><p>Technical Debt and The Infrastructure Accumulation</p><p>In software, technical debt is explicit and easy to detect. Shortcuts are taken to complete a project faster, leaving behind code that should be refactored later. Often, â€œlaterâ€ never comes, and the debt accumulates.</p><p>But technical debt exists in all systems, not just software. In manufacturing, we regularly see equipment thatâ€™s been patched repeatedly, or modules added onto instead of replaced. In organizational design we even see it in the form of reporting lines being added without rethinking the fundamental design. Itâ€™s the sales training program thatâ€™s been updated piecemeal for every new product instead of redesigned.</p><p>Each piece of debt makes future changes harder. The code becomes harder to modify, because the internal logic is already fractal. The manufacturing equipment becomes more fragile. The organization becomes more difficult to reorganize. The training becomes less effective. The system becomes rigid precisely when it needs to be adaptive.</p><p><strong>Complexity Increases Faster Than Our Ability to Understand It</strong></p><p>A systemâ€™s complexity doesnâ€™t scale linearly with system size. A system twice as large isnâ€™t twice as complex. Itâ€™s often four times, eight times, or exponentially moreÂ complex.</p><p>Interaction Effects</p><p>An interaction is the reciprocal cause-and-effect relationship between two components within a system. This is important to understand how systems behave as a whole. Systems are not merely the sum of their parts. It means that as systems grow their complexity is boosted by the mutual and cyclical relationships., highlighting that influences are mutual and cyclical, not linear. A system with 10 components has 45 potential interaction pairs, but a system with 100 components hasÂ 4,950.</p><p>Most interactions donâ€™t matter most of the time. But under stress, under unusual conditions, or when specific combinations occur, obscure interactions become critical. And the more interactions exist, the more likely that some will create failure modes no one anticipated. This is the principle of <a href=""https://uxdesign.cc/bad-design-is-like-a-virus-design-defects-and-latent-failures-1e0ab4be7e52"">resident pathogens</a>.</p><p>You cannot understand a system by understanding its parts in isolation. The interactions between parts often dominate behavior. As those interactions multiply, understanding the whole becomes exponentially harder.</p><p>Emergent Behaviors</p><p>Complex systems exhibit emergent behaviors. Emergent behaviors are system-level properties that donâ€™t exist in any individual component. Traffic jams emerge from individual driver decisions. Market crashes emerge from individual trading behaviors. Organizational dysfunction emerges from individual departmental optimizations. Flocking patterns of birds and Schools of Fish emerge as a result of many constituents which donâ€™t, in and of themselves, possess these emergent properties.</p><figure><img alt=""A flock of birds during a yellow sunset"" src=""https://cdn-images-1.medium.com/max/1024/0*wIMNA47WVg3BzCiR.jpg"" /><figcaption>A Flock of birds as emergent behavior found in nature | Source: Arstechnica.com</figcaption></figure><p>Often spawned by localized decision making, these emergent properties are often negative (at least from the system designerâ€™s perspective), namely because they are unintended and unexpected consequences. And theyâ€™re nearly impossible to predict because they emerge from the interaction of many factors, not from any singleÂ cause.</p><p><em>A side note/rant:</em></p><p><em>This is why Iâ€™m bearish when it comes to the future of gene editing technology. Gene editing methods like </em><a href=""https://news.stanford.edu/stories/2024/06/stanford-explainer-crispr-gene-editing-and-beyond""><em>CRISPR </em></a><em>uses correlations and probability to edit genes for some desired effect, eye color. But (1) these may correlate with other factors not accounted for (</em><a href=""https://www.the-scientist.com/how-are-earwax-and-body-odor-linked-72476""><em>like the relationship between earwax and body odor</em></a><em>) and (2) the collective editing of multiple genes can have greater unintended [read: emergent] consequences.</em></p><p>Cognitive Limits</p><p>Human working memory can hold roughly seven chunks of information. When a system has hundreds or thousands of interacting components, no individual can hold the complete system in their head. Understanding becomes distributed across many people, each of whom has a partialÂ view.</p><p>This fragmentation of understanding is itself a risk. No one sees the whole. Decisions are made based on local knowledge that doesnâ€™t account for global effects. Changes are implemented without understanding full implications. The system becomes too complex for anyone to fully reasonÂ about.</p><p><strong>Real-World Complexity Failures</strong></p><p>Healthcare.gov LaunchÂ (2013)</p><p>The Affordable Care Actâ€™s federal insurance exchange launched in October 2013 and immediately collapsed. The website couldnâ€™t handle traffic. Applications failed. Users couldnâ€™t complete enrollment.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*bbTMPytERu-EIAQH.png"" /><figcaption>The now famous error screen of HealthCare.gov | Source: Medium.com</figcaption></figure><p>The failure wasnâ€™t a single bug or bad decision. It was systemic complexity. Multiple contractors built different pieces. Systems needed to integrate with existing federal databases. State exchanges needed to interface with the federal system. Security requirements added layers. Compliance rules created conditional logic. <a href=""https://medium.com/dataseries/small-is-beautiful-the-launch-failure-of-healthcare-gov-5e60f20eb967"">Edge cases demanded special handling</a>.</p><p>Each component worked (more or less) in isolation. But integrating them revealed cascade failures, timing issues, and interaction effects no one had anticipated. The system was too complex for anyone to fully understand, and that complexity created fragility.</p><p>Knight Capital Trading LossÂ (2012)</p><p><a href=""https://www.henricodolfing.ch/en/case-study-4-the-440-million-software-error-at-knight-capital/"">Knight Capital</a> deployed new trading software to seven of eight servers. The eighth still ran old code. When trading began, the old code executed differently than the new code. Orders from the mixed system created erratic behavior that cost $440 million in 45Â minutes.</p><p>The complexity wasnâ€™t in the trading logic itself but was in the deployment process, version control, and fail-safes (or lack thereof). Each element seemed manageable. But the interaction of partial deployment, legacy code, and automated trading created a failure mode that destroyed theÂ company.</p><p>Boeing 787 Development Delays</p><p><a href=""https://www.cnn.com/2023/02/24/business/boeing-787-dreamliner-halt"">Boeingâ€™s 787 Dreamliner was years late </a>and billions over budget, largely due to complexity in managing a global supply chain with unprecedented outsourcing. Boeing delegated entire aircraft sections to suppliers, who delegated to sub-suppliers.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/780/0*K3iiLYAXxETopbEa"" /><figcaption>A Boeing Dreamliner Production Line | Source: Seattletimes.com</figcaption></figure><p>The complexity wasnâ€™t within the airplane design. It was organizational and logistical. Coordinating work across dozens of companies, ensuring interface compatibility, managing schedule dependencies, and integrating testing added complexity that multiplied with every additional partner and interface.</p><p><strong>Detecting Accumulated Complexity</strong></p><p>Complexity accumulates invisibly until it causes problems. How do you detect it before it becomes critical?</p><p>Warning Signs:</p><ol><li><strong>Lengthening cycle times</strong>: Changes that used to take days now take weeks. This often signals that complexity has increased friction.</li><li><strong>Rising error rates</strong>: More defects, more support tickets, more exceptions. Complexity creates more failureÂ modes.</li><li><strong>Knowledge silos</strong>: Only certain people can work on certain systems because theyâ€™re too complex for newcomers to learnÂ quickly.</li><li><strong>Fear of change</strong>: Teams resist modifications because theyâ€™re not confident about side effects. â€œIf itâ€™s working, donâ€™t touch itâ€ becomes theÂ mantra.</li><li><strong>Escalating maintenance costs</strong>: More time spent fixing and patching, less time spent building new capability.</li><li><strong>Integration problems</strong>: New features break existing functionality in unexpected ways.</li><li><strong>Documentation drift</strong>: Formal documentation no longer matches actual operation because the system has evolved through undocumented changes.</li></ol><p>These symptoms donâ€™t prove complexity directly, but they correlate strongly with systems that have accumulated too much ofÂ it.</p><p>Quantitative Measures:</p><p>For software systems, metrics like <a href=""https://www.geeksforgeeks.org/dsa/cyclomatic-complexity/"">cyclomatic complexity</a>, coupling metrics, and dependency graphs provide numerical complexity measures and diagnostic tools. But even non-software systems can be measured:</p><ul><li><strong>Decision tree depth</strong>: How many conditional branches exist in aÂ process?</li><li><strong>Role count</strong>: How many different roles touch a workflow?</li><li><strong>Approval layers</strong>: How many sign-offs does a decisionÂ require?</li><li><strong>Exception frequency</strong>: How often do standard processes require exceptions?</li><li><strong>Handoff count</strong>: How many times does work transfer between people orÂ systems?</li></ul><p>High values donâ€™t automatically mean thereâ€™s a problem. Complexity is sometimes necessary. But they indicate where to look for opportunities to simplify and where to triage when something breaks.</p><p><strong>Pruning Unnecessary Complexity</strong></p><p>Once youâ€™ve detected complexity, how do you reduce it without breaking things thatÂ work?</p><p>1. Dependency Mapping</p><p>You canâ€™t simplify what you donâ€™t understand. Create visual maps of dependencies:</p><ul><li>What depends onÂ what?</li><li>What components interact?</li><li>What can be changed independently?</li><li>Where are the tight couplings?</li></ul><figure><img alt=""An example of a dependency map"" src=""https://cdn-images-1.medium.com/max/1024/1*ZidzvGzhvpLFVASu2l9qtQ.png"" /><figcaption>An example of a dependency map | Source: dependency-map.com</figcaption></figure><p>Tools exist for software (dependency analyzers, architecture visualization). For organizational systems, this might be process maps, responsibility matrices (RACI), or workflow diagrams.</p><p>2. The 80/20Â Analysis</p><p>Most systems exhibit <a href=""https://www.datacamp.com/tutorial/pareto-distribution"">Pareto distributions</a>: 20% of features deliver 80% of value, 20% of code contains 80% of bugs, 20% of procedures handle 80% ofÂ cases.</p><figure><img alt=""An Example of a Pareto Distribution"" src=""https://cdn-images-1.medium.com/max/1024/0*hKMuHOxk7ZxHLk1Z"" /><figcaption>An Example of a Pareto Distribution | Source: scirp.org</figcaption></figure><p>Identify:</p><ul><li>Which features are rarelyÂ used?</li><li>Which procedures handle edgeÂ cases?</li><li>Which code paths are seldom executed?</li></ul><p>These low-value, high-maintenance components are prime candidates for elimination. Removing them reduces surface area without significantly reducing capability.</p><p><a href=""https://www.lightsondata.com/why-focus-reduce-variation/"">Demingâ€™s focus on variation reduction</a> is relevant here. Simplification reduces sources of variation, making systems more stable and predictable. Eliminating rarely-used features eliminates rare but costly failureÂ modes.</p><p>3. Complexity Budgets</p><p>Treat complexity as a constrained resource, like memory or budget. Every addition must fit within the budget, which means something else might need to beÂ removed.</p><p>This forces explicit trade-offs: â€œTo add this feature, we need to remove three existing ones. Which should go?â€ The question surfaces costs that are otherwise hidden.</p><p><a href=""https://medium.com/@ankitsingh1583/how-netflix-uber-and-amazon-manage-their-microservices-at-scale-97b028da2134"">Netflix famously has a policy limiting microservices complexity</a>: teams can add new services, but the total count must stay within bounds, forcing consolidation and simplification as a regular practice.</p><p>4. Simplification Audits</p><p>Regularly review systems specifically to identify simplification opportunities:</p><ul><li>Which procedures exist because of problems that no longerÂ occur?</li><li>Which features could be consolidated?</li><li>Which integrations could be eliminated?</li><li>Which exceptions could be standardized?</li></ul><p>The <a href=""https://www.tocinstitute.org/theory-of-constraints.html"">Theory of Constraints</a> teaches to focus improvement efforts on constraints. But TOC also recognizes that non-constraint resources shouldnâ€™t be optimized to full capacity. Similarly, not every part of a system needs maximum capability. Some parts can and should be simplified, even if it means slightly reduced local performance, if it improves overall system manageability.</p><p>5. Modular Decomposition</p><p>Break complex systems into loosely <a href=""https://aisel.aisnet.org/ecis2022_rp/52/"">coupled modules </a>with clear interfaces. This doesnâ€™t reduce total complexity, but it contains and partitions it.</p><p>A monolithic system with 1,000 interconnected parts is unmanageable. Ten modules of 100 parts each, with well-defined interfaces between modules, is manageable. You can understand one module deeply without needing to understand allÂ modules.</p><p>This requires discipline in interface design: modules should interact through narrow, well-specified interfaces, not through deep coupling or shared state. When modularity is maintained, complexity within modules stays local and doesnâ€™t ripple system-wide.</p><p>6. Standardization and Platforming</p><p>Reduce variety by standardizing components and building on common platforms. Instead of five different authentication systems, use one. Instead of three different data formats, standardize onÂ one.</p><p>This trades flexibility for simplicity. You canâ€™t optimize each use case perfectly, but you reduce the number of things that need to be understood, maintained, and integrated.</p><p><a href=""https://www.6sigma.us/business-process-management-articles/process-standardization-for-operational-excellence/"">Standardization of processes is foundational for quality</a>. You canâ€™t improve what varies wildly. You canâ€™t maintain whatâ€™s different everywhere. Standardization creates the baseline from which to build, measure, andÂ improve.</p><p><strong>Culture and Resisting Complexity</strong></p><p>Technical approaches help, but the deeper challenge is cultural. Organizations must develop a <a href=""https://www.pmi.org/disciplined-agile/dealing-with-complexity-by-creating-a-bias-for-simplicity"">bias toward simplicity</a>, which cuts against many incentives.</p><p>Incentive Misalignments:</p><ul><li>Product managers are rewarded for feature additions, not featureÂ removals</li><li>Engineers are evaluated on what they build, not what they eliminate</li><li>Processes are added in response to visible problems; removing them is invisible work</li><li>Budgets reward spending, not simplification</li></ul><p>To counter these, organizations needÂ to:</p><ul><li><strong>Celebrate simplification</strong>: Publicize cases where removing features improved theÂ product</li><li><strong>Measure complexity explicitly</strong>: Track metrics like code complexity, process steps, and approvalÂ layers</li><li><strong>Require simplification alongside addition</strong>: New features must be accompanied by the removal of oldÂ features</li><li><strong>Create dedicated simplification initiatives</strong>: Not as ongoing work but as explicit projects with resources</li></ul><p>The Power ofÂ â€œNoâ€</p><p>The most important complexity control is saying no to additions. This is politically difficultâ€Šâ€”â€Ševery addition has a constituency. But the cumulative cost of saying yes too often is a system that collapses under its ownÂ weight.</p><p>Saying no requires:</p><ul><li>Clear criteria for whatâ€™s in scope and whatâ€™sÂ not</li><li>Explicit recognition that the capacity for complexity isÂ limited</li><li>Willingness to disappoint stakeholders in the service of system sustainability</li><li>Authority structures that can enforce boundaries</li></ul><p><a href=""https://www.uwyo.edu/ceps/development/awards/deming.html"">W. Edwards Deming</a>â€™s point about <a href=""https://deming.org/create-constancy-of-purpose/"">constancy of purpose</a> applies here. Without a consistent commitment to simplicity, complexity accumulates as each decision optimizes locally without considering globalÂ effects.</p><p><strong>Living with Necessary Complexity</strong></p><p>Some complexity is essential. Real-world problems are complex; solutions must match that complexity to some degree. The eliminate unnecessary complexity while managing necessary complexity effectively.</p><p><strong>Essential Complexity:</strong></p><ul><li>Business rules that reflect genuine domain complexity</li><li>Integration points that correspond to real organizational boundaries</li><li>Features that deliver significant value to significant user populations</li><li>Redundancy that provides resilience</li></ul><p>This complexity shouldÂ be:</p><ul><li>Explicit: Documented and understood</li><li>Contained: Modularized so it doesnâ€™tÂ leak</li><li>Justified: Regularly validated as still necessary</li></ul><p><strong>Accidental Complexity:</strong></p><ul><li><a href=""https://idenhaus.com/why-workarounds-are-iams-silent-killer/"">Workarounds</a> for systems that should beÂ fixed</li><li>Procedures created in response to one-timeÂ events</li><li>Features that sounded good but are rarelyÂ used</li><li>Integration patterns that evolved organically withoutÂ design</li></ul><p>This complexity should be systematically hunted and eliminated.</p><p>The distinction isnâ€™t always clear, but the question should be constantly asked: is this complexity necessary, or did it just accumulate?</p><p><strong>Conclusion: Complexity as SystemicÂ Debt</strong></p><p>Complexity is like financial debt: sometimes useful, always carrying a cost, and dangerous when it accumulates beyond your ability to serviceÂ it.</p><p>Taking on debt to invest in growth can be smart. But debt that accumulates from routine operations without producing value is insidious. It constrains future options, increases risk, and eventually demands painful restructuring.</p><p>The same is true of complexity. Some complexity enables capability. But much of how complexity propagates is just accumulation, the residue of past decisions that no one has cleaned up. It makes the system fragile, expensive to maintain, and difficult toÂ evolve.</p><p>The challenge is that complexity accumulates gradually and locally while its costs manifest globally and suddenly. Each small addition seems manageable. The cumulative effect is system failure that seems to come from nowhere but was actually built up over years of accretion.</p><p>Managing this requires:</p><ul><li><strong>Vigilance</strong>: Constantly watching for complexity creep</li><li><strong>Discipline</strong>: Resisting additions and forcing eliminations</li><li><strong>Understanding</strong>: Mapping and measuring complexity</li><li><strong>Investment</strong>: Dedicating resources to simplification</li><li><strong>Culture</strong>: Valuing simplicity as much as capability</li></ul><p>Systems should be designed for improvement, not just for operation. This means building systems that can be understood, modified, and simplified. Systems that resist simplification, where every change risks breaking something else, have accumulated too much complexity. I also mentioned this as a key principle to designing <a href=""https://uxdesign.cc/responsible-tech-principles-for-technological-use-and-development-3de9f6d8f49d"">Responsible and Humane Technology</a>.</p><p>The risk isnâ€™t that your system will fail catastrophically tomorrow. Itâ€™s that complexity accumulates silently until one day you discover your system has become so fragile, so opaque, and so expensive to maintain that itâ€™s effectively unmaintainable. By then, you have few options: live with mounting failures or undertake expensive, risky restructuring.</p><p>The solution is prevention: treat complexity as debt, recognize when youâ€™re taking it on, ensure itâ€™s justified, and regularly pay it down. Build systems that can be simplified, not just systems that work. Create cultures that celebrate subtraction as much as addition.</p><blockquote>â€œPerfection is achieved, not when there is nothing left to add, but when there is nothing left to take awayâ€â€Šâ€”â€Š<a href=""https://www.goodreads.com/author/show/1020792.Antoine_de_Saint_Exup_ry"">Antoine de Saint-ExupÃ©ry</a></blockquote><p>Because in the long run, the systems that survive arenâ€™t the ones with the most features, the most procedures, or the most components. Theyâ€™re the ones that remain understandable, maintainable, and adaptable. They are the ones that resisted the inexorable accumulation of unnecessary complexity.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e222182a67f5"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/how-complexity-accumulates-e222182a67f5"">How complexity accumulates</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/being-an-ai-native-designer-isnt-what-you-think-it-is-dae1d03e68f5?source=rss----138adf9c44c---4,1771936389,Being an AI-native designer isnâ€™t what you think it is,"Being an AI-native designer isnâ€™t what you think it is

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/being-an-ai-native-designer-isnt-what-you-think-it-is-dae1d03e68f5?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*706xYB7lTNLPbjN39gK65w.jpeg"" width=""5192"" /></a></p><p class=""medium-feed-snippet"">What 28 design leaders have said AI-native design really is</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/being-an-ai-native-designer-isnt-what-you-think-it-is-dae1d03e68f5?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/extended-overthinking-cdbaa06dc1b8?source=rss----138adf9c44c---4,1771884298,Extended overthinking,"Extended overthinking

<h4>On AI, slot machines, and forgetting how to craftÂ pixels.</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*u1-jjxxKYGk_2CGL.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*A8SrDEMkVK0SBie8.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*DVeJ5pqyxChmsOkV.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*AoIiIENkPFWFjtTo.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*nmOonr_1ocTmqd9d.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*qTSCDPPr5Fxm6__Y.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*YuuaWSSpySVp7sUS.jpeg"" /></figure><p>Iâ€™ve grown tired of AI latelyâ€¦ of what it does toÂ me.</p><p>Every new model, every new tool, every new workflow. Yes, theyâ€™re powerful. Yes, they let us do more. But thereâ€™s this weird disconnect growing between me and the things I make. When everything is instant, it starts feeling like a slot machine. Except you always win. Which makes it more addictive. And somehowâ€¦ alsoÂ boring?</p><p>And you canâ€™t stop. Social media keeps telling us to ship more, faster, be first. But when anyone has the power of a team of 10x engineers (lol), being first isnâ€™t even a moat anymore. Itâ€™s just being slightly lessÂ late.</p><p>The worst part is what this comic is about. I catch myself using AI for things I used to enjoy doing. Changing a font size. Adjusting the border radius. Pushing pixels until the result made meÂ proud.</p><p>I still do something similar, but now itâ€™s a conversation. I tell the spirit in the terminal to do it for me. â€œMake the left padding a bit wider. Make the animation snappier. Use our subtle foreground colorâ€¦ donâ€™t use any color, use our color token. Oh, and make it smaller, go from sm to xs.â€ Thatâ€™s my new <em>pixel-pushing.</em></p><p>Why? Because I can. And thatâ€™s theÂ trap.</p><p>The thing gets done but it doesnâ€™t feel like I did anything. I couldâ€™ve written that code myselfâ€¦ but sometimes I donâ€™t even know where the component lives in the files. Iâ€™d have to inspect the element in the browser, find the classes, copy them, search them in my IDE, locate the file, then edit it (am I the only one who does this?) So insteadâ€¦ I just talk to the machine. I overexplain so it only changes what I want. I donâ€™t design anymore. IÂ direct.</p><p>But these things could direct themselves too. The â€œhuman in the loopâ€ feels less like the guide and more like the thing slowing it all down. Some people call this slowing of the machineâ€¦ this fine-tuningâ€¦ â€œtaste.â€ The ultimate human moat. Guys, stop it with your â€œtaste.â€ Iâ€™ve seen how you dress. You donâ€™t have any. And taste is really just doing things the way the top 10% of creators do instead of the average. Thatâ€™s a pattern. Patterns are exactly what these things are built to learnâ€¦ just give it time (aÂ month?).</p><p>But heyâ€¦ this comic? I tried new angles, more creative shots. All hand-drawn. No model. No worktree. No extra-high reasoning. Just me and the canvas. And that feels good. Likeâ€¦ â€œlook, mom, I madeÂ this!â€</p><p>Look, Iâ€™m in a rut. I really love these tools, I love creating with AI, Iâ€™ve never felt so productive. Theyâ€™re wild and theyâ€™re powerful. But I hope we keep the joy. Because if everything is automated and instant but doesnâ€™t feel like oursâ€¦ what are we evenÂ making?</p><p><a href=""https://pablostanley.substack.com/"">Pabs</a></p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*t3Wqm7CQ3REno6xf.jpeg"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*-jexP73H16tGl-BWnKpc8g.png"" /></figure><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cdbaa06dc1b8"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/extended-overthinking-cdbaa06dc1b8"">Extended overthinking</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/hidden-cost-of-ai-prototypes-leadership-myths-how-designers-use-ai-568b86eb87f2?source=rss----138adf9c44c---4,1771850022,"Hidden cost of AI prototypes, leadership myths, how designers use AI","Hidden cost of AI prototypes, leadership myths, how designers use AI

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://uxdesign.cc/the-hidden-cost-of-ai-prototypes-that-are-made-to-die-00cc4d491dec""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*xDjJNqS0ZKVp-TRi.png"" /></a></figure><p>â€œPrototypes are no longer as special as they once were. Theyâ€™re now the bareÂ minimum.</p><p>But this speed comes with limitations. Many AI-generated prototypes are never meant to survive past the moment theyâ€™re validated. They do their job in a meeting or a user test, but then theyâ€™re rebuilt by engineering or even trashed. But the prototypes didnâ€™t â€œfail,â€ they were just created with a different intention and outcome.â€</p><p><a href=""https://uxdesign.cc/the-hidden-cost-of-ai-prototypes-that-are-made-to-die-00cc4d491dec""><strong>The hidden cost of AI prototypes that are made to die</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/b2f44e1879c9"">AllieÂ Paschal</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/escaping-the-ennui-in-ui-dbc1d63c977d?sk=31b24cf502ac85976ea7edb00a1be6cb""><strong>Escaping the ennui in UI</strong></a><strong> â†’</strong><br />How vibedesign created a vicious slope of AI slop.<br />By <a href=""https://medium.com/u/17dab133f2ba"">DarrenÂ Yeo</a></li><li><a href=""https://uxdesign.cc/your-research-tools-got-smarter-did-you-9fd4339617ca""><strong>Your research tools got smarterâ€¦ Did you?</strong></a><strong> â†’</strong><br />Which side of the line youâ€™re standing on.<br />By <a href=""https://medium.com/u/4b19995ab7ca"">JoshÂ LaMar</a></li><li><a href=""https://uxdesign.cc/get-behind-me-ai-writer-b783ba2f9851""><strong>Get behind me, AI writer</strong></a><strong> â†’</strong><br />A reverse-engineered drafting process that keeps humans in charge.<br />By <a href=""https://medium.com/u/592a18ec83da"">TannerÂ Walsh</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://www.creativeboom.com/inspiration/li-wang-captures-life-love-and-longing-in-colour/""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*W1Y1EwdqiRGM_QIe.png"" /></a></figure><p><a href=""https://www.creativeboom.com/inspiration/li-wang-captures-life-love-and-longing-in-colour/""><strong>Li Wang captures life, love, and longing in color</strong></a><strong>Â â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://jonnyburch.com/life-after-figma/?ref=sidebar""><strong>Life after Figma is coming (and it will be glorious)</strong></a><strong> â†’</strong><br />â€œAs engineers speed up the bottleneck in any given product team is being felt further up the stack in the design team. In modern teams itâ€™s no longer acceptable for a designer to spend 2 weeks in their mind palace creating the perfectÂ UI.â€</li><li><a href=""https://pjonori.blog/posts/design-systems-tomorrows-cause-for-shitty-software/?ref=sidebar""><strong>Design systems are todayâ€™s cure and tomorrowâ€™s cause of shitty software</strong></a><strong> â†’</strong><br />â€œA new kind of claustrophobia has kicked in now. Software ships across countless platforms and device types. UI frameworks are all but considered mandatory. There are layers and layers of complexity that make 2005 feel like a kindergartnerâ€™s naive daydream. Managing the complexity of â€œmodernâ€ software takes considerable focus. And focus doesnâ€™t grow onÂ trees.â€</li><li><a href=""https://ilyabirman.net/meanwhile/all/design-vs-evolution/?ref=sidebar""><strong>Design is dead, itâ€™s all evolution now</strong></a><strong> â†’</strong><br />â€œThere was a time when products were designed with intent. Sections were organized into a hierarchy, features were given logical places. You could feel a system behind the product: what parts it consists of, how screens are organized, what kinds of data it has. Users didnâ€™t analyze it consciously, but it helped them navigate and gave them a sense of control.â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/openai-ads-as-content-708666ddab2b""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*OSVZofLgd90C-i9G.png"" /></a></figure><p><a href=""https://uxdesign.cc/openai-ads-as-content-708666ddab2b""><strong>OpenAI: from ads to content</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/a0f35cc87dd4"">RodrigoÂ Osornio</a></p><figure><a href=""https://uxdesign.cc/getting-carried-away-when-intelligence-is-replaced-by-compliance-f6c63585f7af""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*_yFegXZURrXnb0SR.png"" /></a></figure><p><a href=""https://uxdesign.cc/getting-carried-away-when-intelligence-is-replaced-by-compliance-f6c63585f7af""><strong>Getting carried away: When intelligence is replaced by compliance</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/a23f14c0ef83"">GauravÂ Ramesh</a></p><figure><a href=""https://uxdesign.cc/why-your-ceo-acts-like-a-clown-the-tribal-myths-of-leadership-b3c2a5f6cc17?sk=1de04a1232f05d8d7e6d95d2b562c873""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*AHKFU1FAtcUtNRL7.png"" /></a></figure><p><a href=""https://uxdesign.cc/why-your-ceo-acts-like-a-clown-the-tribal-myths-of-leadership-b3c2a5f6cc17?sk=1de04a1232f05d8d7e6d95d2b562c873""><strong>The tribal myths of leadership</strong></a> â†’<br />By <a href=""https://medium.com/u/161b4eee2ac1"">MaximÂ Kich</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/the-80-job-how-design-leads-are-using-ai-and-its-not-about-mockups-ce5df0ed78cf""><strong>How design leads are using AI</strong></a><strong> â†’</strong><br />The 80% job.<br />By <a href=""https://medium.com/u/7e26e3cc0dfd"">Vlad Derdeicea</a></li><li><a href=""https://uxdesign.cc/practice-notes-on-including-citizens-in-the-design-process-d28bf115700f""><strong>Including citizens in the design process</strong></a><strong> â†’</strong><br />Field notes on trust and shared agency.<br />By <a href=""https://medium.com/u/e1ffebbf296c"">JackÂ Strachan</a></li><li><a href=""https://uxdesign.cc/field-study-prototypes-over-mockups-8581f20102ff""><strong>Prototypes over mockups</strong></a><strong> â†’</strong><br />A practical guide to designing with code in 2026.<br />By <a href=""https://medium.com/u/ef9e6832a598"">Ã‰douardÂ Wautier</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-mob1"">this weekâ€™s sponsor</a> and support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=568b86eb87f2"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/hidden-cost-of-ai-prototypes-leadership-myths-how-designers-use-ai-568b86eb87f2"">Hidden cost of AI prototypes, leadership myths, how designers use AI</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/what-designers-can-learn-from-the-first-iphone-moment-of-ai-4643d1f14171?source=rss----138adf9c44c---4,1771849318,"The iPhone killed Flash, and economists tracked exactly who survived","The iPhone killed Flash, and economists tracked exactly who survived

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/what-designers-can-learn-from-the-first-iphone-moment-of-ai-4643d1f14171?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1200/0*FuBk_bCzrFgBsjxM"" width=""1200"" /></a></p><p class=""medium-feed-snippet"">The pattern is repeating.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/what-designers-can-learn-from-the-first-iphone-moment-of-ai-4643d1f14171?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/designers-we-should-be-killing-it-right-now-c0a0c535f456?source=rss----138adf9c44c---4,1771849297,"Designers, we should be killing it right now","Designers, we should be killing it right now

<h4>Designers should be thriving in the age of AI. Hereâ€™s why we arenâ€™t, why itâ€™s probably our fault, and how we can fixÂ it.</h4><figure><img alt=""The Beatles on red pointy hats with sunflowers"" src=""https://cdn-images-1.medium.com/max/1024/1*wXwxelMpQ2KNjnTN1Tzm-w.png"" /><figcaption>The Beatles, Magical Mystery TourÂ (<a href=""https://www.imdb.com/de/title/tt0061937/mediaviewer/rm3997504000/"">source</a>)</figcaption></figure><p>Much has been said about the future of design in the age of AI. Some think the role will disappear completely. Others say only super-seniors will survive. And yet others say itâ€™s all just a blip in time and there will be no fundamental change.</p><p>I think all areÂ wrong.</p><p>For twoÂ reasons:</p><ol><li>Designers are naturally attuned to adapt to technological change. We are trained to identify and acknowledge change, manage adaptation, and find solutions for friction.</li><li>Weâ€™re moving towards a totally new definition of digital products. Away from interfaces, and towards fluid use cases that weâ€™re only beginning to imagine now. To make this accessible and valuable to all, we will need designers at all levels. <em>Obviously</em>.</li></ol><p>Why, then, has the design community been in absolute panic since AI has been takingÂ off?</p><p>Seniors are telling juniors to count themselves lucky if theyâ€™ll ever find aÂ job.</p><p>Design leaders are jumping from one AI-tool hypetrain to the next in mereÂ weeks.</p><p>Monday, itâ€™s all about prototypes. Thursday, itâ€™s vibe coding. Friday, weâ€™re preaching that output no longer matters (everyone can design now!) and that we should be brilliant strategists instead. By next Monday, weâ€™ll be half-heartedly debating which soft skills are absolutely vital toÂ survive.</p><p><em>Survive.</em> As designers.</p><p>As if our skills have evaporated overnight, and we can only stick around if we somehow show that weâ€™re good for (undefined) otherÂ stuff.</p><p>No.</p><p>We should be thriving.</p><p>Where has it all gone wrong? Why arenâ€™t designers winning in the age of AI, which, at its core, is aboutÂ <em>making</em>?</p><p>The thing we doÂ best.</p><p>Hereâ€™s what IÂ think.</p><h4>Weâ€™ve been sabotaging ourselves.</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*7ogC1IGrkuO2HuDnFDBoKA.png"" /><figcaption>The Beatles, Magical Mystery TourÂ (<a href=""https://www.imdb.com/de/title/tt0061937/mediaviewer/rm1950683648/"">source</a>)</figcaption></figure><p>Please donâ€™t be enraged. Take a deep breath and think aboutÂ it.</p><p>Ever since the first AI tools with strong visual output started emerging, we seemingly overnight started screaming from all rooftopsÂ about:</p><p><strong><em>taste</em></strong>.</p><h4>What the fck isÂ taste?</h4><p><a href=""https://www.nngroup.com/articles/taste-vs-technical-skills-ai/"">According to NNG</a> itâ€™s â€œthe learned, subjective ability to discern and select the most effective, harmonious, and high-quality elements for a projectâ€.</p><p>Maybe, if youâ€™re really smart, you can picture what that means. But really, if youâ€™re honest, taste is a vague concept. Taste is subjective. Taste is not something that makes a product win (for the mostÂ part).</p><p>And vague is not <em>good</em>â€Šâ€”â€Šespecially not in a time of transformation where no one really knows where weâ€™re going yet. Where tech stacks are changing weekly, and user needs are developing at rocketÂ speed.</p><p>You know what else <em>vague</em> is bad for? Convincing an executive to invest in something.</p><p>It generally takes three things to grab an executive's attention.</p><ol><li>Connection (Do you get their problem?).</li><li>Authority (Do you know yourÂ stuff?).</li><li>Vision (Do you know where this isÂ going?).</li></ol><p>Taste doesnâ€™t answer any of those. You know what elseÂ doesnâ€™t?</p><h4>Shitty prototypes.</h4><p>Yeah, Iâ€™ve made my fair share of them, too. But the time when these impressed anyone is over. Even my 0% designer husband can now vibe code stuff and knows how to whip up a design prototype.</p><p>There is a time and place for them. Prototypes and vibe-coded projects are great to show a vision, build excitement, or unblock a team thatâ€™s stuck in process. But theyâ€™re not whatâ€™s gonna convince your engineering stakeholders to give you access to their codebase so you can actually start shipping fixes from your designÂ backlog.</p><p>Iâ€™d like to argue that excessive prototyping is the next big issue thatâ€™s messing with the status of design in the age ofÂ AI.</p><p>Because they undermine our authority. Thereâ€™s the executiveâ€™s next red flag. <em>Do you know yourÂ stuff?</em></p><p>Of course, designers recognised this concern quickly. How did weÂ respond?</p><p>By starting never-ending discussions about:</p><p><strong><em>craft</em>.</strong></p><h4>What the heck isÂ craft?</h4><p>I like <a href=""https://www.nsead.org/resources/teaching-inspiration/craft/defining-craft/"">this definition</a>: â€œCraft can be defined as intelligent making. It is technically, materially and culturally informed. Craft is the designing and making of individual artefacts and objects, encouraging the development of intellectual, creative and practical skills, visual sensitivity and a working knowledge of tools, materials and systemsâ€.</p><p>Welp.</p><p><em>Taste and craft walk into aÂ barâ€¦</em></p><p>Just kidding.</p><p>You get my point. Here is another vague concept that most people associate with activities they liked to do back in kindergarten.</p><p>And listen, Iâ€™m not knocking craft. I love writing poetry, painting, throwing pots at the wheel. All that takes craft and skill, just as my designs at work do. But craft should be so obvious to us as designers that we should not make it our <em>main</em> sellingÂ point.</p><p>Obviously, we develop incredible craft as our experience builds. Obviously, individual designers have different styles. Obviously, we put thought and care into what weÂ make.</p><p>Craft is the baseline. Thatâ€™s what we want the executives to know. By debating it and what it even means, weâ€™re again undermining our authority. And Iâ€™d argue weâ€™re also not really connecting with them OR showing muchÂ vision.</p><p>Well, shit.</p><p><strong>How do we get out of thisÂ mess?</strong></p><p>We need to rememberâ€Šâ€”â€Šand remind othersâ€Šâ€”â€Šwhy design is irreplaceable.</p><h4>Weâ€™re the OGÂ makers.</h4><p>Weâ€™re â€œgrowth mindsetâ€, personified.</p><p>In most classic product companies, there are <a href=""https://www.producttalk.org/glossary-discovery-product-trio/"">trios</a>: A product manager, a designer, and an engineer. The point? To ensure that the perspectives of the users and the business are balanced with the technical capabilities throughout the development process.</p><p>While a well-functioning trio feels like a cheat code to achieving product velocity, an unbalanced one can slow things down, ship mediocre stuff, or not atÂ all.</p><p>The best trios Iâ€™ve worked in and observed had one very obvious trait in common: we all respected each other's practice, but we also understood enough about each otherâ€™s domains to be unafraid to pushÂ back.</p><p>Only a designer who understands the business side of things can really translate business goals into conversion flows.</p><p>Only a product manager who understands the fundamentals of good design can push a designer to levelÂ up.</p><p>And only an engineer who cares for users and understands how the business works is an equal partner in aÂ trio.</p><p>And while AI is bringing all of our roles closer together, we are still the builders of <em>the experience</em>.</p><p>The thing that is actually being used. The thing executives aim toÂ deliver.</p><ol><li><strong>Connection</strong>: You want to make something. We can tell you if itâ€™s possible. If yes, we can ensure itâ€™s made in the best possibleÂ way.</li><li><strong>Authority</strong>: We work at the intersection of what the business wants, the user needs, and what actuallyÂ works.</li><li><strong>Vision</strong>: We have the skills, tools, and mindset to create something you <em>canâ€™t even/can only</em>Â imagine.</li></ol><p>Sold.</p><h4>The design mindset isÂ unique.</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*iI-tGWT87XJnnLmo7XwFKA.png"" /><figcaption>The Beatles, Magical Mystery TourÂ (<a href=""https://www.imdb.com/de/title/tt0061937/mediaviewer/rm725418752/"">source</a>)</figcaption></figure><p>And itâ€™s beautiful.</p><p><strong>Itâ€™s human-centred. </strong>Deep empathy for the user is the foundation, ensuring solutions address real needs, feelings, and motivations.</p><p><strong>It embraces ambiguity.</strong> Viewing problems as opportunities rather than roadblocks.</p><p><strong>It kills its darlings by default and favours learning.</strong> A willingness to â€œfail fast,â€ learn from prototypes, and constantly adapt solutions based on feedback.</p><p><strong>Itâ€™s, at its core, optimistic and inclusive.</strong> Bringing diverse perspectives together, believing that better solutions can always beÂ created.</p><p><strong>Itâ€™s the most curious of mindsets.</strong> Asking â€œwhyâ€ and â€œwhat ifâ€ to challenge the status quo at everyÂ turn.</p><p>You donâ€™t have to read this twice to know: hell yes, we need designers with AI taking over more and more space in ourÂ lives.</p><h4>Hereâ€™s what we need to do.Â Now.</h4><p>In most classic design teams, there are different roles: Product designers, content designers, user researchers, sometimes motion designers, and ops people. Their educational background is essentially the same: developing an understanding of users, business, and products. Some focus more on the look and feel, others on going in depth on the â€œhow itÂ worksâ€.</p><p><strong>So, for the love of everything good, can we please stop debating ourÂ titles?</strong></p><h4>We are all designers.</h4><p>Designers make stuff. Some use words and taxonomy, others use pixels. Some use language, others use code. The mindset is the same. The mindset is whatÂ matters.</p><p><strong>Yes, AI is muddying the lines between design roles. But it doesnâ€™tÂ matter.</strong></p><p>Not because it can replace people, but because it can save time that, in return, can be used to develop the skills traditionally only another role would need. Not so you can replace someone,Â but:</p><p><strong>So you can become a more holistic, betterÂ maker.</strong></p><p>This is notÂ new.</p><p>Thereâ€™s always been a push for all designers to do their own research. For content designers to develop visual skills. For product designers to get strong at prototyping. Now, finally, we can do soâ€Šâ€”â€Šwith far less effort thanÂ before.</p><p>That doesnâ€™t mean we should think less. It means we <em>can</em> thinkÂ more.</p><p>I, personally, love thinking. Nothing gets me as high as solving a problem. Itâ€™s the reason I got into design, and specifically design in tech, in the first place. There were actual (cool) problems toÂ solve.</p><p>I originally picked UX content as my toolkit. Now, my toolkit has expanded. I love that. And I donâ€™t want to waste time wondering what my title should be, whether my taste is good enough, or what <em>exactly</em> my craft isÂ now.</p><p>I want to makeÂ stuff.</p><p>And I think you do,Â too.</p><p>Nicole is a Content Designer turned Design Director based in Stockholm, Sweden. She potters, writes poetry, and raises little girls in a house by a meadow. You can follow her writing here or get it directly to your inbox via her publication, <a href=""https://eggwoman.substack.com/"">eggwoman</a>. Nicole is on <a href=""https://www.linkedin.com/in/nicoletells/"">Linkedin</a>.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c0a0c535f456"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/designers-we-should-be-killing-it-right-now-c0a0c535f456"">Designers, we should be killing it right now</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/something-big-might-be-happening-16cdba2df6ad?source=rss----138adf9c44c---4,1771849175,Something big â€œmightâ€ be happening,"Something big â€œmightâ€ be happening

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/something-big-might-be-happening-16cdba2df6ad?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1200/0*8j9GZ3604R5ROnc8"" width=""1200"" /></a></p><p class=""medium-feed-snippet"">Why the future of design belongs to creative thinkers and problem solvers</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/something-big-might-be-happening-16cdba2df6ad?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/no-vr-cant-make-you-walk-in-others-shoes-608a1ba03e97?source=rss----138adf9c44c---4,1771849139,"No, VR canâ€™t make you walk in othersâ€™ shoes","No, VR canâ€™t make you walk in othersâ€™ shoes

<h4>The shallowness of the â€œempathy machine.â€</h4><figure><img alt=""a guy using VR headset in a fancy living room"" src=""https://cdn-images-1.medium.com/max/1024/0*5waTlYqbHeJwFdxz"" /><figcaption>Photo by <a href=""https://unsplash.com/@silverkblack?utm_source=medium&amp;utm_medium=referral"">Vitaly Gariev</a> onÂ <a href=""https://unsplash.com?utm_source=medium&amp;utm_medium=referral"">Unsplash</a></figcaption></figure><p>I once saw a â€œpoverty simulationâ€ designed to help raise funds and â€œput people in othersâ€™ shoes.â€ I feltâ€¦ weird. Can you imagine someone going through a 10-minute fancy VR experience and suddenly claiming they understand the struggles?</p><p>VR allows users to step into any experience from a first-person perspective. Some people call it an â€œ<a href=""https://www.youtube.com/watch?v=iXHil1TPxvA\"">empathy machine</a>â€ and argue that it could influence decision-makers. I bought into it at first. However, after going through several simulations, I noticed that no matter how moved I was in the moment, none of it led to any real behavioral change.</p><p>Is it just me? Or is this â€œtrigger empathy and cause behavioral changeâ€ design goal too impractical and overhyped?</p><h3>Why do people believe that VR can triggerÂ empathy?</h3><p>VR allows users to inhabit avatars, and their brains might start believing that the virtual body is theirs (<a href=""https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.814565/full"">researchers</a> call this â€œsense of embodimentâ€). Some designers believe this can <strong>encourage perspective-taking, reduce implicit bias, and eventually induceÂ empathy.</strong></p><p>In theory, it makes sense. But in reality, this assumption is too ideal and shallow. First, your brain isnâ€™t that easy to trick. A tiny glitchâ€Šâ€”â€Ša slight delay between movement and render, or weird skin textureâ€Šâ€”â€Šwill remind you itâ€™s fake. More importantly, embodiment alone is just a shallow representation of identity. For example, putting users in a Black body doesnâ€™t give them hundreds of years of history or lived experience. It doesnâ€™t make them part of the Black community, and it certainly wonâ€™t create sustainable empathy.</p><h3>What is empathy,Â exactly?</h3><p>This word seems a bit abstract, so letâ€™s define it better here. When <a href=""https://tmb.apaopen.org/pub/vr-improves-emotional-empathy-only/release/2"">researchers </a>and designers discuss empathy, theyâ€™re usually talking about two different kinds: <strong>emotional </strong>and <strong>cognitive</strong>.</p><p>Emotional empathy is immediate and direct, like seeing someone in pain makes you feel discomfort too. Cognitive empathy goes deeper. Itâ€™s when you actively try to understand someoneâ€™s mental state and decision-making process, and this kind of empathy is what usually leads to behavioral change.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*AiXVB-J8JEHS2BtKZ3n9VA.png"" /></figure><p>VR is pretty good at triggering emotional empathy because it provides users with intense sensory information. But the reaction doesnâ€™t last. For me, it usually starts fading about 10 minutes after removing the headset. I think the problem is that while Iâ€™m in the experience, Iâ€™m so overwhelmed by everything Iâ€™m sensing that I canâ€™t actually think about what the character is going through mentally.<strong> Without that deeper engagement, cognitive empathy never gets triggered.</strong></p><h3><strong>VRâ€™s shallowÂ content</strong></h3><p>Beyond sensory overload, VR simulations lack the depth needed for cognitive empathy.</p><p>The content is often shallow. Letâ€™s compare it with other storytelling media: movies and books are usually built on years of research and interviews, while VR simulations prioritize technical execution, focusing on realistic graphics and interactions over storytelling depth. <strong>Users often end up distracted by the novelty of technology instead of engaging with theÂ issues.</strong></p><p>Time is another constraint. Most VR simulations run under 10 minutes, which isnâ€™t enough to convey background or context. Understanding social issues often requires hours of learning and engagement just to grasp the basics. However, creating longer experiences isnâ€™t practical either because VR headsets are bulky and uncomfortable, and the sensory intensity creates fatigueÂ quickly.</p><h3><strong>When VR simulation mightÂ work</strong></h3><p>VR probably isnâ€™t the best tool for creating sustainable empathy or long-term behavioral change. However, it can still be effective when applied with clear, specific design goals instead of vague â€œtriggering empathyâ€ objectives.</p><p>Take healthcare training for example. <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC6148621/"">Research </a>shows that medical students better understand conditions like Alzheimerâ€™s through VR, improving their compassionate care. It works because <strong>VR complements their existing education.</strong> These students already study these topics extensively through patient shadowing, workshops, and reflective practice.</p><p>Unlike general audiences with no background, these students approach VR with clear learning objectives. They know theyâ€™re not trying to â€œfeel likeâ€ elderly patients but learning to recognize specific physical symptoms. Theyâ€™re less likely to get distracted by the technology and can navigate the experience better. The actual empathy develops later, when they interact with real patients.</p><p>No one can really â€œwalk in othersâ€™ shoes.â€ Empathy is a complex emotion. Social issues are far more complicated than any simulation can capture, and technology only scratches the surface: loud explosions simulate sound, not fear. Disorientation replicates physical sensations, not the psychological toll of experiencing it everyÂ day.</p><p>New technology isnâ€™t always the shortcut to the solution. Real perspective-taking requires a more time-consuming traditional approach: engaging with communities, reading, and listening. As a developer, I try to remember these limitations instead of chasing technology hype with vague, overambitious goals.</p><h3>Reference:</h3><ol><li>Milk, C. [TED]. (2015). How virtual reality can create the ultimate empathy machine [Video]. YouTube. <a href=""https://www.youtube.com/watch?v=iXHil1TPxvA"">https://www.youtube.com/watch?v=iXHil1TPxvA</a></li><li>Martingano, A. J., Hererra, F., &amp; Konrath, S. (2021). Virtual Reality Improves Emotional but Not Cognitive Empathy: A Meta-Analysis. <em>Technology, Mind, and Behavior</em>, <em>2</em>(1). <a href=""https://doi.org/10.1037/tmb0000034"">https://doi.org/10.1037/tmb0000034</a></li><li>Dyer, E., Swartzlander, B. J., &amp; Gugliucci, M. R. (2018). Using virtual reality in medical education to teach empathy. <em>Journal of the Medical Library AssociationÂ : JMLA</em>, <em>106</em>(4), 498â€“500. <a href=""https://doi.org/10.5195/jmla.2018.518"">https://doi.org/10.5195/jmla.2018.518</a></li><li>Sora-DomenjÃ³ C (2022) Disrupting the â€œempathy machineâ€: The power and perils of virtual reality in addressing social issues. Front. Psychol. 13:814565. doi: 10.3389/fpsyg.2022.814565</li></ol><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=608a1ba03e97"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/no-vr-cant-make-you-walk-in-others-shoes-608a1ba03e97"">No, VR canâ€™t make you walk in othersâ€™ shoes</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/on-craft-and-connivence-6fa58e2c865e?source=rss----138adf9c44c---4,1771849127,On craft and connivence,"On craft and connivence

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/on-craft-and-connivence-6fa58e2c865e?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*-wfGuiGXJriR43ufzSNCTQ.png"" width=""26245"" /></a></p><p class=""medium-feed-snippet"">Lessons in design, from a USB drive to the age of AI, and beyond.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/on-craft-and-connivence-6fa58e2c865e?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
