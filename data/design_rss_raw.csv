source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/intent-prototyping-pure-vibe-coding-enterprise-ux/,1758733200,Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1),"Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1)

Yegor Gilyov examines the problem of over-reliance on static high-fidelity mockups, which often leave the conceptual model and user flows dangerously underdeveloped. He then explores whether AI-powered prototyping is the answer, questioning whether the path forward is the popular “vibe coding” approach or a more structured, intent-driven approach."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ambient-animations-web-design-principles-implementation/,1758546000,Ambient Animations In Web Design: Principles And Implementation (Part 1),"Ambient Animations In Web Design: Principles And Implementation (Part 1)

Creating motion can be tricky. Too much and it’s distracting. Too little and a design feels flat. Ambient animations are the middle ground &mdash; subtle, slow-moving details that add atmosphere without stealing the show. In this article, web design pioneer Andy Clarke introduces the concept of ambient animations and explains how to implement them."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/psychology-trust-ai-guide-measuring-designing-user-confidence/,1758276000,The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence,"The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence

With digital products moving to incorporate generative and agentic AI at an increasingly frequent rate, trust has become the invisible user interface. When it works, interactions feel seamless. When it fails, the entire experience collapses. But trust isn’t mystical. It can be understood, measured, and designed for. Here are practical methods and strategies for designing more trustworthy and ethical AI systems."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/how-minimize-environmental-impact-website/,1758189600,How To Minimize The Environmental Impact Of Your Website,"How To Minimize The Environmental Impact Of Your Website

As responsible digital professionals, we are becoming increasingly aware of the environmental impact of our work and need to find effective and pragmatic ways to reduce it. James Chudley shares a new decarbonising approach that will help you to minimise the environmental impact of your website, benefiting people, profit, purpose, performance, and the planet."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/serpapi-complete-api-fetching-search-engine-data/,1758042000,SerpApi: A Complete API For Fetching Search Engine Data,"SerpApi: A Complete API For Fetching Search Engine Data

From competitive SEO research and monitoring prices to training AI and parsing local geographic data, real-time search results power smarter apps. Tools like SerpApi make it easy to pull, customize, and integrate this data directly into your app or website."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/functional-personas-ai-lean-practical-workflow/,1758009600,"Functional Personas With AI: A Lean, Practical Workflow","Functional Personas With AI: A Lean, Practical Workflow

For too long, personas have been created with considerable effort, only to offer limited value. Paul Boag shows how to breathe new life into this stale UX asset and demonstrates that it’s possible to create truly useful functional personas in a lightweight way."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/creating-elastic-bounce-effects-expressive-animator/,1757930400,Creating Elastic And Bounce Effects With Expressive Animator,"Creating Elastic And Bounce Effects With Expressive Animator

Elastic and bounce effects have long been among the most desirable but time-consuming techniques in motion design. Expressive Animator streamlines the process, making it possible to produce lively animations in seconds, bypassing the tedious work of manual keyframe editing."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ux-strategies-real-time-dashboards/,1757689200,From Data To Decisions: UX Strategies For Real-Time Dashboards,"From Data To Decisions: UX Strategies For Real-Time Dashboards

Real-time dashboards are decision assistants, not passive displays. In environments like fleet management, healthcare, and operations, the cost of a delay or misstep is high. Karan Rawal explores strategic UX patterns that shorten time-to-decision, reduce cognitive overload, and make live systems trustworthy."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/integrating-css-cascade-layers-existing-project/,1757498400,Integrating CSS Cascade Layers To An Existing Project,"Integrating CSS Cascade Layers To An Existing Project

The idea behind this is to share a full, unfiltered look at integrating CSS Cascade Layers into an existing legacy codebase. In practice, it’s about refactoring existing CSS to use cascade layers without breaking anything."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/designing-tv-principles-patterns-practical-guidance/,1756980000,"Designing For TV: Principles, Patterns And Practical Guidance (Part 2)","Designing For TV: Principles, Patterns And Practical Guidance (Part 2)

After covering in detail the underlying interaction paradigms of TV experiences in [Part 1](https://www.smashingmagazine.com/2025/08/designing-tv-evergreen-pattern-shapes-tv-experiences/), it’s time to get practical. In the second part of the series, you’ll explore the building blocks of the “10-foot experience” and how to best utilise them in your designs."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/desktop-wallpaper-calendars-september-2025/,1756627200,A Breeze Of Inspiration In September (2025 Wallpapers Edition),"A Breeze Of Inspiration In September (2025 Wallpapers Edition)

Could there be a better way to welcome the new month than with a new collection of desktop wallpapers? We’ve got some eye-catching designs to make your September just a bit more colorful. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/prompting-design-act-brief-guide-iterate-ai/,1756461600,"Prompting Is A Design Act: How To Brief, Guide And Iterate With AI","Prompting Is A Design Act: How To Brief, Guide And Iterate With AI

Prompting is more than giving AI some instructions. You could think of it as a design act, part creative brief and part conversation design. This second article on AI augmenting design work introduces a designerly approach to prompting: one that blends creative briefing, interaction design, and structural clarity."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/designing-tv-evergreen-pattern-shapes-tv-experiences/,1756299600,Designing For TV: The Evergreen Pattern That Shapes TV Experiences (Part 1),"Designing For TV: The Evergreen Pattern That Shapes TV Experiences (Part 1)

TV interface design is a unique, fascinating, and often overlooked field. It’s been guided by decades of evolution and innovation, yet still firmly constrained by its legacy. Follow Milan into the history, quirks, and unshakable rules that dictate how we control these devices."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/optimizing-pwas-different-display-modes/,1756195200,Optimizing PWAs For Different Display Modes,"Optimizing PWAs For Different Display Modes

Progressive Web Apps (PWAs) are a great way to make apps built for the web feel native, but in moving away from a browser environment, we can introduce usability issues. This article covers how we can modify our app depending on what display mode is applied to mitigate these issues."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/week-in-life-ai-augmented-designer/,1755849600,A Week In The Life Of An AI-Augmented Designer,"A Week In The Life Of An AI-Augmented Designer

If you are new to using AI in design or curious about integrating AI into your UX process without losing your human touch, this article offers a grounded, day-by-day look at introducing AI into your design workflow."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/double-edged-sustainability-sword-ai-web-design/,1755684000,The Double-Edged Sustainability Sword Of AI In Web Design,"The Double-Edged Sustainability Sword Of AI In Web Design

AI has introduced huge efficiencies for web designers and is frequently being touted as the key to unlocking sustainable design and development. But do these gains outweigh the environmental cost of using energy-hungry AI tools?"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/beyond-hype-what-ai-can-do-product-design/,1755522000,Beyond The Hype: What AI Can Really Do For Product Design,"Beyond The Hype: What AI Can Really Do For Product Design

AI tools are improving fast, but it’s still not clear how they fit into a real product design workflow. Nikita Samutin walks through four core stages &mdash; from analytics and ideation to prototyping and visual design &mdash; to show where AI fits and where it doesn’t, illustrated with real-world examples."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/psychology-color-ux-design-digital-products/,1755270000,The Psychology Of Color In UX And Digital Products,"The Psychology Of Color In UX And Digital Products

Rodolpho Henrique guides you through the essential aspects of color in digital design and user experience, from the practical steps of creating effective and scalable color palettes to critical accessibility considerations."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/from-line-to-layout-past-experiences-shape-design-career/,1755082800,From Line To Layout: How Past Experiences Shape Your Design Career,"From Line To Layout: How Past Experiences Shape Your Design Career

Your past shapes who you are as a designer, no matter where your career began or how unexpected your career path may have been. Stephanie Campbell shows how those lessons can sharpen your instincts, strengthen collaboration, and help you become a better designer today."
rss,uxdesign.cc,https://uxdesign.cc/is-imitation-theft-or-apprenticeship-fc145f3f3a31?source=rss----138adf9c44c---4,1758878915,Is imitation theft or apprenticeship?,"Is imitation theft or apprenticeship?

<h4>What two forgotten thinkers can teach us about voice, intent and AI-assisted work.</h4><figure><img alt=""A 19th-century oil painting shows a young apprentice painter standing beside a senior artist, carefully copying the master’s work onto his own canvas. The studio is dimly lit but detailed, with wooden floors, high windows, and art supplies scattered around. The apprentice appears focused, while the master, seated nearby, observes with quiet authority. The scene captures the traditional method of learning through imitation and side-by-side practice."" src=""https://cdn-images-1.medium.com/max/1024/1*fxMgjDsG3Ym1H1RevBFf2Q.png"" /><figcaption>Image created by author</figcaption></figure><p>In 18th-century Europe, aspiring painters learned to paint by copying other artists.</p><p>They spent years in studios reproducing sketches and practicing technique. The point was to learn through repetition, and copying helped these aspiring artists understand what good looked like. Imitation was just part of the process.</p><p>Only after years of apprenticeship did painters begin to branch off.</p><p>Today, we’re talking about voice and style — something we used to develop through practice and feedback. Now that we have tools that help us produce faster than ever, we’ve failed to teach what good work looks like along the way.</p><p>When something feels like it was produced with AI, we discount its quality. We often blame the tool, or worse, we blame the person using it.</p><p>To bring some clarity, we’re bringing back two forgotten thinkers: <a href=""https://www.britannica.com/biography/Anna-Laetitia-Barbauld"">Anna Laetitia Barbauld</a> and <a href=""https://www.britannica.com/biography/Richard-Bentley"">Richard Bentley</a>. Together, they offer a path forward.</p><p>I’m <a href=""https://www.linkedin.com/in/natesowder/"">Nate Sowder</a>, and this is <strong>unquoted, installment 7</strong>,<strong> </strong>a series about the people behind the ideas we can’t afford to forget.</p><figure><img alt=""Black-and-white engraved portrait of Anna Laetitia Barbauld, shown in profile facing left. She wears a ruffled cap with dark ribbons and a simple gown with a high neckline and lace collar. The shading is soft and sketch-like, giving the image a delicate, textured quality."" src=""https://cdn-images-1.medium.com/max/1024/1*i4OUBAAlj7v2fbgDo0hzDw.jpeg"" /><figcaption>Engraving of Anna Laetitia Barbauld by Henry Hoppner Meyer, 1822. (Public Domain)</figcaption></figure><h3>Barbauld and the practice of imitation</h3><p>In the late 1700s, Anna Laetitia Barbauld was writing poems, essays, and teaching at a time when few women had access to formal intellectual training.</p><p>She taught at Warrington Academy, a progressive school in England that served students excluded from elite institutions. Many of her pupils had never been taught how to write with structure or style.</p><p>Her method was simple: start by copying existing essays and poems. Over time, that helped students develop a sense of their own style by first understanding others’.</p><blockquote>“The mind must be fed by imitation before it can create.”</blockquote><p>To Barbauld, imitation was the path to originality.</p><figure><img alt=""Engraved portrait of Richard Bentley, an 18th-century English classical scholar. He is shown seated, facing slightly to the left, with long curly hair, wearing clerical robes and a white collar. His right hand rests on a closed book, which he holds at the bottom edge. The background is plain and shaded, emphasizing his face and attire."" src=""https://cdn-images-1.medium.com/max/1024/1*HDZRDgC3rKubmS3_gneIqA.jpeg"" /><figcaption>Bentley, Richard (1662–1742) (Public Domain)</figcaption></figure><h3>Bentley and the structure of style</h3><p>While Barbauld was helping students find their voice, Richard Bentley was working to detect where voice had gone missing.</p><p>Bentley was a classical scholar in the early 1700s who built a reputation on his ability to <a href=""https://www.britannica.com/topic/textual-criticism"">spot forgery</a>. His most famous takedown was <em>The Letters of Phalaris</em>, a widely admired collection of ancient Greek writings once believed to be authentic. Bentley read them and disagreed.</p><p>When the syntax didn’t match, he realized the voice of the piece was all wrong. The references were off and the structure lacked consistency with the rest of the canon. Bentley could hear when something didn’t belong. He didn’t need proof in reference materials and records. Instead, he looked for a pattern he could follow.</p><p>He treated style as evidence and voice as something you could trace.</p><h3>Why it matters</h3><p>When you replace the process of developing expertise with productivity tools you stop teaching people how to build their voice. Instead, you hand them Mad Libs, templates and mandates like “use AI” but never define how, how much or to what end.</p><p>And then when the work feels too clean or like the person who wrote it… didn’t, we don’t ask what the person was trying to say.</p><p>We ask if they cheated.</p><p>That kind of suspicion kills growth. It tells people: Try this, but use it the perfect amount (without ever showing them what that looks like), and when they get it wrong, don’t coach them… judge them.</p><p>If AI becomes a source of shame, I think a lot of people will stop using it. They’ll avoid new opportunities, hide their process and aim for ‘safe and small’ outcomes.</p><h3>What to do instead</h3><p>This problem doesn’t fix itself. If we want people to use AI well, we have to define what that means, not just urge adoption and <em>hope</em> for the best. That means setting clear boundaries, offering real feedback and helping people grow into a voice that’s theirs (which can’t happen in a vacuum).</p><p><strong>Barbauld gave us a blueprint for that kind of growth.</strong><br />She showed that imitation, when guided, builds fluency. It helps people understand how ideas flow, how style works and how meaning holds together.</p><p><strong>Bentley gave us the tools to listen.</strong><br />He showed that voice isn’t invisible. It leaves a trail that can be studied, taught and refined (if we care enough to notice it).</p><p>Together, their teaching offers something AI tools can’t:<br /><strong>A path for learning how to sound like yourself.</strong></p><p>We need less suspicion and more systems that help people build toward authorship.</p><p>Voice and style matter. Put in the work to develop your own.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fc145f3f3a31"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/is-imitation-theft-or-apprenticeship-fc145f3f3a31"">Is imitation theft or apprenticeship?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4,1758821283,The timeless Apple “hello” logo,"The timeless Apple “hello” logo

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/772/1*7u06zeblW0tCidijNrro6g.png"" width=""772"" /></a></p><p class=""medium-feed-snippet"">The understated beauty and whimsy of pixel art typography &#x1f3a8; &#x1f3ae;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4,1758796015,Don’t make me blush: Are machines truly capable of emotion?,"Don’t make me blush: Are machines truly capable of emotion?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1920/1*RzKnBbop38qmtAgiSQER3Q.jpeg"" width=""1920"" /></a></p><p class=""medium-feed-snippet"">Can technology truly experience emotion, or only mimic it convincingly?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/vibe-code-straight-from-your-website-ce52eef25d95?source=rss----138adf9c44c---4,1758795859,Vibe code straight from your website,"Vibe code straight from your website

<h4>Skip Figma and prototype where your product already lives</h4><p>Prototyping and testing new product features or concepts usually means starting from scratch with a blank design canvas. The workflow looks a little like this: UX designers build product screens in Figma, pass the designs for feedback, then developers recreate the same screens in code. Though this is the traditional design and development process we’re used to, the workflow can be slow and redundant.</p><p><strong>Not only does this established process cause inefficiency in product development, but it’s disconnected from the actual product, losing context and real user-interaction behavior.</strong></p><p>But what if you can adapt your design and development workflow to skip the unnecessary rework and keep the user’s context? Being able to prototype directly on your live website’s product pages, like tweaking layouts or exploring features, allows you to cut the time and resources needed to implement and test new ideas.</p><figure><img alt=""Vibe coding with Anima’s “Web-to-code” feature with the AI chat on the left and code preview on the right"" src=""https://cdn-images-1.medium.com/max/1024/1*yF0WH6JRq6nAnWjpMQisWg.png"" /><figcaption>Vibe coding with <a href=""https://chromewebstore.google.com/detail/web-to-code-by-anima/paddhneaanoeljlmdepnheehdkaegblo"">Anima’s “Web-to-code”</a> feature</figcaption></figure><p><strong>By vibe coding straight from your website, you keep the design process realistic to the user’s experience, and keep design and implementation in sync from the start.</strong></p><p>You may be thinking of ways you can streamline your own design-development process or if vibe coding is right for you and your team. To answer these questions, let’s explore vibe coding’s benefits and limits when using live websites, demo tools that enable this workflow, and review use cases to determine where this process can be integrated within the design process.</p><h3>Benefits and limits of vibe coding with your website</h3><p><strong>Instead of starting the vibe code process from Figma or Sketch designs, you can cut straight to your live product.</strong> Vibe coding directly on your website avoids duplicate effort (e.g., creating the same UI mockup with slight variations), and keeps the user’s context that gets lost in design tools. This results in prototypes that not only look realistic, but behave like the actual product — making them easier to validate with both users and stakeholders.</p><blockquote><em>For more of an introduction to vibe coding and how it fits in the UX process, check out this article: </em><a href=""https://uxdesign.cc/testing-your-ux-ideas-with-vibe-coding-8302620c17af""><em>“Testing your UX ideas with vibe coding.”</em></a></blockquote><h4>Benefits to your website</h4><ul><li><strong>Speed</strong>: By modifying spacing, colors, or users flows right on your site, you eliminate the extra steps of remaking your product screens in any design tool — cutting hours (or even days) from the iteration cycle.</li><li><strong>Accuracy</strong>: Vibe coding in your website keeps behaviors like hover states, responsiveness, and navigation (typically lost in design tools), so the prototype reflects real user interactions with the product.</li><li><strong>Testing confidence</strong>: Because changes are made on top of real product flows, usability testing offers reliable feedback (which you don’t get from artificial prototypes in Figma or Sketch).</li></ul><figure><img alt=""Patagonia’s home page at a mobile breakpoint from Chrome’s dev tools on a desktop screen"" src=""https://cdn-images-1.medium.com/max/1024/1*4Ew1U1pkaYa1Bs2Hlq72iQ.png"" /><figcaption>Using a site to vibe code allows you to view mobile and desktop breakpoints; via <a href=""https://www.patagonia.com/home/"">Patagonia</a></figcaption></figure><h4>Limits with vibe coding</h4><ul><li><strong>Messy code</strong>: Depending on the tool, vibe coding can generate code that’s great for exploration but is not production-ready; developers will need to evaluate and possibly rebuild the code.</li><li><strong>Security risks</strong>: When working with live sites or sites with required user sign-in, you need to be careful about exposing sensitive data like user info, tokens, or private content.</li><li><strong>Not scalable for large systems</strong>: Vibe coding works well for small tweaks and user flows, but is not a replacement for building complex features or keeping consistency across platforms.</li></ul><figure><img alt=""Slack’s login page to sign in with a company email"" src=""https://cdn-images-1.medium.com/max/1024/1*5F12b9_n-luEuqBcDO0byQ.png"" /><figcaption>Vibe coding with authenticated sites can pose security issues; via <a href=""https://slack.com/get-started#/createnew"">Slack</a></figcaption></figure><h3>How to start vibe coding with your site</h3><p>There are plenty of vibe coding tools out there today, but not many let you vibe code directly from your live website. Most focus on creating one to multi-page user flows from a few design mockups from Figma or from AI prompts. These prototypes and the AI-generated code can be helpful, but keep you one step removed from your actual product.</p><p>Let’s get into Anima’s “web to code” feature and Chrome extension to demo how you can vibe code directly from your (or any public) website, then look into other similar tools that offer vibe coding from your live site.</p><h4>“Web to code” demo</h4><ol><li>Copy your website’s URL and paste it into <a href=""https://dev.animaapp.com/?framework=react&amp;language=typescript&amp;styling=tailwind&amp;l2cEngine=auto&amp;importType=link"">Anima’s web to code tool</a></li><li>Choose your preferred framework, language, and styling (or keep the default options), then select the “arrow” icon button</li></ol><blockquote>Note<em>: Anima automatically recognizes your Design System’s UI components; when it creates additional pages, it will reuse the components to maintain consistency.</em></blockquote><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*AIExuPUd4fhrx-oZ5ICf6g.png"" /><figcaption>Copy and paste any public website URL into Anima to generate design and code</figcaption></figure><p>3. After selecting the arrow icon button, you’re asked if you’re using the website as inspiration or if you own/ have right to the website; select the applicable option</p><blockquote>Note<em>: For the purpose of the demo, I used </em><a href=""https://www.eventbrite.com/""><em>Eventbrite’s website</em></a><em> so I selected “Use as inspiration.” You can use any public website in addition to your personal or company website.</em></blockquote><p>4. The tool scans and builds the site page from the URL; this can take a couple minutes depending on the website’s asset complexity</p><p>5. Once the build is finished, compare the URL to the output for any discrepancies (Anima’s output is pretty consistent with the input)</p><figure><img alt=""Comparison between the original website and Anima’s output, which shows a consistent match"" src=""https://cdn-images-1.medium.com/max/1024/1*lXR1JI6J2wQpJX6xO-142w.png"" /><figcaption>Anima’s output is pretty consistent with the original input</figcaption></figure><p>6. Prompt the AI assistant for any needed tweaks; I prompted, “Make the grid section a list view” and “Add a sidebar to filter events by category”</p><blockquote>Note<em>: Make smaller, bite-sized adjustments at a time so the prompts are more clear to the AI assistant — giving better results.</em></blockquote><figure><img alt=""Prompting the AI chat for changes to make to the Eventbrite website in Anima"" src=""https://cdn-images-1.medium.com/max/1024/1*tZW0yT94XXXLgtp-vucx6g.png"" /><figcaption>Prompting the AI chat for changes to make to the Eventbrite website</figcaption></figure><p>7. Continue to make adjustments until the output is good-to-go, then select “Publish” for the prototype link or select “Download code” (depending on if you’re user testing or pushing code into a repository)</p><p>There is also a <a href=""https://chromewebstore.google.com/detail/web-to-code-by-anima/paddhneaanoeljlmdepnheehdkaegblo"">Web-to-code Chrome extension</a> to select a specific page from any public website and generate its code-build in Anima’s playground. So instead of toggling back-and-forth between Anima and your site, you can move directly from the site to Anima.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*PTQ1NsEC57wzDuHdCIRN3g.png"" /><figcaption>Anima’s Chrome extension tool to go straight from the site to code generation</figcaption></figure><h4>Other tools to explore</h4><ul><li><a href=""https://chromewebstore.google.com/detail/html-to-framer/haijifigpgpndcnbbjooffflaceedhdp""><strong>HTML to Framer</strong></a>: Framer offers a Chrome extension that lets you copy one to multiple design elements from any public website, then paste it into your Framer project. This is dependent on if you house your website in Framer (and also doesn’t allow for code modifications), but is an easy way to grab design elements as starting points.</li></ul><figure><img alt=""HTML to Framer’s Chrome extension allows copying elements from the site"" src=""https://cdn-images-1.medium.com/max/1024/1*ZAQHRylnyBju-60gvVG66g.png"" /><figcaption>HTML to Framer’s Chrome extension allows copying elements from the site</figcaption></figure><ul><li><a href=""https://chromewebstore.google.com/detail/mockflow-wireframepro/ghkgfdamcfjiflldnfiollnhkdjilmde?hl=en""><strong>Mockflow’s URL to wireframe</strong></a>: Mockflow offers a feature to convert sections or full pages from live websites into editable wireframes. This feature is similar to Anima’s web-to-code feature since it provides an easy way to explore ideas, but Mockflow doesn’t produce editable code like Anima does.</li></ul><figure><img alt=""Mockflow’s Chrome extension creates wireframes from URLs to import to a canvas in Mockflow"" src=""https://cdn-images-1.medium.com/max/1024/1*cDsnk3xhMyt8oMJD5FCh1Q.png"" /><figcaption>Mockflow’s Chrome extension creates wireframes from URLs</figcaption></figure><ul><li><a href=""https://wireframeit.com/""><strong>Wireframeit</strong></a>: The Wireframeit Chrome extension also converts live websites into editable designs that can be exported into Figma or as images. Again, this tool doesn’t focus on code production or output, but offers a way to extract design assets from your browser to Figma.</li></ul><figure><img alt=""Wireframeit’s Chrome extension creates wireframes on top of the browser"" src=""https://cdn-images-1.medium.com/max/1024/1*czfkr9NMvz2ABl0jjQ7Ouw.png"" /><figcaption>Wireframeit’s Chrome extension creates wireframes on top of the browser</figcaption></figure><h3>Where vibe coding fits in your workflow</h3><p>Vibe coding isn’t about replacing Figma (or your favorite design tool), wireframes, or high-fidelity prototypes; it’s about complementing them. Vibe coding speeds up specific points in the workflow where product teams usually get stuck. For instance, designers can generate and test small design tweaks from their existing website without remaking each UI mockup, as well as validate ideas with prototypes that provide real interactions.</p><p>By integrating vibe coding into your design-development process, you can cut unnecessary steps while gaining the output from traditional prototypes. Let’s look into where product teams can most benefit, then look at when vibe coding shouldn’t be used.</p><h4>For designers</h4><ul><li><strong>Ideate with user context</strong>: Instead of designing mockups on static canvases or creating artificial prototypes, you can generate changes on your actual product pages and see how they behave.</li><li><strong>Validate with users</strong>: Using vibe-coded prototypes for user testing gets more realistic feedback versus clickable prototypes made in Figma or Sketch (also prevents “glitchy” prototypes).</li><li><strong>Avoid design tool integration</strong>: Many vibe coding tools are integrated with only Figma (excluding other design tools); with live-site prototyping, designers without Figma can still vibe code.</li></ul><figure><img alt=""Builder.io’s home page asking designers to submit a Figma file to start using the tool"" src=""https://cdn-images-1.medium.com/max/1024/1*ZO6lPrS9ZOQ5SwIVgmQLxg.png"" /><figcaption>Builder.io requires designers to start with a Figma file</figcaption></figure><h4>For developers</h4><ul><li><strong>Experiment faster</strong>: Vibe coding lowers the barrier to testing since developers can make edits without creating a new dev environment each time; so you can validate the change before committing code.</li><li><strong>Prototype without damage</strong>: Since developers are working in a “playground” environment, they can try new things without worrying about breaking the main repository (or anything else).</li></ul><h4>For product teams</h4><ul><li><strong>Close the handoff gap</strong>: Since designers and developers are working from the same context, there are fewer misinterpretations compared to developers implementing from design files and specs.</li><li><strong>Condense design cycles</strong>: Vibe coding eliminates redundant steps, like recreating the same UI mockup over and over again, so ideas can move from concept to testable prototype in a day or two instead of weeks.</li></ul><figure><img alt=""Modified Eventbrite prototype generated with Anima including changes requested in the demo"" src=""https://cdn-images-1.medium.com/max/1024/1*S4RkOzydArhP-KfN6jNvfA.png"" /><figcaption>Modified Eventbrite prototype generated with Anima</figcaption></figure><h4>When not to use vibe coding</h4><ul><li>​​<strong>Brand new features</strong>: When there is no existing product page or user flow to build from in the existing website, you need to start with wireframes in design tools instead of vibe coding.</li><li><strong>Complex user journeys</strong>: For multi-step user flows or branching paths, traditional prototyping helps you map everything clearly because vibe coding may miss important context.</li><li><strong>Design Systems</strong>: Design libraries require structured, reusable foundations to create UI components and patterns that are better defined and used in tools like Figma.</li><li><strong>High-level concepts</strong>: When you need to present and communicate abstract ideas or early-stage concepts to stakeholders, low-fidelity wireframes or static user journeys are often more effective.</li></ul><h3>Conclusion</h3><p>Vibe coding directly on your live website changes how teams can explore new ideas. This process reduces the redundant work in traditional design-to-dev workflows, while keeping user interactions accurate and in-context.</p><p>Not only is vibe coding from your website a workflow shift, it aligns design and implementation from the start of any iteration cycle — balancing quality, speed, and collaboration while building a better product experience.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce52eef25d95"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/vibe-code-straight-from-your-website-ce52eef25d95"">Vibe code straight from your website</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/from-products-to-systems-the-agentic-ai-shift-eaf6a7180c43?source=rss----138adf9c44c---4,1758749690,From products to systems: The agentic AI shift,"From products to systems: The agentic AI shift

<h4><em>Agents are here, how we build and use them is challenging many of the foundations for building software that we established over the last few decades — and even the very idea of what a product is.</em></h4><figure><img alt=""Abstract illustration of humans and abstracted AI agents collaborating on a complex system"" src=""https://cdn-images-1.medium.com/max/1024/1*ATfGSozp4wJyENvP5ocGiw.jpeg"" /><figcaption>Prompt by the author, image by Sora.</figcaption></figure><p><em>This article is a continuation of previous explorations on the theme of how AI is impacting design and product (</em><a href=""https://uxdesign.cc/design-in-the-age-of-vibes-8a761d2fe21f""><em>Vibe-code designing</em></a><em>, </em><a href=""https://uxdesign.cc/the-future-of-ai-design-navigating-challenges-and-opportunities-2170c92d80bd?sk=cfcc997fa7c1de3641bbe6194356f9bf""><em>Evolving roles</em></a><em>), and is based on a presentation delivered at ‘</em><a href=""https://toomuch.parallel.systems/""><em>The Age of TOO MUCH</em></a><em>’ exhibition in Protein studios, as part of London Design Week 2025.</em></p><p>There’s a <a href=""https://www.youtube.com/watch?v=v-xh_gq8sbk"">scene</a> in one of my favorite movies, Interstellar, where the characters are on a remote, water-covered planet. In the distance there is what initially appears to be a large landmass, but as Cooper, the main character, looks on, he realizes that they aren’t in fact mountains, but enormous waves steadily building and towering ominously over them.</p><figure><img alt=""The wave scene from interstellar, with AI tools overlaid on top, bearing down on an astronaut. This is a metaphor for how it has felt being a designer over the last few years."" src=""https://cdn-images-1.medium.com/max/640/1*nbUDmK6VRwjlDpBK3HnwYg.gif"" /><figcaption>Interstellar wave scene: ‘<a href=""https://www.youtube.com/watch?v=v-xh_gq8sbk"">Those aren’t mountains, those are waves </a>‘ — Cooper</figcaption></figure><p>With AI, it feels like we’ve had a similarly huge wave building on the horizon for the last few years. I wrote previously about how <a href=""https://uxdesign.cc/design-in-the-age-of-chatgpt-3c80e6fc8cf7?source=friends_link&amp;sk=461b4bc8bb082e00c2c2db113c73f52d"">Generative AI</a> and <a href=""https://john-moriarty.medium.com/design-in-the-age-of-vibes-8a761d2fe21f?source=friends_link&amp;sk=b54cfe4bd68a9f9faea2258765fa38a9"">Vibe Coding</a> are changing how we design. In recent months it feels like another seismic shift is underway with agentic AI. So what exactly is this wave, and how is it reshaping the landscape we thought we knew?</p><p>I lead the product design team at <a href=""https://www.datarobot.com/"">DataRobot</a>, an enterprise platform that helps teams build, govern and operate AI models and agents at scale. From this vantage point, I’m seeing these changes reshape not just how we design, but also many long-held assumptions about what products <em>are</em> and how they’re built.</p><h3>What’s actually changing</h3><p>Agents are a fundamentally different paradigm to predictive and generative AI. What sets them apart, aside from being multimodal and capable of deep reasoning, is their <em>autonomous</em> nature. It sounds deceptively simple, but when software has agency — the ability to make decisions and take actions on its own — the results can be quite profound.</p><p>This creates a fundamental challenge for companies integrating AI software, which is traditionally built for <em>deterministic</em>, predictable workflows. Agentic AI is inherently <em>probabilistic</em> — the same input can produce different outputs, and agents may take unexpected paths to reach their goals. This mismatch between deterministic infrastructure and probabilistic behavior creates new design challenges around governance, monitoring, and user trust. These aren’t just theoretical concerns, they’re already playing out in enterprise environments. That’s why we partnered with <a href=""https://www.nvidia.com/en-us/on-demand/session/gtc25-S72261/"">Nvidia </a>to build on their AI Factory design and delivered as agentic apps embedded directly into <a href=""https://www.datarobot.com/solutions/partners/sap/"">SAP</a> environments, so customers can run these systems securely and at scale.</p><p>But even with this kind of hardened infrastructure, moving from experimentation to impact remains difficult. Recent<a href=""https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/""> MIT research</a> found that 95% of enterprise generative AI pilots fail to deliver measurable impact, highlighting an industry-wide challenge in moving from prototype to production. Our ‘AI Expert’ service — where specialised consultants work directly with customers to deploy and run agents — delivers outstanding results through personalized support. To extend this level of guidance to a broader customer base, we needed to develop scalable approaches that could address complexity barriers at scale.</p><figure><img alt=""Screenshot of the DataRobot homepage"" src=""https://cdn-images-1.medium.com/max/1024/1*rmSUGY7cXdvQpzrUk-UHwQ.png"" /><figcaption><a href=""https://www.datarobot.com/"">Datarobot</a> homepage</figcaption></figure><p>Moving from AI experimentation to production involves significant technical complexity. Rather than expecting customers to build everything from the ground up, we decided to flip the offering and lead instead with a series of <a href=""https://docs.datarobot.com/en/docs/workbench/wb-apps/app-templates/index.html"">agent and application templates</a> that give them a head start.</p><p>To use a food analogy, instead of handing customers a pantry full of raw ingredients (components and frameworks), we now provide something closer to ‘HelloFresh’ meal kits: pre-scaffolded agent and application templates with prepped components and proven recipes that work out of the box. These templates codify best practices across common customer use cases and frameworks. AI builders can clone them, then swap out or modify components using our platform or in their preferred tools via API.</p><figure><img alt=""Illustration showing an architectural diagrm of DataRobot agentic application templates on one side, with sample front-end interfaces on the other side, to illustrate what’s included in these application templates."" src=""https://cdn-images-1.medium.com/max/1024/1*37NA6kRGLHFwuJeKZTwtVQ.png"" /><figcaption><em>Use case specific </em>Agentic Application Templates</figcaption></figure><p>This approach is changing how AI practitioners use our platform. One significant challenge is creating front-end interfaces that consume the agents and models — apps for forecasting demand, generating content, retrieving knowledge or exploring data.</p><p>Larger organisations with dedicated development teams can handle this easily. But smaller organisations often rely on IT teams or our AI experts to build these interfaces, and app development isn’t their primary skill.</p><p>We mitigated this by providing customisable <a href=""https://docs.datarobot.com/en/docs/workbench/wb-apps/app-templates/index.html"">reference apps</a> as starting points. These work if they are close to what you need, but they’re not straightforward to modify or extend. Practitioners also use open-source frameworks like Streamlit, but the quality of these often falls short of enterprise requirements for scale, security and user experience.</p><p>To address this, we’re exploring solutions that use agents to generate dynamic applications — dashboards with complex user interface components and data visualizations, tailored to specific customer needs, all using the DataRobot platform as the back-end. The result is that users can generate production-quality applications in days, not weeks or months.</p><a href=""https://medium.com/media/1c5c875292b4c38002fa61e15fab4140/href"">https://medium.com/media/1c5c875292b4c38002fa61e15fab4140/href</a><p>This shift towards autonomous systems raises a fundamental question: how much control should we hand over to agents, and how much should users retain? At the product level, this plays out in two layers: the infrastructure AI practitioners use to create and govern workflows, and the front-end apps people use to consume them. Our customers are now building both layers simultaneously — guidance agents configure the platform scaffolding while different generative agents build the React-based applications that sit on top.</p><p>These aren’t prototypes — they’re production applications serving enterprise customers. AI practitioners who might not be expert app developers can now create customer-facing software that handles complex workflows, rich data visualization, and business logic. The agents handle React components, layout and responsive design, while the practitioners focus on domain logic and user workflows.</p><p>We are seeing similar changes in other areas too. Teams across the organisation are using new AI tools to build compelling demos and prototypes using tools like<a href=""https://v0.dev/""> V0</a>. Designers are working alongside front-end developers to contribute production code. But this democratization of development creates new challenges; now that anyone can build production software, the mechanisms for ensuring quality and scalability of code, user experience, brand and accessibility need to evolve. Instead of checkpoint-based reviews, we need to develop new systems that can scale quality to match the new pace of development.</p><figure><img alt=""Animated GIF showing an example of a DataRobot front-end application for forecasting talent attrition in a fictional company."" src=""https://cdn-images-1.medium.com/max/1024/1*B-SiD2yK-cUbOq8t-_hkvA.gif"" /><figcaption><em>An example of an app built by our field team using </em><a href=""https://v0.dev/""><em>V0</em></a><em> that leverages agent-aware design system docs.</em></figcaption></figure><h3>Learning from the control paradox</h3><p>There are lessons from our AutoML (automated machine learning) experience that apply here. While AutoML workflows helped democratize access for many users, some experienced data scientists and ML engineers felt control was being taken away. We had automated the parts they found most rewarding — the creative, skilled work of selecting algorithms and crafting features — while leaving them with the tedious infrastructure work they actually wanted to avoid.</p><figure><img alt=""Screenshot of the DataRobot user interface from approximately 2012, showing data uploded an a ‘start’ action button."" src=""https://cdn-images-1.medium.com/max/1024/1*LGiOcy4h1eOCe6MHiFmaiA.png"" /><figcaption><em>Earlier version of the DataRobot UI that focused on democratizing access to machine learning</em></figcaption></figure><p>We’re applying this lesson directly to how we build agentic applications. Just as AutoML worked when it automated feature engineering but not always model interpretation, our customers will succeed when agents handle UI implementation while AI/ML experts retain control over the agentic workflow design. The agents automate what practitioners don’t want to do (component wiring, state management) while preserving agency over what they do care about (business logic, user experience decisions).</p><p>Now, with agentic AI, this tension plays out at a much broader scale with added complexity. Unlike the AutoML era when we primarily served data scientists and analysts, we now target a broader range of practitioners including App developers who might be new to AI workflows, along with the agents themselves as end users.</p><p>Each group has different expectations about control and automation. Developers are comfortable with abstraction layers and black-box systems — they’re used to frameworks that handle complexity under the hood, but they still want to debug, extend, and customise when needed. Data scientists still want explainability and intervention capabilities. Business users just want results.</p><p>But there’s another user type we’re designing for: the agents themselves. This represents a fundamental shift in how we think about user experience. Agents aren’t just tools that humans use — they’re collaborative partners that need to interact with our platform, make decisions, and work alongside human practitioners.</p><figure><img alt=""Visual representation of the different DataRobot practitioner archetypes, mapped along a vertical axis of ‘code maturity’ and a horizontal axis of ‘AI/ML maturity’."" src=""https://cdn-images-1.medium.com/max/1024/1*xnKXPra7MJxuwjYOzHsKPg.png"" /><figcaption><em>Overview of the users who interact with the DataRobot platform</em></figcaption></figure><p>When we evaluate new features now, we ask: will the primary user be human or agent? This changes everything about how we approach information architecture, API design, and even visual interfaces (if required). Agents need different types of feedback, different error handling, and different ways to communicate their reasoning to human collaborators.</p><p>Looking ahead, it’s possible agents may emerge as primary users of enterprise platforms. This means designing for human-agent collaboration rather than just human-computer interaction, creating systems where agents and humans can work together effectively, each contributing their strengths to the workflow.</p><h3>From designing flows to architecting systems</h3><p>These changes challenge fundamental assumptions about what a product <em>is</em>. Traditionally, products are solutions designed to solve specific problems for defined user groups. They usually represent a series of trade-offs: teams research diverse user needs, then create single solutions that attempt to strike the best balance of multiple use cases. This often means compromising on specificity and simplicity to achieve broader appeal.</p><p>Generative AI has already begun disrupting this model by enabling users to bypass traditional product design and development processes entirely. Teams can now get to an approximation of an end result almost instantaneously, then work backward to refine and perfect it. This compressed timeline is reshaping how we think about iteration and validation.</p><p>But agentic AI offers something more fundamental: the ability to generate products and features on demand. Instead of static experiences that try to serve a broad audience, we can create dynamic systems that generate specific solutions for specific contexts and audiences. Users don’t just get faster prototypes — they get contextually adaptive experiences that reshape themselves based on individual needs.</p><figure><img alt=""Illustration of different product development processs, such as waterfall, agile and AI, using vehicles as an analogy for how they work."" src=""https://cdn-images-1.medium.com/max/1024/1*F5vDEkRuurvkLcRVen8jxQ.png"" /><figcaption><em>How the product development process is evolving with AI. Credit unknown.</em></figcaption></figure><p>This shift changes the role of design and product teams. Instead of executing individual products, we become architects of systems that can create products. We curate the constraints, contexts, and components that agents use to generate experiences while maintaining brand guidelines, product principles, and UX standards.</p><p>But this raises fundamental questions about interaction design. How do affordances work when interfaces are generated on demand? Traditional affordances — visual cues that suggest how an interface element can be used — rely on consistent patterns that users learn over time. Interestingly, AI tools like <a href=""https://cursor.com/"">Cursor</a>, V0, and Lovable address this challenge by leveraging well-established UX frameworks like Tailwind and ShadCN. Rather than creating novel patterns that users need to learn, these tools generate interfaces using robust, widely-adopted design systems that provide familiar starting points. When agents generate interfaces contextually using these established frameworks, users encounter recognizable patterns even when the specific interface is new.</p><p>At DataRobot, we’ve approached this challenge by systematizing our design process and standards as agent-aware artifacts. We’ve converted our Figma design system into machine-readable markdown files that agents can consume directly. Using Claude, we translated our visual design guidelines, component specifications, and interaction principles into structured text that can be dropped as context into AI tools like Cursor, V0, and Lovable.</p><figure><img alt=""Visual represetnation titled  ‘agent aware artifacts’ showing a figma design system on the left, with an arrow pointing to a ‘claude ai’ icon and another pointing to a screenshot of a coding tool with a markdown file loaded, titled ‘design-system.md’ to communicate how design artifacts are being translated into formats for agent consumption."" src=""https://cdn-images-1.medium.com/max/1024/1*HVd30Uc-MS7DzkxPATxsHg.png"" /><figcaption><em>Translating design files into agent-aware artifacts like markdown files.</em></figcaption></figure><p>This approach allows us to maintain design quality at scale. Instead of manually reviewing every generated interface, we encode our design standards upstream, ensuring that agents generate consistent, accessible, and brand-appropriate experiences by default.</p><p>We’re already seeing this in action within DataRobot itself. Our AI Experts use these agent-aware design artifacts when building agentic applications, maintaining design consistency through our systematized guidelines while focusing on the unique business logic and user workflows.</p><h3>What this means for product &amp; design leaders</h3><p>I previously wrote about how the <a href=""https://john-moriarty.medium.com/the-future-of-ai-design-navigating-challenges-and-opportunities-2170c92d80bd?source=friends_link&amp;sk=cfcc997fa7c1de3641bbe6194356f9bf"">boundaries between disciplines are blurring</a>. What shape the product triad will take, or if it remains a triad at all, is unclear. While it’s likely that design will absorb many front-end development tasks (and vice-versa), and some PMs will take on design tasks, I don’t think any roles will disappear <em>entirely</em>. There will always be a need for specialists; while individuals can indeed do a lot more than before, there is only a certain amount of context that we can all retain.</p><p>So while we might be able to execute more, we still need people who can go deep on complex problems along with a level of craft that becomes increasingly valuable as a differentiator. In a world where anyone can create anything, the quality of execution and depth of understanding that comes from specialization will be what separates good work from exceptional work.</p><blockquote><strong>The companies that are going to distinguish themselves are the ones that show their craft. That they show their true understanding of the product, the true understanding of their customer, and connect the two in meaningful ways.</strong></blockquote><p>— <a href=""https://www.youtube.com/watch?v=QaDsk4iH1aw"">Krithika Shankarraman</a> (Product, OpenAI)</p><figure><img alt=""Animated gif showing the traditional product triad of product, engineering and UX design that blurs in and out, suggesting the boundaries between these roles are blurring."" src=""https://cdn-images-1.medium.com/max/1024/1*LcnWd3ZVITmmmsVBgGvAfQ.gif"" /><figcaption>The blurring boundaries of the product triad.</figcaption></figure><p>As these boundaries blur and new capabilities emerge, it’s worth remembering what remains constant. The hard problems remain hard:</p><ul><li>Understanding people and their needs within complex contexts. <br /><em>What unmet needs are we addressing?</em></li><li>Building within interdependent systems and enterprise constraints. <br /><em>Will this work with existing architectures?</em></li><li>Aligning technical capabilities to business value. <br /><em>Is this solving a problem that matters?</em></li></ul><p>Our role as design leaders is evolving from crafting individual experiences to architecting systems that <em>generate</em> experiences. We’re evolving from designing screens to designing systems that can make contextual decisions while maintaining design integrity.</p><p>This changes our methodology fundamentally. Instead of designing for personas or generalised scenarios, we’re designing systems that adapt to individual contexts in real-time. Rather than creating single user journeys, we’re building adaptive frameworks that change pathways based on user intent and behavior.</p><p>User research also evolves: we still need to understand human needs, but now we must translate those insights into rules and constraints that agents can interpret. The challenge isn’t just knowing what users want, but encoding that knowledge to maintain design quality across infinite interface variations.</p><a href=""https://medium.com/media/0adf05b68982681f7579e5f9734e2af3/href"">https://medium.com/media/0adf05b68982681f7579e5f9734e2af3/href</a><p>This fundamental truth doesn’t change — but our methods for translating human understanding into actionable systems do. The uniquely human work of developing deep contextual understanding becomes more valuable, not less, as we learn to encode that wisdom for AI systems to use effectively.</p><h3>Design quality in an agent-first world</h3><p>This shift toward agent-generated experiences creates new design challenges. If agents are creating interfaces on demand, how do you maintain coherence across an organisation? How do you ensure accessibility compliance? How do you handle edge cases that training data didn’t capture?</p><p>We believe that part of the answer lies in creating foundational artifacts that both humans and agents can consume. At DataRobot, we are currently exploring:</p><ul><li>Making documentation agent-aware using formats like <a href=""https://www.anthropic.com/news/model-context-protocol"">MCP</a>, <a href=""https://agents.md/"">agents.md</a> and <a href=""https://langchain-ai.github.io/langgraph/llms-txt-overview/"">llms.txt</a>.</li><li>Converting our design system into foundational markdown files that codify principles and patterns, for use in AI development tools.</li><li>Creating automated checks for UI language, accessibility standards, and interaction patterns.</li></ul><p>This approach enables others in our organisation to build compelling applications with AI tools while adhering to our design system and brand consistency. But here’s the crucial insight: while these AI-generated applications might look impressive, the polish can mask underlying UX challenges. As Preston notes:</p><a href=""https://medium.com/media/1deda45b93d917a65c099af08ac55b7e/href"">https://medium.com/media/1deda45b93d917a65c099af08ac55b7e/href</a><p>AI tools excel at execution, but they don’t replace the difficult UX work required to ensure you’re executing <em>the right thing</em>.</p><p>This creates a new challenge for design teams: when everyone is a builder, how do we ensure we build the right things and ensure we meet quality standards? We’ve struggled with knowing when to lean in. There are times, like creating demos or throwaway prototypes, when it’s fine for design to be less involved. But there are critical moments when our involvement <em>is</em> important, otherwise poor quality experiences can ship to production. Our customers don’t care about how or who created the products they interact with.</p><p>The key is catching issues as far upstream as possible. This means the documentation and enablement materials that guide how people use and customise our templates have become the new ‘products’ our design team is responsible for. By creating thorough agent-aware guidelines and design system documentation, we can ensure higher quality output at scale.</p><p>But we still need quality checks without slowing down the process too much. We’re still learning how to balance speed with standards — when to trust the system we’ve built and when human design judgment is a must have.</p><h3>Riding the wave</h3><p>The last few years have felt like a rollercoaster because they have been. But I believe our job as designers is to lean into uncertainty, to make sense of it, shape it, and help others navigate it.</p><p>Like Cooper in Interstellar, we’ve recognised that what seemed like distant mountains are actually massive waves bearing down on us. The question isn’t whether the wave will hit, it’s already here. The question is whether we’ll be caught off guard or whether we’ll have prepared ourselves to harness its power.</p><p>Here’s what we’ve learned so far at DataRobot, for anyone navigating this transition:</p><ul><li><strong>Embrace the change &amp; challenge orthodoxies</strong><br />Try new tools and workflows outside your traditional lane. As roles blur, staying relevant means expanding your capabilities</li><li><strong>Build systems, not just products</strong> <br />Focus on creating the foundations, constraints, and contexts that enable good experiences to emerge, rather than crafting every detail yourself</li><li><strong>Focus on the enduring hard things</strong><br />Double down on the uniquely human work of understanding needs, behaviours, and contexts that no algorithm can fully grasp.</li><li><strong>Exercise (your) judgment</strong> <br />Use AI for speed and capability, but rely on your experience and values to decide what’s right.</li></ul><p>AI doesn’t make design irrelevant. It makes the uniquely human aspects of design more valuable than ever. The wave is here, and those who learn to harness it will find themselves in an incredibly powerful position to shape what comes next. This isn’t about nostalgia for how design used to work, it’s about taking an optimistic stance and embracing what’s possible with these technologies, doing things and going further than we ever could before. As <a href=""https://www.acquired.fm/episodes/adapting-episode-3-intel"">Andy Grove</a> put it perfectly:</p><blockquote><strong>Don’t bemoan the way things were, they will never be that way again. Pour your energy — every bit of it — into adapting to your new world, into learning the skills you need to prosper in it, and into shaping it around you.</strong></blockquote><p><a href=""https://www.johnmoriarty.me/""><em>John Moriarty</em></a><em> leads the design team at </em><a href=""https://www.datarobot.com/""><em>DataRobot</em></a><em>, an enterprise AI platform that helps AI practitioners to build, govern and operate agents, predictive and generative AI models. Before this, he worked in Accenture, HMH and Design Partners.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eaf6a7180c43"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/from-products-to-systems-the-agentic-ai-shift-eaf6a7180c43"">From products to systems: The agentic AI shift</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/building-trust-in-opaque-systems-ce38cef741b6?source=rss----138adf9c44c---4,1758712552,Building trust in opaque systems,"Building trust in opaque systems

<h4>Why the better AI gets at conversation, the worse we get at questioning it</h4><figure><img alt=""Illustration of a magic 8 ball used as a crystal ball"" src=""https://cdn-images-1.medium.com/max/1024/1*1Hye8aYVK6-cw367zTTNDg.png"" /><figcaption>illustration by author</figcaption></figure><p>How do we know when to trust what someone tells us? In person conversations give us many subtle cues we might pick up on, but when they happen with AI system designed to sound perfectly human, we lose any sort of frame of reference we may have.</p><p>With every new model, conversational AI sounds more and more genuinely intelligent and human-like, so much so that every day, millions of people chat with these systems as if talking to their most knowledgeable friend.</p><p>From a design perspective, they’re very successful in the way they feel natural, authoritative and even empathetic, but this very naturalness becomes problematic as it makes it hard to distinguish when outputs are true or simply just plausible.</p><p>This creates exactly the setup for misplaced trust: trust works best when paired with critical thinking, but the more we rely on these systems, the worse we get at it, ending up in this odd feedback loop that’s surprisingly difficult to escape.</p><h3>The illusion of understanding</h3><p>Traditional software is straightforward — click this button, get that result. AI systems are something else entirely because they’re unpredictable as they can make new decisions based on their training data. If we ask the same question twice we might get completely different wording, reasoning, or even different conclusions each time.</p><p>How this<em> thing</em> thinks and speaks in such human ways, <a href=""https://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html"">feels like magic</a> to many users. Without understanding what’s happening under the hood, it’s easy to miss that those “magical” sentences are ‘simply’ the most statistically probable chain of words, making these systems something closer to a ‘<a href=""https://www.ft.com/content/9029cc1c-4a3f-42ca-9939-f3ef8e8336ae"">glorified Magic 8 Ball</a>’.</p><p>Back in 2022 when ChatGPT opened to public, I was also admittedly mesmerised by it, and after it proved useful in a couple of real-world situations, I started reaching for it more and more, even for simple questions and tasks.</p><p>Until one day I was struggling with a presentation segment that felt flat compared to the rest and asked <a href=""https://claude.com/product/overview"">Claude</a> for ideas on how to make it more compelling. We came up with a story I could reference, one I was already familiar with, but there was this one detail that felt oddly specific, so I asked for the source.</p><figure><img alt=""Screenshot from a conversation with Claude"" src=""https://cdn-images-1.medium.com/max/1024/1*xmUNlpXiOUKjKpgrEXoyMQ.png"" /><figcaption>Part of the conversation with Claude (screenshot by author)</figcaption></figure><p>You can imagine my surprise when Claude casually mentioned it had essentially fabricated that detail for emphasis.</p><p>How I could have so easily accepted that made-up information¹ genuinely unsettled me and became the catalyst for me to really try and understand what I was playing with. What I didn’t know at the time was that this behaviour represents exactly what these systems are designed to do: generate responses that sound right, regardless if they’re actually true or not.</p><h3>Human-like, but not human</h3><p>The core problem when it comes to building trust in AI is that the end goal of these systems (utility) works directly against the transparency needed to establish genuine trust.</p><p>To maximise usefulness, AI needs to feel seamless and natural — nobody wants to talk to a robot, its assistance should be almost invisible. We wouldn’t consciously worry about the physics of speech during conversation, so why should we think about AI mechanics? We ask a question, we get an answer.</p><p>But healthy scepticism requires transparency, which inevitably introduces friction. We should pause, question, verify, and think critically about the information we receive. We should treat these systems as the sophisticated <em>tools</em> they are rather than all-knowing beings.</p><p>The biggest players seem to be solving for trust by leaning into illusion rather than transparency.</p><figure><img alt=""Screenshot from Claude’s interface showing “Gathering my thoughts, be right there…”"" src=""https://cdn-images-1.medium.com/max/1024/1*U3eHtyXa_507Z5yFS_1HwA.png"" /><figcaption>Claude thinking indicator (screenshot by author, Sept 2025)</figcaption></figure><p>One key technique is anthropomorphising the interface through language choices. For example, the many “thinking” indicators that appear while actually just preparing a response, it’s a deliberate attempt at building trust. This works brilliantly because these human-like touches make users feel <a href=""https://www.nngroup.com/articles/anthropomorphism/"">connected and understood</a>.</p><p>However, giving AI qualities like these thinking indicators, conversational tone, personality, and “empathy” creates two subtle yet critical problems:</p><h4>#1</h4><p>Giving AI human-like qualities, makes us lose the uncertainty signals that would normally help us detect when something is off. Humans naturally show <em>knowing what they don’t know</em> through hesitation, qualifying statements (like “I think…” “maybe…”), or simply by admitting uncertainty. These are very <a href=""https://medium.com/personal-growth/epistemic-humility-dont-expect-to-know-enough-to-be-sure-of-anything-b9db217d0299"">helpful signals</a> that let us know when to be more careful about trusting what someone is saying.</p><p>AI systems however, rarely do this — they can sound equally confident whether they’re giving you the population of Tokyo (which they probably know) or making up a detail about a case study (which they definitely don’t know). That’s why detecting a mistake or a “lie” in these cases can be extremely hard.</p><h4>#2</h4><p>On top of this, users <a href=""https://crestresearch.ac.uk/comment/emotional-over-trust-in-ai-technology/"">are more likely to assume the AI will perform better</a> while feeling a deeper connection to it. So we end up trusting it based on how it <em>feels</em> rather than how well it actually works.</p><p>The industry calls this <a href=""https://pair.withgoogle.com/chapter/explainability-trust/"">trust calibration</a>, which is about finding the right level of trust so that users rely on AI systems appropriately, or in other words, in just the right amount based on what those systems can <em>actually</em> do. This is no easy feat in general, but because AI often sounds confident while being opaque and inconsistent, getting this balance right is extremely challenging.</p><p>So how are companies currently attempting to solve this calibration problem?</p><h3>The limits of current solutions</h3><p>As a solution, there’s a lot of talk around <a href=""https://pair.withgoogle.com/chapter/explainability-trust/"">explainability</a>. This refers to turning AI systems’ hidden logic into something humans can make sense of, helping users decide when to trust the output (and more importantly, when not to do so).</p><p>Yet, this information only appears spontaneously in scenarios like medical or financial advice, or when training data is limited. In more routine interactions — brainstorming, seeking advice — users would need to actively prompt the AI to reveal the reasoning (as I had to do with Claude).</p><p>Imagine constantly interrupting a conversation to ask someone where they heard something. The chat format creates an illusion of natural conversation that ends up discouraging the very critical thinking that explainability is meant to enable.</p><p>Recognising these challenges, companies <a href=""https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails"">implement various other guardrails</a>: refusal behaviours for harmful tasks, contextual warnings for sensitive topics, or straight up restriction of certain capabilities. These aim to prevent <a href=""https://www.forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/"">automation bias</a>: our tendency to over-rely on automated systems.</p><p>These guardrails, tho, have significant limitations. Not only are there <a href=""https://futurism.com/researchers-discover-chatgpt-jailbreak"">known workarounds</a>, but they fail to account for how these tools are actually used by millions of people with vastly different backgrounds and technical literacy.</p><p>The contradiction becomes obvious when you notice where warnings actually appear. ChatGPT’s disclaimer that it “can make mistakes. Check important info” sits right below the input field, yet I wonder how many people actually see it, and of those who do, how many take that advice. After all that effort to anthropomorphise the interface and create connection, a small grey disclaimer hardly feels like genuine transparency.</p><figure><img alt=""Screenshot from Claude’s interface showing that Claude can make mistakes"" src=""https://cdn-images-1.medium.com/max/1024/1*a5BFiRLHdhtP7f_sODIvLA.png"" /><figcaption>Although tiny, Claude’s disclaimer appears more contextually within the last reply provided (screenshot by author, Sept 2025)</figcaption></figure><p>Companies invest heavily in making AI feel more human and trustworthy through conversational interfaces, while simultaneously expecting users to maintain critical distance through small warnings and occasional guardrails. The result is that these become another form of false reassurance allowing companies to claim plausible deniability while essentially paying lip service to transparency and trust.</p><h3>Scaffolding over crutches</h3><p>This reveals a fundamental flaw in the current approach: they’re asking users to bear the weight of responsible use while providing tools designed to discourage the very scepticism they require. This, not only contradicts established UX principles about designing for your users’ actual capabilities and contexts, but also ignores how trust is actually formed.</p><p>In fact, trust isn’t built through one single intervention, but rather systematically across many touchpoints. So how might we approach this problem differently?</p><figure><img alt=""Black and white photograph of scaffoldings"" src=""https://cdn-images-1.medium.com/max/1024/0*s_UHoBZqO5j9rTxy"" /><figcaption>Photo by <a href=""https://unsplash.com/@rgaleriacom?utm_source=medium&amp;utm_medium=referral"">Ricardo Gomez Angel</a> on <a href=""https://unsplash.com?utm_source=medium&amp;utm_medium=referral"">Unsplash</a></figcaption></figure><p>A first step, I believe, would be ditching the seamless approach and rethinking friction. What if, instead of treating transparency as friction to reduce, design treated it as a capability to build upon? Instead of hiding complexity to fast-track utility, interfaces could gradually build users’ ability to work effectively with AI systems — eventually teaching them not only how to use them responsibly, but when to trust them as well.</p><p>As a parallel, think scaffolding versus crutches. Current AI systems function more like crutches — they provide so much support that users become dependent on them. Users lean on AI for answers without developing the skills to evaluate them, and much like actual crutches, this helps in the moment but prevents underlying capabilities (critical thinking, in this case) from getting stronger over time.</p><h3>Designing transparency as scaffolding</h3><p><a href=""https://odettejansen.nl/scaffolding-as-a-ux-method-for-designing-better-products/"">In a scaffolding model</a> instead, AI systems could be much more flexible and adaptable so to surface transparency and guidance based on the user’s developing skills and the stakes of the decision.</p><p>For example, we could imagine having different modes. A “learning mode” could surface uncertainty more explicitly within responses — alerts prompting users to verify claims the AI cannot back up directly, or inviting users to take answers with a grain of salt. This could happen in expandable sections so as not to intrude on the conversation flow, and as users interact with these components, the interface could gradually reduce explicit prompts while maintaining the underlying safeguards.</p><figure><img alt=""Interface explorations on how a learning mode could look like"" src=""https://cdn-images-1.medium.com/max/1024/1*WWrWy5pc5syiXJEPP-risg.png"" /><figcaption>Quick and dirty explorations of a “learning mode” (by author)</figcaption></figure><p>For high-stakes decision, the interface could default to maximum transparency, like for example requiring users to verify factual claims with external sources before accessing final outputs. Visual indicators could distinguish between trained knowledge, recent search results, and generated examples, helping users understand where information comes from.</p><p>This approach would treats AI as temporary support that builds user capabilities rather than replacing them, and instead of optimising for immediate task completion, scaffolding design would help fostering long-term competence by helping users develop verification habits and critical thinking skills.</p><figure><img alt=""Screenshot from Gemini showing an inline tip on how to refine images"" src=""https://cdn-images-1.medium.com/max/1024/1*2WR2u7ct_2J1649QW4g5Bg.png"" /><figcaption>Google’s Gemini offers inline tips while images are being generated and then persist them on screen. This type of content is clearly distinguishable from the rest of the conversation and provides useful and contextual information based on the task the user is performing (screenshot by author, Sept 2025)</figcaption></figure><h3>A trade-off worth making</h3><p>Much of this goes against conventional product design principles around maximising ease of use. Adding these steps and indicators might seem like deliberate obstacles to user engagement… because they are, but that’s the point.</p><p>The friction introduced in this case, would serve a different purpose than arbitrary barriers — it’s protective and educational rather than obstructive. If designed mindfully, friction can help users treat AI tools as scaffolding rather than crutches, by developing the judgment skills needed to work safely with these systems.</p><p>That conversation with Claude taught me something crucial about the gap between how these systems are presented and what they actually are. <br />We face a choice between immediate utility while undermining our critical thinking, or building people up rather than making them dependent by accepting some friction as the price of maintaining our ability to think independently. The path forward isn’t avoiding AI, but demanding better design that teaches us to use these tools wisely rather than depending on them entirely.</p><p><strong>Footnotes<br /></strong>¹ <em>I’m aware that my example here is a pretty silly one compared to the amount of misinformation, bad advice and just factually incorrect tidbits people are potentially exposed to everyday through these interactions. But aha moments work in mysterious ways</em></p><p><strong>Suggested reads<br />- </strong><a href=""https://uxdesign.cc/lifting-the-fog-co-constructing-intent-with-ai-agents-fbb503599ac0"">Co-constructing intent with AI agents</a> by <a href=""https://medium.com/u/76a7b6e47e41"">TenoLiu</a><br />- <a href=""https://blog.prototypr.io/the-psychology-of-trust-in-a-world-where-products-keep-breaking-promises-3491fafc5b74"">The Psychology Of Trust In A World Where Products Keep Breaking Promises</a> by <a href=""https://medium.com/u/16993edcb922"">Mehekk Bassi</a><br />- <a href=""https://uxdesign.cc/from-journey-maps-to-control-maps-17aac58b9dd9"">Designing for control in AI UX</a> by <a href=""https://medium.com/u/1e7ee2935e64"">Rob Chappell</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce38cef741b6"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/building-trust-in-opaque-systems-ce38cef741b6"">Building trust in opaque systems</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/interview-with-lan-johnson-senior-designer-at-square-530d9054fde6?source=rss----138adf9c44c---4,1758627064,"Interview with Lan Johnson, Senior Designer at Square","Interview with Lan Johnson, Senior Designer at Square

<figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*gsgg-nvGihveBtvYa0v6UQ.png"" /></figure><p>Lan Johnson is a Senior Product Designer at Square. We met over 10 years ago in 2014 in Dallas, at Tekzenit where we both worked as user experience designers.</p><p>Lan is a military brat and grew up in Japan and South Korea, and Guam. Lan’s father retired in Las Vegas and then they eventually moved to Dallas.</p><p>Lan currently lives in Seattle, Washington with her boyfriend and their dog.</p><p>You can find Lan on <a href=""https://www.linkedin.com/in/lanjhnson/"">LinkedIn</a>.</p><p><strong>What was your journey getting into product design?<br /></strong>I actually started out thinking I wanted to be a graphic designer. I was really into anime as a kid, and when I got my hands on a (very outdated and pirated) copy of Photoshop 6 at around age 11, I was hooked. In high school, I also taught myself how to code, which opened the door to doing small freelance jobs here and there while I was still in school.</p><p>Eventually, I joined a startup in New York, before moving back to Dallas to finish my degree. From there, I spent about 10 years in consulting, working across different agencies and design shops. That period was fun and full of variety, but I found myself missing the feeling of being deeply connected to a single product.</p><p>In 2020, just a few weeks before the pandemic hit, I made the leap to go in-house. I stayed almost two years in that role, and now I’m continuing my journey at Square.</p><p><strong>For better or worse, how do you think your parents, family, or friends influenced how you approach problem solving in your day to day work?<br /></strong>I had to learn how to problem-solve on my own from a young age, which made me very independent. My family moved around a lot, so I was constantly rebuilding my support system and adapting to new cultures. That experience shaped the way I work today — it taught me how to be flexible, resilient, and comfortable walking into unfamiliar environments.</p><p>Those skills came in handy when I moved into consulting. I had no trouble starting conversations, building relationships quickly, and feeling at ease in different rooms. In high school, I went to a Department of Defense school in East Asia with only about a thousand students total from kindergarten through senior year. With so few people, it felt like being in a small startup — you had to be resourceful, self-sufficient, and figure things out because there weren’t always obvious answers. That mindset has carried through into my approach to design and problem-solving today.</p><p><strong>How would you describe your background at Capital One, Project202 and Tekzenit?<br /></strong>Each place was really different and shaped me in unique ways. At Tekzenit, I was just starting out. It was in the telecom space, and honestly, I was still figuring out how to navigate the corporate world while learning an industry that didn’t end up being directly relevant to me later. But it was an important first step.</p><p>At Project202, I had the chance to work across a wide range of industries and clients. For example, I worked with Southwest Airlines, learning how they assign pilots and cabin crew, which gave me insight into complex scheduling and logistics. I also helped JCPenney retrofit their site to be mobile and desktop friendly, back when responsive design was still a big shift. That variety really sharpened my ability to adapt quickly and problem-solve across different domains.</p><p>Capital One was especially interesting because of how structured and unionized their systems were. They had this massive scheduling platform that auto-generated crew schedules, but it always had to be corrected by hand. Once a year or so, pilots and crew reps from the union would come in to review and debate the schedules, approving what worked and pushing back on what didn’t. It gave me a fascinating look into how large-scale systems intersect with human needs and negotiations.</p><p><strong>How would you describe your current role and experience at Square?<br /></strong>Stepping away from management, I joined Square as an individual contributor, and I’m really happy with that shift. At my last four jobs I was in management, so it feels good to be back in the weeds, hands-on with the work again.</p><p>Previously, I worked on identity verification, so moving into printers recently has been a big jump, but a good one. I think what I missed most in management was the craft. In consulting especially, so much of the role was about selling the work and managing stakeholders, rather than actually building. I enjoyed mentoring and growing talent, but I often felt pulled away from the fun of shipping products with a team.</p><p>At Square, I feel like I’ve come full circle. I get to contribute directly, push projects over the finish line, and rediscover the parts of design that made me love this work in the first place.</p><p><strong>What are the biggest challenges you are currently facing at work?<br /></strong>Right now, my biggest challenge is onboarding into the world of printers. There are so many nuances I didn’t anticipate, especially since I focus on food and beverage, where every kitchen has very specific needs for how things run. Navigating those requirements has been a steep but interesting learning curve.</p><p>Another challenge is balancing engineering costs, business priorities, and what’s ultimately best for the end user. Like all teams, we’re constantly deciding whether to patch immediate issues or invest in longer-term fixes that will pay off later. We’re making progress, but it’s definitely a journey.</p><p><strong>What are some ways that you leverage AI in your workflow?<br /></strong>AI is a big focus for us. Our CEO, Jack Dorsey, is very forward-looking when it comes to future technologies like Bitcoin and decentralized identity, so adopting AI has become a company-wide initiative. We use a tool called Goose that allows us to automate some tasks. It saves me from having to wait on a data team to pull stats I can access the information I need instantly, which is incredibly helpful.</p><p>Personally, I also use ChatGPT for writing tasks since it’s just more efficient, and I’ve been experimenting with v0 to prototype. That tool can be a little frustrating at times, but it’s also fun and pushes me to think about design workflows in new ways.</p><p><strong>What are parts of your job where you find using AI unnecessary or inefficient?<br /></strong>AI is mostly useful as a baseline. I don’t rely on it heavily in my day-to-day design work, since it can’t really handle more sophisticated tasks. Where I do find it helpful is when teammates who aren’t as design focused, like PMs, use it to get their ideas across. Even if the output isn’t perfect, it gives us something concrete to react to.</p><p>Recently, I organized a V0 prototyping workshop where participants used AI to create solutions for the same problem. None of the prototypes were perfect, but I was able to pull useful pieces from each. So while AI isn’t my main tool, it does provide a good starting point.</p><p><strong>What are the most important aspects of pitching your design work to stakeholders?<br /></strong>For me, the most important part is setting the right context. I’ve found that when I take the time to explain the problem, why it matters, and the broader landscape we’re working within, stakeholders are naturally more aligned with my design decisions. Jumping straight into the solution can leave gaps, but grounding the conversation in the “why” builds trust and clarity.</p><p>I often include a few introductory slides or notes at the beginning of my Figma files for this reason. It gives everyone a shared foundation and makes the actual design discussion more productive.</p><p><strong>Where do you get your design inspiration from?<br /></strong>I use Dribbble a lot, but lately I’ve been really inspired by the resurgence of 90s aesthetics. I especially love 35mm film because it feels so raw and honest. Square has been leaning into that vibe too, with a stronger focus on photography and visual storytelling that highlights our sellers. I’m excited to see our design move more in that direction.</p><p><strong>What’s one failure or misstep that taught you something invaluable?<br /></strong>I learned a lot during my time at AT&amp;T, which often felt like trial by fire. The work environment was chaotic, and I made the mistake of pushing myself too hard, working while sick, putting in extra hours, and sacrificing balance. In hindsight, none of that effort really mattered, because it wasn’t appreciated and didn’t change the outcome. That experience taught me the importance of work-life balance and setting boundaries.</p><p>I also got my first crash course in corporate politics. I had to learn how to navigate different personalities, especially difficult ones. For example, there was a teammate who constantly needed to feel important, and if you didn’t give him that, he could make things unnecessarily difficult. I eventually figured out how to work through a proxy to get what I needed. As frustrating as it was, it taught me how to manage around egos and still get work done, something I carry with me today.</p><p><strong>When you start on a new design team, where do you spend your time and energy?<br /></strong>When I join a new team, the first thing I do is dig through all the files I can get my hands on: org charts, Figma files, documentation, anything available. That exploration helps me form better questions and makes my one-on-ones more productive.</p><p>I also schedule 1:1s with my core team, partners, and anyone I’ll be working closely with. A lot of those conversations are informal, just getting to know each other on a personal level, which I find really valuable. But when it comes to PMs or engineering leads, I’ll bring specific questions based on what I’ve already uncovered. That way, instead of a vague chat, I walk away with concrete answers or more resources to dive into.</p><p><strong>Do you work on any side projects outside of work?<br /></strong>Lately, I’ve been struggling to enjoy my hobbies the way I used to, but I’ve been trying to make space for them again. Drawing has always been a big part of my creative life; it’s actually what led me into design in the first place. I’m especially drawn to food illustration, and I’ve been experimenting with watercolors, alcohol markers, and colored pencils to get back into it.</p><p>I’ve also been getting into photography. I recently picked up a film camera and I’m looking forward to bringing it with me on upcoming trips to New York and San Francisco. For me, these side projects are less about output and more about reconnecting with the creative activities that inspire me outside of work.</p><p><strong>What are the most important qualities you look for in a design leader?<br /></strong>Humility is the big one. Of course, a good leader should know their craft and be able to guide a team, but at this level those qualities are often a given. What really stands out to me is whether they can say no and whether they can admit when they’re wrong. If a leader can do those two things, chances are they’re strong in the other areas that matter too.</p><p><strong>How do you balance business goals with design integrity when they’re at odds?<br /></strong>I think about it the same way I think about relationships. Compromise alone doesn’t really solve anything. If one side simply gives in, it often leads to resentment. Instead, I try to collaborate closely with the team to understand the trade-offs and find a solution that works for everyone. There are usually many ways to slice an experience: some features can be a fast follow, or we can plan milestones that eventually reach the same outcome in a more balanced way.</p><p>Of course, there are cases where trade-offs are unavoidable, like when legacy code ties everyone’s hands. In those situations, it’s about recognizing the limitation and planning for the larger migration effort that will ultimately make better solutions possible.</p><p><strong>What skills do you find relevant to product design that are not taught in school?<br /></strong>One of the biggest lessons I had to learn early on was how to protect myself in the workplace. As a younger designer, I often felt taken advantage of, and no one had prepared me for that. I always encourage people to read up on employment laws and understand their rights. Ideally, you’ll also have a manager or senior teammate who can help you navigate those situations.</p><p>Another important skill is knowing when not to overwork. In product design, we’re rarely saving lives, so putting in constant overtime doesn’t necessarily create better results. In fact, protecting your peace and maintaining balance makes you a better creative, because good decisions and strong design work come from clarity and energy, not burnout.</p><p><strong>What are the most common aspects in designer portfolios that bother you?<br /></strong>One thing I’ve noticed is that many portfolios still lean on process checklists, showing every step of the design process without really explaining the thinking behind it. What I’m really looking for is decision-making: why you chose a certain methodology, what you learned, where you failed, and the trade-offs you had to make along the way. Every project involves trade-offs, and understanding those is often more valuable than a polished checklist.</p><p>I’ll admit, writing case studies is tough, and I don’t always enjoy it myself. One tip I picked up at Square is to keep a “hype doc,” a running log of your accomplishments, metrics you moved, and decisions you influenced. If you spend even an hour a month updating it, you’ll have a backlog of material that makes writing case studies so much easier later. I struggle to keep it up myself, but it’s an invaluable habit.</p><p><strong>Do you have any tips for designers trying to break into the product design world?<br /></strong>When you’re starting out, the biggest challenge is building work you can actually show in applications. My advice is to pick a problem you personally care about and design a solution end to end. Avoid random problem generators; when the problem is real to you, your work will feel more authentic. You can even use tools like V0 to prototype without needing engineering support, which makes it easier to bring your ideas to life.</p><p>I’ve seen great examples of this. At Tekzenit, one intern designed an app to help their sister manage diabetes. It wasn’t just a design exercise; it was personal and meaningful. Projects like that stand out.</p><p>Beyond the work itself, do your homework. Learn about your rights as an employee, research salary ranges so you can advocate for yourself, and come prepared to interviews. And don’t underestimate the power of networking. Reach out to people on LinkedIn who work at companies you admire and ask for 15–30 minutes of their time. Even better if they’re local, because those connections can turn into ongoing mentorship.</p><p><strong>Have you gotten your jobs through referrals or cold applications?</strong></p><p>Almost every job I’ve had has come through a referral. The one exception was early in my career when I cold-applied to an agency that focused on lawyers. I only stayed there for a few months because the environment was really toxic.</p><p>After that, I started leaning on my network more. I ended up working at the same company as my brother, who needed a WordPress developer, and then moved on to Tekzenit after a referral from JK (our mutual friend), who I had almost hired at my previous role. Later, I joined Project202 by following Andy and Ryan, who I knew from Texas. Building those connections made each transition much smoother than applying cold.</p><p><strong>How do you see the product designer role evolving in the next few years?<br /></strong>I think product design will continue to shift beyond just creating visuals and flows and move more toward empathy and problem-solving. In many ways, our role already overlaps with product management, but we bring a different lens by championing the user. That perspective is still something many organizations struggle to fully embrace.</p><p>AI will likely take on more of the executional work, but I believe the real value of designers will be in weaving stories, framing decisions, and making sure user needs stay at the center. That is the part of the role I do not see being automated anytime soon, and hopefully what will keep us not just relevant but essential.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=530d9054fde6"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/interview-with-lan-johnson-senior-designer-at-square-530d9054fde6"">Interview with Lan Johnson, Senior Designer at Square</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/look-past-the-smart-glasses-meta-just-unveiled-the-future-of-wearables-da453a90cd7e?source=rss----138adf9c44c---4,1758627062,Look past the smart glasses: Meta just unveiled the future of wearables,"Look past the smart glasses: Meta just unveiled the future of wearables

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/look-past-the-smart-glasses-meta-just-unveiled-the-future-of-wearables-da453a90cd7e?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1024/0*fiHUBUwVfupYEnjt.png"" width=""1024"" /></a></p><p class=""medium-feed-snippet"">The controls demonstrated by the Meta Neural Band offer an exciting new answer to the question of how we&#x2019;ll interact with the tech of the&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/look-past-the-smart-glasses-meta-just-unveiled-the-future-of-wearables-da453a90cd7e?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/why-design-agencies-are-dying-why-integration-matters-to-designs-future-48f8c82c29cc?source=rss----138adf9c44c---4,1758627028,Why design agencies are dying & why integration matters to design’s future,"Why design agencies are dying & why integration matters to design’s future

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-design-agencies-are-dying-why-integration-matters-to-designs-future-48f8c82c29cc?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*2cqdVUpnuAYLIDfzZ_IA0A.jpeg"" width=""6000"" /></a></p><p class=""medium-feed-snippet"">How to go from &#x2018;separate creative unit&#x2019; to a strategic design partner</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-design-agencies-are-dying-why-integration-matters-to-designs-future-48f8c82c29cc?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/why-does-tesla-have-a-bad-reputation-22c3a86854d6?source=rss----138adf9c44c---4,1758521100,Why does Tesla have a bad reputation?,"Why does Tesla have a bad reputation?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-does-tesla-have-a-bad-reputation-22c3a86854d6?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1200/0*pb8wpwTZs6lsHFWE.jpg"" width=""1200"" /></a></p><p class=""medium-feed-snippet"">Analysis of how Elon Musk&#x2019;s politics, manufacturing failures, and service disasters destroyed Tesla&#x2019;s market dominance</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-does-tesla-have-a-bad-reputation-22c3a86854d6?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
