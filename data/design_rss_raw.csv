source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/the-grayscale-problem/,1760349600,The Grayscale Problem,"The Grayscale Problem

From A/B tests to AI slop, the modern web is bleeding out its colour. Standardized, templated, and overoptimized, it’s starting to feel like a digital Levittown. But it doesn’t have to be."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/smashing-animations-part-5-building-adaptive-svgs/,1759755600,"Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries","Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries

SVGs, they scale, yes, but how else can you make them adapt even better to several screen sizes? Web design pioneer Andy Clarke explains how he builds what he calls “adaptive SVGs” using ``, ``, and CSS Media Queries."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/intent-prototyping-practical-guide-building-clarity/,1759485600,Intent Prototyping: A Practical Guide To Building With Clarity (Part 2),"Intent Prototyping: A Practical Guide To Building With Clarity (Part 2)

Ready to move beyond static mockups? Here is a practical, step-by-step guide to Intent Prototyping &mdash; a disciplined method that uses AI to turn your design intent (UI sketches, conceptual models, and user flows) directly into a live prototype, making it your primary canvas for ideation."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/desktop-wallpaper-calendars-october-2025/,1759230000,Shades Of October (2025 Wallpapers Edition),"Shades Of October (2025 Wallpapers Edition)

How about some new wallpapers to get your desktop ready for fall and the upcoming Halloween season? We’ve got you covered! Following our monthly tradition, the wallpapers in this post were created with love by the community for the community and can be downloaded for free. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/from-prompt-to-partner-designing-custom-ai-assistant/,1758880800,From Prompt To Partner: Designing Your Custom AI Assistant,"From Prompt To Partner: Designing Your Custom AI Assistant

What if your best AI prompts didn’t disappear into your unorganized chat history, but came back tomorrow as a reliable assistant? In this article, you’ll learn how to turn one-off “aha” prompts into reusable assistants that are tailored to your audience, grounded in your knowledge, and consistent every time, saving you (and your team) from typing the same 448-word prompt ever again."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/intent-prototyping-pure-vibe-coding-enterprise-ux/,1758733200,Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1),"Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1)

Yegor Gilyov examines the problem of over-reliance on static high-fidelity mockups, which often leave the conceptual model and user flows dangerously underdeveloped. He then explores whether AI-powered prototyping is the answer, questioning whether the path forward is the popular “vibe coding” approach or a more structured, intent-driven approach."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ambient-animations-web-design-principles-implementation/,1758546000,Ambient Animations In Web Design: Principles And Implementation (Part 1),"Ambient Animations In Web Design: Principles And Implementation (Part 1)

Creating motion can be tricky. Too much and it’s distracting. Too little and a design feels flat. Ambient animations are the middle ground &mdash; subtle, slow-moving details that add atmosphere without stealing the show. In this article, web design pioneer Andy Clarke introduces the concept of ambient animations and explains how to implement them."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/psychology-trust-ai-guide-measuring-designing-user-confidence/,1758276000,The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence,"The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence

With digital products moving to incorporate generative and agentic AI at an increasingly frequent rate, trust has become the invisible user interface. When it works, interactions feel seamless. When it fails, the entire experience collapses. But trust isn’t mystical. It can be understood, measured, and designed for. Here are practical methods and strategies for designing more trustworthy and ethical AI systems."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/how-minimize-environmental-impact-website/,1758189600,How To Minimize The Environmental Impact Of Your Website,"How To Minimize The Environmental Impact Of Your Website

As responsible digital professionals, we are becoming increasingly aware of the environmental impact of our work and need to find effective and pragmatic ways to reduce it. James Chudley shares a new decarbonising approach that will help you to minimise the environmental impact of your website, benefiting people, profit, purpose, performance, and the planet."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/serpapi-complete-api-fetching-search-engine-data/,1758042000,SerpApi: A Complete API For Fetching Search Engine Data,"SerpApi: A Complete API For Fetching Search Engine Data

From competitive SEO research and monitoring prices to training AI and parsing local geographic data, real-time search results power smarter apps. Tools like SerpApi make it easy to pull, customize, and integrate this data directly into your app or website."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/functional-personas-ai-lean-practical-workflow/,1758009600,"Functional Personas With AI: A Lean, Practical Workflow","Functional Personas With AI: A Lean, Practical Workflow

For too long, personas have been created with considerable effort, only to offer limited value. Paul Boag shows how to breathe new life into this stale UX asset and demonstrates that it’s possible to create truly useful functional personas in a lightweight way."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/creating-elastic-bounce-effects-expressive-animator/,1757930400,Creating Elastic And Bounce Effects With Expressive Animator,"Creating Elastic And Bounce Effects With Expressive Animator

Elastic and bounce effects have long been among the most desirable but time-consuming techniques in motion design. Expressive Animator streamlines the process, making it possible to produce lively animations in seconds, bypassing the tedious work of manual keyframe editing."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ux-strategies-real-time-dashboards/,1757689200,From Data To Decisions: UX Strategies For Real-Time Dashboards,"From Data To Decisions: UX Strategies For Real-Time Dashboards

Real-time dashboards are decision assistants, not passive displays. In environments like fleet management, healthcare, and operations, the cost of a delay or misstep is high. Karan Rawal explores strategic UX patterns that shorten time-to-decision, reduce cognitive overload, and make live systems trustworthy."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/integrating-css-cascade-layers-existing-project/,1757498400,Integrating CSS Cascade Layers To An Existing Project,"Integrating CSS Cascade Layers To An Existing Project

The idea behind this is to share a full, unfiltered look at integrating CSS Cascade Layers into an existing legacy codebase. In practice, it’s about refactoring existing CSS to use cascade layers without breaking anything."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/designing-tv-principles-patterns-practical-guidance/,1756980000,"Designing For TV: Principles, Patterns And Practical Guidance (Part 2)","Designing For TV: Principles, Patterns And Practical Guidance (Part 2)

After covering in detail the underlying interaction paradigms of TV experiences in [Part 1](https://www.smashingmagazine.com/2025/08/designing-tv-evergreen-pattern-shapes-tv-experiences/), it’s time to get practical. In the second part of the series, you’ll explore the building blocks of the “10-foot experience” and how to best utilise them in your designs."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/desktop-wallpaper-calendars-september-2025/,1756627200,A Breeze Of Inspiration In September (2025 Wallpapers Edition),"A Breeze Of Inspiration In September (2025 Wallpapers Edition)

Could there be a better way to welcome the new month than with a new collection of desktop wallpapers? We’ve got some eye-catching designs to make your September just a bit more colorful. Enjoy!"
rss,uxdesign.cc,https://uxdesign.cc/how-to-keep-design-strategic-when-youre-suddenly-in-a-startup-environment-c0b27ae793e4?source=rss----138adf9c44c---4,1760441259,How to keep design strategic when you’re suddenly in a startup environment,"How to keep design strategic when you’re suddenly in a startup environment

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-to-keep-design-strategic-when-youre-suddenly-in-a-startup-environment-c0b27ae793e4?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*8li3VzYCi_UK2aiRnUR0MQ.jpeg"" width=""4080"" /></a></p><p class=""medium-feed-snippet"">When your company shrinks back to startup size, how can you adapt?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-to-keep-design-strategic-when-youre-suddenly-in-a-startup-environment-c0b27ae793e4?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/its-not-you-it-s-hierarchy-47b44e18e8d4?source=rss----138adf9c44c---4,1760441141,"It’s not you, it’s hierarchy","It’s not you, it’s hierarchy

<h4>How I demoted my tree diagrams.</h4><figure><img alt=""Loose ink illustration of a middle aged man with glasses in front of a tree diagram."" src=""https://cdn-images-1.medium.com/max/1024/1*lhi6kFWm4PDPGPwlrEjIlA.png"" /><figcaption>Image AI Generated (Midjourney)</figcaption></figure><p>It’s 9:03 a.m. I join a Zoom meeting titled “Team Structure Alignment — Attendance Required,” the type of meeting title commonly reserved for nightmares. As soon as I join HR appears in one tile, smiling like this is <em>definitely</em> covered in their onboarding. It isn’t. We’re here today to demote a sentient diagram.</p><p>Long story short: afew years ago a lightning bolt totally hit a Texas data center while someone had Lucidchart open, and a Information Architecture Tree Diagram (our old reliable sitemap buddy) woke up, and has been with us ever since.</p><figure><img alt=""Lightning striking a modern style warehouse building on a decilate landscape."" src=""https://cdn-images-1.medium.com/max/1024/1*mVW-6kKKIBa5rfZOpzHlpA.png"" /><figcaption>Image AI Generated (Midjourney)</figcaption></figure><p>The I.A.Tree drops into the meeting late– connection lines crinkled and nodes misaligned.</p><p>“I’ve been up all night reorganizing the course pages. The client added three new ‘top-level categories’ that are actually just filters. The homepage has eight parents now. And someone renamed one of my root nodes ‘Global Navigation 2.’ Wait… why is HR here?”</p><p>I take a breath. “This is going to be a hard conversation.”</p><p>A couple of I.A. diagrams’ boxes squeeze into near triangles — making a kind of squint. “If this is about course registration prerequisites again, that’s not my job. I’m an architecture diagram, not an interactivity diagram. Or a… relationship diagram. Or whatever new kind of diagram you design kids are using to cosplay as engineers now.”</p><p>I glance at HR’s tiny Zoom window. I’m sure the HR lady is doing the same to me.</p><p>“Exactly,” I say. “You’re great at hierarchy, I.A. Diagram. But we keep asking you to model things that aren’t just parents and children. We need our go to diagram to show shared data, reusable components, relationships that shift when users interact or when the system changes over time — and you keep telling us doing those things aren’t your job.”</p><p>The Tree folds a few of his far off branches in what I think is supposed to be a sort of cross armed pout. “Because it’s not my job! You want to show relationships that move? That’s a <em>state diagram.</em> You want to show dependencies? That’s a <em>system map.</em> I’m an <strong>architecture</strong> diagram, I only should have to show where content lives.”</p><p>“Right,” I say. “But we need to show <em>cardinality</em> now — how many relationships exist, how things multiply or overlap as systems evolve.”</p><p>The Tree bristles. “Cardinality? Who the hell do you think you are — the Pope?”</p><figure><img alt=""Sketch of a laptop screen with a man speaking to a woman in another panel in the video conference interface."" src=""https://cdn-images-1.medium.com/max/1024/1*CG7FmSg9mAHZBTLPDJRbyA.png"" /><figcaption>Image AI Generated (Midjourney)</figcaption></figure><p>To be fair, the Tree isn’t malicious — just absolutely certain about where its job ends.</p><p>“Okay,” I say, “let’s walk through this again. A course can have multiple instructors across different semesters — how do we show that with you?”</p><p>“I don’t,” the Tree says flatly. “That’s not my job.”</p><p>“What about courses that fulfill multiple degree requirements?”</p><p>“Still not my job.”</p><p>“Okay… and prerequisites that reference other courses?”</p><p>“Definitely not my job.”</p><p>“Students registered across multiple sections — sometimes cross-listed — how would you handle that?”</p><p>“I wouldn’t. Sounds like somebody else’s problem.”</p><p>“Whose problem?”</p><p>“Maybe a flowchart. Maybe, I don’t know, ask an engineer.</p><p>Every time relationships appear, the Tree punts: put it in a flowchart, an entity relationship diagram, or “engineering will figure it out.” But in 2025 UX, structure <strong>is</strong> part of the designer’s job: we’re expected to map persistent objects, cardinality, reuse, role-based access, and system constraints — well before anyone writes code.</p><p>We need a diagram that can carry that weight.</p><p>A horrible realization crosses the Tree Diagram’s root node where it’s face would have been, “am I Being… Fired?”</p><p>HR unmutes, voice gentle and corporate: “I.A. Tree Diagram, you’ve been a huge part of this team’s documentation. Your impact on navigation and hierarchy has been — ”</p><p>I.A. Tree freezes. “You’re firing me.”</p><p>“No,” I say quickly. “Not firing. <em>Demoting</em>. You’re no longer our primary structural diagram. You’ll still be critical to how we design navigation and be used every time we create content hierarchy. But the product design team is promoting class diagrams to our go to diagram.”</p><p>He stares. A few nodes detach.</p><p>“Class diagrams? That’s full-on UML. Why not sell your guitar, buy Magic cards, and rock a fanny pack while you’re at it?”</p><p>“Look,” I say. “We’re not role-playing engineers. We’re trying to plan out and communicate how the product actually fits together — that’s like the definition of design work. Class diagrams show objects, attributes, and relationships — cleanly. That’s what we need.”</p><h3>Why class diagrams need a promotion in design teams</h3><p>As design literacy spreads beyond traditional “Product Designer” titles — <a href=""https://www.forbes.com/sites/lucianapaulise/2024/06/06/new-essential-92-of-leaders-expect-employees-to-have-design-skills/?utm_source=chatgpt.com"">Forbes notes that 92% of leaders now expect employees to have some level of design skill</a> <strong>— </strong>Those of us who pay the mortgage with our design skills need to bring value that goes well beyond making and explaining interface-level decisions. The old approach — classifying information monolithically and statically — no longer fits the realities of today’s complex, high-stakes digital products.</p><p>The Nielsen Norman Group recently published a great piece called <a href=""https://www.nngroup.com/articles/future-proof-designer/?utm_source=chatgpt.com""><em>The Future-Proof Designer</em></a>, arguing that today’s best product designers aren’t just defining how a product looks from state to state at launch — they’re also creating the kinds of diagrams and doing the type of work that helps cross-functional teams solve complex problems together.</p><p>An information architecture tree diagram, for example, is like trying to survey a river by taking a single snapshot. It’s useful for orientation, but no longer the tool we need to deliver what’s expected of us now — showing how systems connect, and evolve.</p><p>Class diagrams are different from I.A. trees because they let us:</p><ul><li>Define <strong>what</strong> exists (objects/classes),</li><li>Specify <strong>what they contain</strong> (attributes),</li><li>Show <strong>how they relate</strong> (associations with cardinality),</li><li>Capture <strong>inheritance/extension</strong> (when needed),</li></ul><p>If you want a “how to make class diagram” resource go watch <a href=""https://www.youtube.com/watch?v=6XrL5jXmTwM"">Lucidchart’s excellent, short intro to class diagrams on YouTube</a>.</p><h3>Example</h3><p>A tree diagram can show hierarchy beautifully — parent, child, sibling. It can even make an unruly architecture look organized (if only at a glance). A tree diagram <em>does</em> have its place — especially early in the design cycle. As the Nielsen Norman Group points out in their article “<a href=""https://www.nngroup.com/articles/tree-testing/?utm_source=chatgpt.com""><em>Tree Testing: Fast, Iterative Evaluation of Menu Labels and Categories</em></a><em>”</em>, tree testing is ideal <strong>before</strong> you build page layouts or visual design: it lets you “test multiple IA options … without any design, coding, or content development” to see which structure works best. But a tree assumes that every object has one clear parent and that relationships flow neatly downward. That’s a comforting fiction, but fiction isn't’ what’s needed when making critical decisions about the design of a system.</p><p>For an example let’s think of a course registration product for a university. If the design team was required to wireframe out this system we’d need to diagram at a minimum to represent :</p><ul><li>A <strong>Student</strong> can register for many <strong>Courses</strong> (and vice versa).</li><li>Each <strong>Course</strong> may be taught by multiple <strong>Instructors</strong>.</li><li><strong>Courses</strong> can have <strong>Prerequisites</strong> (other Courses).</li><li>Some <strong>Courses</strong> fulfill <strong>Degree Requirements</strong>.</li><li><strong>Courses</strong> are offered in specific <strong>Semesters</strong>.</li></ul><h4>What’s the Problem Starting With a Tree Diagram?</h4><p>If I took this problem and made a tree diagram out of it — well it would look like this, and how the hell could I go back to my desk and start sketching a wire frame from this spaghetti? But more importantly it can’t identify design flaws early, something class diagrams are <em>explicitly designed to do</em>, as noted in <a href=""https://www.archimetric.com/the-importance-of-class-diagrams-in-software-development/?utm_source=chatgpt.com"">Archimetric’s “<em>The Importance of Class Diagrams in Software Development</em>.</a>”</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*Dou5K2TnwLV0RT3yiOlfYw.png"" /><figcaption>Tree Diagram Generated using <a href=""https://www.mermaidchart.com"">Mermaid Chart</a></figcaption></figure><p>There’s no clear canonical “object.” Are these <em>course instances</em> or just <em>labels</em>? What on this diagram represents an actual, screen-level piece of information — and what’s simply a class definition? Cardinality is either invisible or misleading. Are there many instances of a node, or just one? Tree diagram you drive me crazy!</p><h4>How and Why I’d Use A “Designerly Class Diagram Instead”</h4><p>I’d treat each category as its own “designerly class,” separating the information and interactivity into distinct conceptual objects, then map how they work together to create value for the user. That diagram would look something like this (although honestly most of the time I just sketch it on my iPad)</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*O4BpHoKk_fzomhwBmdNviQ.png"" /></figure><p>As a designer, I know which input methods users are most familiar with when interacting with these properties. I know where they’ll likely look for the information needed to complete each task. What I <em>don’t</em> instinctively know is how all these pieces of information work together — as a system, as a product. It’s too complex to hold in my head while I’m working. That’s what the diagram is for: not just to share how the system works with others, but to free up mental space so I can actually solve problems.</p><h3><strong>“I’m Architecture, Not Interactivity”</strong></h3><p>Back on Zoom, the I.A. Tree digs in:“I show where things go. Someone else can say how they connect.”</p><p>“That’s the crux,” I say. “In 2025, <em>structure</em> isn’t just ‘where stuff goes.’ It’s what the stuff <strong>is</strong> and <strong>how it relates</strong>, across roles and contexts. If our documentation can’t carry that, engineering inherits ambiguity — and users inherit weirdness.”</p><p>He grumbles, a grizzled veteran tone. “In my day, we mapped a whole site with a sharpie, a few sticky notes, and a dream. And it worked.”</p><p>“It did — for brochureware and early apps. Today we’re designing systems.”</p><p>He eyes me. “So we’re… opening the relationship?”</p><p>“We’re building an ensemble, not a monarchy,” I reply.</p><p>The HR lady nods, proud of us all while the Tree goes quiet, then mutes. The tile turns gray. I hear what can only be described as a leafy sniffle. When he reappears, he looks smaller. “Okay,” he says. “I’m not the lead anymore. That… stings. But if you need a three-tier menu with mobile fallbacks — ”</p><p>“You’re our first call,” I say.</p><p>He lifts a branch. “And don’t draw those class diagrams like code. Keep them human. We all need to read them — no curly braces, OK?”</p><p>“We will.”</p><p>He sighs — a wind-through-leaves sound. “All right. Just… make sure my pension vests.”</p><p>HR: “We’ll, uh, look into that.”</p><p>We end the call. And for the first time in a long time, I don’t feel compelled to invent a new dashed-gold-double-legend line on a I.A. Tree diagram just to explain the structure underneath our design.</p><h4>Acknowledgments</h4><p><a href=""https://intertwingled.org/the-polar-bear-book/""><em>The Polar Bear Book</em> — <em>Information Architecture for the World Wide Web</em></a> by Peter Morville and Louis Rosenfeld — has been hugely influential in how I think about structure, systems, and the evolving role of design literacy in product teams.</p><p>Morville, Peter, and Louis Rosenfeld. <em>Information Architecture for the World Wide Web: Designing Large-Scale Web Sites</em>. 4th ed., O’Reilly Media, 2015.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=47b44e18e8d4"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/its-not-you-it-s-hierarchy-47b44e18e8d4"">It’s not you, it’s hierarchy</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/butterfly-effect-nostalgia-in-ux-a-framework-for-emotions-privacy-with-smart-glasses-1df5f096a8c9?source=rss----138adf9c44c---4,1760355179,"Butterfly effect, nostalgia in UX, a framework for emotions, privacy with smart glasses","Butterfly effect, nostalgia in UX, a framework for emotions, privacy with smart glasses

<h4>Weekly curated resources for designers — thinkers and makers.</h4><figure><a href=""https://www.doc.cc/articles/ux-butterfly-effect""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*xVOVnMRw2-KeUN1j.png"" /></a></figure><p>“As designers, we constantly make decisions. Whether we design objects, devices, websites, apps, or policies, we choose one option over another, setting parameters for subsequent actions to unfold.</p><p>The law of unintended consequences observes that every decision made can have both positive and negative outcomes that were not foreseen by the person making the decision.”</p><p><a href=""https://www.doc.cc/articles/ux-butterfly-effect""><strong>The UX butterfly effect</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/643ec17e83aa"">Martin Tomitsch</a> and <a href=""https://medium.com/u/47c37d1ba5a7"">Steve 'Doc' Baty</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/nostalgia-as-product-strategy-3bc78ba17e16?sk=84355c7b65d6b0f0ffe98809fdf015f9""><strong>Nostalgia as product strategy</strong></a><strong> →</strong><br />The emotional design behind AI marketing campaigns.<br />By <a href=""https://medium.com/u/8797adcdd8a8"">Fabrizia Ausiello</a></li><li><a href=""https://uxdesign.cc/how-to-approach-privacy-in-the-age-of-smart-glasses-bb8ff360157a?sk=aa431ea5f4a635e1b1e5c66704e9de8e""><strong>How to approach privacy in the age of smart glasses</strong></a><strong> →</strong><br />New opportunities for scammers, perverts, and cheaters.<br />By <a href=""https://medium.com/u/8ab653ea27a6"">Daley Wilhelm</a></li><li><a href=""https://uxdesign.cc/the-novelty-and-potential-acceptance-of-conversational-ai-5896a7020060""><strong>The novelty and acceptance of Conversational AI</strong></a><strong> →</strong><br />Managing trust and social influence.<br />By <a href=""https://medium.com/u/e49585a9fcb1"">Tony Phillips</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about their work.</em></p><figure><a href=""https://ikeamuseum.com/en/explore/ikea-catalogue/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*0PuwPbeenou8FAVC.png"" /></a></figure><p><a href=""https://ikeamuseum.com/en/explore/ikea-catalogue/?ref=sidebar""><strong>IKEA Museum: browse IKEA catalogues through the ages</strong></a><strong> →</strong></p><h3>Make me think</h3><ul><li><a href=""https://www.suffsyed.com/futurememo/designers-should-look-to-demis-hassabis-not-jony-ive?ref=sidebar""><strong>Designers should look to Demis Hassabis, not Jony Ive</strong></a><strong> →</strong><br />“Designers went from niche artisans to cultural icons. Apple became not just a company, but a symbol of design perfection. For thirty years, this was the pinnacle of what it meant to “design technology.” Ive’s era gave us the form language of the modern world: clean, minimal, achingly precise. But that world is now dissolving beneath our feet.”</li><li><a href=""https://www.wheresyoured.at/sora2-openai/?ref=sidebar""><strong>OpenAI Is just another boring, desperate AI startup</strong></a><strong> →</strong><br />“To be clear, many of these are ideas that OpenAI has leaked specifically so the media can continue to pump up its valuation and continue to raise the money it needs — at least $1 Trillion over the next four or five years, and I don’t believe the theoretical (or actual) costs of many of the things I’ve listed are included.”</li><li><a href=""https://mechanicalsurvival.com/blog/team-dynamics-after-ai/?ref=sidebar""><strong>Team dynamics after AI</strong></a><strong> →</strong><br />“So much of the discourse around AI assumes an inevitability to adoption, seeing quality as the only barrier to that. Downstream of inevitability we have the discourse of feasibility, of how we get it all to work, which tends to treat inevitability as given. I think we ought to be talking instead about desirability.”</li></ul><h3>Little gems this week</h3><figure><a href=""https://uxdesign.cc/the-532-000-dot-job-why-small-design-changes-cost-big-2fbd2b44fd89?sk=74d05da8aad7008f8d7c1ca66121a5e9""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*LT39ccZS6zJB_x-6.png"" /></a></figure><p><a href=""https://uxdesign.cc/the-532-000-dot-job-why-small-design-changes-cost-big-2fbd2b44fd89?sk=74d05da8aad7008f8d7c1ca66121a5e9""><strong>The “£532,000” dot job: Why small design changes cost big</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/af434fd67626"">Ian Batterbee</a></p><figure><a href=""https://uxdesign.cc/ai-interface-when-intelligence-outgrows-its-container-78f7ddfa3341""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*o1rDrKU-R_K4f7dB.png"" /></a></figure><p><a href=""https://uxdesign.cc/ai-interface-when-intelligence-outgrows-its-container-78f7ddfa3341""><strong>AI interface: When intelligence outgrows its container</strong></a><strong> →<br /></strong>By <a href=""https://medium.com/u/fdfb6f98971c"">Sen Lin</a></p><figure><a href=""https://uxdesign.cc/the-world-is-more-complex-than-ever-55f81058d38e?sk=890d49f7233f11e407fa1e087d9706ea""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*JuV-zXdh_EmK2Sw2.png"" /></a></figure><p><a href=""https://uxdesign.cc/the-world-is-more-complex-than-ever-55f81058d38e?sk=890d49f7233f11e407fa1e087d9706ea""><strong>The world is more complex than ever</strong></a> →<br />By <a href=""https://medium.com/u/9373adfc5a12"">Ed Orozco</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/the-12-emotional-journeys-of-color-psychology-4033d4625fa1""><strong>Color psychology</strong></a><strong> →</strong><br />The 12 emotional journeys.<br />By <a href=""https://medium.com/u/3203528c5800"">Brian Cugelman, PhD</a></li><li><a href=""https://medium.com/design-bootcamp/providing-for-the-thrill-seeker-in-us-the-role-of-emotions-in-design-dc6f7c2ed92f""><strong>A framework for emotions</strong></a><strong> →</strong><br />Mapping emotional needs to design decisions.<br />By <a href=""https://medium.com/u/3140eccd3993"">Marc Reekers</a></li><li><a href=""https://medium.com/design-bootcamp/when-case-studies-become-anti-ux-702ee50def0b""><strong>When case studies become anti-UX</strong></a><strong> →</strong><br />Drowning clarity in a flood of process and detail.<br />By <a href=""https://medium.com/u/4ef587a46021"">Aurélien Aries</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, here’s how you can support us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-uxda3"">this week’s sponsor</a> to support their work too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor an edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1df5f096a8c9"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/butterfly-effect-nostalgia-in-ux-a-framework-for-emotions-privacy-with-smart-glasses-1df5f096a8c9"">Butterfly effect, nostalgia in UX, a framework for emotions, privacy with smart glasses</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/visual-designs-future-is-the-scenic-route-45983f55196e?source=rss----138adf9c44c---4,1760355109,Visual design’s future is the scenic route,"Visual design’s future is the scenic route

<h4>How design will evolve from solving functional problems to creating depth, connection, and significance in the age of AI.</h4><figure><img alt=""A winding road curves through a vibrant autumn forest, with trees displaying brilliant yellow, orange, and red leaves, evoking a serene and colorful scene."" src=""https://cdn-images-1.medium.com/max/1024/1*w-gjipzCRbySOTRjbtW9ZQ.jpeg"" /><figcaption>Image source: <a href=""https://www.dreamstime.com/winding-road-curves-autumn-foliage-trees-new-england-scenic-image190256695"">dreamstime.com</a></figcaption></figure><p>I recently stumbled across a <a href=""https://www.linkedin.com/posts/rafaeltome_if-90-of-the-interfaces-in-2030-will-activity-7380601223575388160-F6ZV?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAjeyKgBQCZhfzRiqeFgjIs6IUn4naWnk4E"">LinkedIn post</a> by Rafael T. making a bold prediction—by 2030, 90% of interfaces will be invisible. According to him, voice, chat, and autonomous agents will replace screens and buttons as the primary ways we interact with technology.</p><p>Designers, he argued, will no longer focus on crafting pixels but on choreographing conversations, shaping intent, and defining how AI behaves. His conclusion was stark—visual design, as a distinct profession, will disappear.</p><figure><img alt=""Alt text: A social media post questions the future of visual design with the rise of AI and voice interactions. It shows a city scene with a large billboard that reads, “If users stop seeing screens, what’s left to design?” The post discusses evolving design roles and the shift from visual aesthetics to interaction architecture."" src=""https://cdn-images-1.medium.com/max/1024/1*ilAfZba7-51lW6y1oVumCg.png"" /><figcaption>Image source: <a href=""https://www.linkedin.com/posts/rafaeltome_if-90-of-the-interfaces-in-2030-will-activity-7380601223575388160-F6ZV?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAjeyKgBQCZhfzRiqeFgjIs6IUn4naWnk4E"">LinkedIn</a></figcaption></figure><p>This argument isn’t new. In fact, I made a similar prediction nearly two years ago. In December 2023, I published an essay titled <a href=""https://uxdesign.cc/design-is-dead-and-we-have-killed-it-ba46cf1dc18b""><em>Design Is Dead. And We Have Killed It.</em></a><em> </em>I explored how AI’s rapid evolution would render design — not just designers — obsolete.</p><p>I argued that visual design’s core purpose is to translate complexity into clarity. And if AI can achieve that same clarity by unifying experiences and anticipating needs across contexts — particularly through non-visual interfaces — it will eventually absorb the function of UI design entirely.</p><p>But since writing that article, my perspective has been shifting. I now believe that visual design may still have a pulse. Understanding that future starts with a simple metaphor— <em>taking the scenic route</em>.</p><figure><img alt=""Map with a red route through New Hampshire’s towns and a bright autumn scene of a red covered bridge surrounded by vibrant yellow foliage."" src=""https://cdn-images-1.medium.com/max/1024/1*PhVuxIjHSaAi0aL6MOV0vw.jpeg"" /><figcaption>Image source: <a href=""https://www.aarp.org/travel/vacation-ideas/road-trips/new-hampshire-road-trip/"">aarp.org</a></figcaption></figure><h4>From utility to choice</h4><p>When traveling, we often face a choice. The fastest route is efficient and predictable, optimized to get us from point A to point B. The scenic route is slower and longer, but richer — winding roads through forests, detours along a coastline. It doesn’t make “sense” in a strictly utilitarian framework, but it does as an expression of human values.</p><p>This metaphor maps directly onto the current debate about design. The rational view assumes that once AI and invisible interfaces handle functional tasks, visual design will become unnecessary. After all, if a <a href=""https://www.uxtigers.com/post/ai-agents"">voice agent</a> can complete a transaction instantly, why bother designing a screen?</p><p>The answer is that necessity and value are not the same thing. While the fastest route may be a straight highway, that doesn’t make it the most meaningful or memorable. In the same way, a frictionless voice interface might be the most efficient way to get something done, but it is not always the most satisfying.</p><p>When trying to understand how such value is communicated, <a href=""http://www.visual-memory.co.uk/daniel/Documents/S4B/sem06.html"">semiotics</a> can help explain this process by describing the dualistic nature of interface communication.</p><p>Every interface communicates on two levels—the denotative (what it does) and the connotative (what it means). Invisible systems excel at the first. Visible, intentional design emphasizes the second — signaling care, identity, values, and intent. Choosing to design something, even when you don’t need to, declares that the interaction is meant to be experienced, not just completed.</p><p>Think of a banking app that still shows you a welcoming dashboard instead of just confirming a deposit by text, or a smart-home system that visualizes energy usage rather than simply optimizing it silently. Both are gestures that transform a transaction into a relationship. They show that interfaces do more than deliver outcomes—they infuse narratives, values, and meaning into those outcomes.</p><h4>The value of inefficiency</h4><p>Once utility is taken care of by automation, effort itself becomes expressive. What optimization once treated as waste — time, ornament, friction, even delay — can instead become thoughtful design materials. They slow people down just enough to notice, reflect, or connect.</p><p>For users, the “scenic route” means richer, more meaningful interactions. A well-crafted interface invites exploration instead of simple completion, shaping how people feel as they move through a system because it makes the care and effort behind it visible.</p><p>We often feel that difference when someone chooses to spend effort on us.</p><p>For example, when I left a company after nearly 13 years, my boss and mentor mailed me a handwritten note congratulating me and thanking me for my work and friendship. He could have sent an email — faster, clearer, and certainly more legible (his handwriting is atrocious) — but I would have read it once and moved on. Instead, I keep that note on my shelf as a reminder of the effort and story it represents.</p><p>This dynamic is well described by <a href=""https://en.wikipedia.org/wiki/Signalling_theory"">signaling theory</a>, which helps explain why effort itself can communicate value. A “costly signal” — one that takes time or effort — carries more weight because it tells users that the experience was worth investing in.</p><p>A handwritten note feels meaningful because someone cared enough to write it. And in the same way, a thoughtfully designed product feels intentional because it respects the user’s humanity.</p><h4><strong>Human variability and the future of design</strong></h4><p>Most people will choose frictionless utility for routine tasks. But smaller groups seeking deeper, more intentional experiences often shape markets and brand perception in unexpected ways. Just look at how <a href=""https://www.theguardian.com/commentisfree/2023/dec/31/the-observer-view-on-the-joys-of-the-vinyl-record-resurgence"">vinyl records made a comeback</a>. Few would have predicted such a revival in an era dominated by streaming music.</p><figure><img alt=""Vinyl album sales chart from 1993 to 2013 shows a rise, peaking in 2013. Inset pie chart: CDs at 165m, digital 118m, LPs 6m. “The LP is Back!”"" src=""https://cdn-images-1.medium.com/max/960/1*UZx_04mIZoMXn2z8hLoP3A.jpeg"" /><figcaption>Image source: <a href=""https://www.statista.com/chart/1465/vinyl-lp-sales-in-the-us/?srsltid=AfmBOorHuTcApja1yRVf2qctm93NAClOgqNZSRTYyMVxEpl1bd3UZUT1"">statista.com</a></figcaption></figure><p>What was once considered obsolete can return with renewed relevance when it speaks to deeper values, and design is no different. The rise of AI and agent-based interaction won’t erase visual design—it will reframe it. As everyday interactions shift toward voice and conversation, design’s role will move from functional to expressive.</p><p>Designers won’t win by competing with AI on speed and output. Machines will always outperform there. But they cannot replicate human judgment, taste, or the ability to infuse meaning into form. The designer’s work will be knowing when a scenic route is worth taking — when inefficiency signals values or identity.</p><p>Visual design will no longer be the default. But precisely because of that, it will become more powerful — shaping meaning in ways automation cannot, long after screens disappear.</p><p><strong><em>Don’t miss out! </em></strong><a href=""https://micbuckcreative.medium.com/subscribe""><strong><em>Join my email list</em></strong></a><strong><em> and receive the latest content.</em></strong></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=45983f55196e"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/visual-designs-future-is-the-scenic-route-45983f55196e"">Visual design’s future is the scenic route</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/ai-interfaces-and-the-role-of-good-writing-222cef13047f?source=rss----138adf9c44c---4,1760273886,AI interfaces and the role of good writing,"AI interfaces and the role of good writing

<h4>Why clear, strategic writing is more critical than ever.</h4><figure><img alt=""An outline of a pencil surrounded by AI icons that look like stars."" src=""https://cdn-images-1.medium.com/max/1024/1*sSQy65QWDjIgpqyXRWkEFw.png"" /></figure><p>If you’ve used an AI product recently, you probably know that the technology is incredible. The UX? Not so much.</p><p>Maybe you’ve gotten comfortable writing prompts or using simple one-click tools. But as AI interfaces start to take different forms, many of them are still kinda hard to figure out. Navigating them can be overwhelming. It doesn’t feel like you’re <em>using</em> these products so much as <em>deciphering</em> them. The engineering is powerful, but the flows don’t make sense.</p><p>If you’re lost in an AI user flow, blame the writing.</p><p>Lots of these tools use unclear labeling, make phony promises, or simply cram interfaces with vague, hyphenated phrases like “AI-enabled.”</p><p>The usability issues make sense, because AI is relatively new. We’ve seen this happen before. Think about the first time you tapped on a smartphone. Or the first time you sent an email. Every big shift takes a little getting used to. As new technology arrives, new interaction patterns emerge. And the role of words in the interface needs to be figured out.</p><p>The solution: good UX writing. Smart, strategic, honest language that keeps users clear and makes products simpler. It’s more important than ever.</p><p>So if you’re designing an AI product, here are some things to consider.</p><h3>Define your audience</h3><p>And do it <em>before</em> you write. The first step of writing is understanding your reader. This decision will influence the way you write. It’ll also influence your feature set and product roadmap. Different audiences need different things. An AI fact-checking tool for journalists will look very different than one for biology students.</p><figure><img alt=""Three different CTAs with different phrasing speaking to different audiences."" src=""https://cdn-images-1.medium.com/max/1024/1*penmi9jhlEEyTg33fxDhYg.png"" /><figcaption>Understand who you’re writing for and how they’ll use your product.</figcaption></figure><h3>Decide where AI sits in the product</h3><p>That means shaping the strategy and architecture of whatever you’re building. Before you add AI language and icons onto every screen, align on your approach to AI. Does AI live across the <em>whole</em> product, or just one feature? Is there a character that sits “on top” of the interface?</p><p>Now is also a good time to ask: is your product using AI at all? Have an honest discussion. If it’s not AI, don’t say it is.</p><figure><img alt=""Three screens that introduce an AI product in different ways. The third doesn’t say “AI” at all."" src=""https://cdn-images-1.medium.com/max/1024/1*AulYk4ooJpeQNBaDdREBxg.png"" /><figcaption>Consider how you’ll introduce AI, if at all.</figcaption></figure><h3>Guide the user input</h3><p>Millions of people are still learning how AI products work. So when you’re writing, think about the first-time user. Will they know what to search? Which file to upload? Where to go for help? Find ways to share guidance or give examples. The best products make sense from the very first screen.</p><figure><img alt=""Three different ways of showing a search bar. One screen has no suggestions, the other lists topics, and the third shows actual search queries."" src=""https://cdn-images-1.medium.com/max/1024/1*ATpX-8vM4wxB0zmq8bdIlQ.png"" /><figcaption>Try different ways to help users get started.</figcaption></figure><h3>Add structure to the writing</h3><p>Formatting matters, especially for readability. As you’re choosing good words, think about form, size, color, and spacing. Find the right approach for your information. Maybe that’s a perfect paragraph. Increasingly, it’s short, scannable pieces of text. Try different ways to show the same idea. You can work with the engineering team to create guidelines around how text gets displayed.</p><figure><img alt=""Three screens showing how color, formatting, and lists can add clarity to writing."" src=""https://cdn-images-1.medium.com/max/1024/1*bdAajcoy654fJfUlHqCgUg.png"" /><figcaption>Explore different ways of displaying the same information.</figcaption></figure><h3>Choose smart, specific actions</h3><p>This is one of the toughest pieces of language to land for AI tools. What is the product actually <em>doing</em>? Language shapes understanding, so try different ways to approach the same feature. Play around with phrasing to see what works best. A button that says “use AI” isn’t precise enough.</p><figure><img alt=""Three buttons that say different things about how they’ll change an image. Adjust colors, enhance image, or touch up."" src=""https://cdn-images-1.medium.com/max/1024/1*RoQwf6my2w-mrqBoX84-Tw.png"" /><figcaption>Be specific about what your AI product is doing. Photo by <a href=""https://unsplash.com/@coleito"">Cole Keister</a></figcaption></figure><h3>Give a helpful next step</h3><p>The best AI products are more than intuitive — they’re predictive. They understand user needs and suggest a path forward. The next time you’re designing one screen of your product, consider what might come next. Explore common use cases and try to avoid dead ends.</p><figure><img alt=""Three versions of next steps after a query. If a user asks about an author, maybe they want to visit a library, buy a book, or show the author’s other books."" src=""https://cdn-images-1.medium.com/max/1024/1*ZI5NMoe8OPBI80GHyPlLaQ.png"" /><figcaption>Use the interface to help create a path forward.</figcaption></figure><h3>Label your interface honestly</h3><p>Whatever your product, make it clear what came from AI. Users should know if they’re talking a chatbot—or a person. They should know if the song was written by a musician—or generated by an app. The solution is simple: use words and images to tell the truth.</p><figure><img alt=""Three versions of how content can be labeled depending on if it was created by AI or a person."" src=""https://cdn-images-1.medium.com/max/1024/1*MeUCJ5qaDBU6r4EgoNA4TQ.png"" /><figcaption>Be honest about how AI was involved.</figcaption></figure><h3>Show your sources</h3><p>It’s a way to build trust with the user. It’s also a way to keep people safe. Showing your source doesn’t feel all that urgent if you’re displaying NBA scoring titles. But AI products are now commonly used for things like nutrition, finance, and medicine. Users should know where important information is coming from.</p><figure><img alt=""Three ways an AI-generated response might cite the source material."" src=""https://cdn-images-1.medium.com/max/1024/1*ZvXH_GCOwVg0vpHNJQIbYw.png"" /></figure><h3>Write for all people</h3><p>Many of today’s AI products were built for early adopters. These products use the language — and acronyms — of engineering. And they presume a deep fluency with technology.</p><p>As AI products move into the mainstream, the writing in the interfaces should evolve, too. The writing should become more readable. Respectful. Inclusive.</p><p>Crafting that language takes talent and experience. It requires deep expertise and a sense of empathy. Sure, AI tools can generate endless amounts text. But to build and ship great products, you need people on the team who can actually <em>write.</em></p><p>If you liked this article, you might enjoy some other things I’ve written about digital product design:</p><ul><li><a href=""https://uxdesign.cc/writing-the-onboarding-experience-c1d9b70925be"">Writing the onboarding experience</a></li><li><a href=""https://uxdesign.cc/every-design-team-needs-writers-95ddbd4d8081"">Every design team needs writers</a></li><li><a href=""https://uxdesign.cc/advanced-techniques-for-writing-good-interfaces-c030ae60150"">Advanced techniques for writing good interfaces</a></li><li><a href=""https://uxdesign.cc/writing-with-respect-fb3d9604a374"">Writing with respect</a></li><li><a href=""https://uxdesign.cc/how-to-write-inclusive-accessible-digital-products-2f4b35ec59a2"">How to write inclusive, accessible digital products</a></li><li><a href=""https://uxdesign.cc/this-is-good-ux-writing-10c4b956a6c3"">This is good UX writing</a></li><li><a href=""https://uxdesign.cc/how-to-write-digital-products-with-personality-2f0bd6197248"">How to write digital products with personality</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=222cef13047f"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ai-interfaces-and-the-role-of-good-writing-222cef13047f"">AI interfaces and the role of good writing</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/what-perplexitys-ai-browser-reveals-about-ux-s-future-d7a702529a4a?source=rss----138adf9c44c---4,1760273679,What Perplexity’s AI browser reveals about UX’s future,"What Perplexity’s AI browser reveals about UX’s future

<h4>A systematic analysis of the first truly AI-native browser and what it teaches us about designing for intention rather than navigation</h4><p>On day 3 of testing <a href=""https://www.perplexity.ai/comet"">Perplexity’s Comet browser</a>, something remarkable happened: I stopped typing URLs entirely. My brain had completely rewired from “where do I go?” to “what do I want?” — and this cognitive shift happened before the AI could reliably deliver on that promise. This gap between mental transformation and technical reality defines the next decade of UX design.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*Yl1U41mM7GSCSVme09UvKA.png"" /><figcaption>Traditional navigation requires multiple decision points and manual processing, while intention-based design compresses user goals into direct AI execution.</figcaption></figure><h3>What makes Comet different from every browser you’ve used</h3><p>Comet isn’t just another browser with AI features bolted on — it’s a fundamental rethinking of what browsers do. Unlike Chrome or Safari, where you navigate TO information, Comet brings information to you.</p><p>Here’s how it works: Instead of a traditional address bar, Comet presents a natural language interface. But the real innovation happens behind the scenes — the browser maintains persistent context across your entire session, understanding not just your current query, but your underlying intent.</p><figure><img alt=""Comet’s clean interface featuring natural language search instead of traditional URL navigation"" src=""https://cdn-images-1.medium.com/max/1024/1*47gAe3dhGpY0bHBdR4gxqg.png"" /><figcaption>Comet’s clean interface featuring natural language search instead of traditional URL navigation.</figcaption></figure><p>Three core capabilities distinguish Comet from traditional browsers:</p><p><strong>Contextual AI assistant</strong>: A sidebar that doesn’t just answer questions — it proactively analyzes what you’re viewing and suggests relevant insights. Looking at flight options? It compares prices across tabs automatically.</p><figure><img alt=""Comet AI sidebar analyzing gluten-free candy selection at Mercadona, displaying contextual product recommendations while maintaining awareness of celiac dietary constraints"" src=""https://cdn-images-1.medium.com/max/1024/1*3UPryT_FiqFtjfytQbdKGQ.png"" /><figcaption>Comet AI sidebar analyzing gluten-free candy selection at Mercadona, displaying contextual product recommendations while maintaining awareness of celiac dietary constraints.</figcaption></figure><p><strong>Persistent intent memory</strong>: Unlike chat interfaces that forget context when you close them, Comet maintains understanding of your goals across your entire browsing session. Start researching hotels in one tab, and it remembers your budget constraints when you switch to restaurant searches.</p><p><strong>Cross-site synthesis</strong>: The system can simultaneously process multiple sources, comparing information and identifying patterns across everything you have open — something that would take humans dozens of manual steps.</p><p>This isn’t just a faster way to browse. It’s a different paradigm for how humans interact with information online.</p><h3>Three breakthrough discoveries</h3><p>After two weeks of systematic testing, three insights emerged that every UX team needs to understand:</p><p><strong>The mental model shift is instant</strong>: Users adapt to intention-based interfaces within <em>days</em>, not weeks — even when AI only delivers 60–70% reliability</p><p><strong>AI excels where we least expected</strong>: 90% success rate for synthesis tasks vs 30% for linear workflows — most teams are building AI features backwards</p><p><strong>The future is distributed, not monolithic</strong>: Specialized AI services collaborating feel more seamless than one system trying to do everything</p><h3>Day 3: The moment my brain rewired itself</h3><p>The difference is immediate and stark. Traditional browsing: Chrome’s blank page asks “where do I go?” AI-native browsing: Comet’s search field invites “what do I want?”</p><p><strong>My first test:</strong> “Find cheap flights to Tokyo for May, maximum budget $800.”</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*apgdrt0u57htaseGxsZKeQ.png"" /><figcaption>Natural language query replacing traditional navigation: delegating a complex task with multiple constraints.</figcaption></figure><p><strong>Traditional approach:</strong></p><ul><li>Open 15+ tabs across multiple flight sites</li><li>Manually compare prices and schedules</li><li>Cross-reference dates and availability</li><li>Time investment: 15–20 minutes of active navigation</li></ul><p><strong>Comet approach:</strong></p><ul><li>Single natural language request</li><li>AI handles research and synthesis automatically</li><li>Time investment: 30 seconds setup + background processing</li></ul><p><strong>The critical insight:</strong> When Comet worked, it was transformative. When it failed, it was frustrating enough to reset user confidence to zero.</p><p>Success rates I documented:</p><ul><li>Simple requests: ~70%</li><li>Complex criteria: ~30%</li><li>Booking workflows: ~30%</li></ul><p>But users mentally adapted to the new paradigm <em>regardless of success rate</em>.</p><h3>Day 7: When AI surprised me (and why most teams build backwards)</h3><p>Day 7 brought an unexpected revelation. I had 8 browser tabs open with diverse UX research from different sources — articles, studies, case studies, forum discussions.</p><p>Command: “Analyze all open tabs and identify common patterns in UX trends for 2025”.</p><figure><img alt=""Comet AI assistant displaying synthesized findings from eight UX research sources, identifying five recurring design trends with specific citations and detecting contradictions between sources in under 60 seconds."" src=""https://cdn-images-1.medium.com/max/1024/1*KKcTcLyHaXuifqP19Ki-bQ.png"" /><figcaption>Comet AI assistant displaying synthesized findings from eight UX research sources, identifying five recurring design trends with specific citations and detecting contradictions between sources in under 60 seconds.</figcaption></figure><p>Result in under 60 seconds:<br />→ Analyzed content from 8 diverse sources<br />→ Identified 5 recurring trends with specific citations <br />→ Detected contradictions between sources<br />→ Suggested connections my manual analysis missed<br />→ Success rate: 90%+ reliability</p><p>This was <em>significantly superior</em> to AI’s performance on sequential tasks like booking flights or shopping.</p><p><strong>The Strategic Insight:</strong> AI excels at parallel information processing, not sequential task execution. Framework for teams: Build AI features around analysis and synthesis <em>first</em>. Save execution automation for later iterations when reliability improves.</p><h3>Day 10: Two AIs started talking to each other — without integration</h3><p>The most surprising discovery wasn’t about Comet itself — it was about how AI systems can work together without explicit integration.</p><p>What happened: I asked Perplexity to analyze my travel spending from Gmail. When I switched to Gmail to verify results, Comet Assistant was immediately contextually aware of my travel expense research.</p><p>No API integration required. Both systems maintained “intention persistence” — understanding my underlying goal across platform transitions.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*BGEhBQVOqO5HBCy_KYWH6g.png"" /><figcaption>Distributed AI systems collaborating through shared intention context without technical integration.</figcaption></figure><p><strong>Critical validation:</strong> Distributed AI collaboration can feel more seamless than monolithic systems. Users benefit from specialized intelligences working together rather than one system attempting everything.</p><h3>Day 12: When delegation actually works</h3><p>By the end of week two, I decided to test Comet with a real-world, high-stakes scenario: planning my daughters’ 11th birthday party. The constraint? They’re celiac, and I needed to shop at Mercadona, a Spanish supermarket.</p><p>My query: “I need to prepare a birthday party for my 11-year-old daughters who are celiac. Help me create a shopping list for Mercadona with all categories: bread, cookies, cakes, candies, and ice cream.”</p><figure><img alt=""Mercadona online store in Comet browser showing initial product search results with AI sidebar providing contextual shopping assistance for gluten-free products suitable for children’s parties"" src=""https://cdn-images-1.medium.com/max/1024/1*wj0VeCCdKHIzRjh612c8mA.png"" /><figcaption>Mercadona online store in Comet browser showing initial product search results with AI sidebar providing contextual shopping assistance for gluten-free products suitable for children’s parties.</figcaption></figure><p>What happened next demonstrated the difference between AI that responds and AI that collaborates.</p><p>Instead of dumping a generic list, Comet’s assistant:<br />1. <strong>Understood the constraint</strong> (gluten-free requirement)<br />2. <strong>Maintained context</strong> across multiple product categories<br />3. <strong>Verified availability</strong> in the specific store<br />4. <strong>Built incrementally</strong>, category by category with my approval<br />5. <strong>Executed the outcome</strong>, adding items to my actual cart</p><figure><img alt=""Comet AI organizing gluten-free products by category (snacks, candies, cookies) with real-time availability verification and stepwise user approval"" src=""https://cdn-images-1.medium.com/max/1024/1*nNUGK2A9WrVKUNC5y5HmdA.png"" /><figcaption>Comet AI organizing gluten-free products by category (snacks, candies, cookies) with real-time availability verification and stepwise user approval.</figcaption></figure><p>The breakthrough wasn’t speed — it was <strong>control</strong>. At each stage, I could see what the AI was selecting and why. When it found bread options, it explained the selection. When moving to cookies, it remembered the celiac constraint without being reminded.</p><figure><img alt=""Completed Mercadona shopping cart populated by AI assistant with gluten-free birthday party items across all requested categories, totaling €31.32 after stepwise user approval process demonstrating successful task delegation"" src=""https://cdn-images-1.medium.com/max/1024/1*pfiIj4bHeRHxx8jONJI1ZQ.png"" /><figcaption>Completed Mercadona shopping cart populated by AI assistant with gluten-free birthday party items across all requested categories, totaling €31.32 after stepwise user approval process demonstrating successful task delegation.</figcaption></figure><p>This is what genuine delegation looks like: I specified the goal, the AI orchestrated the execution, and I maintained meaningful oversight throughout.</p><p><strong>Success rate for this complex, multi-step task: 95%</strong></p><p>The 5% gap? One item suggestion wasn’t available in my postal code, but the AI caught this and offered alternatives before I even clicked checkout.</p><p>This experience crystallized the difference between intention-based and navigation-based interfaces:</p><p><strong>Traditional approach would require:</strong><br />- Manually searching each category<br />- Verifying each product is gluten-free<br />- Cross-referencing availability<br />- Remembering what you already added<br />- 30–45 minutes of active work</p><p><strong>Delegation approach:</strong><br />- Single natural language goal<br />- AI handles research and verification<br />- Stepwise approval of selections<br />- 5 minutes of oversight, 10 minutes of AI work</p><p><strong>Critical insight: Users will tolerate AI reliability issues if they maintain control over outcomes.</strong></p><h3>When the magic broke: Understanding AI failure modes</h3><p>Documenting failures is as important as celebrating successes. But after two weeks of testing, I learned that not all failures are equal — and the distinction matters for design.</p><h4>When AI admits its limits (the good kind of failure)</h4><p>I asked Comet to find hotels in downtown Manhattan within walking distance of Central Park, budget under $200/night for October dates.</p><figure><img alt=""Booking.com hotel search interface in Comet browser with natural language query specifying downtown Manhattan location near Central Park with $200 per night maximum budget constraint for October dates"" src=""https://cdn-images-1.medium.com/max/1024/1*TFmmb3pyyaTQCEp82wuNXg.png"" /><figcaption>Hotel search in Comet with explicit constraints: downtown Manhattan, walking distance of Central Park, under $200/night.</figcaption></figure><p>After processing multiple sources, it returned results significantly above my budget — but with crucial transparency:</p><figure><img alt=""Comet browser showing Booking.com hotel search results with transparent failure communication, displaying available Manhattan hotels priced at $463-$1,882 while explaining that no properties meet the $200 budget constraint and offering alternative search parameters"" src=""https://cdn-images-1.medium.com/max/1024/1*KmKY4a-4WdIhblrVEmPvqw.png"" /><figcaption>Comet displaying search results with transparent communication about constraint limitations, showing available hotels above budget while explaining why and offering alternatives.</figcaption></figure><p>The AI didn’t fail silently. It acknowledged my constraints, searched comprehensively, and honestly communicated the reality: “There are currently no hotels available in downtown Manhattan within walking distance of Central Park for under $200/night on Booking.com for your dates. Most available properties in this area range from $400-$2,000/night.”</p><p>Then it offered alternatives: expand search radius, adjust budget, or try different dates.</p><p>This is <strong>transparent failure</strong> — the system attempted to fulfill my intention, couldn’t, and explained why with actionable options. Crucially, user trust remains intact because the AI showed its reasoning.</p><h4>When AI fails silently (the dangerous kind)</h4><p>Real trust destroyers look different. These are failures where AI confidently delivers wrong results without signaling uncertainty:</p><p><strong>Silent execution failures I documented:</strong><br />- Grocery queries returning “cilantro seeds” instead of “fresh cilantro”<br />- Flight bookings with incorrect date interpretations<br />- Multi-constraint searches that quietly ignore specific criteria<br />- Location parameters that get deprioritized without explanation</p><p>The pattern: AI appears confident while being incorrect. No warning signals. No acknowledgment of limitations. Just wrong results presented as right ones.</p><p><strong>The design implication:</strong> AI systems must distinguish between “I can’t fulfill this request” and “I fulfilled this request incorrectly.”</p><p>The first builds trust through honesty and explanation. <br />The second destroys trust through false confidence.</p><p>For UX designers: Design for graceful failure acknowledgment, not just graceful success paths. The quality of your error states determines long-term user trust more than the quality of your success states.</p><h4>Performance and security considerations</h4><p>Beyond functional reliability, Comet faces technical challenges that affect real-world viability:</p><p><strong>Performance: </strong>Noticeably slower than Chrome for basic browsing tasks, particularly on initial page loads and when processing multiple tabs simultaneously.</p><p><strong>Security:</strong> <a href=""https://brave.com/blog/comet-prompt-injection/"">Brave researchers documented prompt injection vulnerabilities</a> in Comet’s architecture, revealing attack vectors unique to AI-native browsers that traditional security models don’t address. As AI becomes infrastructure rather than feature, new security paradigms become necessary.</p><p>These aren’t dealbreakers — they’re growing pains of a new category. But they’re important context for teams considering similar architectures.</p><h3>The new metrics you need to track</h3><p>Traditional engagement metrics miss the fundamental shift. In AI-native interfaces, success depends on the system, not the user. Track these instead:</p><ul><li><strong>Intention success rate</strong>: Does the user’s goal get accomplished?</li><li><strong>Delegation trust index</strong>: How quickly users trust AI with different tasks</li><li><strong>Intention continuity rate</strong>: How well user intent persists across platform transitions</li></ul><h3>The threshold that will reshape everything</h3><p>Based on systematic analysis: <strong>Traditional navigation interfaces will feel cognitively primitive to users who have experienced genuine delegation — the question isn’t if, but how quickly this threshold is reached.</strong></p><p><strong>Supporting evidence</strong>: Users adapt to intention-based paradigms within days, but current AI can only reliably deliver on those intentions 60–70% of the time. This creates a unique design challenge — bridging transformed user expectations with current technological limitations.</p><p><strong>Industry implication:</strong> Companies should focus on AI interoperability and intention continuity rather than building comprehensive AI monoliths. The competitive advantage lies in orchestrating collaborative AI ecosystems, not singular super-systems.</p><h4>What changes Monday morning</h4><p><strong>→ Start with synthesis, not automation</strong><br />Build AI features around information processing first</p><p><strong>→ Map intention flows, not user flows </strong><br />Design for delegation, with traditional navigation as fallback</p><p><strong>→ Design trust incrementally</strong><br />Prove reliability in low-stakes scenarios first</p><p><strong>→ Build graceful degradation</strong><br />Clear pathways back when AI fails</p><h3>Conclusions</h3><p>Comet represents the first complete empirical validation of theoretical AI UX principles. More importantly, it revealed that the future lies not in monolithic AI systems, but in specialized services collaborating to create unified user experiences.</p><p><strong>For UX designers:</strong> The shift from navigation to intention is operational, not theoretical. Start designing intention flows that span multiple AI systems.</p><p><strong>For product managers:</strong> “Intention Continuity Rate” may be more predictive of success than traditional engagement metrics.</p><p><strong>For the industry:</strong> Early implementation of ecosystem-level AI collaboration provides competitive advantage over isolated AI features.</p><p>The paradigm shift is happening whether our technology is ready or not. The question isn’t whether to participate — it’s whether you’ll lead the transition or follow it.</p><h4><strong>References and further reading:</strong></h4><p><a href=""https://www.perplexity.ai/comet"">Perplexity Comet Browser</a><br /><a href=""https://brave.com/blog/comet-prompt-injection/"">Brave Security Research: Agentic Browser Security</a><br /><a href=""https://www.nngroup.com/articles/mental-models/"">Mental Models in UX Design — Nielsen Norman Group</a><br /><a href=""https://www.starburst.io/blog/parallel-vs-sequential-processing/"">Parallel vs Sequential Processing in Computing</a><br /><a href=""https://arxiv.org/html/2501.06322v1"">Multi-Agent Collaboration Mechanisms in AI</a><br /><a href=""https://www.sciencedirect.com/science/article/pii/S266730532300056X"">Distributed AI Systems: Taxonomy and Framework</a><br /><a href=""https://www.interaction-design.org/literature/topics/human-computer-interaction"">Human-Computer Interaction Design Principles</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d7a702529a4a"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/what-perplexitys-ai-browser-reveals-about-ux-s-future-d7a702529a4a"">What Perplexity’s AI browser reveals about UX’s future</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-532-000-dot-job-why-small-design-changes-cost-big-2fbd2b44fd89?source=rss----138adf9c44c---4,1760098402,"The “£532,000” dot job: Why small design changes cost big","The “£532,000” dot job: Why small design changes cost big

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-532-000-dot-job-why-small-design-changes-cost-big-2fbd2b44fd89?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1920/1*pUcWSSCy3kdID9X3ZRxmWA.jpeg"" width=""1920"" /></a></p><p class=""medium-feed-snippet"">Why did a tiny logo change cost GOV.UK so much?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-532-000-dot-job-why-small-design-changes-cost-big-2fbd2b44fd89?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-12-emotional-journeys-of-color-psychology-4033d4625fa1?source=rss----138adf9c44c---4,1760025486,The 12 emotional journeys of color psychology,"The 12 emotional journeys of color psychology

<p>Journey mapping is one of the most widely used tools in interactive design, helping us create products and campaigns that connect with users on a deeper emotional level. This is key to building long-term loyalty, where users and customers feel an irrational sense of trust and gratitude toward your brand.</p><p>In this article, I’ll explain what an emotional journey is to give you a strategic perspective on how we use emotional design to shape user experiences. Then we’ll explore the 12 major emotional journeys, helping you better understand the different types of transitions that motivate and reinforce user behavior. This will give you — and potentially your colleagues — a shared set of terms for describing emotional journeys, making it easier to discuss and debate design strategies.</p><p>Finally, we’ll look at a new wave of color science that explores the link between color and motivation, so you can use color more strategically to strike the right emotional tone.</p><h3>Cugelman emotion map</h3><p>We’re going to use the Cugelman Emotion Map to explain each of the emotional transitions and look at them strategically, so let’s start with an overview. I developed the Emotion Map in the Behavioral Design Academy as a model based on neuroscience and psychology of emotion, that I simplified to help designers apply science-based emotional design strategies.</p><p>In this article, I’ll give you an overview of the Map, then we’ll step up and use the model to understand the bigger picture in emotional design. If you’d like to explore it in more detail, here’s a deeper explanation: <a href=""https://www.behavioraldesign.academy/color-psychology/colors-and-emotions"">https://www.behavioraldesign.academy/color-psychology/colors-and-emotions</a></p><p>The Cugelman Emotion Map divides emotional experience into four quadrants — each representing one of the broad emotional states that either motivate or reinforce people’s behavior.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/600/0*EkCIV2xWRiLE_SaU.png"" /></figure><h3>Motivators vs. reinforcers</h3><p>People often confuse the terms <em>motivator</em> with <em>reinforcer</em> — and while they’re closely related, they’re actually two distinct psychological principles that we use in different ways.</p><p>You can usually tell when someone doesn’t understand the difference because they use the term <em>“carrot and stick”</em> inconsistently — sometimes as a motivator, other times as a reinforcer — without realizing they’re blending two separate principles. This kind of confusion can seriously harm their design and communication work.</p><p>It’s hard to apply psychology effectively when you mix up the most fundamental principles. So let’s make sure we’re clear on the difference.</p><ul><li>Motivators are design strategies that evoke excitement or fear about a future outcome. We use the term motivator to describe how emotional design can spark a desire to act — either to gain something desirable (which evokes an optimistic emotion) or avoid something unpleasant (that evokes an insecure emotion).</li><li>Reinforcers, on the other hand, are design strategies that deliver an emotionally rewarding or painful experience in the present. These aren’t about driving action, but about reinforcing behavior — shaping user habits by encouraging repetition of something rewarding, and discouraging of things that feel painful or frustrating.</li></ul><p>Let’s contrast these a bit more.</p><p>Motivators are emotions that drive people to take action. Reinforcers, on the other hand, are the emotional rewards or punishments that shape how people behave over time — determining whether they’ll repeat a behavior or avoid it in the future.</p><p>Motivators reflect the energizing emotional response to an anticipated threat someone wants to avoid, or an opportunity they hope to obtain. Reinforcers describe the emotional experience based on what we achieved — whether it’s a positive emotion tied to success, which boosts the odds of repeating the behavior, or a negative emotion tied to failure, which teaches us to try harder or adopt a different approach.</p><p>While motivators inspire us to act, reinforcers teach us how to act.</p><p>Since emotions can be used both to motivate and to reinforce user behavior, understanding how they work gives us a more strategic way to design emotional experiences.</p><p>Let’s look at each quadrant in the Cugelman Emotion Map to better understand how these emotions function, and then we’ll build on this, by exploring the 12 transitions and colors psychology of each quadrant.</p><h3>Motivators (Green quadrants)</h3><p>In the Cugelman Emotion Map, the two motivator quadrants are shown in green, representing go. These are the areas where we people feel motivated to act — either by creating opportunities drive their optimism, or threats that drive their feelings of insecurity. Here’s an explanation of each:</p><ul><li><strong>Optimistic (High energy, positive emotion):</strong> This is where excitement, curiosity, and engagement live. These emotions drive focus, approach and movement towards the goal. Strategically, this is where we showcase incentives, highlight product value, and aim to satisfy our users’ needs. If you don’t offer enough to evoke these emotions, your product will feel unmotivating but if you overdo it, you may come across as selling too hard.</li><li><strong>Insecure (High energy, negative emotion):</strong> These are the stress emotions, with anxiety, worry or a sense of pressure. Strategically, we may use urgency, FOMO, or any of many threat avoidance strategies to drive action. However, this must be used carefully — too much can feel manipulative, overly negative, or stressful. Think of it like a spice: just a dash can be effective, but too much is overwhelming.</li></ul><h3>Reinforcers (Red quadrants)</h3><p>The two reinforcer quadrants are shown in red. These reflect the emotional experiences users feel after taking action — either a rewarding or painful experience.</p><ul><li><strong>Secure (Low energy, positive emotion):</strong> Users feel calm, trusting, and satisfied. Strategically, this is where we want users to land — feeling confident that our product consistently meets their needs. This is the emotional zone where we build long-term loyalty which is often the key to designing a successful product. The downside here, is users can start to feel complacent and start to disengage once they get what they thought they wanted.</li><li><strong>Pessimistic (Low energy, negative emotion):</strong> This is where users feel disappointed, trapped, or helpless. It signals disengagement and the risk of churn. But these emotions are potentially dangerous. If users stay here too long, this is the zone where resentment can form. Resentment is the opposite of loyalty, where people will never trust your company and may go out of their way to harm your reputation and income. Never leave users stuck in this state for long, unless you enjoy responding to nasty comments on social media. The up side is that if your competitors trap users in this quadrant, you can easily poach them.</li></ul><p>This gives us a basic overview of the Cugelman Emotion Map, so let’s move on to the strategic use of these emotions.</p><h3>User journeys are emotional transitions</h3><p>Years ago, I became interested in writing screenplays and read several classic books on the subject — including Aristotle’s Poetics. This 2,000-year-old classic analyzes theater and explains how stories resonate with audiences.</p><p>While reading it, I sketched out a diagram of a play, as a timeline with a curve representing the emotional tone. It rises toward high positivity, then dips into lower negativity over time — similar to how we compose music, shifting between moments of high and low tension.</p><p>Years later, I discovered that Kurt Vonnegut had used a similar framework to analyze the narrative arcs of literature — possibly also inspired by Aristotle. I also came across a scientific paper that used AI to analyze the plot structures of numerous books, using the same emotional diagram.</p><p>I’ve adapted this concept into the Cugelman Emotion Map, which we’ll use to understand the rise and fall of emotional tension as part of our emotional design strategies.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*wSX89it6UbKAdh-W.png"" /></figure><p>To show you how it works, let’s walk through a classic love story — between a frustrated user and an online product that steps in as the hero, solves their problem, and ultimately earns their long-term loyalty. In the chart below, you’ll see how each transition (in the Emotion Map) places our user in one emotional state before and another right after.</p><p>In this story, our user begins in a state of contentment but soon realizes they have a problem. They try to solve it, fail, and gradually sink into a sense of despair — feeling hopeless and ready to give up on finding a solution.</p><p>Then they discover your product, which sparks a sense of renewed optimism. They decide to give it a try. Your product delivers on its promises, and as the user starts to experience real benefits, their trust in your product and brand begins to grow.</p><p>If we continue to reinforce their trust by consistently delivering on our promises, the user may eventually feel something even more powerful: gratitude and the greatest prize of all — their loyalty. At this point, they’re not just satisfied; they’re emotionally invested.</p><h3>The 12 emotional journeys</h3><p>Based on the four quadrants, there are 12 primary emotional journeys that represent every possible transition across the motivators and reinforcers.</p><p>These transitions can happen quickly, but they can also unfold over a much longer period — sometimes taking months or even years — as people gradually shift from one emotional state to another. For example, someone might spend years feeling pessimistic about their life before something changes and they find a new way forward.</p><p>To help you better understand these patterns, below is an overview of all twelve emotional journeys, including one in-depth example for each quadrant.</p><h3>Optimism strategies</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/600/0*snfgPZ8BVlKRcnKJ.png"" /></figure><p>These are the most positive emotional transitions, where users pursue a goal as we support them. If your only aim is to get users to take a single action, one optimistic motivational strategy may be enough. However, in most cases, we use these strategies to prompt initial action, then we start focusing on the secure quadrant, where we work to build a long-term, repeat relationship.</p><p>That said, optimistic emotions are the primary tool we use to get people started. Below are three common emotional journeys:</p><ul><li><strong>Inspiring: </strong>Our audience is already content with their current situation, but by offering something truly exciting, they feel that things can go from good to great. This is how we fire up their excitement to leave their place of comfort.</li><li><strong>Incentivizing: </strong>Our audience feels pressure to avoid an imminent threat while progressively feeling optimistic that their course of action will help them avoid the threat and gain benefits. At some point, the positives outweigh the negatives, leaving our audience more positive about the experience.</li><li><strong>Liberating: </strong>Our audience feels trapped in a hopeless position, but when we provide the promise of escape or change for the better, pessimistic despair fades in favor of optimistic hope.</li></ul><h4>Credit Karma aims to inspire users</h4><p>Users often settle when their credit score is “good enough” and stop thinking about improving. This is a common challenge in behavioral design. Once people reach a goal, they tend to disengage — and that’s often when we see them regress, too.</p><p>While the ultimate goal of behavior change is usually long-term loyalty in the secure quadrant, once people reach this point, we typically need to shift towards maintenance strategies to keep them regular. Credit Karma uses mainly inspiring tactics, motivating users with positivity and encouraging continued progress through uplifting, goal-oriented messages. Yes, there is a slight dash of implied fear messaging, but overall, this is far more positive than negative, with a nice calming blue.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*18xFzXplwELrcFT_.png"" /></figure><h3>Insecurity strategies</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/600/0*VKbAovXJ9cUFVRJM.png"" /></figure><p>This quadrant involves using stress-arousing techniques that motivate our audience to move in the right direction or stop them from heading the wrong way. I recommend including at least a small dose of these techniques consistently. However, it’s important not to overdo them, as they can backfire when misapplied. Here are the three transitions:</p><ul><li><strong>Pressuring</strong> — Our audience is moving toward something positive, but then realizes there’s an emerging threat. Their current path becomes more attractive because it will also help them avoid this imminent danger.</li><li><strong>Agitating</strong> — Our audience feels secure at first, but their contentment turns to stress as an emerging threat slowly takes over, dominating their thoughts and leaving them feeling they must act urgently.</li><li><strong>Scaring</strong> — Our audience feels trapped in an emotionally painful situation and then experiences growing anxiety to act urgently to avoid an imminent threat they may feel powerless to escape. This is an extremely stressful and punishing transition, but a mainstay of political communications.</li></ul><h4>Booking.com pressures customers with threats</h4><p>Booking makes you feel optimistic that you’ll be able to get the room you want, but then they layer-on classic pressure tactics by telling you that others are booking that same room right now, forcing you from the solidarity of your safe bedroom to a public space where you’re now competing to not lose that room.</p><p>They use their friendly colors in combination with some alarming red, warning you that you’d better act or risk losing that sweet deal. You can read more about <a href=""https://www.behavioraldesign.academy/blog/7-principles-of-social-influence-for-digital-psychology"">booking.com’s social influence strategies here</a>.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1000/0*Mko_D70CMOWAj3Z_.jpg"" /></figure><p>A common technique is to make users aware that if they don’t act someone else will get it first, forcing them into a competitive, zero-sum game they never intended to play. Booking.com is famous for this, with this example showing how they’re telling me other people are booking this property now. They really turn up the heat later when I reach the booking page, telling me someone else will get the room if I dare close the page.</p><h3>Security strategies</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/600/0*Dayib-OvNDWiAkPB.png"" /></figure><p>For most of what we do, this quadrant represents the ultimate goal of emotional design: fostering long-term, loyal relationships with our target audience.</p><p>When I say <em>loyalty</em>, I don’t mean repeat habits. I’m talking about something deeper — when your audience forms an emotional bond with your brand and starts acting in ways that don’t always make logical sense. They’ll resist switching to competitors even when better deals are available, and some may even feel like they’re “cheating” on your brand because their loyalty feels authentic. These are also the people who often become brand advocates and drive referrals.</p><p>However, the downside of bringing people into this secure quadrant is that they can become complacent. This is why we typically shift into <em>maintenance psychology</em> once our audience reaches this stage.</p><p>Below are the three main ways we bring people into the secure quadrant:</p><ul><li><strong>Gratifying</strong> — Our audience is pursuing something truly motivating, which is fulfilling enough that they feel secure in their ability to achieve it or trust those who provide it — ideally our brand. This is the most satisfying and rewarding experience, the place where trust and loyalty are nurtured, as our audience feels compelled to rep</li><li><strong>Relieving</strong> — Our audience is actively working to avoid an imminent threat, and then discovers a solution that may not excite them but solves the problem, leading them to feel relaxed and secure as tension fades into relief.</li><li><strong>Saving</strong> — Our audience feels trapped in a painful situation but then discovers a solution that may not have seemed exciting yet lifts them from their plight, leaving them feeling secure and filled with deep gratitude.</li></ul><h4>Zappos gratifies its customers</h4><p>Zappos has earned one of the top reputations for phenomenal customer support — and they’ve clearly learned a critical lesson: when customers are pursuing a goal, the company must help them achieve it and never leave them feeling trapped with a product they don’t want or a transaction they consider unfair.</p><p>What’s impressive about their site is how easy it is to find the support page. Not only does it offer a straightforward way to return products, but contacting the company is also straightforward. Compare that to many other companies, where contact info is buried in the footer or hidden behind a bizarre maze of frustrating, nonsensical complexity.</p><p>And when you call that number, you discover how Zappos truly gratifies customers and earns loyalty: by offering support staff who weren’t hired just for competence, but equally for their deeply empathetic personalities.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*lSj9wqDiBVRC14PS.png"" /></figure><h3>Pessimism strategies</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/600/0*R0ph0d6pV6qLVWv6.png"" /></figure><p>The last quadrant is the most negative — and the riskiest to work with — as it deals with our most disheartening emotions. Unlike the secure emotions that build loyalty, this quadrant is where self-hate or long-term resentment toward your brand can take root — the exact opposite of what we want to achieve.</p><p>Users can end up here intentionally, through sadistic design, or more commonly, through simple incompetence. Despite this, there are situations where it’s necessary to take users into this space — for example, when they haven’t paid their bills or we have to close an unprofitable product that people depend on. Whether you’re in damage control mode or trying to turn a bad experience into a positive one, it’s critical to understand these emotions and how they function.</p><p>The upside is that when your competitors have driven their users into this quadrant, they’re ripe for defection. All you need to do is step in as the savior, with a product that makes people feel optimistic that it’s time to try something new.</p><p>Here are the three main ways users end up in pessimistic emotional states:</p><ul><li><strong>Overwhelming: </strong>Our audience tries to avoid a threat, but when escape proves impossible, they experience the consequences directly and find themselves trapped in helplessness.</li><li><strong>Discontenting: </strong>Our audience once felt secure, but as their sense of safety erodes, they begin to feel pessimistic, finding themselves trapped in an emotionally punishing situation.</li><li><strong>Disappointing: </strong>Our audience was pursuing an exciting opportunity, only to end up worse off, where hope turns to disappointment and they feel trapped in an awful situation.</li></ul><h4>Temu’s overwhelming wheel of hell</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/406/0*XuBOZoIycWuOMOou.png"" /></figure><p>Temu earns the award for having one of the most frustrating web interfaces that overwhelms users. Instead of allowing people to use their mobile website freely, they aggressively push users toward their mobile app using a manipulative design pattern.</p><p>When you search for products on their mobile web interface, a spinning gambling-wheel pops up, forcing you to play a fake game, win a misleading prize, and then pressuring you to download their app to not lose it.</p><p>If you don’t download the app, the same popup keeps appearing whenever you return to the search results page — making the site far too frustrating to use. On the other hand, if you download the app, you risk installing potential spyware linked to the Chinese Communist Party. Either way, you lose.</p><p>So to get their low prices, you must pay the real price — stress or privacy risks — and each sucks. So the only real choice is not to use their product and assume there’s a hidden cost to their deals.</p><h3>Colors of emotional journeys</h3><p>When it comes to visual design strategies during transitions, color psychology can be a powerful tool for amplifying emotional tone. But before diving in, let’s clear up a few common misunderstandings.</p><h3>Universal color-emotion claims are usually nonsense</h3><p>First, many of the so-called magical links between color and emotion are largely nonsense — ideas invented, recycled, and repeated over time. The design industry has long had a quiet love affair with color pseudoscience, but that approach is becoming increasingly outdated.</p><p>Today, a new wave of research in color psychology and neuroscience is uncovering real, scientifically supported connections between color and emotion. The problem is that much of this knowledge remains buried in academic papers. That’s why I, along with many others, am working to make this research more accessible.</p><h3>Color-emotion associations are context-specific</h3><p>Second, color–emotion associations are real, but they’re context dependent. This means color must always be evaluated within the situation it’s being used. When color and context align, emotional impact is amplified. When they don’t, your message can be weakened and the user experience disrupted. This principle is called <a href=""https://www.behavioraldesign.academy/blog/color-in-context-theory-extended"">color-in-context theory</a>.</p><p>When any color matches the emotional tone of the context, psychologists call this color congruency. A mismatch creates incongruency, a subtle but jarring feeling that makes it hard for people to understand what’s going on, while also eroding trust.</p><p>For example, if you’re shopping and see a red sticker on jeans you’ve been eyeing, you may feel excited — red signals a sale. But if you’re a crypto trader and see a red candlestick on a chart, your heart might sink — red signals a financial loss. In one case, red feels positive; in the other, negative. The emotional response comes not from the color itself, but from what it means in that specific context.</p><p>This is why blanket statements like “red means danger” or “blue means calm” are misleading. What truly matters is color authenticity — choosing colors that accurately reflect the emotional context, rather than applying assumed meanings arbitrarily.</p><p>When color and context are congruent, design becomes more emotionally resonant and persuasive. When mismatched, it creates friction.</p><p>Congruent colors also enhance cognitive fluency — users process information more quickly, trust the experience more, and are more likely to accept the message. Incongruent colors slow processing, raise skepticism, and prompt users to scrutinize more carefully — not always in a good way.</p><h3>Color-emotion associations are rooted in facial perception</h3><p>Third, if color-emotion associations aren’t magical, where do they come from?</p><p>The common explanation points to culture. While cultural meaning plays a role, growing research suggests a deeper origin: our ability to read emotional cues from facial color changes.</p><p>Babies can identify five basic colors — purple, blue, green, yellow, and red — the same hues our brains use to interpret emotional signals in faces. While cultural learning shapes these associations over time, the foundational training begins in infancy. Across all cultures, humans learn to associate certain facial color patterns with specific emotional states in specific contexts.</p><p>Context matters here, too. If someone apologizes but doesn’t blush, you might doubt their sincerity. What you call “intuition” could be your brain registering the absence of a familiar emotional color pattern. Similarly, we judge health based on skin tone. A greenish hue might suggest illness to you; to a doctor, it could signal a specific condition.</p><p>Here’s how it works: Our faces emit subtle color patterns based on blood oxygenation. Oxygenated blood creates red tones; deoxygenated blood creates blue ones. These combine into distinct facial color signatures for different emotions — and they’re visible across all skin tones. People of all ethnicities are able to detect these shifts within their communities, regardless of melanin levels. This appears to be a universal human trait.</p><p>These signals are so consistent that researchers have developed video algorithms capable of estimating heartbeat and emotional state based on facial color shifts. When people view the color masks generated by these systems, they’re surprisingly accurate at guessing emotional states — further validating the theory that facial color cues underpin emotional perception.</p><p>While cultural influence is real, our lifelong training to read facial color changes is likely the strongest source of our color-emotion associations.</p><h3>We project facial-color emotions to non-human things</h3><p>Fourth, research suggests that we unconsciously project facial color associations onto inanimate objects.</p><p>Humans are pathological anthropomorphizers — we assign human traits to animals, machines, and even lifeless objects. The fact that a “pet rock” can have a personality says it all.</p><p>We don’t just see a color — we interpret it through the lens of human emotion. That’s why a blue couch might feel “calm,” or a red button might feel “urgent.” We’re unconsciously applying the same facial color-emotion patterns we’ve observed in people to everything around us.</p><p>In a 2018 study, Thorstenson and colleagues asked participants to match objects, facial expressions, and emotions with different colors. While the match wasn’t perfect, in the chart below, you’ll see there was a strikingly close fit — supporting the idea that our general color-emotion associations originate from the emotional color patterns we first learned by observing our parents’ emotions, and their facial signals.</p><h3>Color contexts of the emotional quadrants</h3><p>Because color-emotion links rely on authentic, context-specific use of color, I’ve merged findings from a wide range of scientific studies and mapped them to the Cugelman Emotion Map. This framework includes major motivational contexts behind emotional experience — such as physiological wellbeing, safety, social bonding, status, and reproductive instincts (love, sex, parenting).</p><p>We won’t go into the full details here, just the high-level emotional tones used for motivating and reinforcing behavior.</p><p>This framework gives us a basic color palette that congruently amplifies the emotional tone across the “12 Journeys” users take as they transition from one emotional state to another.</p><p>Here’s a high-level overview of the emotional color quadrants:</p><ul><li><strong>Optimistic-to-pessimistic emotions: </strong>These range from vibrant rainbow hues in the optimistic quadrant to desaturated gray tones in the pessimistic quadrant.</li><li><strong>Insecure-to-secure emotions:</strong> These range from red, oxygenated blood tones in the insecure quadrant to calm, blue-appearing blood tones in the secure quadrant.</li></ul><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/708/0*uaOgRvIC0E8M3pJx.png"" /></figure><h3>Optimistic-to-pessimistic emotions: Desaturated to saturated colors</h3><p>When exploring the motivational context of emotional quadrants, certain key colors do emerge; however, the general rule centers on saturation. A well-known study found that among the range of optimistic and pessimistic emotions, one pattern stood out: optimistic emotions are strongly associated with saturated, vivid colors — the kind seen in children’s programming or rainbow imagery. These colors tend to feel more exciting and energetic.</p><p>By contrast, colors tied to pessimistic emotions become increasingly desaturated, often fading toward gray. These muted tones reflect a loss of vitality and align with feelings of decline, detachment, or emotional fatigue.</p><p>A classic example is the “before and after” narrative often used in marketing. The “before” scene typically features dull, desaturated tones — representing a life that’s uninspired or unfulfilled. The “after” scene bursts into vibrant, saturated color, instantly signaling emotional uplift and positivity.</p><h4>Optimistic colors</h4><p>Optimistic colors span the full spectrum but tend to lean toward warmer tones. As a general rule, a diverse palette of saturated, vibrant hues conveys positivity and emotional energy.</p><p>Research from human facial studies shows that red is associated with competitiveness, athletic performance, dominance, and social status. As red shifts toward yellow-orange, it begins to signal health and even sexual attractiveness — patterns commonly observed in facial color and dating studies.</p><p>That said, red’s emotional meaning shifts radically depending on context. While it can be used for optimistic emotions, I typically avoid it as a strategic designer due to its potential to send mixed signals. In positive contexts, I minimize its use, reserving it primarily for insecure emotions where it carries more weight.</p><p>The general guideline is clear: use a vibrant, colorful palette to represent optimistic positivity, but be selective about how and when red is applied.</p><h4>Pessimistic colors</h4><p>Pessimistic emotions are best expressed through desaturated tones — colors that appear faded, aged, or washed out. As hues lose saturation, they naturally drift toward gray, mirroring emotional states such as sadness, depletion, or disconnection.</p><p>In fact, the link between gray and depression is so strong it runs both ways. People experiencing depression often perceive the world as more gray and tend to apply filters to their Instagram photos that appear bluer, darker, and grayer.</p><p>Some hues carry specific negative connotations. For instance: Green is often linked to illness and has been shown to reduce perceived attractiveness in dating studies. Greenish-yellow can signal disgust — which makes sense, as it’s a visible indicator of serious, potentially life-threatening health conditions. Red can suggest blushing, embarrassment, or shame. Blue is closely associated with sadness.</p><p>I generally avoid red and blue in pessimistic contexts, keeping them for more sharply defined emotional contrasts elsewhere in the palette. But if you do use them, desaturate them in depressive or low-energy contexts to maintain emotional accuracy.</p><h3>Insecure-to-secure emotions: Red-blooded to blue tones</h3><p>Facial coloration offers one of the clearest explanations for our color-emotion associations. Specifically, it’s the interplay between oxygenated red veins and deoxygenated blue arteries that produces the wide range of facial colors linked to different emotional states.</p><p>While specific motivational contexts bring their own colors, the broad trend is a shift from red to blue across the insecure-to-secure spectrum.</p><p>A classic example can be found in warnings, alerts, and system messages, which almost always use red to signal urgency or threat. On the other hand, websites that aim to reassure users — such as those handling transactions or personal data — often use baby blues, soft gradients, and calming skies to convey security and trust.</p><h4>Insecure colors</h4><p>In states of insecurity — when people feel vulnerable, anxious, or threatened — red becomes a dominant color. It’s consistently linked to perceptions of aggression and arousal, though the exact meaning depends heavily on context. A flushed face might indicate hostility in a confrontation, or attraction in a romantic moment.</p><p>Because red is emotionally intense and highly context-sensitive, I reserve it primarily for anxious or threat-based emotions, using it strategically and sparingly in other areas.</p><p>Darker tones can also express the intensity of insecurity — leaning more toward deep black rather than neutral gray. These hues add weight and contrast, especially in high-impact or “reverse” palettes. Greenish-brown also fits into this emotional range, often signaling disgust or contempt and reinforcing the darker, more defensive aspects of insecurity.</p><h4>Secure colors</h4><p>Lower blood oxygenation is associated with relaxed, stable emotional states, which are often reflected in blue-to-purple hues, with some slight extensions into red. These tones evoke calm, trust, contentment, and emotional stability — qualities tied to low arousal and composure.</p><p>As emotional activation increases slightly, emotions like admiration or appreciation begin to shift toward subtly warmer tones within the same spectrum. Still, I usually keep these emotions within the bluish palette, as it best conveys the ease, connection, and quiet assurance of trust.</p><h3>Final words</h3><p>I hope this article offered a fresh perspective on color psychology and sparked some new ideas for how you might apply it to your own projects.</p><p>I’m sharing this as a test of the structure for a book I’m currently publishing on the topic. If you have any feedback on the format — whether you found it helpful or see areas for improvement — I’d genuinely appreciate hearing it.</p><p>Enjoy the journey.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/120/1*n_39MynndCiz3GwGQPKfRg.png"" /><figcaption>Brian Cugelman</figcaption></figure><h3>Meet the author</h3><p>Dr. Brian Cugelman is a specialist in using psychology and data science for digital products.</p><p>Thousands of students from companies like Samsung, Microsoft, Apple, Google, Facebook, and Salesforce have completed his digital psychology training.</p><p>He has authored over 25 publications and spoken at MIT, the University of Toronto, Johns Hopkins, and various conferences, including TEDx.</p><p>Dr. Cugelman leads the Behavioral Design Academy, offering training on applying psychology to technology. Connect at: <a href=""https://www.behavioraldesign.academy."">https://www.behavioraldesign.academy.</a></p><p><strong>ARTICLE SOURCE:</strong><br /><a href=""https://www.behavioraldesign.academy/color-psychology/authors-final-words"">https://www.behavioraldesign.academy/color-psychology/authors-final-words</a></p><h3>Bibliography</h3><ul><li>Jonauskaite, D., Abu-Akel, A., Dael, N., Oberfeld, D., Abdel-Khalek, A. M., Al-Rasheed, A. S., … &amp; Mohr, C. (2020). Universal patterns in color-emotion associations are further shaped by linguistic and geographic proximity. Psychological Science, 31(10), 1245–1260.</li><li>Benitez-Quiroz, C. F., Srinivasan, R., &amp; Martinez, A. M. (2018). Facial color is an efficient mechanism to visually transmit emotion. Proceedings of the National Academy of Sciences, 115(14), 3581–3586.</li><li>Elliot, A (2015): Elliot and Niesta, 2008; Roberts et al., 2010; Stephen and McKeegan, 2010; Guéguen and Jacob, 2014; Lin, 2014 (cf. Lynn et al., in press; Stephen et al., 2012b)</li><li>Ghosh, S. K., &amp; Bandyopadhyay, D. (2019). The color of skin: green diseases of the skin, nails, and mucosa. Clinics in dermatology, 37(5), 516–519.</li><li>Nakajima, K., Minami, T., &amp; Nakauchi, S. (2017). Interaction between facial expression and color. Scientific reports, 7(1), 1–9.</li><li>Perrett, D. I., Talamas, S. N., Cairns, P., &amp; Henderson, A. J. (2020). Skin color cues to human health: carotenoids, aerobic fitness, and body fat. Frontiers in psychology, 11, 392.</li><li>Reece, A. G., &amp; Danforth, C. M. (2017). Instagram photos reveal predictive markers of depression. EPJ Data Science, 6(1), 15.</li><li>Stephen, I. D., Coetzee, V., Law Smith, M., &amp; Perrett, D. I. (2009). Skin blood perfusion and oxygenation colour affect perceived human health. PloS one, 4(4), e5083.</li><li>Thorstenson, C. A., Elliot, A. J., Pazda, A. D., Perrett, D. I., &amp; Xiao, D. (2018). Emotion-color associations in the context of the face. Emotion, 18(7), 1032.</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4033d4625fa1"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-12-emotional-journeys-of-color-psychology-4033d4625fa1"">The 12 emotional journeys of color psychology</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/nostalgia-as-product-strategy-3bc78ba17e16?source=rss----138adf9c44c---4,1759964365,Nostalgia as product strategy,"Nostalgia as product strategy

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/nostalgia-as-product-strategy-3bc78ba17e16?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2100/1*JvrEqusX5-Bb0C6RUcZKyw.png"" width=""2100"" /></a></p><p class=""medium-feed-snippet"">The emotional design behind the latest AI marketing campaigns.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/nostalgia-as-product-strategy-3bc78ba17e16?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/ai-interface-when-intelligence-outgrows-its-container-78f7ddfa3341?source=rss----138adf9c44c---4,1759873227,AI interface: When intelligence outgrows its container,"AI interface: When intelligence outgrows its container

<h4>How AI redefines user interfaces, and why the chat box gets it wrong</h4><figure><img alt=""A person typing on a vintage tablet prototype, overlaid with a modern AI search bar."" src=""https://cdn-images-1.medium.com/max/1024/1*fdhCb8tb0yzs0zFG8Rropg.png"" /><figcaption>Image source: <a href=""https://kokonautlabs.wordpress.com/2013/02/27/alan-kay-on-marshal-mcluhan-and-the-personal-computer/"">Kokonaut Labs</a> / Recreated by author</figcaption></figure><p>In 1989, Alan Kay published <a href=""https://worrydream.com/refs/Kay_1989_-_User_Interface,_a_Personal_View.pdf""><em>User Interface: A Personal View</em></a>, building on Marshall McLuhan’s idea that <a href=""https://web.mit.edu/allanmc/www/mcluhan.mediummessage.pdf""><strong>“the medium is the message.”</strong></a> A medium doesn’t just carry information, it reshapes how we think. To make sense of it, we first internalize the medium.</p><p><strong>An interface, then, is a cognitive framework.</strong></p><p>Today, AI interfaces are shifting fast: from chat to voice, from canvases to agent-driven cross-tool spaces. As models converge in capability, the real differentiation has moved to the interface layer. The interface is no longer just a channel. It is the key that unlocks technology, translating complexity into affordances and shaping the flow of human attention.</p><h3>The collapse of interaction</h3><p>Before large language models, our typical path to finding answers online looked something like this: break your question down into keywords (like pizza, recipe, tutorial) and feed them to a search engine.</p><p>Then you wade through a long list of results, browsing page by page, clicking on a few promising links to read carefully, and finally mentally stitching those fragments together into your own version of the answer.</p><figure><img alt=""Diagram comparing command-based, process-driven, and AI-driven intent-based interfaces through Google and Perplexity examples."" src=""https://cdn-images-1.medium.com/max/1024/1*-VaSvfujeqbYtSkUzrczRQ.png"" /></figure><p>In contrast, with conversational AI products, I simply say: “Give me the perfect pizza recipe and instructions,” and the AI immediately serves up a curated answer. If it’s not quite right, I add a couple more sentences, the AI continues to refine or rewrite, and soon I’ve iterated to a final answer.</p><p>So with AI’s intervention, we can see two major shifts in product interaction paradigms:</p><h4><a href=""https://www.nngroup.com/articles/ai-paradigm/"">From command-based to intent-based</a></h4><p>Traditional interfaces relied on a turn-taking loop: <strong>input → output → user judgment → next command.</strong> Now, instead of issuing step-by-step instructions, the user states the goal, and the system handles the process behind the scenes.</p><h4>From process-driven to outcome-driven</h4><p>Interaction used to feel like a visible journey, where users accumulated knowledge and built judgment along the way. Today, much of that process is folded into the backend. Interaction becomes a cycle of prompting and refining around the result itself. The user’s main task is to evaluate the output, while the system dynamically connects the dots based on intent.</p><h3>The unmoored chat box</h3><p>Interestingly, most AI products have converged on the same choice: a chat box. The reason is obvious — chat feels natural, with virtually zero learning curve. Prompts unfold as back-and-forth conversation, offering high interactivity, tolerance for errors, low barriers to entry, and almost unlimited flexibility. It’s the perfect vehicle for mass adoption.</p><figure><img alt=""Grid showing six AI chat interfaces, including ChatGPT, Gemini, Claude, Perplexity, DeepSeek, and Grok, all sharing similar layouts."" src=""https://cdn-images-1.medium.com/max/1024/1*Uyp3cUr0RbKUIwfIUOBUoQ.png"" /></figure><p>This is why Sam Altman wants to build ChatGPT into a <a href=""https://youtu.be/ctcMA6chfDY?si=WLb9A244XcdJmTnT"">Personal Life OS</a>. In that value narrative, the experiential intuitiveness and multimodal extensibility of conversational interaction is the solution for vast life scenarios.</p><p>But there’s another, less visible factor: LLMs are inherently <a href=""https://maggieappleton.com/squish-structure"">squishy</a>. The same intent, placed in slightly different contexts, can produce different results. Therefore, ensuring that a setting always corresponds to stable, reproducible effects is a thankless task.</p><p>As a result, AI products often bury parameters deep in the system instead of exposing them as explicit controls.</p><figure><img alt=""Composite interface mockup showing an AI tool presenting maps, videos, product listings, and charts in one unified workspace."" src=""https://cdn-images-1.medium.com/max/1024/1*aNaUD3ArHvj-QxGZJuMiOw.png"" /></figure><p>Take ChatGPT as an example. Beyond plain text, it can also produce tables, images, charts, code snippets, videos, and content cards.</p><p>One way to unlock these formats is to be explicit in the prompt — say, asking the AI to present the answer as a flowchart. But this puts the burden back on the user, who now has to master structured prompting and understand how content should align with different formats.</p><p>The second is to let the AI decide, having the system choose the appropriate presentation based on the generated content’s characteristics. This points to a major trend in future interfaces — <a href=""https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces?_sm_vck=J8qN47SpWnMDrN8LSrDW9NkMQHB0Q8RH7DJrRRslW9447Q7sqsRN"">Generative UI</a>.</p><p>In this model, AI doesn’t just generate content, it simultaneously decides and renders the most fitting presentation container, truly merging output with interface for genuine personalization.</p><p>But before Generative UI becomes reality, the chat box stays out of control.</p><h3>Category error</h3><p>Dave Edwards, founder of <a href=""https://artificialityinstitute.org/"">Artificiality</a>, offered a thought-provoking <a href=""https://artificialityinstitute.org/the-design-illusion-of-llms/"">metaphor</a> that most digital products fall into one of two categories:</p><p><strong>Windows</strong>: they connect users to external information and resources — think Tripadvisor, Airbnb, or Spotify.</p><p><strong>Rooms</strong>: they provide spaces for work, collaboration, and creation — tools like Figma, Photoshop, or PowerPoint.</p><figure><img alt=""Comparison between Figma and Tripadvisor interfaces illustrating two tool metaphors: “room” for exploration and “window” for creation."" src=""https://cdn-images-1.medium.com/max/1024/1*nU3L_X_hnCmYOBNsZIHJmA.png"" /></figure><p>If we map AI users along a proficiency spectrum: there are beginners, intermediate users, and power users.</p><p>Conversational interfaces naturally cater to the first two groups. They brand the system as a “no learning required” product. Perfect for newcomers, right? But for power users, the chat box strips away control panels and leaves only an open-ended input field.</p><pre>Analyze this software licensing agreement for legal risks and liabilities.<br /><br />We’re a multinational enterprise considering this agreement for our core data infrastructure.<br /><br />&lt;agreement&gt;<br />{{CONTRACT}}&lt;/agreement&gt;<br /><br />This is our standard contract for reference:<br />&lt;standard_contract&gt;{{STANDARD_CONTRACT}}&lt;/standard_contract&gt;<br /><br />&lt;instructions&gt;<br />1. Analyze these clauses:<br />- Indemnification<br />- Limitation of liability<br />- IP ownership<br /><br />2. Note unusual or concerning terms.<br /><br />3. Compare to our standard contract.<br /><br />4. Summarize findings in &lt;findings&gt; tags.<br /><br />5. List actionable recommendations in &lt;recommendations&gt; tags.&lt;/instructions&gt;</pre><p>That’s why you’ll see one user writing a 300-word structured prompt with <a href=""https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#example-legal-contract-analysis"">XML tags</a>, while another asks <em>“How many shapes of McNuggets are there?”</em></p><figure><img alt=""Illustration of user spectrum from beginner to power user, mapping AI tools like ChatGPT, Claude, and Gemini in between."" src=""https://cdn-images-1.medium.com/max/1024/1*Nbcg2eZ1fdgoiyvhg23W0Q.png"" /></figure><p>The problem is that many AI products are designed as “windows” with a clean input box that seems able to carry any conversation. But in terms of technical capability, they’re absolutely “rooms” capable of supporting deep creation.</p><p>And here lies the category error: <strong>users with complex needs require explicit functions and sufficient control, yet find themselves trapped in a “window.”</strong></p><figure><img alt=""ChatGPT dashboard interface showing weekly usage, top topics, and quotas, designed to visualize ongoing chats and research progress."" src=""https://cdn-images-1.medium.com/max/1024/1*lnnouJ646h2xSVEiYG728w.jpeg"" /><figcaption>What if ChatGPT offered a dashboard instead of just a chat box? / <em>Image by author</em></figcaption></figure><p>So people improvise:<br /><em>They buy prompt templates.<br />They use Raycast to manage and trigger prompts.<br />They spin up endless new chats every day, stack them in the sidebar.<br />They save outputs into notes — then bring them back into the chat again.</em></p><blockquote>The intelligence isn’t limited, the interface is what cages it.</blockquote><figure><img alt=""Diagram depicting a trade-off slider with human and AI figures at opposite ends, emphasizing shared agency in interaction."" src=""https://cdn-images-1.medium.com/max/1024/1*y79Jc2v48KEknRTegsm1Zw.png"" /></figure><p>As AI systems mature, the real question is not simply which interface will dominate, but how we will <strong>negotiate agency between human and machine.</strong> That balance between outcome and process, freedom and control will define the next era of design.</p><h4>📖 Further reading</h4><ul><li><a href=""https://worrydream.com/refs/Kay_1989_-_User_Interface,_a_Personal_View.pdf"">User Interface: A Personal View </a>— Alan Kay</li><li><a href=""https://www.nngroup.com/articles/ai-paradigm/"">AI: First New UI Paradigm in 60 Years</a>—Jakob Nielsen</li><li><a href=""https://maggieappleton.com/squish-structure"">Squish Meets Structure</a> — Maggie Appleton</li><li><a href=""https://artificialityinstitute.org/the-design-illusion-of-llms/"">The Design Illusion of LLMs</a> — Dave Edwards</li><li><a href=""https://lukew.com/ff/entry.asp?2118"">Chat is: the Future or a Terrible UI</a> — Luke Wroblewski</li><li><a href=""https://lg.substack.com/p/conversational-interfaces-the-good"">Conversational Interfaces: the Good, the Ugly &amp; the Billion-Dollar Opportunity </a>— Julie Zhuo</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=78f7ddfa3341"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ai-interface-when-intelligence-outgrows-its-container-78f7ddfa3341"">AI interface: When intelligence outgrows its container</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
