source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,Pivoting¬†Your Career Without Starting From Scratch,"Pivoting¬†Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, ‚ÄúIs this still what I want to be doing?‚Äù This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as you‚Äôre reading this or you‚Äôre still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? We‚Äôve got you covered."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/giving-users-voice-virtual-personas/,1766484000,Giving Users A Voice Through Virtual Personas,"Giving Users A Voice Through Virtual Personas

Turn scattered user research into AI-powered personas that give anyone consolidated multi-perspective feedback from a single question."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/,1766138400,How To Measure The Impact Of Features,"How To Measure The Impact Of Features

Meet TARS ‚Äî a simple, repeatable, and meaningful UX metric designed specifically to track the performance of product features. Upcoming part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code üéü <code>IMPACT</code> to save 20% off today)."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/smashing-animations-part-7-recreating-toon-text-css-svg/,1765965600,Smashing Animations Part 7: Recreating Toon Text With CSS And SVG,"Smashing Animations Part 7: Recreating Toon Text With CSS And SVG

In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk) shows his techniques for creating [Toon Text titles](https://stuffandnonsense.co.uk/toon-text/index.html) using modern CSS and SVG."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/accessible-ux-research-ebook-release/,1765296000,"Accessible UX Research, eBook Now Available For Download","Accessible UX Research, eBook Now Available For Download

We‚Äôve got exciting news! eBook versions of ‚ÄúAccessible UX Research,‚Äù a new Smashing Book by Michele A. Williams, are now available for download! Which means soon the book will go to the printer. Order the eBook for instant download now or <a href=""https://www.smashingmagazine.com/printed-books/accessible-ux-research/"">reserve your print copy at the presale price.</a>"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/state-logic-native-power-css-wrapped-2025/,1765274400,"State, Logic, And Native Power: CSS Wrapped 2025","State, Logic, And Native Power: CSS Wrapped 2025

CSS Wrapped 2025 is out! We‚Äôre entering a world where CSS can increasingly handle logic, state, and complex interactions once reserved for JavaScript. Here is an unpacking of the standout highlights and how they connect to the bigger evolution of modern CSS."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-ux-professionals-can-lead-ai-strategy/,1765180800,How UX Professionals Can Lead AI Strategy,"How UX Professionals Can Lead AI Strategy

Lead your organization‚Äôs AI strategy before someone else defines it for you. A practical framework for UX professionals to shape AI implementation."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/beyond-black-box-practical-xai-ux-practitioners/,1764946800,Beyond The Black Box: Practical XAI For UX Practitioners,"Beyond The Black Box: Practical XAI For UX Practitioners

Explainable AI isn‚Äôt just a challenge for data scientists. It‚Äôs also a design challenge and a core pillar of trustworthy, effective AI products. Victor Yocco offers practical guidance and design patterns for building explainability into real products."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/masonry-things-you-wont-need-library-anymore/,1764669600,Masonry: Things You Won‚Äôt Need A Library For Anymore,"Masonry: Things You Won‚Äôt Need A Library For Anymore

CSS Masonry is almost here! Patrick Brosset takes a deep dive into what this long-awaited feature means for web developers and how you could make use of it in your own work."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/desktop-wallpaper-calendars-december-2025/,1764493200,A Sparkle Of December Magic (2025 Wallpapers Edition),"A Sparkle Of December Magic (2025 Wallpapers Edition)

With December just around the corner, how about some new desktop wallpapers to welcome the last month of the year ‚Äî and the holiday season, if you‚Äôre celebrating? Our latest edition of monthly wallpapers has got you covered. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/accessibility-problem-authentication-methods-captcha/,1764237600,The Accessibility Problem With Authentication Methods Like CAPTCHA,"The Accessibility Problem With Authentication Methods Like CAPTCHA

CAPTCHAs were meant to keep bots out, but too often, they lock people with disabilities out, too. From image classification to click-based tests, many ‚Äúhuman checks‚Äù are anything but inclusive. There‚Äôs no universal solution, but understanding real user needs is where accessibility truly starts."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/design-system-culture/,1764093600,Design System Culture: What It Is And Why It Matters (Excerpt),"Design System Culture: What It Is And Why It Matters (Excerpt)

We‚Äôre so happy to announce that ‚ÄúMaturing Design Systems‚Äù‚Äîa Smashing book by Ben Callahan &mdash; will soon be joining the Smashing Library! Ben‚Äôs insights and advice are so powerful, we thought you might like to read an excerpt from the book. <a href=""https://www.smashingmagazine.com/the-smashing-newsletter/"">Subscribe to our Smashing newsletter</a> to be notified when orders are open."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/designing-for-stress-emergency/,1763989200,Designing For Stress And Emergency,"Designing For Stress And Emergency

Practical guidelines on designing time-critical products that prevent errors and improve accuracy. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code üéü <code>IMPACT</code> to save 20% off today). With a <a href=""https://smashingconf.com/online-workshops/workshops/vitaly-friedman-impact-design/"">live UX training</a> starting next week."
rss,uxdesign.cc,https://uxdesign.cc/same-same-but-new-ux-research-in-the-age-of-llms-36285d007845?source=rss----138adf9c44c---4,1767788015,"Same, but new: UX Research in the age of LLMs","Same, but new: UX Research in the age of LLMs

<h4>How researchers can define quality, guide prompts, and shape the value of AI¬†outputs.</h4><p>AI agents, synthetic users, deep research, staying relevant as a UX researcher can feel like a challenge that resets every week. Teams across product, design, and engineering are moving faster than ever, often powered by the same underlying AI technologies. <a href=""https://medium.com/user-experience-design-1/human-machine-responsible-ai-workflows-for-ux-research-22a5c39ac0ec"">Prompt engineering and system design have quickly become central topics across disciplines</a>, raising a familiar, and uncomfortable, question: <em>where does UX research fit¬†now?</em></p><p>My experience building LLM-based products over the past two years has led me to a clear conclusion. This moment is not the end of UX research. It is the same work we have always done, understanding people, defining value, but applied to a new class of systems. And for researchers willing to adapt, it creates an opportunity to move upstream and become more strategic than ever. As products become cheaper to build and AI spreads across nearly every workflow, teams now face a new foundational decision: how much AI should this feature¬†contain?</p><p><a href=""https://uxdesign.cc/is-your-ai-use-case-idea-really-going-to-work-7718c695e7c0"">When the answer is ‚Äúyes‚Äù, and it is not always</a>, the work does not stop there. A second, equally important question follows: <em>what form should that AI take?</em> One of the most prescient frameworks in this space comes from <a href=""https://www.emcap.com/thoughts/your-success-with-generative-ai-may-come-down-to-these-ux-decisions"">Jake Saper and Jessica Cohen at Emergence Capital, who describe AI products along a spectrum</a>. On one end are pure chat-based systems that maximize flexibility. On the other are AI-enhanced features that trade flexibility for simplicity. Most production features live closer to the latter. The product defines the prompt, sometimes with light user input, and delivers the output in a predetermined format. Every ‚Äúsummarize,‚Äù ‚Äúrewrite,‚Äù or ‚Äúgenerate‚Äù button we encounter today reflects this tradeoff.</p><p>Delivering value with AI enhanced features means having a solid understanding of what the user is attempting to achieve within the context of their workflow both for the actual output and the design of how it is delivered. Take for example, a summarize feature. A summary can mean many different things depending on where it is being delivered. A ‚ÄúSummarize‚Äù button offered in Gmail likely needs punchy and bulleted contents. The same within Adobe acrobat for a large PDF could mean a multi paragraph executive summary. It is all about context and the actual need in the moment. The same we have always been doing but¬†new.</p><figure><img alt=""Adobe buttons for taking AI Actions"" src=""https://cdn-images-1.medium.com/max/774/1*lYL-7x1LLVuJ-LBP0ey62w.png"" /><figcaption>Adobe buttons for taking AI¬†Actions</figcaption></figure><p>NotebookLM offers a compelling example of this shift. The product began as a chat-based, retrieval-augmented system. It gained widespread attention with its audio overview feature, which generated a podcast-style summary of a user‚Äôs materials, no prompting required. That feature delivered immediate, differentiated value by meeting a specific user need in a novel format. While the initial novelty has faded, subsequent updates have reinforced NotebookLM‚Äôs position as a model for AI-enhanced productivity.</p><figure><img alt=""A screenshot of the NotebookLM feature including sources, the overview page, and the studio feature."" src=""https://cdn-images-1.medium.com/max/1024/1*5e0Ox6q7MpceIhZjBBiXBw.png"" /><figcaption>A screenshot of the NotebookLM feature including sources, the overview page, and the studio¬†features</figcaption></figure><p>The Studio feature set within NotebookLM illustrates the pattern particularly well. Users are presented with a set of structured options that guide them toward generating reports, briefs, or analyses. The real power lies not in unrestricted chat, but in the ability to lightly customize a pre-generated prompt. In Emergence Capital‚Äôs terms, this is a true copilot: a system that helps users provide the right input in order to receive a valuable output. When a user asks NotebookLM to generate a report, success is not defined by grammatical correctness or factual accuracy alone. Success is whether the output fits the user‚Äôs actual need, whether it advances their task, supports their workflow, or deepens their understanding.</p><p>This is where the role of UX research begins to change‚Ä¶ not in kind, but in¬†scope.</p><h3>A New Way to Create¬†Value</h3><p>Creating value with LLM-based features is not about writing the cleverest prompt. It is about defining the right instructions so the system produces something that is genuinely useful to the user in that moment. Prompt quality matters, but prompts do not exist in a vacuum. They sit at the intersection of engineering, design, and, critically, research.</p><p>NotebookLM‚Äôs opening chat response is a useful example. As a user logs in, the chat window is filled with an overview of all contents that helps users make sense of their materials as soon as they open a notebook, reducing the cognitive cost of re-orienting themselves. Engineering work was required to craft prompts that reliably surface the right insights. Design work was required to decide how that information should appear on the page. But neither of those efforts can succeed without first understanding what users actually need at the moment of entry. That understanding is where research does its most important work, informing both what the system should generate and how that output should be presented.</p><figure><img alt=""NotebookLM opens with a summary of the Notebooks"" src=""https://cdn-images-1.medium.com/max/1024/1*Hk912CHJxIPta3jysWeUEg.png"" /><figcaption>NotebookLM opens with a summary of the Notebooks</figcaption></figure><p><a href=""https://uxdesign.cc/ai-ux-design-for-intelligent-interfaces-bc966e96107d"">Design guidance for displaying AI-generated content is relatively well covered.</a> <a href=""https://medium.com/user-experience-design-1/search?q=ai+in+product"">Many strong frameworks already exist for structuring text, surfacing key information, and presenting outputs in ways that are readable and actionable.</a> What has received far less attention is the upstream work of shaping the instructions that guide generation in the first place. Ensuring a prompt is directionally correct‚Ää‚Äî‚Ääaligned to real user needs rather than abstract capabilities, was always important. With LLMs, it becomes foundational.</p><p>This is where UX research creates new leverage. By engaging early, researchers can help teams anchor feature development in what is actually possible given both the state of the technology and the user‚Äôs needs in context. In my experience, this approach consistently opens up more promising product directions. Instead of retrofitting research onto an already-defined solution, teams start with a shared understanding of value, giving design and engineering a clearer target to aim for as they¬†build.</p><h3>A New Process for Defining Quality in¬†Outputs</h3><p>For decades, UX research has focused on identifying the user needs a product must satisfy. That part of the work is unchanged. What <em>is</em> new is the nature of the systems we are designing. With large language models, teams no longer have complete control over outputs. These systems are inherently non-deterministic, we can guide them, but we cannot fully dictate what they will¬†produce.</p><p>In traditional product design, many needs could be satisfied with deterministic solutions. When Apple realized people were using their iPhones as flashlights, the solution was straightforward: a single button that produced a single, predictable outcome. One tap, immediate value. No ambiguity, no interpretation required. That model works well when the need is simple and the desired outcome is¬†clear.</p><figure><img alt=""iPhone flashlight buttons that is placed on the Lock Screen for ease of use"" src=""https://cdn-images-1.medium.com/max/1024/0*WDyogOfVTb78FQwo"" /><figcaption>iPhone flashlight buttons that is placed on the Lock Screen for ease of¬†use</figcaption></figure><p>As needs become more complex, so does the solution. Uber faced a different problem: passengers felt anxious while waiting for their ride. The company could not control the behavior of individual drivers, so instead it designed an experience to manage uncertainty. <a href=""https://www.wired.com/story/uber-algorithm-fake/?utm_source=chatgpt.com"">A live map showed the driver‚Äôs progress (although not always truthfully)</a>. Messaging explained potential delays. Contact options gave users a sense of agency. Each element addressed the same underlying issue, negative sentiment during the wait, even though the core system remained unpredictable.</p><figure><img alt=""A screen grab of a car moving toward a destination on Uber App"" src=""https://cdn-images-1.medium.com/max/800/0*SrfQbAaDBqm8Gh6H"" /><figcaption>A screen grab of a car moving toward a destination on Uber¬†App</figcaption></figure><p><a href=""https://medium.com/ai-ux-designers/ai-is-breaking-free-an-emerging-ai-ux-pattern-26894a915d93"">Working with LLMs is similar, but amplified</a>. An LLM behaves less like a traditional interface and more like a human collaborator: responsive, capable, and inconsistent. It may produce insightful results one moment and confident-sounding nonsense the next. This unpredictability is not a flaw; it is a property of the technology. The challenge, then, is not eliminating variability, but maximizing output quality despite¬†it.</p><p>That challenge requires a different approach. Rather than treating quality as an after-the-fact judgment, teams must define what ‚Äúgood‚Äù looks like in advance, and do so in a way that acknowledges uncertainty. This is where UX research plays a central role: translating user needs into clear quality signals that can guide generation, evaluation, and ongoing refinement, even when outputs cannot be fully controlled. Here is how I got about¬†it.</p><h4>Surfacing Quality¬†Signals</h4><p>The first step is establishing a shared understanding of what constitutes a high-quality experience. When a user requests a briefing document in NotebookLM, what are they actually expecting to see? The answer is inherently subjective. Different users bring different expectations, shaped by their goals, context, and prior experience.</p><p>This is why qualitative research is essential. In-depth interviews allow teams to understand not just <em>what</em> users say they want, but <em>how</em> they judge AI-generated outputs in practice. I start by asking users to share what they expect to see as an output. Afterwards, I walk them through examples, either outputs they already use or ones I introduce, and have them describe what they mean when they say something ‚Äúinforms,‚Äù ‚Äúsummarizes,‚Äù or ‚Äúprovides direction.‚Äù These conversations reveal the mental models users bring to AI systems and the tradeoffs they are willing to¬†make.</p><p>As classic Jobs to Be Done research has shown, people are rarely asking for features in the abstract, they are trying to make progress in a specific situation. The same principle applies here. With that mindset, research becomes a game of identifying the main themes in what users are asking for in the¬†output.</p><p>In the case of NotebookLM, early qualitative work might surface themes such as trust, cognitive relief, contextual relevance, and actionability. Users may not articulate all of these dimensions explicitly, but patterns emerge across interviews. A useful heuristic here is the 80/20 rule: a relatively small set of research-derived criteria can account for the majority of users‚Äô expectations.</p><p>For example, a high-quality briefing report in Notebook might be judged on whether¬†it:</p><ul><li>Feels trustworthy</li><li>Demonstrates understanding across multiple¬†sources</li><li>Reflects the user‚Äôs current¬†context</li><li>Connects insights to realistic next¬†actions</li></ul><h4>Validation and Refinement</h4><p>Once core quality themes are identified, the next step is validation and refinement at scale. Surveys are particularly effective here. They allow teams to translate high-level themes into more specific, testable factors and to understand how consistently those factors matter across users and contexts. When designing these studies, I ask participants to evaluate outputs that closely resemble what the product would actually generate. Users are then asked to rate and critique those outputs, providing nuance around what makes them useful, or¬†not.</p><p>Take trust as an example. Users frequently say they want AI outputs they can trust, but trust is not a single, universal attribute. At a minimum, it implies factual correctness. Beyond that, trust is shaped by tone, length, structure, and framing, all of which vary by context. <a href=""https://medium.com/%40mariamargarida/designing-with-ai-ux-considerations-and-best-practices-5c6b69b92c4c"">An email summary should be concise and direct. An executive briefing should surface key themes and unexpected insights.</a> A call recap should highlight action items and mention relevant stakeholders. When an output matches what users expect in that situation, trust¬†follows.</p><p>Surveys help teams refine these distinctions. In the NotebookLM case, researchers might explore when users feel a pre-created executive briefing demonstrates contextual awareness and when it does not. For example, users may respond positively when recent meetings or emails are incorporated appropriately, and negatively when outdated or irrelevant documents are surfaced. This level of specificity is critical, it directly informs how prompts should be written and constrained.</p><h4>Creating a Quality¬†Rubric</h4><p>With qualitative depth and survey validation in place, the next step is synthesizing insights into a shared quality rubric. There is an immediate opportunity for the engineering team to create refinement, yet as previously suggested, it is not just about the actual output but how it is designed. As such, this rubric can become the centering focus for the entire¬†team.</p><p>A well-designed rubric defines each quality factor clearly, illustrates what good and poor outputs look like, and makes tradeoffs explicit. It allows designers, product managers, and engineers to align on what success means and how it should be evaluated. Importantly, it translates research insights into something actionable.</p><p>For prompt engineers, the rubric serves as a definition of the <strong>global maximum</strong>, the set of characteristics the system should optimize for overall. Prompt iteration can then focus on finding local maxima within that boundary, confident that improvements are aligned with real user needs rather than proxy¬†metrics.</p><figure><img alt=""Example of Metric Rubric for NotebookLM"" src=""https://cdn-images-1.medium.com/max/1024/1*r0e7MNnSxTo_jHMxDAVlug.png"" /><figcaption>EXAMPLE: NotebookLM Summary Output Quality¬†Rubric</figcaption></figure><h4>Continued Refinement</h4><p>Even with a strong rubric and well-crafted prompts, the work does not end. Many teams now rely on AI-based testing and automated evaluation to refine LLM outputs over time. Companies such as <a href=""https://www.braintrust.dev/"">BrainTrust</a> have built extensive platforms that allow product teams to test the output of their prompts at scale, across models. Leveraging these tools are far more effective when grounded in research-defined quality criteria.</p><figure><img alt=""Screenshot of the Braintrust app, showing evals at scale."" src=""https://cdn-images-1.medium.com/max/1024/1*ci85QVqGfpeeBUbeWFYSlw.png"" /><figcaption>Braintrust has an extensive automated evaluation system</figcaption></figure><p>A solid rubric ensures that synthetic user testing, automated scoring, and iterative refinement are anchored in metrics that matter to real people. Rather than optimizing loosely connected signals, teams can focus on outcomes that genuinely improve the user experience.</p><p>This ongoing refinement is especially important in a fast-moving market. User expectations are evolving quickly as the Overton window of what is possible with AI continues to shift. A bullet-point summary that felt impressive yesterday may be table stakes today, replaced by audio, visual, or personalized formats tomorrow. Quality rubrics must be revisited and updated as expectations change, creating a sustained, strategic role for UX research in keeping AI systems aligned with human¬†value.</p><h3>UX Research as the Interpreter of Human¬†Value</h3><p>The science of UX research has not changed. People are still complex, contextual, and inconsistent, and understanding what they need remains the core of the work. The methods have not changed either. UX researchers are still experts at learning from users, identifying patterns, and translating insight into¬†action.</p><p>What <em>has</em> changed is the nature of the systems we are shaping. With LLM-based products, outputs are no longer guaranteed, and a new stakeholder, the prompt engineer, has entered the room. <a href=""https://uxdesign.cc/a-practitioners-journal-on-navigating-ux-in-the-age-of-ai-97f0a11e8319"">Research now has a direct line into how AI systems are instructed, evaluated, and scaled.</a> Insights no longer stop at informing interfaces or features; they define the criteria by which machine-generated work is judged as successful.</p><p>This process is not foreign to UX research, but the leverage it creates is new. By defining quality up front, researchers can shape how intelligence itself is tuned, guiding optimization, grounding automation, and ensuring that faster iteration does not come at the expense of human value. In my own work, this shift has made the field feel more relevant and more exciting than it has in¬†years.</p><p>Done well, UX research can become the discipline that defines what people want from AI systems, and holds those systems accountable to real outcomes. AI will continue to do more of the work. That is not changing. What can change is whether that work actually matters. UX research is uniquely positioned to make sure it¬†does.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=36285d007845"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/same-same-but-new-ux-research-in-the-age-of-llms-36285d007845"">Same, but new: UX Research in the age of LLMs</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4,1767702176,"If your confidence is at an all-time low in design, try this","If your confidence is at an all-time low in design, try this

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*b7RqqzAQSJn18pNskWDBXQ.jpeg"" width=""4085"" /></a></p><p class=""medium-feed-snippet"">How writing can help tackle self-confidence issues in design</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/if-your-confidence-is-at-an-all-time-low-in-design-try-this-b4b071161e74?source=rss----138adf9c44c---4"">Continue reading on UX Collective ¬ª</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/beyond-conversations-natural-language-as-interaction-influencer-8b39ed123c39?source=rss----138adf9c44c---4,1767702078,Beyond conversations: natural language as interaction influencer,"Beyond conversations: natural language as interaction influencer

<h4>From chat to canvas to control panel: Understanding natural language interaction patterns</h4><figure><img alt=""Soft, misty background with a blurred human face profile on the right and the heading ‚ÄúNatural Language Interaction Patterns‚Äù on the left, accompanied by pill-shaped labels reading Intent, Action, and Orchestration."" src=""https://cdn-images-1.medium.com/max/1024/1*GNkosiM1Eioj63cPsN-qMg.png"" /></figure><p>For much of the history of software, users had to build a mental model of the system before they could use it effectively. You learned where things lived like which menu contained which action, which screen held which information, how different parts of the interface connected to each¬†other.</p><p>Interaction followed a structured pattern: navigate screens by clicking buttons, type into fields, scroll through content, use gestures, menus, or keyboard shortcuts to move between states. Every action required first understanding the system‚Äôs organizational logic, then locating the right control, and finally performing the correct interaction on it. Users translated what they wanted into a series of UI interactions the system understood.</p><p>While <em>affordance</em> was explicit, <em>intent</em> was indirect.</p><h3>When systems begin to understand intent</h3><p>As natural language based interaction to machine evolves, they didn‚Äôt just change how we express intent, they fundamentally compress entire workflows into single expressions.</p><p>For instance, Google search transformed how we find information precisely because it eliminated the directory-browsing model of early web¬†portals.</p><figure><img alt=""Image comparing two navigation approaches. At the top, a hierarchical categories flow shows stacked panels moving left to right: Technology ‚Üí Software ‚Üí Operating System ‚Üí Linux, with each selection highlighted in blue and arrows indicating deeper navigation. At the bottom, a single search bar labeled ‚ÄúDirect Natural Language Search‚Äù shows the query ‚Äúlatest news on linux OS,‚Äù illustrating direct access without navigating categories."" src=""https://cdn-images-1.medium.com/max/1024/1*4CH_JqrSYUIkVUtYkLu8DQ.png"" /></figure><p>The system becomes responsible for translating that intent into the underlying sequence of actions, queries, and transformations.</p><p>This transformation fundamentally changes the contract between user and tool. Traditional interfaces required users to learn the system‚Äôs language, its navigation patterns, its terminology, its organizational logic. Natural language interfaces require the system to learn the user‚Äôs language¬†instead.</p><h4>The Agent Shift: From understanding intent to executing work</h4><p>Modern AI interfaces extend this principle even further. Where Google compressed <em>navigation</em>, AI systems compress <em>action</em>, as Ben Shneiderman explores in his work on <a href=""https://dl.acm.org/doi/10.1145/3419764"">bridging the gap between ethics and practice in human-centered AI</a>.</p><p>Plus, typing into a message box in natural language to converse with a system is straightforward, much like sending a text message. This familiarity lowers the entry barrier dramatically, making powerful AI tools immediately accessible to non-experts. And made tools like ChatGPT, Claude, Gemini, Perplexity, Microsoft Copilot etc achieved mainstream adoption with remarkable speed.</p><h4>The conversation feed overload¬†problem</h4><p>These conversation feed-based AI tools excel at expressing intent and getting relatively straightforward answers with better multi-turn controls. But the conversation feed can become overloaded when tasks involve multiple subsequent actions, require human intervention at various steps, or produce persistent artifacts that need to remain visible or outcomes become duplicative and longer. The linear nature of conversation thread often struggles to accommodate these complexities.</p><figure><img alt=""Animated GIF showing a user scrolling through a ChatGPT conversation feed in dark mode, revealing structured sections with headings, bullet points, and to convey longer message chains."" src=""https://cdn-images-1.medium.com/max/1024/1*0vGE_GTPNE1cECtP1Y2xNw.gif"" /></figure><p>Different tools are responding to this¬†tension:</p><ul><li>Some keep everything in the chat thread, treating code and documents as just another¬†message</li><li>Others split the experience entirely, placing all output in a dedicated canvas</li><li>A few blend both approaches, using conversation for steering while the canvas holds the¬†work</li></ul><p>This question of AI placement in UI design, which Sharang Sharma explored in his <a href=""https://uxdesign.cc/where-should-ai-sit-in-your-ui-1710a258390e"">article</a>, becomes increasingly critical as these tools mature. The rest of this article covers observations from industry AI tools using different natural language-based interaction patterns, how they align with key aspects of interaction elements, and what we can learn if we want to build natural language-driven features, products, or¬†systems.</p><h3>Natural language as an interaction medium</h3><p>When examining natural language interfaces through the lens of interaction design, Don Norman‚Äôs concept of the <a href=""https://mitpress.mit.edu/9780262525671/the-design-of-everyday-things/"">Gulf of Execution and Gulf of Evaluation</a> provides a powerful framework for understanding how interaction loop with natural language work in these¬†tools.</p><p><em>The Gulf of Execution</em> represents the gap between what a user intends to do and the actions required to execute it in the interface.</p><p><em>The Gulf of Evaluation </em>represents the gap between what the system does and the user‚Äôs understanding of that¬†outcome.</p><figure><img alt=""Diagram illustrating Norman‚Äôs action cycle with two loops. From ‚ÄúUser Goal,‚Äù the top execution path flows through Identify Intention ‚Üí Identify Actions ‚Üí Execute in Interface ‚Üí Interface. The bottom evaluation path flows from Interface Output ‚Üí Interpretation ‚Üí Evaluation back to User Goal, labeled as the Gulf of Execution (top) and Gulf of Evaluation (bottom)."" src=""https://cdn-images-1.medium.com/max/1024/1*jK0bzL1YdrRarBHK55o7nA.png"" /></figure><p>For natural language driven interaction, instead of manually identifying and executing interface actions, users express intent directly through language. The system handles the translation from intention to action to execution. Instead of piecing together what happened from interface changes, users receive feedback in natural language, visual outputs, or a combination of both, making interpretation and evaluation more¬†direct.</p><p>However, the effectiveness of this approach depends on how the interface distributes these interactions across different spaces.</p><p>Across existing tools that I‚Äôve come across, I notice several patterns in how natural language bridges these gulfs. I‚Äôve summarized three of them based on where execution happens and where evaluation takes¬†place.</p><h4><strong>Pattern 1: Natural language interface as primary workspace</strong></h4><p>This pattern makes the <em>conversation itself the main workspace</em>, where the user expresses intent entirely in natural language and the system generates outputs in the same thread. It treats the chat as the central place for input, execution, and results along with persistent message¬†history.</p><figure><img alt=""Four-panel comparison of AI assistant interfaces displayed in a grid, each showing long-form, structured responses in dark mode, including bullet points, headings, tables, and search-based results. Order of tools (top left to bottom right): ChatGPT, Gemini, Microsoft Copilot, Perplexity"" src=""https://cdn-images-1.medium.com/max/1024/1*8tCUXqcI03M3zRrcAYIrpQ.png"" /><figcaption>Side-by-side view of AI assistants: <a href=""https://chatgpt.com/"">ChatGPT</a>, <a href=""https://gemini.google.com/app"">Gemini</a>, <a href=""https://copilot.microsoft.com/"">Microsoft Copilot</a>, and <a href=""https://www.perplexity.ai/"">Perplexity</a></figcaption></figure><p>Both gulfs are bridged entirely within the same conversational space. You express what you want in the chat, the system executes, and you evaluate the results all in the same thread. The entire interaction loop lives in the conversation. Your journey can end there, or you move forward into a different tool to continue the¬†work.</p><p><strong><em>Things to be aware of</em>: </strong>Users can express broad intent easily, but they have <em>limited fine-grained control</em> over how outputs are produced, and refining results still relies on more natural language rather than precise edits. Also Piras documents <a href=""https://www.smashingmagazine.com/2024/02/designing-ai-beyond-conversational-interfaces/"">how conversational interfaces, while seemingly intuitive, introduce usability challenges</a> designers solved decades ago in GUI design. The ‚Äúblank page problem‚Äù remains acute: users often don‚Äôt know what to type to get ideal output, and the burden of articulating intent shifts entirely to the¬†user.</p><h4><strong>Pattern 2: Natural language interface as contextual action¬†block</strong></h4><p>Contextual input area, not a full chat interface. A natural language input component appears near your selection or as a menu¬†option</p><figure><img alt=""Four-panel grid showing AI-assisted creation across different tools: Figma with an ‚ÄúDescribe your edit‚Äù prompt, Notion with inline AI writing suggestions, Photoshop with a generative image fill prompt over a blurred image, and Wispr Flow displaying voice dictation converting speech into text."" src=""https://cdn-images-1.medium.com/max/1024/1*64GJWusQ_N1eIgdBjb3aXw.png"" /><figcaption>AI-assisted workflows across <a href=""https://www.linkedin.com/feed/update/urn:li:activity:7373707174193156096/"">Figma</a>, <a href=""https://www.notion.com/help/guides/notion-ai-for-docs"">Notion</a>, <a href=""https://www.adobe.com/products/photoshop/generative-fill.html"">Photoshop</a>, and <a href=""https://wisprflow.ai/"">Wispr¬†Flow</a></figcaption></figure><p>Gulf of execution happens through language interface, but gulf of evaluation happens visually on the canvas. There‚Äôs typically no conversation history in this space (can be stored and displayed in different interface seciton), each prompt is a fresh, contextual interaction. The canvas remains the primary work surface; natural language is just another input method within your existing workflow. This pattern often references context implicitly, bundling related information into single commands which Tang terms ‚Äú<a href=""https://uxdesign.cc/emerging-interaction-patterns-in-generative-ai-experiences-8c351bb3392a"">context bundling</a>‚Äù to reduce typing burden while preserving</p><p><strong><em>Things to be aware of</em>: </strong>Pattern 2 treats each language prompt as a discrete action command tied to the workspace¬†. For example, ‚Äúsummarize this selection‚Äù or ‚Äúgenerate chart from this table‚Äù. This mean the pattern often reference context implicitly. it often struggles to integrate rich external context (like files, multiple references, or tool chains) and doesn‚Äôt naturally support deep follow-up refinement through language¬†alone.</p><h4>Pattern 3: Natural language interface as control¬†panel</h4><p>Having a persistent conversational panel alongside a workspace helps with iterative refinement and visibility of results. This dedicated chat composer provides a full, persistent conversational interface with message history. The system interprets the request, plans a sequence of actions from the converstation panel and executes them in a separate workspace</p><figure><img alt=""Four-panel screenshot showing an AI-assisted development workflow: Cursor AI editing a React/TypeScript codebase with inline suggestions, and OpenAI ChatGPT Atlas in agent mode executing tasks"" src=""https://cdn-images-1.medium.com/max/1024/1*aA7XTemjn2iJ5Hzlw80cHg.png"" /><figcaption>Agent-driven workflows using <a href=""https://cursor.com/agents"">Cursor AI </a>and OpenAI <a href=""https://chatgpt.com/atlas/"">ChatGPT¬†Atlas</a></figcaption></figure><p>Gulf of execution and gulf of evaluation are bridged across separate spaces. You execute through conversation in one space, but you evaluate by watching both the external workspace and reading feedback in the chat. This creates a supervisory relationship where the natural language interface is your control mechanism while work happens elsewhere. Users must monitor both spaces to fully understand what happened. Design principle from <a href=""https://uxdesign.cc/ai-ux-design-for-intelligent-interfaces-bc966e96107d"">article written by Basu</a> emphasize how to provide clear indicators of what the agent is doing in the background, so users feel in control even when the system is proactive. Interpretation requires synthesizing information from the workspace (seeing what changed) and the chat (reading what the system did and why). The control panel enables iteration that you can refine, redirect, or build on previous turns while the agent continues working.</p><p>Agent Advancements like Anthropic‚Äôs <a href=""https://www.anthropic.com/news/3-5-models-and-computer-use"">Computer Use</a>, OpenAI‚Äôs <a href=""https://openai.com/index/introducing-operator/"">Operator</a>, Google‚Äôs <a href=""https://blog.google/technology/google-deepmind/gemini-computer-use-model/"">Computer Space</a>, operates an entire computer or browser interface while you supervise from the chat panel. You provide high-level instructions (‚Äúbook a restaurant reservation for Friday‚Äù), and the agent navigates websites, fills forms, and completes multi-step tasks. As these agents become more autonomous, the tension between letting them work and maintaining meaningful control becomes more acute, echoing the classic debate between direct manipulation and interface agents that <a href=""https://pienso.com/blog/direct-manipulation-vs-interface-agents-revisiting-the-classic-debate-decades-later"">Pienso</a> revisited in their 2024 analysis.</p><figure><img alt=""Diagram comparing three natural language interface patterns. Pattern 1 shows a single full-screen conversation area. Pattern 2 displays a canvas with a contextual input field and separate workspace. Pattern 3 illustrates a split view with a chat panel on the right and workspace on the left"" src=""https://cdn-images-1.medium.com/max/1024/1*5W0gVWTy1weWjKlAYZvXBg.png"" /></figure><p>Interaction loop can be summarized as¬†follows:</p><a href=""https://medium.com/media/dc5ca7d1bc382799e7d95e1b194822c9/href"">https://medium.com/media/dc5ca7d1bc382799e7d95e1b194822c9/href</a><p>While the three patterns above represent the primary ways natural language functions as an active interaction medium, two other common approaches exist but fall outside this framework. <em>Dedicated intent capture pages</em> like homepage or AI tool template galleries serve as short-lived entry points that help users articulate what they want before routing them to one of the three core patterns for actual work. <em>Promoted prompts as interface actions</em> like ‚ÄúImprove Writing‚Äù or ‚ÄúSummarize‚Äù buttons embed common natural language instructions into traditional UI elements, removing the need for users to type. These approaches differ fundamentally because they either don‚Äôt sustain the interaction (intent capture is just an entry point) or don‚Äôt require active natural language input (the instruction is predefined in the¬†button).</p><h3>Reflections: How tools are built today and what‚Äôs¬†ahead</h3><p>Looking at tools launched in 2024‚Äì2025, most follow a familiar structure: <a href=""https://www.thirteen23.com/updates/the-prompt-box-paradox"">start with an intent capture page</a> (templates, starter prompts), then route users to either Pattern 1 for conversational tasks or Pattern 3 for agent-driven work. Pattern 2 appears as embedded features within existing¬†tools.</p><p>As tools mature, frequently-used prompts get ‚Äúpromoted‚Äù into buttons such as ‚ÄúImprove Writing,‚Äù ‚ÄúSummarize,‚Äù ‚ÄúTranslate.‚Äù Natural language coexists with traditional UI, reducing friction for common tasks while preserving flexibility for open-ended prompting.</p><p>This structure isn‚Äôt entirely new, it mirrors how traditional software has been built for decades. Classic tools also started with an onboarding or template selection page, then moved users into the main workflow interface. The difference now is that within that workflow page, natural language acts as a new control layer, either as a control panel (Pattern 3) orchestrating work, or as an action bar (Pattern 2) augmenting existing canvas-based workflows.</p><h4>What patterns might¬†emerge?</h4><p>As we move through 2026, one interesting question that strikes my mind is that, how will human intervention and interaction loop in these AI tools¬†evolve?</p><figure><img alt=""Animated GIF showing a human finger and a robotic finger reaching toward each other against a cosmic sky background, symbolizing connection between humans and machines."" src=""https://cdn-images-1.medium.com/max/500/0*in9E65KC0ifJVc5V.gif"" /></figure><p>Many tools have started addressing intervention, but few experiences have become overwhelming with multiple pause points, confirmation dialogs, and approval gates. The challenge is making intervention intuitive and natural, not just possible. Also, the users need to develop an strong mental model for when to step in versus when to trust the¬†agent.</p><p>Also supervision isn‚Äôt enough. The real challenge is understanding <em>how and why the agent made changes</em>, a concern central to <a href=""https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/"">Microsoft Research‚Äôs guidelines for human-AI interaction</a>.</p><blockquote>As agents become more capable, we risk creating dependency where users accomplish tasks but don‚Äôt understand the underlying work.</blockquote><p>This is critical for people learning new¬†skills</p><p>When an agent generates code or modifies a design, users need to comprehend the reasoning: not just ‚Äúlines 45‚Äì67 changed,‚Äù but ‚Äúhere‚Äôs why this approach, here‚Äôs the trade-off, here‚Äôs what else was considered.‚Äù Yet there‚Äôs a critical gap: agents can provide these explanations, but users still need foundational knowledge to fully grasp them. An explanation of why a particular code structure was chosen doesn‚Äôt help if you don‚Äôt understand fundamentals.</p><p>Without this understanding, users can‚Äôt effectively intervene, correct, or extend the work. They become dependent on the agent to modify its own output.Aubergine (2025) calls this the ‚Äú<a href=""https://www.aubergine.co/insights/designing-for-ai-agents"">learning arc</a>‚Äù¬†problem.</p><p>By designing systems that show learning progression, users experience agents as reliable collaborators that grow alongside them, not opaque black¬†boxes.</p><p>The next generation of interaction model needs to balance efficiency with transparency. The design goal shifts from ‚Äúmake AI do the work‚Äù to ‚Äúhelp users understand what‚Äôs being done and how they could do it themselves,‚Äù addressing what researchers at CHI 2020 identified as the <a href=""https://dl.acm.org/doi/10.1145/3313831.3376301"">unique difficulties in designing human-AI interaction</a>.</p><p>As product builders, our task is to observe how these interaction patterns perform, understand where they succeed and struggle, and continue pushing toward interfaces that make powerful tools that leverages accessibility, learnability and human¬†control.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8b39ed123c39"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/beyond-conversations-natural-language-as-interaction-influencer-8b39ed123c39"">Beyond conversations: natural language as interaction influencer</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4,1767647684,"Why you can‚Äôt fix your iPhone, and how the entire tech industry learned to profit from it","Why you can‚Äôt fix your iPhone, and how the entire tech industry learned to profit from it

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/822/1*swa7xccTQoC6ZAVy-MjNaA.png"" width=""822"" /></a></p><p class=""medium-feed-snippet"">What General Motors figured out in 1924, Apple perfected it with your smartphone</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/why-you-cant-fix-your-iphone-and-how-the-entire-tech-industry-learned-to-profit-from-it-f11b34b643d3?source=rss----138adf9c44c---4"">Continue reading on UX Collective ¬ª</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4,1767615432,What good writing looks like,"What good writing looks like

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*XecumDv5a3um7nPZZzHs0w.jpeg"" width=""5668"" /></a></p><p class=""medium-feed-snippet"">The essential (micro) copy rules I used at Google.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/what-good-writing-looks-like-ca02f45045ed?source=rss----138adf9c44c---4"">Continue reading on UX Collective ¬ª</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4,1767615366,The Apple-Sony special relationship,"The Apple-Sony special relationship

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/600/0*lioyERWiSiHamScl.jpg"" width=""600"" /></a></p><p class=""medium-feed-snippet"">Getting to the bottom of why Apple products pair so naturally with Sony</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-apple-sony-special-relationship-3fa78c3b308f?source=rss----138adf9c44c---4"">Continue reading on UX Collective ¬ª</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/how-the-tools-we-use-change-the-products-we-design-9117e021dac8?source=rss----138adf9c44c---4,1767615309,How the tools we use change the products we design,"How the tools we use change the products we design

<h4>‚ÄúThe medium is the message‚Äù‚Ää‚Äî‚ÄäMarshall¬†McLuhan</h4><figure><img alt=""‚ÄúHow the Tools We Use Change the Products we Design‚Äù‚Ää‚Äî‚Ääbanner image."" src=""https://cdn-images-1.medium.com/max/1024/1*-H8x4axWhYP0QCL9rRws4w.png"" /><figcaption>Background art by Pierre-Auguste Renoir,¬†1876.</figcaption></figure><p>Every era of product design on the web brings with it new design tools, these tools change how we design websites and also influences the next generation of design tools to¬†come.</p><p>I know it seems like a novel idea for some of you reading this, you might think you design the websites you want to design and you‚Äôre only limited by your imagination, but you‚Äôre only half-right.</p><p>That‚Äôs somewhat true but also you‚Äôre human and all humans are lazy sometimes and we like to design websites that are easily designed and easily developed, we don‚Äôt like friction, as any designer who studied UX already¬†knows.</p><p>So as Marshall McLuhan once said ‚ÄúThe medium is the message‚Äù, meaning that our ever-changing medium does box us into certain realities as we approach the tools for web¬†design.</p><p>In this article I‚Äôll try to go over the different tools for designing the web as they were used in chronological order, of course some of these tools got used simultaneously so there is no clean¬†cut.</p><p>But I‚Äôll do my best to paint the history of web design tools in stages as I lived through them, so let‚Äôs¬†begin.</p><p>First, we had plain¬†HTML.</p><h3>HTML</h3><p>Before any design tool ever existed, there was HTML, it was (and still is) the most fundamental building material of the¬†web.</p><p>When HTML was the only way to design websites we had WYSIWYG interfaces to better move around what was essentially just HTML tags like paragraphs, headings, tables and¬†images.</p><p>CSS didn‚Äôt exist yet so all the styling was done inside of the actual HTML itself (remember <em>bgcolor</em>?) and the only way to center anything was to use tables and make their borders invisible.</p><p>In some ways simple HTML styling lives on today in email newsletters and passion projects but the web itself has moved on to better¬†things.</p><p>Websites of this area were made to emphasis the tags and their aesthetics were unique with lots of GIFs, lots or background images that repeated themselves endlessly, and of course some background music to set the¬†mood.</p><p>The most well known offender in this category of early 90s websites was GeoCities, which did offer a WYSIWYG editor for everybody to use for¬†free.</p><figure><img alt=""GeoCities web editor was one of the first publicly available WYSIWYG editors."" src=""https://cdn-images-1.medium.com/max/640/0*YLJ_Xt0xreCr6UIh"" /><figcaption>GeoCities web editor was one of the first publicly available WYSIWYG¬†editors.</figcaption></figure><figure><img alt=""Netscape Composer live edits, image from Pier-Luc Brault‚Äôs Blog."" src=""https://cdn-images-1.medium.com/max/1024/0*83CyO7vFFtTOROrC.png"" /><figcaption>Netscape Composer live edits, image from Pier-Luc Brault‚Äôs Blog¬†(<a href=""https://plbrault.com/blog-posts/i-used-netscape-composer-in-2024/"">Link</a>)</figcaption></figure><p>Websites of that era were built for Netscape or later for Internet Explorer, nobody ever tried to make their websites cross compatible and they all just worked sometimes.</p><p>These compatibility issues often occurred while using specific tags (that aren‚Äôt in use anymore) like lots of <em>marquee</em> tags, <em>framesets</em>, <em>blink</em> tags and¬†more.</p><p>Those were visually unique but ultimately were deprecated for accessibility and/ or security reasons, so we could only find them in early web design¬†relics.</p><p>Speaking of security concerns, then came¬†Flash</p><h3>Flash</h3><p>When Macromedia Flash (later‚Ää‚Äî‚ÄäAdobe Flash) became the standard tool everyone was both a designer and a developer, Flash had its own scripting language called <a href=""https://en.wikipedia.org/wiki/ActionScript""><em>ActionScript</em></a> and it‚Äôs own animation-driven interface.</p><p>As a result people started replacing their entire websites with Flash sites, these sites were very animated and very tailored to their needs, no more templates and no more copying HTML tags from one another (Flash sites were nutritiously closed off‚Ää‚Äî‚Ääunlike HTML ‚Äú<em>view source</em>‚Äù¬†feature)</p><p>Flash transformed the web more than any other tool, it made the entire web dependent on its proprietary technology, it made us all developers and animators, and sometimes even game designers.</p><p>As a result those sites were often bloated, since optimization was optional, and they were very unfriendly to SEO, since it was all closed¬†off.</p><figure><img alt=""Newgrounds landing page from the early 2000s."" src=""https://cdn-images-1.medium.com/max/640/0*6Uw-fXM3AN3_hkeX.jpg"" /><figcaption>Newgrounds‚Ää‚Äî‚ÄäIf you know, you¬†know.</figcaption></figure><p>But the Flash era was the most creative the web had even been, Flash websites could do pretty much anything we could imagine, Flash games were also a big thing in the mid-2000s, see Newgrounds website¬†above.</p><p>Flash is still alive in the form of Adobe Animate, but today it‚Äôs less geared towards websites, since the web had moved on‚Ää‚Äî‚Ääpartly since the web moved to a mobile first¬†web.</p><p>Flash websites were bloated and had security issues but above all else: they weren‚Äôt responsive enough to survive in the mobile internet era, when screen real estate and battery life were much more¬†scarce.</p><p>I encourage everyone to read ‚Äú<a href=""https://web.archive.org/web/20170615060422/https://www.apple.com/hotnews/thoughts-on-flash/"">Thoughts on Flash</a>‚Äù by Steve Jobs, it sums the problems with Flash on mobile devices¬†nicely.</p><h3>Photoshop / Illustrator</h3><p>Photoshop and Illustrator are both Adobe products, they weren‚Äôt new at this point but the industry defaulted to them when Flash was on its deathbed.</p><p>When Flash was no longer the dominant design tool for the web, nothing could really fill its place, so the industry moved on to the tools that were already proven to stick¬†around.</p><p>This era of web design felt especially static, as designers only designed Desktop and Mobile websites, with often nothing in between, keep in mind that iPads weren‚Äôt a thing yet and/ or just came¬†out.</p><figure><img alt=""An Illustrator-designed website, it was never great."" src=""https://cdn-images-1.medium.com/max/720/0*3aY-7j9JtQ37VdXa"" /><figcaption>An Illustrator-designed website, it was never¬†great.</figcaption></figure><p>Everything was done manually using hard labor, no automation, no tools to make the process any easier, certainly no specialized tools¬†yet.</p><p>Photoshop and Illustrator are general purpose software‚Ää‚Äî‚ÄäPhotoshop is for editing images and Illustrator is for editing vector shapes, none of them were made for web design specifically.</p><p>As a result they had many tools that were irrelevant to Product Design and many relevant tools were¬†missing.</p><p>These relevant/ irrelevant tools were the blueprint for the next generation of tools, that built upon the workflow of Photoshop/ Illustrator and decided what tools to include and what tools to¬†exclude.</p><p>Photoshop and Illustrator as web design tools were never great tools for the job, but they were great at being placeholders until some more specialized tools¬†arrived.</p><h3>Sketch</h3><p>Sketch, for many designers, was just that‚Ää‚Äî‚Ääa new tool built from the ground up for Product Design (or UI Design, as it was called then). Sketch didn‚Äôt have the bloat Photoshop and Illustrator had since it was purpose¬†built.</p><figure><img alt=""Sketch circa 2017, image from Newbird"" src=""https://cdn-images-1.medium.com/max/1024/0*LduuUHZW42-rfbQ5.jpeg"" /><figcaption>Sketch circa 2017, image from Newbird¬†(<a href=""https://newbird.com/digital-design-tool-review-sketch-app/"">Link</a>)</figcaption></figure><p>The application itself and the tools in it were lean and were exactly what users wanted. I didn‚Äôt get into Sketch although a lot of my friends and colleagues did. Sketch was (and still is) a Mac only application so I knew it can‚Äôt be the tool of the¬†future.</p><p>There were entire industries built on Windows PCs and the Mac-only Sketch were making a lot of problems in their pipelines, for example: the gaming industry, the data security industry, AR &amp; VR (at the time), the banking industry¬†etc.</p><p>Sketch did a lot of things right but eventually the one thing it did was making the entire design industry reconsider the tools they¬†use.</p><p>Sketch walked so Figma could¬†run.</p><h3>Figma</h3><p>Figma wasn‚Äôt just a cross-platform version of Sketch, Figma took the formula that Sketch made of lean and precise design tool specifically made for UI design and expanded upon¬†it.</p><figure><img alt=""Figma in 2019, image from OneSignal"" src=""https://cdn-images-1.medium.com/max/1024/0*bd9eOPG0mhlINjkR.jpg"" /><figcaption>Figma in 2019, image from OneSignal (<a href=""https://onesignal.com/blog/designing-with-figma/"">Link</a>)</figcaption></figure><p>It was a new kind of tool‚Ää‚Äî‚Ääit was an online first tool, Figma was available from your browser, without any installation (when it did that, it was all new and exciting, I know today it‚Äôs more¬†common).</p><p>Since it was all online, Figma files could also be shared and worked on together, Figma had the most advanced ‚Äúmultiplayer‚Äù tools I‚Äôve ever seen, which meant designers can work together on the same design file and in the same time, since it was all¬†online.</p><p>Think of Google Docs, you can also edit the same file in Google Docs, or the same code in a Git repository, for example, but Figma brought the same philosophy into a design tool and since then many tools tried to do the¬†same.</p><p>Since Figma tried to be lean (much like Sketch before it), many tools were dropped in the process, no more photo editing tools, limited filters, limited Motion Design tools, no 3D tools¬†etc.</p><p>On the other side many new tools were introduced, responsive design controls for every frame, a prototyping tool and auto-layout controls‚Ää‚Äî‚Ääjust to name a¬†few.</p><figure><img alt=""An example of responsive design in Figma."" src=""https://cdn-images-1.medium.com/max/610/0*LTf-cs6mmbWU2up_.png"" /><figcaption>An example of responsive design in¬†Figma.</figcaption></figure><p>Still, Figma was very ‚Äúflat‚Äù looking by design and more detailed work was harder to achieve, many still used Adobe Illustrator or Photoshop for detail design and many just gave up and embraced the flatness.</p><p>Since advanced Motion, Animations or working with 3D elements is virtually impossible in Figma and as a result, those elements are very rare to see in the web¬†today.</p><p>I would argue that to this day, features like Motion Design and 3D work are still missing since they weren‚Äôt present in the original catch-all tools Photoshop/ Illustrator and as a result they are still missing from Figma¬†today.</p><p>Just to be clear‚Ää‚Äî‚ÄäI am not against any of it, I like flat design and I think intelligent design can be done in any style and in any medium, regardless of the rendered output, when I say ‚Äú<em>flat</em>‚Äù I don‚Äôt mean it as a criticism‚Ää‚Äî‚Ääjust as a visual observation.</p><h3>Closing words</h3><p>From no tools for design, through WYSIWYG and Flash, Photoshop/ Illustrator, Sketch and of course Figma it was quite a¬†ride.</p><p>The tools change not only <strong>how</strong> we design interactive websites but <strong>what</strong> we design as well, including how they look, how they work and how the users experience them. No website is made in a¬†vacuum.</p><p>We can clearly see how the tools of each era influenced the design of the websites below, they are all promotional websites that were designed when the movie released.</p><figure><img alt=""Space Jam official movie website, 1996."" src=""https://cdn-images-1.medium.com/max/544/0*oGSAc-WnPMYG5AfQ.png"" /><figcaption>Space Jam official movie website,¬†1996.</figcaption></figure><figure><img alt=""What is The Matrix‚Ää‚Äî‚Ääofficial movie website, 1999."" src=""https://cdn-images-1.medium.com/max/830/1*vkyS5ePhZTj81kAdPnRkcw.png"" /><figcaption>What is The Matrix‚Ää‚Äî‚Ääofficial movie website,¬†1999.</figcaption></figure><figure><img alt=""John Wick official movie website, 2014."" src=""https://cdn-images-1.medium.com/max/1024/1*l9mstz6xGkAUQPbJUKETNA.png"" /><figcaption>John Wick official movie website,¬†2014.</figcaption></figure><p>The first example (Space Jam) used HTML and WYSIWYG tools and the result is a more fined version of GeoCities websites, with the repeated background image and the secluded elements.</p><p>The Matrix example was done in the era of Flash and it has many TVs showing small clips from the movie, notice how they don‚Äôt really design a UI but they design a ‚Äúworld‚Äù you can go¬†visit.</p><p>The Last example‚Ää‚Äî‚ÄäJohn Wick is modern design that was probably done with Figma, it is highly reusable, probably using the same template as any other movie and it is a UI with text, titles, menu and even a video in a rectangular shape, how long have we come¬†indeed.</p><p>It can be said that any creative industry is bound to change, the history of painting and art in general is full of these examples‚Ää‚Äî‚Äähow the invention of oil colors gave a way to the renaissance masters to shine, how watercolors freed the impressionists from their studio to go paint outside and so¬†on.</p><figure><img alt=""Finally out of the studio and into the bar. √âdouard Manet, 1882."" src=""https://cdn-images-1.medium.com/max/1024/1*rGPrXfoPO83Pq7RuSWsThg.jpeg"" /><figcaption>Finally out of the studio and into the bar. √âdouard Manet,¬†1882.</figcaption></figure><p>As Marshall McLuhan proclaimed more than 60 years ago: ‚ÄúThe medium is the message‚Äù and it is much more pronounced in any technological field since technological tools change all the¬†time.</p><p>No one can predict the future. However I‚Äôm pretty sure that the tools will keep evolving and Figma won‚Äôt be the end-all for Product¬†Design.</p><p>Thank you for Reading¬†üôè</p><h3>Resources</h3><p><a href=""https://www.webdesignmuseum.org/web-design-history"">Web Design History Timeline</a> / Web Design¬†Museum</p><p><a href=""https://edenvidal.medium.com/a-brief-history-of-web-design-tools-9a75aff2d861"">A Brief History of Web Design Tools and the Original Sin</a> / Eden¬†Vidal</p><p><a href=""https://www.digitalimpactmarketers.com/ahistoryofwebdesign"">A History of Web Design: From Notepad to AI (1998‚Äì2025)</a> / Digital¬†Impact</p><p><a href=""https://www.webdesign-inspiration.com/blog/web-design-history-evolution"">The History and Evolution of Web Design (Timeline)</a> / WebDesign Inspiration</p><h4>Links in this¬†article</h4><p><a href=""https://plbrault.com/blog-posts/i-used-netscape-composer-in-2024/"">I Used Netscape Composer in 2024</a> / Pier-Luc¬†Brault</p><p><a href=""https://newbird.com/digital-design-tool-review-sketch-app/"">Sketch App Review</a> /¬†Newbird</p><p><a href=""https://onesignal.com/blog/designing-with-figma/"">How to Design with Figma</a> / OneSignal</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9117e021dac8"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/how-the-tools-we-use-change-the-products-we-design-9117e021dac8"">How the tools we use change the products we design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/algorithmic-atelier-escaping-ai-sludge-vibe-code-for-pms-10-ux-shifts-for-2026-75d9d3d72a6c?source=rss----138adf9c44c---4,1767615241,"Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026","Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026

<h4>Weekly curated resources for designers‚Ää‚Äî‚Ääthinkers and¬†makers.</h4><figure><a href=""https://uxdesign.cc/the-algorithmic-atelier-4f3db0837136""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*8QiJgXx_a2zv-cQB.png"" /></a></figure><p>‚ÄúTo understand this moment, we must contextualise AI within the history of artistic tools and conceptual shifts, while simultaneously confronting the very real socio-economic and ethical challenges it poses to the creative ecosystem.‚Äù</p><p><a href=""https://uxdesign.cc/the-algorithmic-atelier-4f3db0837136""><strong>The algorithmic atelier</strong></a><strong> ‚Üí<br /></strong>By <a href=""https://medium.com/u/3ae8d4237762"">Joshua¬†Leigh</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/from-hcd-to-hcd-what-i-learned-from-don-norman-24a3cdf79c4c""><strong>What I learned from Don Norman</strong></a><strong> ‚Üí</strong><br />From HCD to HCD+.<br />By <a href=""https://medium.com/u/17dab133f2ba"">Darren¬†Yeo</a></li><li><a href=""https://uxdesign.cc/reliability-by-design-designing-trustworthy-ai-for-healthcare-products-13a078d53bb0""><strong>Reliability by design</strong></a><strong> ‚Üí</strong><br />Designing trustworthy AI for healthcare products.<br />By <a href=""https://medium.com/u/594e163637c3"">Aur√©lie¬†Radom</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about their¬†work.</em></p><figure><a href=""https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*T50ZuGOMCqpSCILg.png"" /></a></figure><p><a href=""https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/?ref=sidebar""><strong>Vibe coding a bookshelf with Claude Code</strong></a><strong>¬†‚Üí</strong></p><h3>Make me¬†think</h3><ul><li><a href=""https://miguelcarranza.es/cto-year-8?ref=sidebar""><strong>My role as a founder CTO: year eight</strong></a><strong> ‚Üí</strong><br />‚ÄúThere are courses promising millions if you learn to build apps, turning app development into what drop shipping was a few years ago. We were forced to quickly adapt and expand our definition of developer. We went from helping developers make more money, to helping apps make more money, and eventually to helping vibe coders make more¬†money.‚Äù</li><li><a href=""https://alearningaday.blog/2025/12/27/fall-in-love-with-your-new-reality/?ref=sidebar""><strong>Fall in love with your new reality</strong></a><strong> ‚Üí</strong><br />‚ÄúSometimes our role in life isn‚Äôt to judge something‚Ää‚Äî‚Ääit is to figure out how to fall in love with it, especially when it becomes part of our new reality. The other day, I was in a conversation where someone was describing their new commute. The question that came up was, ‚ÄòDo you like it?‚Äô And of course, the natural instinct is to evaluate it: I don‚Äôt like this part, I don‚Äôt like that part,¬†etc.‚Äù</li><li><a href=""https://www.smashingmagazine.com/2025/12/how-design-for-with-deaf-people/?ref=sidebar""><strong>How to design for (and with) Deaf people</strong></a><strong> ‚Üí</strong><br />‚ÄúDeafness spans a broad continuum, from minor to profound hearing loss. Around 90‚Äì95% of deaf people come from hearing families, and deafness often isn‚Äôt merely a condition that people are born with. It frequently occurs due to exposure to loud noises, and it also emerges with age, disease, and accidents.‚Äù</li></ul><h3>Little gems this¬†week</h3><figure><a href=""https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*PfJxlbwdVQVY535w.png"" /></a></figure><p><a href=""https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458""><strong>Escaping AI sludge</strong></a><strong> ‚Üí<br /></strong>By <a href=""https://medium.com/u/e140b6f5f08a"">James¬†Skinner</a></p><figure><a href=""https://uxdesign.cc/design-for-the-nose-6c5037f67ed8?sk=fb275baca0f69180f0628bab15843ee4""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*HJNisIxxpJabO3E2.png"" /></a></figure><p><a href=""https://uxdesign.cc/design-for-the-nose-6c5037f67ed8?sk=fb275baca0f69180f0628bab15843ee4""><strong>Design for the nose</strong></a><strong> ‚Üí<br /></strong>By <a href=""https://medium.com/u/b95d4ccb538e"">Rita Kind-Envy</a></p><figure><a href=""https://medium.com/design-bootcamp/the-history-of-radial-menus-in-video-games-e6968bb1bac6""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*N9z9JH0beTquht1p.png"" /></a></figure><p><a href=""https://medium.com/design-bootcamp/the-history-of-radial-menus-in-video-games-e6968bb1bac6""><strong>The history of radial menus in video games</strong></a> ‚Üí<br />By¬†<a href=""https://medium.com/u/34ec66185b3"">Barbesz</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/how-pms-can-vibe-code-to-build-stronger-requirements-11faeedb5274""><strong>Vibe code for PMs</strong></a><strong> ‚Üí</strong><br />Leveraging AI to build stronger product requirements.<br />By <a href=""https://medium.com/u/ba6349c9c628"">Chris¬†Butler</a></li><li><a href=""https://uxdesign.cc/a-nano-banana-with-color-theory-da9608277e4e?sk=6bcc8c9a5863877eadf28d4ec5a6e513""><strong>A NanoBanana with color theory</strong></a><strong> ‚Üí</strong><br />Using Gemini to build an Accessible Perceptual Uniform Triad.<br />By <a href=""https://medium.com/u/bac2b370b37f"">Theresa-Marie Rhyne</a></li><li><a href=""https://uxdesign.cc/10-ux-design-shifts-you-cant-ignore-in-2026-8f0da1c6741d""><strong>10 UX design shifts</strong></a><strong> ‚Üí</strong><br />Trends you can‚Äôt ignore in 2026.<br />By <a href=""https://medium.com/u/2bea45f96a95"">Arin¬†Bhowmick</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, here‚Äôs how you can support¬†us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-lab4"">this week‚Äôs sponsor</a> to support their work¬†too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor an¬†edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=75d9d3d72a6c"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/algorithmic-atelier-escaping-ai-sludge-vibe-code-for-pms-10-ux-shifts-for-2026-75d9d3d72a6c"">Algorithmic atelier, escaping AI sludge, vibe code for PMs, 10 UX shifts for 2026</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/truth-and-certainty-c7a838135e28?source=rss----138adf9c44c---4,1767449920,Truth and certainty,"Truth and certainty

<h4>Kierkegaard on how fa*th becomes a bad¬†word.</h4><figure><img alt=""Stylized watercolor and graphite portrait of S√∏ren Kierkegaard in a landscape composition, shown from the chest up with softly sketched lines, light-colored hair, blue eyes, and a high white collar against a muted, textured background."" src=""https://cdn-images-1.medium.com/max/1024/1*O3kTmU3w1zIwBZ43mPzgCA.png"" /><figcaption>Kierkegaard‚Ää‚Äî‚ÄäImage created using¬†AI</figcaption></figure><p>You can tell something isn‚Äôt true the moment its certainty becomes mandatory.</p><p><em>I‚Äôm </em><a href=""https://www.linkedin.com/in/natesowder/""><em>Nate Sowder</em></a><em>, and this is </em><strong><em>unquoted, installment 15</em></strong><em>. Kierkegaard.</em></p><figure><img alt=""Nineteenth-century street scene in Copenhagen, 1831, showing pedestrians in period clothing gathered beneath a large stone archway, with soldiers, civilians, and a dog in the foreground, and classical buildings lining a sunlit public square."" src=""https://cdn-images-1.medium.com/max/550/1*3QIx7pXA3PzPjB1Y0FFNhw.png"" /><figcaption>Martinus Rorbye painting of the city jail next to Copenhagen town hall and courthouse (1831)</figcaption></figure><h3><strong>Designed certainty</strong></h3><p>For <a href=""https://iep.utm.edu/kierkega/"">Kierkegaard</a>, Christianity wasn‚Äôt a choice so much as the background noise of Copenhagen. In the early 1800s, belief didn‚Äôt require conviction, it required attendance. You inherited your faith the same way you inherited your surname, and no one seemed particularly bothered by the gap between saying the right words and understanding what they¬†meant.</p><p>People were comfortable with answers being given to them before questions were even asked. Faith was spoken about constantly, often with confidence, but this confidence felt rehearsed. Kierkegaard couldn‚Äôt tell if people ever wrestled with or questioned their¬†beliefs.</p><p>Eventually, he realized there was nothing <em>to</em> question. The system had already done the hard part. The role of the individual was to nod in agreement. This created a kind of harmony, but a shallow one‚Ä¶ a collective certainty that never had to prove itself against anything¬†real.</p><p>As he grew older, Kierkegaard saw how quickly certainty had replaced belief. Whenever a group becomes too sure of itself, it stops producing individuals capable of doing the inward work that faith requires. People learn to <em>perform</em> conviction rather than <em>develop</em> it. Say something often enough and you can skip the part where you understand (or question) it.</p><p>He noticed another pattern: People spoke confidently about truths they had never encountered firsthand, truths they had never risked anything to understand. And inherited certainty revealed an uncomfortable vulnerability: Once you depend on a system to hand you your conclusions, you tend to move as the system moves‚Ä¶ and you move with confidence.</p><p>Kierkegaard wasn‚Äôt worried about disbelief. He wasn‚Äôt even worried about people changing their minds. His concern was <a href=""https://www.sorenkierkegaard.org/""><strong>unearned belief.</strong></a><strong> </strong>Conviction without scrutiny and identity without introspection. The key here, is that the desire for certainty often poses as a strength, but usually signals the opposite:</p><p><strong>A lack of¬†faith.</strong></p><p>A society can become so certain of its truths that it forgets how to look for them. Faith gets replaced by the appearance of faith. Inquiry becomes unnecessary (and frowned upon), and once that happens, no one notices the¬†cost:</p><p>How easily people trade the effort of trying to understand for the comfort of believing (and being told) they already¬†do.</p><h3><strong>The mechanics of unearned certainty</strong></h3><p>Certainty has a way of sounding like confidence, but Kierkegaard knew it‚Äôs usually the result of something else. People reach for certainty when the truth underneath gets a little shaky. It feels safer to defend an answer than to admit the question hasn‚Äôt been resolved.</p><p><em>And from here on, when we talk about ‚Äúfaith,‚Äù we‚Äôre using Kierkegaard‚Äôs meaning‚Ää‚Äî‚Äänot belief in a doctrine, but the inner stance required to live with unanswered questions. If that sounds narrowly religious, it‚Äôs a misread. Kierkegaard is describing a stance that shows up wherever people have to act without guarantees: in innovation, in design, in leadership, and many other forms of¬†work.</em></p><p>For him, faith was never meant to be a conclusion. This stance was an ongoing willingness to live with what can‚Äôt be guaranteed. But certainty makes a different promise. It offers closure. It lets a person stop examining what they believe and start repeating it instead, resulting in something that feels like strength (even when nothing has been strengthened).</p><p>Systems (institutions) depend on predictability, and certainty delivers. It keeps people aligned, keeps roles stable, and keeps operations smooth enough that no one has to confront the inner workings. Churches, governments, workplaces, even families in their more rigid forms, all learn to reward conviction that doesn‚Äôt ask questions. Call it clarity or discipline or commitment, but the effect is the same: the more certainty people perform, the less individual they¬†become.</p><p>This creates a loop that‚Äôs hard to break. People adopt certainty because it makes them feel secure. Institutions reinforce certainty because it makes people easier to manage. And the more those two forces reinforce each other, the more faith becomes something referenced rather than¬†lived.</p><p>Unearned certainty has consequences. As it takes over, faith has nothing left to do. The questions don‚Äôt disappear, but people learn to avoid them. Individuals learn to shrink to fit the expectations of the system‚Ä¶ and the system rewards the shrinking.</p><h3>The altitude where faith stops being¬†allowed</h3><p>Systems don‚Äôt eliminate faith outright. They don‚Äôt have to. They simply move it to a place it can‚Äôt interfere with anything important. Faith becomes symbolic (something you reference or admire) while certainty takes over all the places where actual decisions get¬†made.</p><p>Real faith requires inwardness. It asks for reflection, doubt, and examination. It forces a person to confront what they believe and why. That kind of faith creates individuals, but guess what? Individuals complicate systems.</p><p>But if you lift faith out of lived experience and into abstraction, it stops being disruptive. It becomes something recited rather than wrestled with. You stop practicing it and start admiring it. A system can allow that kind of faith because it never threatens the model. It doesn‚Äôt challenge authority or create variance. And it certainly doesn‚Äôt create individuals.</p><p>So institutions learn to reserve certainty for the ground level (where behavior happens) and faith for the clouds, where it can‚Äôt disrupt anything. Super subtle‚Ä¶ super effective. People are encouraged to feel faithful while acting certain. They speak as if belief guides them, but their choices follow the conclusions they were¬†given.</p><p>Over time, faith becomes an ornament. Something safe at a high altitude. And the higher it rises, the less room there is for the kind of faith Kierkegaard actually meant: the kind that forms a¬†self.</p><h3>The modern landscape of managed¬†truth</h3><p>In Kierkegaard‚Äôs time, people didn‚Äôt have access to the full picture. We do. We have more information, more perspectives, more lived experiences and more context than any moment that came before us. And somehow, the more we gained in perspective, the more firmly we settled into our conclusions.</p><p>Institutions don‚Äôt limit information‚Ä¶ they package it and hand us interpretations wrapped in language that tell us what a ‚Äúreasonable‚Äù or ‚Äúmoral‚Äù person should think. White papers, talking points, abacus briefs, policy summaries‚Ää‚Äî‚Ääall built to steer us toward conclusions that feel responsible without requiring us to understand the full situation.</p><p>It‚Äôs a familiar pattern. You don‚Äôt have to comprehend the complexity. You only need to sound aligned with it. Certainty becomes a performance of being well-informed, and systems reward the performance because it keeps everything moving in one direction.</p><p>This creates a strange contradiction. We now have unprecedented access to the full picture, but we rarely use it. We reach for summaries, frameworks, pre-digested opinions, and the moral scaffolding provided by the groups we belong to. We inherit not just the conclusions, but the emotional stance that comes with them. We feel confident long before we comprehend anything.</p><p>Getting information hasn‚Äôt been the barrier. The part no system can automate for us is the effort needed to understand the full¬†picture.</p><p>People stop wrestling with ideas because the system makes wrestling feel unnecessary. Certainty is faster. Certainty is cleaner. Certainty signals belonging.</p><p>The tragedy is this: certainty has never been easier to acquire, and understanding has never required more from¬†us.</p><h3>The psychological cost</h3><p>Dependence doesn‚Äôt really announce itself. It doesn‚Äôt feel like surrender or even like trust. For most, it feels like relief. It‚Äôs the relief of not having to hold the weight of your own conclusions. But once that relief settles in, the work of examining what you believe starts to fade because someone else has taken on that responsibility.</p><p>This is where certainty becomes a habit, and habits reshape identity.</p><p>When certainty becomes the default position, people stop defending ideas and start defending themselves. Think about the last couple disagreements you had. They feel personal (not because the topic was important, but) because certainty is doing the psychological heavy lifting. It keeps the self coherent. It keeps your view on the world¬†intact.</p><p>To Kierkegaard, certainty can‚Äôt survive examination. It depends on avoiding questions, not engaging them. Faith works in the opposite direction. Faith strengthens under examination. It depends on someone willing to confront whatever might be uncovered.</p><p>Where certainty is rewarded, so is avoidance (or disciplined with guilt if confronted). And avoidance eventually hollows out a person from within. If you can be predictable, that‚Äôs a sign of stability. Alignment starts to look like maturity. People learn to treat their beliefs the way they treat their job descriptions: something maintained through compliance rather than reflection.</p><p>But here‚Äôs what happens: once certainty becomes an identity, people stop seeking truth. They start seeking reinforcement.</p><p>At that point, who cares about¬†faith?</p><h3>The turn</h3><p>There‚Äôs an overlooked difference between certainty and faith, and it explains what I think Kierkegaard worried¬†about.</p><p>When your goal is certainty, you have to win the moment. It demands immediate validation because it can‚Äôt tolerate the possibility of being wrong‚Ä¶ not even briefly. Certainty must hold up under scrutiny right now, in real time, in front of witnesses.</p><p>Faith works on a different clock. It doesn‚Äôt panic when challenged or rush to close the gap. Faith can afford to lose the moment because it trusts that truth will be found over time. Faith plays the long-game, and in doing so, doesn‚Äôt look for quick wins because it knows it needs to understand the whole picture. Faith needs clarity. Where questions may be seen as threats to certainty, to faith, they‚Äôre healthy invitations.</p><p>This is why faith creates individuals and certainty creates loyalists.</p><p>Systems reward the people who need to win today. They‚Äôre predictable. They‚Äôre motivated. They‚Äôre aligned. People who run on faith (patient, reflective, grounded) are harder to manage. They aren‚Äôt in a hurry, and they aren‚Äôt afraid of being wrong. The bottom line is they don‚Äôt feel like their identity is at¬†stake.</p><p>Once you see the difference, you can see why certainty thrives wherever institutions want control, and why faith survives only where individuals are willing to take responsibility for themselves.</p><p>It‚Äôs the same reason creative departments are the first to go. Creativity introduces possibility, and possibility threatens certainty.</p><p>Innovation works the same way. To innovate is to admit you might be wrong‚Ää‚Äî‚Ääto revise, rethink, even replace what you‚Äôve built. Institutions built on certainty can‚Äôt tolerate that, so they cut the functions that would force¬†it.</p><h3>Faith as the work of becoming a¬†person</h3><p>Kierkegaard didn‚Äôt argue against certainty because he disliked confidence. He saw what it replaced. Certainty stands in the spot where an individual is supposed to¬†develop.</p><p>Faith, as he meant it, was never about doctrinal agreement. It was about becoming someone capable of truth. This means someone who could be questioned without collapsing. Someone who could change without losing themselves in the process. Someone who didn‚Äôt need the comfort of winning today in order to grow tomorrow.</p><p>Systems will always prefer certainty. It keeps everything predictable and everyone aligned. They‚Äôre comfortable with faith only when it stays high enough not to interfere. Real faith lives lower‚Ä¶ close to the ground, where it forms individuals instead of dependents. And most institutions don‚Äôt know what to do with individuals.</p><p>I think the biggest danger is how willingly I see smart people trade the slow, difficult work of faith for the quick relief of being¬†sure.</p><p>Once certainty replaces inwardness, the individual starts to disappear. Once the individual disappears, faith has no reason to exist. What remains is a society full of people repeating truths they never had the chance to discover for themselves.</p><p>Which is what Kierkegaard feared all along: a world where belief is abundant, and faith is¬†gone.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c7a838135e28"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/truth-and-certainty-c7a838135e28"">Truth and certainty</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458?source=rss----138adf9c44c---4,1767364101,Escaping AI sludge: why MVPs should be delightful,"Escaping AI sludge: why MVPs should be delightful

<h4>Function is the floor, not the ceiling. It‚Äôs time to raise the bar and prove that the most viable products are the ones that feel¬†human.</h4><figure><img alt=""Hand-drawn sheep, all identitical, face the same direction in a grid layout‚Ää‚Äî‚Ääbaaaaa one. The odd-one-out is highlighted in pink and facing the opposite direction."" src=""https://cdn-images-1.medium.com/max/1024/1*ZSRvWvjMzqAy0DvT-1J3bg.png"" /><figcaption>Escaping the AI¬†Sludge</figcaption></figure><p>AI is now omnipresent in our workflows, but it's come at a cost: a sea of sameness. Lately, products have begun to look and feel homogeneous &amp; indistinguishable, leading to diluted brands and increasingly sterile interactions. Big tech paves the way for others to follow; It‚Äôs time to stop settling for ‚Äúgood enough‚Äù and blindly following established conventions. Let‚Äôs continue to solve user problems and challenge the attitudes of an MVP (Minimum Viable Product) through the use of¬†craft.</p><p>As explored in a recent <a href=""https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html"">New York Times interactive</a>, an LLM‚Äôs output is tethered to its training data, revealing a fundamental limitation we must be aware of: AI is a master of regurgitation, not revelation. By drawing from a finite pool of existing designs, these models produce an exponential volume of garbled content‚Ää‚Äî‚Ääsimilar to a game of Chinese Whispers where the quality of the message degrades with every time it is retold. While these outputs meet functional requirements, they lack the distinct emotional character and style typically derived from an organic human-design process, required to stand out in a crowded marketplace.</p><p>In this article, I address a growing concern regarding the current state of MVP delivery in consumer products. We stand at a precarious intersection: the pressure to ship fast is colliding with a rising tide of generic AI outputs. We must dissect how designers can retain their creative edge in this environment and empower them to push back against stakeholders for the product's success. The challenge before us is not just to learn how to use new tools, but to continue to push past what‚Äôs been done before and continuously set new standards for the products we¬†ship.</p><p>And so, we need to continue to elevate our craft. We must move beyond the basic utility of the MVP and change our attitudes on experiential standards‚Ää‚Äî‚Ääcreating work that proves, unequivocally, that there is a human behind the design of every¬†screen.</p><p>As popularised by Maya Angelou, American poet and civil rights activist:</p><blockquote>‚ÄúAt the end of the day, people won‚Äôt remember what you said or did; they will remember how you made them¬†feel.‚Äù</blockquote><p><em>While Angelou may have popularised the sentiment later, </em><a href=""https://speeches.byu.edu/speakers/carl-w-buehner/""><em>Buehner</em></a><em> is the earliest recorded¬†source.</em></p><figure><img alt=""A hand-drawn illustration, by Ryan Gillet, of a two people carrying freshly prepared food from the oven. The pair seem to very pleased with the delights of their cooking."" src=""https://cdn-images-1.medium.com/max/1024/1*xgMch7zKNt_CbWfjJDQ3QQ.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>The common misconception of¬†MVPs</h3><p>The MVP, popularised by Eric Ries in <a href=""https://www.startuplessonslearned.com/2009/08/minimum-viable-product-guide.html""><em>Lean Startup (2011)</em></a>, is often viewed as a functional baseline; it is a stripped-back product intended to prove viability today, with the future promise of augmentation reserved for tomorrow (subject to demand, resources &amp; budget‚Ää‚Äî‚Ääto name a few!) While many MVPs successfully meet basic user needs, they often fail to deliver a unique or engaging experience. This ordinary quality makes them bland and easily imitated by competitors, making it difficult for a brand to stand out and become compelling.</p><p>To understand the <strong>gap between function and value</strong>, consider a parallel from the physical world: the newly constructed house. At its core, a new build fulfils a functional requirement, providing essential shelter and space. Yet, without personalisation and decoration, it remains a generic structure, a standard configuration of walls and windows that is often repeated worldwide; We‚Äôve seen it all before. It is a commodity, not a destination.</p><p>A house only becomes truly <em>desirable</em> when it transcends its utility. It requires the texture of life: the specific choice of paint, the curated furniture, and the family photos on the mantle. Without these personal touches, the structure creates no emotional resonance. It lacks the essential ingredients that transform a house into a¬†home.</p><p>In product design, as in architecture, the structure is merely the canvas. It‚Äôs not until you apply a layer of craft that the screen turns from a habitable space into a valuable¬†one.</p><p>And so, product teams must go beyond just a bare-bones MVP and strive for something desirable. This means crafting a superior user experience unlike other products that meet &amp; surpass a user‚Äôs needs &amp; expectations. This approach is crucial for gaining a competitive advantage and establishing a strong, lasting connection with your customers.</p><figure><img alt=""A joyful hand-drawn illustration, by Ryan Gillet, of a couple seasoning their food."" src=""https://cdn-images-1.medium.com/max/1024/1*YcfK92q9XNakNjSlCUT3ZA.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>We need to change our attitudes toward¬†MVPs</h3><p>The real issue, in my opinion, however, isn‚Äôt solved by a new acronym (something the tech industry already has plenty of!) [<a href=""https://excited.agency/blog/minimum-lovable-product#:~:text=Conclusion-,What's%20a%20minimum%20lovable%20product%3F,bestselling%20book%2C%20%22Lovability%22"">MLP‚Ää‚Äî‚ÄäMinimum Loveable Product</a>]. The issue is that we often fail to build truly <em>viable</em> MVPs from the start. Henrik St√•hl‚Äôs article, <a href=""https://medium.com/user-experience-design-1/minimum-viable-whatever-ae78c5ad1e3d""><em>Minimal Viable Whatever</em></a><em>,</em> earlier this year, made me question my work when throwing about the acronym¬†‚ÄúMVP‚Äù.</p><blockquote>How do we know that the minimum thing we‚Äôre doing is viable¬†enough?</blockquote><p>A consumer product, put simply, cannot be viable (from a business perspective) without a strong <strong>brand voice</strong> and a delightful <strong>customer experience</strong>. To further the house metaphor, a family is unlikely to have bought the house in the first place if all the inner services of the building were exposed &amp; its walls laid bare. Typically, a property developer would furnish the space to give it the best chance of a sale and further enhance their ROI. And so, maybe the issue lies with companies shipping half-baked MVPs in a need to generate¬†revenue.</p><p>Building an enjoyable and satisfying product shouldn‚Äôt be seen as an additional arduous task to be deferred until after the delivery of an MVP. It‚Äôs too late by then; users will have already formed an opinion about the product &amp; the wider brand. It‚Äôs hard to change someone‚Äôs first impressions. Similar to property developers, tech companies would likely achieve a greater return on investment if they were to delay launch until version one of their product was ‚Äúfinished.‚Äù</p><figure><img alt=""A hand-drawn illustration, by Ryan Gillet, of a chef revealling a present otherwise hidden by their chef‚Äôs hat."" src=""https://cdn-images-1.medium.com/max/1024/1*4n6y3DPJpyAzMD6zDMepbg.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>What do I mean by delightful experiences?</h3><p>If ‚Äúcraft‚Äù has established itself as the <a href=""https://trends.uxdesign.cc/"">defining design buzzword in 2024‚Äì2025</a> in light of AI assurgence, then ‚Äú<em>delight</em>‚Äù is its emotional predecessor‚Ää‚Äî‚Ääand perhaps its most crucial outcome. While the two concepts are deeply intertwined, distinguishing them helps us understand what actually elevates a product from ‚Äúgood‚Äù to ‚Äúbeloved.‚Äù</p><p>To understand delight, we have to look past the code and the pixels. When done well, delight is the bridge that takes a user interaction beyond the baseline requirements of functionality and usability. As UX researcher <a href=""https://www.tandfonline.com/doi/abs/10.1207/S15327590IJHC1304_07"">Marc Hassenzahl notes</a>, true delight isn‚Äôt found in the product‚Äôs surface features, but in its ability to satisfy ‚ÄòHedonic‚Äô needs‚Ää‚Äî‚Ääsuch as competence and stimulation‚Ää‚Äî‚Ääwhile seamlessly handling and optimising ‚ÄòPragmatic‚Äô tasks like time efficiencies.</p><h4>What <em>delights</em> us as¬†Humans?</h4><p>Why do some tools make us feel empowered while others leave us drained? As psychologists Edward Deci and Richard Ryan demonstrated through <a href=""https://selfdeterminationtheory.org/theory/"">Self-Determination Theory</a>, our most meaningful experiences are rooted in how well a tool supports our human needs. They identified three essential drivers that must be met for us to feel truly motivated and ‚Äòdelighted‚Äô by an experience:</p><ul><li><strong>Autonomy:</strong> The need to feel in control of one‚Äôs own actions and¬†choices.</li><li><strong>Competence:</strong> The need to feel effective, capable, and ‚Äúsmart‚Äù while performing a¬†task.</li><li><strong>Relatedness:</strong> The need to feel connected to others or valued within a community.</li></ul><p>In the words of Shipra Kayan in <a href=""https://uxdesign.cc/medium.com/r?url=https%3A%2F%2Fuxdesign.cc%2Fdelight-is-not-cute-flourishes-2a1ce118ced5""><em>Delight is not cute flourishes</em></a><em>:</em></p><blockquote>Moments of delight can only happen when products help people be smarter, feel fulfilled, and avoid mundane¬†tasks.</blockquote><p>We must stop equating delight with cute decorative florishes. Real delight is the quiet satisfaction of a tool that anticipates and fulfils a user‚Äôs¬†needs.</p><p>Here are some nice examples I‚Äôve come¬†across:</p><ol><li>Apple: Helping users when they‚Äôre not expecting it</li></ol><figure><img alt=""3 screenshots of Apple‚Äôs iphone Wifi sharing flow. The bottom sheet appears when a contact is wanting to join a new wifi router, catching the user by surprise."" src=""https://cdn-images-1.medium.com/max/1024/1*324-MA4fv6Bywm_omyz23A.png"" /></figure><p>2. Duolingo‚Ää‚Äî‚ÄäWelcome back¬†message</p><figure><img alt=""a series of 3 screens detailing Duolingo UI recalling when a user has been inactive for a prolonged period of time. The Duo owl welcomes users back."" src=""https://cdn-images-1.medium.com/max/1024/1*X_cPwZKMsaQO6f32xLJpqQ.png"" /></figure><p>3. Monzo‚Ää‚Äî‚ÄäGet paid¬†early</p><figure><img alt=""Monzo‚Äôs get paid early flow where users interact by dragging the cash illustration down into a wallet to complete the task."" src=""https://cdn-images-1.medium.com/max/1024/1*9kJQjy1kOMSyFBptabj-pw.png"" /></figure><h3>What delight is¬†not‚Ä¶</h3><p>To understand the value of delight, we must first dismantle the misconceptions that have diluted its meaning. There is a tendency in product design to treat delight as the ‚Äúcherry on top‚Äù‚Ää‚Äî‚Ääthe final step to be taken only if the budget and resourcing permit.</p><p><strong>It is not decoration.</strong> Delight is not an expensive afterthought or a superficial layer of polish applied to a finished product. Single UI alone cannot mask a poor experience. If the core functionality is broken, no amount of charming illustrations or witty copy can save it. In fact, applying ‚Äúdelight‚Äù to a screen in a frustrating user flow often feels more patronising than enjoyable.</p><p><strong>It is not a gimmick.</strong> True delight is not merely a fleeting ‚Äúwow‚Äù moment. Flashy animations or unexpected interactions that are disconnected from the user‚Äôs core needs are distractions, not delight. If an interaction dazzles the user but ultimately slows them down or confuses their progress, it has¬†failed.</p><p><strong>It is not a checkbox.</strong> Perhaps most importantly, delight is not a line item on a product roadmap to be marked ‚Äúdone‚Äù and forgotten. It cannot be treated as an optional extra, dependent on whether the team has leftover capacity.</p><p>Instead, real delight is the result of a <strong>holistic and intentional approach</strong>. It is woven into the product's architecture from day one, demonstrating that the designers respect the user‚Äôs time, intelligence, and emotional state.</p><h3>Delight only works when basic expectations are¬†met</h3><p><a href=""https://www.nngroup.com/articles/theory-user-delight/?source=post_page-----4c96e0bf00f4---------------------------------------"">Abraham Maslow‚Äôs hierarchy of needs</a> taught us that basic needs act as a gateway to higher motivations (love, self-esteem, and creativity). Our basic survival needs must be met before any higher motivations can influence behaviour. Put simply, you don‚Äôt worry about ‚Äúcreativity‚Äù when you‚Äôre worried about finding your next¬†meal.</p><p>Product development requires the same discipline. We must ruthlessly prioritise utility first. Until the software runs without bugs and the core problem is solved, emotional design is merely decoration. You cannot charm a user who is struggling to log¬†in‚Ä¶!</p><p>This brings us to the crux of the issue: In an era where AI tools are democratizing development and efficiency, utility is no longer a differentiator‚Ää‚Äî‚Ääit is a commodity. When any competitor can use an LLM to generate functional code or optimise a workflow, simply ‚Äúworking error-free‚Äù becomes the bare minimum requirement for entry. To build a product that is not only commercially viable but truly ‚Äústicky,‚Äù <strong>utility alone is not a competitive advantage‚Ää‚Äî‚Ääit‚Äôs just the baseline. </strong>To create a commercially viable product, teams must move beyond a product that works to a product that <em>feels right</em>. This is where design craft will continue to be a product differentiator.</p><figure><img alt=""A hand-drawn illustration, by Ryan Gillet, of a giant palm guiding the user through their journey."" src=""https://cdn-images-1.medium.com/max/1024/1*aBQ3rfdWcQd9YsWkmZsefw.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>Delight vs User Satisfaction</h3><p>Delight and user satisfaction are not the same thing. While both are positive outcomes in user experience, they represent different levels of emotional engagement.</p><p><strong>User satisfaction</strong> refers to a user‚Äôs contentment with a product or service. It‚Äôs the feeling of having their needs met by achieving something or having a want met. A user is satisfied when a product works as expected, is easy to use, and fulfils its intended purpose. This is the <strong>non-negotiable prerequisite</strong> for¬†quality.</p><p><strong>Delight</strong> goes a step further. It‚Äôs an emotional response that exceeds a user‚Äôs expectations. <a href=""https://www.oxfordlearnersdictionaries.com/definition/english/delight_1"">Delight is the feeling of great pleasure</a>, joy, or even awe that comes from an interaction with a product or service. It‚Äôs what transforms a good experience into a great one. For example, a user is satisfied when a mobile banking app processes a transaction quickly. They are delighted when the app congratulates them on their first successful deposit with a celebratory animation.</p><p><strong>Frequency</strong> plays a pivotal role in this distinction. ‚ÄúThink of delight as a crescendo‚Ää‚Äî‚Ääa powerful, high-impact climax to an experience. However, not every click and interaction in a user flow is going to generate excitement. And that‚Äôs ok, otherwise the experience would be overstimulating and just irritating. User<strong> </strong>satisfaction, on the other hand, operates differently: it may offer a lower perceived value in the moment, but it sustains the product experience through a steady, reliable¬†rhythm.</p><figure><img alt=""A pen-drawn illustrative arrow pointing down"" src=""https://cdn-images-1.medium.com/max/1024/1*h93bIqp-7TQQ-z2_LZE7AA.png"" /></figure><blockquote>That‚Äôs great and all but how can we put this theory into practice‚Ä¶?</blockquote><figure><img alt=""A simple flow diagram of a typical product delivery roadmap: First the product is designed &amp; developed, then typically the MVP is shipped &amp; then teams give the product personality &amp; soul via a Minimum Loveable Product."" src=""https://cdn-images-1.medium.com/max/1024/1*_r_kCziOcO1U6ButNyb7dA.png"" /><figcaption>Is a product truly ‚Äòviable‚Äô if it doesn‚Äôt connect emotionally? We need to rethink why personality is often cut from the¬†MVP.</figcaption></figure><h3>Delight is not at the end of a product¬†roadmap</h3><p>Delight should not be viewed as a nice-to-have garnish or a static end destination, as illustrated above‚Ää‚Äî‚ÄäIt‚Äôs a Foundation. To treat design as a purely functional ‚ÄòPoint A to Point B‚Äô exercise is like approaching a first date with zero personality or charisma. You may have technically shown up, but nobody builds a relationship devoid of emotion. Would you expect a second date? Absolutely not‚Ää‚Äî‚Ääand products are no different. <strong>When we strip away emotion, we strip away the incentive to return. </strong>Crucially, if that first encounter is defined by generic experiences that are indifferent, you aren‚Äôt getting a second chance. First impressions are notoriously difficult to rewrite, which is why deferring ‚Äòpersonality‚Äô until after the MVP is a strategic oversight. By then, the user has already judged the brand; if you didn‚Äôt delight them at the start, you‚Äôve likely lost them for¬†good.</p><p>Brands that create emotional experiences with their audiences are the most commercially viable (The proof is in the previous example: Apple, Monzo, and Duolingo have already set the gold standard for this approach). While often relegated to the ‚Äònice-to-have‚Äô category, designing for delight represents a significant, untapped lever for product performance. Far from being an aesthetic indulgence, designing for delight is a high-impact lever for product performance. It drives the metrics that matter most: long-term retention, stickiness, and Lifetime Value (LTV). Moreover, it turns users into a self-sustaining marketing engine, slashing customer acquisition costs (CAC) through natural, fan-led referrals. In this light, delight is a key component of ‚Äúviability.‚Äù <strong>When build resources are tight, emotional resonance shouldn‚Äôt be the first thing we descope‚Ää‚Äî‚Ääit should be the reason we build in the first¬†place.</strong></p><figure><img alt=""Whimsical, hand-drawn illustration, by Ryan Gillet, of a waiter or chef in a tall toque lifting a cloche from a serving tray with a flourish."" src=""https://cdn-images-1.medium.com/max/1024/1*iSw4Hxb6nGnOUJR4RpL71Q.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>Let‚Äôs build desirable MVPs</h3><p>Successful product teams enhance a Minimum Viable Product (MVP) by focusing on a continuous cycle of building, measuring, and learning. The process is not about launching a single, final product, but rather viewing the product as organic and ever-evolving based on an active user feedback loop. In my opinion, the term delight should be intrinsic to the product‚Äôs ‚Äúviability‚Äù as it should be a byproduct of a business and product¬†agenda.</p><h4>Strategies the best teams¬†adopt:</h4><ul><li>Establish a <strong>continuous discovery process</strong>, ensuring that every product/business evolution is anchored in real-world user insights rather than assumptions.</li><li>Let the <strong>data lead</strong>: the best teams prioritise development cycles by weighing features against hard metrics and validated user¬†needs.</li><li><strong>Design for the user, not the workflow: </strong>Create resonant experiences that move past utility and acknowledge the emotional intent behind a task, ensuring that completion feels like a win rather than a digital¬†chore.</li><li>Teams <strong>own &amp; champion emotional design</strong>, acknowledging its commercial benefit.</li><li>View <strong>every release as a hypothesis</strong>: replace guesswork with continual validation to ensure product refinements evolve in tandem with user behaviour.</li><li><strong>Delight cannot exist in a vacuum. </strong>Teams prioritise a functional baseline, ensuring products adhere to the highest accessibility standards before attempting to layer on emotional resonance.</li></ul><figure><img alt=""Whimsical, hand-drawn illustration, by Ryan Gillet, of a joyful character in a pillbox hat and jacket, waving enthusiastically with energetic motion lines."" src=""https://cdn-images-1.medium.com/max/1024/1*yivYkv7DYHnIiWHYXJHgGw.png"" /><figcaption>Illustration by Ryan¬†Gillet</figcaption></figure><h3>Key principles to¬†adopt</h3><h4>For design &amp; product¬†teams</h4><ol><li><strong>Change product attitudes</strong>: Delight should not be seen as an additive or a nice-to-have; it should be baked into our product design experience.</li><li>Even in an MVP, <strong>delight should be intrinsic</strong> to the product‚Äôs ‚Äúviability‚Äù.</li><li><strong>How we communicate:</strong> When presenting our work, we should not frame delight as an add-on or an extra. It is the solution that meets the brief. Without the added delight, the product does not perform as well as it could against its¬†goals.</li><li><strong>Hold ourselves to account:</strong> Designing for delight focuses on delivering an emotive experience &amp; unexpected rewards to users, rather than solely on the products themselves. We should aim to make the experience a pleasure, not a¬†chore.</li><li><strong>Don‚Äôt ship half-baked features;</strong> ship fully viable products.</li><li><strong>Experiment!</strong> Designers should foster a culture of experimentation and rapid refinement. Through data collection, we‚Äôll build evidence on the impact of delight through in-app¬†tests.</li><li><strong>Continual active feedback loop:</strong> Many MVPs are released without delight, and without action, we will still be descoping delight going forward. However, if we better analyse MVPs post-release, we‚Äôll have an active feedback loop that will inform us where to make enhancements and create a business case for delightful improvements.</li></ol><h4>For products</h4><p>While the pursuit of deep delight may feel utopian, it forces us to sharpen our craft and further brands' relationships with their customers. Consequently, products¬†must:</p><ul><li><strong>Anticipate and Adapt:</strong> Predict user needs and adjust the interface to the individual.</li><li><strong>Deliver Reliability:</strong> Work as expected (or better), every single¬†time.</li><li><strong>Maintain Consistency:</strong> Unify form, tone, and voice so the product feels like a single¬†entity.</li><li><strong>Promote authentic emotion over artificial celebration.</strong> We must stop using ‚Äúconfetti‚Äù for benign tasks. Users don‚Äôt need a digital party for simply logging in. For example, we must remember that a user doesn‚Äôt want a bank account; they want the financial control that an account offers. True delight doesn‚Äôt celebrate the tool; it connects directly to the user‚Äôs feelings about what they are achieving with¬†it.</li><li><strong>Don‚Äôt mistake a functional product for a successful one. </strong>The real competitive edge isn‚Äôt just solving a problem‚Ää‚Äî‚Ääthe most successful products are emotive, proving there‚Äôs a person behind the solution.</li></ul><h3>References</h3><p>For more illustrations, please check out the brilliant Ryan Gillet! <a href=""https://www.ryangillett.com/work"">https://www.ryangillett.com/work</a></p><p>Luke Murphy, Zero Heights, Building Delight into Your Design System <a href=""https://webinars.zeroheight.com/register/zeroheight-ds-live-luke-murphy-building-delight-into-your-design-system"">https://webinars.zeroheight.com/register/zeroheight-ds-live-luke-murphy-building-delight-into-your-design-system</a></p><p>Don Norman. 2005. Emotional Design: Why We Love (or Hate) Everyday Things (1st ed.). Basic Books, New York,¬†NY.</p><p><em>Have you noticed any recent shortcomings of MVPs lacking emotion? Please share any recent examples!</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=04d267292458"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/escaping-ai-sludge-why-mvps-should-be-delightful-04d267292458"">Escaping AI sludge: why MVPs should be delightful</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
