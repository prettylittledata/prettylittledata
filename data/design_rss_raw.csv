source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/from-prompt-to-partner-designing-custom-ai-assistant/,1758880800,From Prompt To Partner: Designing Your Custom AI Assistant,"From Prompt To Partner: Designing Your Custom AI Assistant

What if your best AI prompts didn’t disappear into your unorganized chat history, but came back tomorrow as a reliable assistant? In this article, you’ll learn how to turn one-off “aha” prompts into reusable assistants that are tailored to your audience, grounded in your knowledge, and consistent every time, saving you (and your team) from typing the same 448-word prompt ever again."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/intent-prototyping-pure-vibe-coding-enterprise-ux/,1758733200,Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1),"Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1)

Yegor Gilyov examines the problem of over-reliance on static high-fidelity mockups, which often leave the conceptual model and user flows dangerously underdeveloped. He then explores whether AI-powered prototyping is the answer, questioning whether the path forward is the popular “vibe coding” approach or a more structured, intent-driven approach."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ambient-animations-web-design-principles-implementation/,1758546000,Ambient Animations In Web Design: Principles And Implementation (Part 1),"Ambient Animations In Web Design: Principles And Implementation (Part 1)

Creating motion can be tricky. Too much and it’s distracting. Too little and a design feels flat. Ambient animations are the middle ground &mdash; subtle, slow-moving details that add atmosphere without stealing the show. In this article, web design pioneer Andy Clarke introduces the concept of ambient animations and explains how to implement them."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/psychology-trust-ai-guide-measuring-designing-user-confidence/,1758276000,The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence,"The Psychology Of Trust In AI: A Guide To Measuring And Designing For User Confidence

With digital products moving to incorporate generative and agentic AI at an increasingly frequent rate, trust has become the invisible user interface. When it works, interactions feel seamless. When it fails, the entire experience collapses. But trust isn’t mystical. It can be understood, measured, and designed for. Here are practical methods and strategies for designing more trustworthy and ethical AI systems."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/how-minimize-environmental-impact-website/,1758189600,How To Minimize The Environmental Impact Of Your Website,"How To Minimize The Environmental Impact Of Your Website

As responsible digital professionals, we are becoming increasingly aware of the environmental impact of our work and need to find effective and pragmatic ways to reduce it. James Chudley shares a new decarbonising approach that will help you to minimise the environmental impact of your website, benefiting people, profit, purpose, performance, and the planet."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/serpapi-complete-api-fetching-search-engine-data/,1758042000,SerpApi: A Complete API For Fetching Search Engine Data,"SerpApi: A Complete API For Fetching Search Engine Data

From competitive SEO research and monitoring prices to training AI and parsing local geographic data, real-time search results power smarter apps. Tools like SerpApi make it easy to pull, customize, and integrate this data directly into your app or website."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/functional-personas-ai-lean-practical-workflow/,1758009600,"Functional Personas With AI: A Lean, Practical Workflow","Functional Personas With AI: A Lean, Practical Workflow

For too long, personas have been created with considerable effort, only to offer limited value. Paul Boag shows how to breathe new life into this stale UX asset and demonstrates that it’s possible to create truly useful functional personas in a lightweight way."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/creating-elastic-bounce-effects-expressive-animator/,1757930400,Creating Elastic And Bounce Effects With Expressive Animator,"Creating Elastic And Bounce Effects With Expressive Animator

Elastic and bounce effects have long been among the most desirable but time-consuming techniques in motion design. Expressive Animator streamlines the process, making it possible to produce lively animations in seconds, bypassing the tedious work of manual keyframe editing."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/ux-strategies-real-time-dashboards/,1757689200,From Data To Decisions: UX Strategies For Real-Time Dashboards,"From Data To Decisions: UX Strategies For Real-Time Dashboards

Real-time dashboards are decision assistants, not passive displays. In environments like fleet management, healthcare, and operations, the cost of a delay or misstep is high. Karan Rawal explores strategic UX patterns that shorten time-to-decision, reduce cognitive overload, and make live systems trustworthy."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/integrating-css-cascade-layers-existing-project/,1757498400,Integrating CSS Cascade Layers To An Existing Project,"Integrating CSS Cascade Layers To An Existing Project

The idea behind this is to share a full, unfiltered look at integrating CSS Cascade Layers into an existing legacy codebase. In practice, it’s about refactoring existing CSS to use cascade layers without breaking anything."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/09/designing-tv-principles-patterns-practical-guidance/,1756980000,"Designing For TV: Principles, Patterns And Practical Guidance (Part 2)","Designing For TV: Principles, Patterns And Practical Guidance (Part 2)

After covering in detail the underlying interaction paradigms of TV experiences in [Part 1](https://www.smashingmagazine.com/2025/08/designing-tv-evergreen-pattern-shapes-tv-experiences/), it’s time to get practical. In the second part of the series, you’ll explore the building blocks of the “10-foot experience” and how to best utilise them in your designs."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/desktop-wallpaper-calendars-september-2025/,1756627200,A Breeze Of Inspiration In September (2025 Wallpapers Edition),"A Breeze Of Inspiration In September (2025 Wallpapers Edition)

Could there be a better way to welcome the new month than with a new collection of desktop wallpapers? We’ve got some eye-catching designs to make your September just a bit more colorful. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/prompting-design-act-brief-guide-iterate-ai/,1756461600,"Prompting Is A Design Act: How To Brief, Guide And Iterate With AI","Prompting Is A Design Act: How To Brief, Guide And Iterate With AI

Prompting is more than giving AI some instructions. You could think of it as a design act, part creative brief and part conversation design. This second article on AI augmenting design work introduces a designerly approach to prompting: one that blends creative briefing, interaction design, and structural clarity."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/designing-tv-evergreen-pattern-shapes-tv-experiences/,1756299600,Designing For TV: The Evergreen Pattern That Shapes TV Experiences (Part 1),"Designing For TV: The Evergreen Pattern That Shapes TV Experiences (Part 1)

TV interface design is a unique, fascinating, and often overlooked field. It’s been guided by decades of evolution and innovation, yet still firmly constrained by its legacy. Follow Milan into the history, quirks, and unshakable rules that dictate how we control these devices."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/optimizing-pwas-different-display-modes/,1756195200,Optimizing PWAs For Different Display Modes,"Optimizing PWAs For Different Display Modes

Progressive Web Apps (PWAs) are a great way to make apps built for the web feel native, but in moving away from a browser environment, we can introduce usability issues. This article covers how we can modify our app depending on what display mode is applied to mitigate these issues."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/week-in-life-ai-augmented-designer/,1755849600,A Week In The Life Of An AI-Augmented Designer,"A Week In The Life Of An AI-Augmented Designer

If you are new to using AI in design or curious about integrating AI into your UX process without losing your human touch, this article offers a grounded, day-by-day look at introducing AI into your design workflow."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/double-edged-sustainability-sword-ai-web-design/,1755684000,The Double-Edged Sustainability Sword Of AI In Web Design,"The Double-Edged Sustainability Sword Of AI In Web Design

AI has introduced huge efficiencies for web designers and is frequently being touted as the key to unlocking sustainable design and development. But do these gains outweigh the environmental cost of using energy-hungry AI tools?"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/beyond-hype-what-ai-can-do-product-design/,1755522000,Beyond The Hype: What AI Can Really Do For Product Design,"Beyond The Hype: What AI Can Really Do For Product Design

AI tools are improving fast, but it’s still not clear how they fit into a real product design workflow. Nikita Samutin walks through four core stages &mdash; from analytics and ideation to prototyping and visual design &mdash; to show where AI fits and where it doesn’t, illustrated with real-world examples."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/08/psychology-color-ux-design-digital-products/,1755270000,The Psychology Of Color In UX And Digital Products,"The Psychology Of Color In UX And Digital Products

Rodolpho Henrique guides you through the essential aspects of color in digital design and user experience, from the practical steps of creating effective and scalable color palettes to critical accessibility considerations."
rss,uxdesign.cc,https://uxdesign.cc/making-useful-filters-24a841dc4aab?source=rss----138adf9c44c---4,1758977047,Making useful filters,"Making useful filters

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/making-useful-filters-24a841dc4aab?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*Ng8PE8TZtDhLEC6ILTVPoQ.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">Filters can make or break your UX, and designing them is not as straightforward as you might think.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/making-useful-filters-24a841dc4aab?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/start-with-the-experience-0ab1513b81dc?source=rss----138adf9c44c---4,1758976961,Start with the experience,"Start with the experience

<h4>What Genie taught us about customer-centric innovation — and how those lessons still shape great products today</h4><figure><img alt=""Two early mobile phones, Nortel Orbitor and Nokia 7110, displayed on either side of a white Genie Internet mug, symbolising the pioneering era of mobile internet innovation in the late 1990s."" src=""https://cdn-images-1.medium.com/max/1024/1*JTf1Dgh1CU79G8F3Bm4-ow.png"" /><figcaption>The tools of a mobile revolution — early handsets and the original Genie Internet brand that helped shape the first era of mobile experiences.</figcaption></figure><p><em>Long before apps and app stores, this is how a small team out-paced global giants to design one of the world’s first mobile internet portals — and shape the future of connected experiences.</em></p><p>In the late 1990s, the global giants of tech and telco bet billions on mobile internet architecture. We anchored ourselves to a single principle: that the future of the internet would be <em>personal, mobile, and woven into every moment</em>. This is the story of how our small team, Genie, out-paced those giants with $100 million less — by starting with the experience, not the platform. And crucially, we weren’t just thinking differently — we were moving faster.</p><p>Even more remarkable, Genie’s first public alpha launched as early as 1997, more than three years before Vodafone and Vivendi unveiled Vizzavi in June 2000. When it came to WAP — the technology that made mobile web experiences possible — Genie’s services went live in January 2000, a full six months before Vodafone entered the market. By the point Vizzavi was preparing for launch, Genie already had 900,000 registered users. While much of the industry was still debating what “mobile internet” meant, BT Cellnet had already shipped a working prototype — so innovative that <em>The Guardian</em> noted that “BT Cellnet has been an innovator and launched the mobile [WAP] version of its Genie web portal in January.” That early advantage — measured in years, not months — shaped how we approached every decision that followed.</p><p>This core conviction led to the creation of Genie, one of the UK’s first mobile internet portals. It also set us directly against the largest corporate forces in Europe. While incumbent telco giants spent hundreds of millions trying to force massive, integrated platforms onto the market — such as the Vodafone/Vivendi Vizzavi joint venture — our small team had to achieve more with roughly 1/20th of the capital.</p><p>This case study compares those two radically different innovation strategies: the Architecture-first approach of the incumbent and our Experience-first approach. It is a story about how sequencing — starting with the customer experience and working backwards to the technology — transformed an idea into market impact, and why those same lessons still define the gap between product failure and breakthrough success today.</p><h3>When the internet learned to move</h3><p>Having worked on some of the world’s earliest smartphone prototypes at BT Cellnet — including Nortel’s pioneering Orbitor/Europa concept — I went on to co-found Genie, the UK’s first mobile internet portal and one of the first anywhere in the world. I served as head of music, games and entertainment, receiving a BT Recognition Award as a co-founder.</p><p>This is the story of what we built, how we did it, and what it taught us about designing products and services that people genuinely want. It’s also a reflection on the choices that made the difference—the strategic calls, cultural decisions and customer-centred design principles that transformed ideas into impact.</p><p>Most importantly, it’s a story about <em>how strategy really works</em> when technology, experience and organisational change collide, and why those same lessons still matter for startups and product teams today.</p><h3>The set-up: two very different bets on the “mobile internet”</h3><p>This case study compares two radically different approaches to innovation during the first mobile-internet wave — Genie<strong> </strong>(BT Cellnet/BT) and Vizzavi (Vodafone + Vivendi) — and distils what those choices mean for two audiences:</p><ol><li>Early-stage startups searching for product-market fit.</li><li>Large organisations trying to think and ship like startups.</li></ol><p>My aim is to show, with evidence, how decisions around strategy, business-model innovation and value-proposition design can either accelerate ideas into reality, or quietly stop them from ever getting there. This is because in my role today mentoring startups, I still see the same patterns we lived through repeating themselves today.</p><h3>Personal context (1996–1997)</h3><p>I joined BT Cellnet in 1996 as Business Development Manager for smartphones, coming from a user-centred design and customer-experience background inside BT. Even before the word “smartphone” existed, we were already proving how mobile devices could deliver real services, not just calls and texts.</p><figure><img alt=""A BT Cellnet Alcatel mobile phone from the mid-1990s featuring a dedicated “B” button for checking Barclaycard balances, an early example of integrated mobile services before smartphones."" src=""https://cdn-images-1.medium.com/max/718/1*6mXcu9NM7BbE6XUG_LVn2A.png"" /><figcaption>A BT Cellnet handset launched in partnership with Barclaycard in the mid-1990s, offering customers 20 % off calls and a dedicated “B” button to check credit card balances — a pioneering example of mobile services before the smartphone era.</figcaption></figure><p>One of the most significant projects I worked on was a collaboration with Alcatel and Barclaycard on a handset that offered customers 20 % off their call costs and included a dedicated “B” button to check credit card balances, all powered by over-the-air menu updates (SOAP). The strength of the idea lay in its simplicity, and usability was intentionally built in from the beginning. My role was to help shape the vision into something tangible: defining the user experience, scoping how the service would work, and building the partnerships needed to bring it to life. That experience deeply shaped my thinking when we went on to build Genie, showing how a clear value proposition and seamless experience could change customer behaviour at scale.</p><p>By 1997 we were already building client–server mobile services. BT Cellnet was among the most innovative operators in Europe at the time, and handset manufacturers selected us as their development-partner network, giving our small team hands-on experience with device–service integration long before it was mainstream.</p><p>Even at this early stage, we were exploring bold visions of what a connected, mobile future might look like. As Business Development Manager for smartphones, my role was to identify these emerging opportunities and translate them into real partnerships, prototypes and product concepts.</p><figure><img alt=""A 1995 Nortel concept illustration showing a person holding an early smartphone prototype with a headset device, representing one of the first visions of mobile internet interaction."" src=""https://cdn-images-1.medium.com/max/1024/1*geKCuQShABLh75VFRjlD_w.jpeg"" /><figcaption>A Nortel concept image from 1995 imagining the future of mobile communication — an early vision of the smartphone era that inspired the Orbitor/Europa prototype and informed Genie’s design approac</figcaption></figure><p>That background gave us an edge over Vodafone. We treated design as strategy, embedding user experience, service design and customer insight into product and partnership choices, rather than relying on traditional corporate levers like mergers, acquisitions or joint ventures. This was design thinking in its original sense: putting the customer and the end-to-end experience <em>inside</em> strategy, not simply layering it on top.</p><p>(For context, 1997 was also the year Steve Jobs famously contrasted Java’s “cross-platform” vision with Apple’s integrated approach — a debate that shaped how we thought about platforms and apps.)</p><h3>Experience-first vs. architecture-first</h3><p>Jobs also argued that you must “start with the customer experience and work backwards to the technology.” That principle became our north star. We began with the end-to-end experience and the value proposition we wanted to deliver, then built the enabling stack and partnerships around it.</p><p>By contrast, Vodafone and Vivendi started with <strong>a </strong>joint-venture architecture, trying to reconcile brands, organisations, technology and content <em>before</em> they had a clear, validated customer experience. That difference in sequencing shaped everything that followed.</p><p>The contrast in sequencing also reflected a profound difference in risk appetite. Genie’s approach embraced the calculated risk of rapid iteration and low-cost failure — shipping simple services quickly and learning from real user behavior within the constraints of the technology. By contrast, Vizzavi chose the traditional corporate risk: massive capital outlay and structural integration <em>before</em> validating a clear customer value proposition. This structural difference determined not only their speed but their ultimate financial viability.</p><p>Genie’s playbook emphasised shipping services that people could actually use on 2G/WAP; making them network-agnostic to maximise audience; pricing them to encourage exploration rather than meter usage; and iterating fast with content partners. The public record shows key Genie milestones: the UK’s first free-access mobile ISP, the first commercial pre-pay WAP service, and later the UK’s first unmetered 24/7 mobile internet service for £20/month.</p><p>Vizzavi’s playbook, meanwhile, focused on building one pan-European portal and brand, backed by heavy investment and exclusive content. The joint venture ultimately cost hundreds of millions, struggled operationally (including a botched email-platform upgrade), and was folded into Vodafone live! by late 2002, having spent £500 million building the brand.</p><p>The outcomes highlight the failure of the architecture-first approach. Vizzavi focused on consolidating assets and capital, but the platform was never truly designed around solving a fundamental customer job-to-be-done. In contrast, Genie’s success proved that agile execution and genuine customer value beat billions in misaligned capital — a lesson that remains universally true for any startup facing large incumbents.</p><h3>What a mobile internet portal was (and where WAP fits)</h3><p>In the late 1990s, a “portal” meant a curated front door to online services. AOL and CompuServe served as dial-up destinations on PCs — but there was no equivalent on mobile. Genie was created to fill that gap, set up as an Internet Service Provider, a web portal and a suite of mobile information services, initially delivered via SMS to build habitual use before WAP was ready. On handsets, we were starting from scratch: tiny screens, 2G bandwidth, high latency, limited memory and a brand-new software stack.</p><figure><img alt=""Vintage BT Cellnet Pay &amp; Go phone bundle with Genie software CD — an early example of how mobile internet services were distributed before app stores existed."" src=""https://cdn-images-1.medium.com/max/730/1*kNvmRpzy-fLK5jXJQOtdNg.png"" /><figcaption>In the pre-app era, Genie distributed its mobile internet software via CDs and bundled services directly with BT Cellnet handsets — transforming phones into a channel for innovation.</figcaption></figure><p>Distribution was equally experimental. Before app stores existed, we shipped our software on physical CDs and partnered with BT Cellnet to bundle services directly through pre-pay phones. Handsets weren’t just devices; they became a channel to market — a way to deliver the mobile internet experience directly into users’ hands.</p><p>Long before software updates were a tap away, distribution was part of the design challenge. By bundling our services with physical devices and using CDs as delivery mechanisms, we weren’t just marketing a product , we were shaping the entire user journey from the moment someone unboxed their phone. It taught us that when the platform doesn’t yet exist, you have to build the ecosystem around it yourself. Designing not just the product, but the pathway it travels is a mindset that still applies today in emerging technologies, from spatial computing to AI-driven services.</p><h4>WAP’s role</h4><p>As part of BT’s delegation, I was a member of the WAP Forum, where we helped define the early standards that made mobile web experiences possible on constrained devices. WAP provided a shared way to render simple pages and trigger actions (like messaging and look-ups) on phones — a pragmatic bridge between the open web and the real-world limitations of mobile hardware.</p><h4>Genie alpha: from web-to-SMS to information services</h4><p>Our first public experiment was a simple Genie alpha site that allowed anyone to register for free and send an SMS from a web page to a mobile device. It was the first such service in the UK, and arguably the first commercial, public web-to-SMS service globally, launched in beta in 1998, before the official Genie Internet launch in March 1999.</p><p>As BBC coverage at the time noted, Genie already had thousands of text-message users before the official launch. Initially, it operated as a BT Cellnet web portal and value-added service. We then layered on basic information services — football scores, weather updates, news headlines — because they aligned with people’s daily habits.</p><h4>Device partnerships shaped the portal</h4><p>The client–server work we had begun with Nortel, Nokia, Motorola and Ericsson fed directly into our service ideas. We weren’t simply publishing WAP pages; we were designing interactions that devices could realistically deliver and aligning with manufacturers’ roadmaps wherever possible.</p><h3>Speed to market mattered</h3><p>Genie launched in beta in 1998, with the official launch in March 1999 — well ahead of Vodafone and Vivendi’s Vizzavi, which wasn’t announced until May 2000. Shipping something simple rather than waiting for perfect gave us a head-start and helped us build an early-adopter base. As the audience grew, major content brands (MTV, EMI, Dotmusic, Ministry of Sound) and gaming partners approached us to develop their first mobile services.</p><a href=""https://medium.com/media/1c7568ab2485ac932e3afd9b70c41358/href"">https://medium.com/media/1c7568ab2485ac932e3afd9b70c41358/href</a><p>The UK’s first WAP advert, created by BT Cellnet together with Genie, showing how we first introduced the idea of mobile internet to the public in the late 1990s.</p><h3>What we Shipped (and why it mattered)</h3><h4>1. Network-agnostic content (before micropayments)</h4><p>We deliberately made services accessible on any UK network, not just BT Cellnet. That widened our reach and created a powerful acquisition loop: customers who discovered Genie elsewhere often returned to BT Cellnet for better pricing, devices or support. The press at the time explicitly noted that <em>Big Brother</em> mobile services were available across all networks.</p><figure><img alt=""Presentation of Genie’s early mobile internet service for Channel 4 in the late 1990s, with a demonstrator showing how mobile devices could access online content on screen."" src=""https://cdn-images-1.medium.com/max/1024/1*ayGXkayw0kkZ3BxX-myooQ.png"" /><figcaption>Demonstration for Channel 4 of Genie’s pioneering mobile internet service in the late 1990s, showing early content services for mobile phones during a product presentation.</figcaption></figure><p><strong>What we learned:</strong> Without mature billing rails inside the portal, attention and habit were the currency. Openness grew usage, and usage reduced churn for the host network.</p><h4>2. Pricing that Unlocked Behavior: The Customer R&amp;D Model</h4><p>In November 2000, Genie launched the UK’s first unmetered mobile internet plan at £20 per month — a bold move designed to drive mass adoption and exploration.</p><p>This pricing decision was, in effect, a subsidy for customer research and development. At the time, mobile internet was universally billed on a terrifying per-minute or per-kilobyte basis, which paralyzed users with “fear of the bill” and prevented experimentation. The metered approach actively killed the very behavior we needed to discover.</p><p><strong>What we learned</strong>: People cannot discover what a new medium is <em>for</em> under a metered plan. The flat-rate, “all-you-can-eat” model was a strategic call to remove that financial barrier, letting users experiment, fail, and develop sticky habitswithout punishment. For product builders today, the lesson is simple: your monetization model must encourage the desired user behavior, not restrict it.</p><h4>3. G Live Music — Reimagining How Fans and Artists Connect</h4><p>By the late 1990s, the music industry was waking up to the fact that the internet would radically change how artists reached their audiences, and that mobile could become the most important channel of all. Major labels were already experimenting: Danny van Emden returned to Virgin Records to establish the UK’s first New Media department, ensuring that every artist had an online presence and launching <em>The Raft</em>, one of the earliest label websites. EMI, Virgin’s parent company, quickly followed suit, with Fergal Gara and Eric Winbolt leading a dedicated new media team.</p><p>What they understood, and what many others missed, was that the next generation of fans might never experience the web primarily through a computer. Mobile, not desktop, was going to be the dominant way they discovered, consumed, and interacted with music. That made Genie a natural partner.</p><a href=""https://medium.com/media/a6c0323b4c475f694d22d7da6c8f06a8/href"">https://medium.com/media/a6c0323b4c475f694d22d7da6c8f06a8/href</a><p><em>At the top of the BT Tower, G Live Music launched with artists like Atomic Kitten on hand — marking a breakthrough moment when record labels, artists and Genie teamed up to connect directly with fans through their phones, long before the era of Twitter and streaming.</em></p><p>BT Retail had already been exploring voice-based services, while Genie was leading the market for SMS. The breakthrough idea was to combine the two into a hybrid experience, G Live Music<strong>, </strong>where EMI could send text alerts to fans that included not only headlines and updates, but also a phone number they could call to hear more.</p><p>To make the service engaging, I designed four distinct channels — <em>Stars</em>, <em>Guitars</em>, <em>Heartbeats</em> and <em>Breakbeats</em> — covering rock, indie, pop and dance music. Virgin hired BBC Radio 1’s Jo Wiley as the voice of the service, and record labels including Virgin, EMI, Chrysalis and Parlophone arranged for the artists themselves to record exclusive personal messages. This was more than a content feed . It was a direct line from band to fan, offering the kind of personalised access that would only become mainstream a decade later with platforms like Twitter.</p><p>G Live Music launched with major publicity at the top of the BT Tower, signalling a new direction for how artists and audiences could connect. It was an early example of how mobile services could go beyond delivering information — they could build <em>relationships</em>, turning devices into channels for authentic, human connection.</p><p><strong>What we learned:</strong> Personalisation and proximity are powerful drivers of engagement. When artists’ voices reached fans directly — literally in their pockets — the emotional connection was far stronger than any banner ad or website visit. The project showed that successful mobile experiences are not just about content delivery, but about creating <em>intimacy</em> and <em>community</em> at scale.</p><h4>4. Interactive Formats at Scale — From Big Brother to a Global Games Platform</h4><p>One of the most powerful proofs of Genie’s approach came through our work on interactive entertainment, not just as content, but as a new category of mobile experience.</p><p>The <em>Big Brother: Lifestylers</em> project is often remembered as one of the first large-scale interactive mobile games in Europe, giving users the chance to shape virtual characters and influence outcomes on their phones. But the real story wasn’t the gameplay itself. It was the platform behind it.</p><p>When BT decided not to build a dedicated gaming platform in-house, the consultant I had been working with, Kevin Bradshaw, founded a startup to take the idea forward. That company — Digital Bridges — would go on to become one of the world’s top three mobile multiplayer gaming platforms, powering many of the early titles that defined the mobile games industry in the early 2000s.</p><p>By integrating the Digital Bridges platform into Genie, we were able to scale quickly and support a new wave of interactive formats. <em>Big Brother: Lifestylers</em> alone generated around 2.5 million play-minutes from roughly 60,000 players in just five weeks — a clear sign that people were willing to invest time and attention in mobile experiences when they were designed for the medium. And crucially, the service was available on all UK networks, reflecting Genie’s belief that reach and behaviour-building were more valuable than short-term exclusivity.</p><figure><img alt=""Screenshot of Genie’s Big Brother: Lifestylers WAP game, an early mobile entertainment service built on the Digital Bridges platform."" src=""https://cdn-images-1.medium.com/max/1024/1*8vZeuZSCUL31swang_pJig.png"" /></figure><p><em>The Big Brother: Lifestylers WAP game, launched by Genie in partnership with Picofun and Channel 4, showcased the potential of interactive entertainment on mobile and helped accelerate the rise of Digital Bridges, which became one of the world’s leading multiplayer gaming platforms.</em></p><p>This phase of Genie’s evolution wasn’t just about a single hit. It was about building the infrastructure and partnerships that made new kinds of engagement possible. The success of Digital Bridges proved that mobile could support complex, multi-player, interactive formats long before app stores existed, and that those experiences could play a central role in shaping customer habits and expectations.</p><h4>5. Device-level ambition (and why we pulled back): Nortel “Orbitor”</h4><p>We explored integrating Genie-style services into Nortel’s Orbitor — a touchscreen, voice-recognition smartphone concept (1998).</p><figure><img alt=""Close-up of an early Nortel Orbitor smartphone prototype showing a stylus-based interface and contact list, illustrating one of the first Java-powered attempts to combine voice, messaging, touchscreen and internet services on a single mobile device."" src=""https://cdn-images-1.medium.com/max/1024/1*oxT6hwXA94-W7B7Efkh6Sw.jpeg"" /><figcaption>An early prototype of the Nortel “Orbitor” smartphone concept from the late 1990s — a bold attempt to integrate voice, touchscreen and internet services using Java, years before such functionality became standard.</figcaption></figure><p>The idea was right, but the technology was too early. Public museum records document both the ambition and the limitations of the device.</p><p>Working on Orbitor reinforced a lesson that would guide us throughout Genie’s development: visionary ideas are only as powerful as the technology that enables them. The device itself was remarkable — it combined voice, messaging, touchscreen navigation and over-the-air services, all running on Java long before that was standard in mobile environments. Even though the hardware and networks weren’t yet ready to support such ambitions at scale, the experience we were aiming for became a north star — shaping how we approached service design, interfaces and the broader future of mobile interaction.</p><p><strong>What we learned:</strong> Vision needs timing. A decade later, iPhone-class hardware and OSs finally caught up with the idea.</p><h4>6. GenieMobile — Extending the Portal Beyond the Phone</h4><p>Genie Internet was also one of the earliest examples of what we would now call a virtual mobile operator. It operated entirely digitally, with no physical retail presence, building its brand, acquiring customers and delivering services exclusively online. That approach, radical for its time, allowed us to move quickly, experiment with new propositions and scale without the overhead of traditional mobile infrastructure.</p><p>While Genie was conceived as a mobile-first service, we knew from the start that the experience couldn’t end at the handset. Most users were still accessing the web from desktop computers, and they needed a simple way to manage their accounts, discover services and prepare content before going mobile. That insight led to GenieMobile, a companion desktop application designed to extend the value of the portal far beyond the small screen.</p><figure><img alt=""Promotional advert for GenieMobile showing a free Nokia 3330 mobile internet phone offer from BT Cellnet’s Genie service."" src=""https://cdn-images-1.medium.com/max/120/1*RrzXCvEKqksTMk64sufb6Q.gif"" /><figcaption>Promotional campaign for GenieMobile offering a free Nokia 3330 internet-ready handset to new users.</figcaption></figure><p>GenieMobile allowed users to manage and personalise their mobile internet experience before they even picked up their phone. Among its most popular features were:</p><ul><li>SMS alerts, delivering breaking information directly to a user’s handset as it happened.</li><li>Email on WAP, providing free access to services like BT Internet, Talk21, Freeserve and Genie email accounts from anywhere in the UK.</li><li>A personalised WAP menu, letting users select favourites on the Genie website and have them appear automatically on their phone for easier navigation.</li><li>GenieOne, a unified inbox that brought together emails, faxes and voice messages in one place, accessible from either a PC or a mobile device.</li></ul><p>At a time when over-the-air delivery was expensive and limited, GenieMobile acted as a seamless bridge between desktop and handset. It was one of the earliest attempts to synchronise services and preferences across devices, paving the way for the companion app model that would later become standard in the smartphone era.</p><p>GenieMobile’s web-to-handset portal liberated users from the nightmare of GenieMobile’s web-to-handset portal freed users from the hassle of configuring finicky ISP settings on clunky Nokia or Ericsson phones, enabling seamless SMS forwarding and address book management from any browser — a proto-cloud lifeline for professionals juggling work PCs and early mobiles. By cutting setup friction, it doubled daily engagement for power users, cementing loyalty and outpacing rivals stuck in mobile-only complexity. This experience-first innovation, despite primitive network limits, laid groundwork for the cloud era before 3G arrived</p><p><strong>What we learned</strong>: A great mobile experience doesn’t start on the phone — it starts wherever the user is. GenieMobile showed that extending the journey across devices could deepen engagement and reduce friction, years before companion apps became the norm.</p><h3>Building for a 3G Future — and Inventing the Cloud Before It Had a Name</h3><p>That shift in perception created the foundation for what came next — a move beyond 2G services toward a future shaped by 3G networks, cloud storage, and entirely new kinds of mobile experiences.</p><p>While much of Genie’s early innovation focused on creating compelling services within the limits of 2G — like short-form entertainment, mobile radio, and interactive formats — we were already thinking well beyond those constraints. Inside the team, our discussions and prototypes increasingly centred on what would be possible once 3G networks, Java-enabled devices, and always-on connectivity became the norm.</p><p>The ambition was bold: to create a fully integrated content ecosystem that could support music, games, messaging, ringtones, and even personal media — all underpinned by payment infrastructure, digital rights management (DRM), and a personal digital locker. We wanted people to be able to download content directly to their devices, store it in the cloud (though we didn’t yet use that word), and access it seamlessly across multiple touchpoints: phones, PDAs, and even desktop browsers.</p><p>Central to this vision was the idea of openness and interoperability. The platform would expose APIs that allowed third-party developers and content providers — including early partners like Digital Bridges, mp3.com, Vitaminic and Club Nokia — to plug their services directly into Genie’s ecosystem. This was a radical idea for its time: instead of a closed, operator-controlled platform, Genie aimed to become a value store — a distribution hub where customers could browse, purchase, and manage all their digital experiences from a single interface.</p><p>The diagram below, taken from one of our internal architecture documents, shows how advanced this thinking already was. It envisioned a system capable of provisioning content, handling payments, and enforcing usage permissions, in other words, a blueprint for the modern app store and cloud service model.</p><figure><img alt=""A flow diagram showing Genie’s proposed content management and payment system for games, music and MP3 downloads, including third-party integrations, an API interface, and early plans for cloud-style storage and delivery."" src=""https://cdn-images-1.medium.com/max/950/1*EHSHtVEvq0N8bwWV1-r-1w.png"" /><figcaption><em>An internal Genie architecture diagram from the early 2000s outlining one of the first end-to-end visions for cloud-based content delivery — integrating payments, digital rights management, and third-party media into a unified mobile experience.</em></figcaption></figure><p>Even with the concept fully mapped out, one major challenge stood in the way: rights management and legal complexity. Delivering music, games and other premium content required navigating a labyrinth of contracts, distribution deals and licensing agreements. For a startup-scale venture inside BT — even one as ambitious as Genie — that proved difficult to resolve.</p><p>It’s telling that Vodafone, despite its scale and its deep partnership with Vivendi, ran into similar roadblocks. The ecosystem was simply too fragmented, and the legal and commercial incentives too misaligned, for anyone to solve the problem within the constraints of early-2000s mobile infrastructure. In the end, it took Apple’s vertically integrated approach — hardware, software, content, payments and rights all controlled under one roof — and the launch of the iPhone in 2007 to finally make the seamless mobile content model viable.</p><p>But even if we couldn’t deliver it at scale, the vision itself was prophetic. Genie’s platform work was one of the earliest serious attempts to combine content distribution, DRM, payment, storage, and developer integration into a single, customer-centric service. Seen with hindsight, it was a glimpse of the future, one that would eventually define the smartphone era.</p><h3>Taking WAP to the Mainstream — and Telling a New Story</h3><p>For all the innovation we were doing inside Genie, none of it would matter if people didn’t actually use it. The late 1990s mobile landscape was still defined by calls and texts, and the idea of browsing the internet on a phone was, for most people, more science fiction than reality. To succeed, we had to make the concept not only technically possible but emotionally compelling — and that meant changing the story around what a mobile phone <em>was for</em>.</p><p>One of the most significant milestones was the launch of the UK’s first pre-pay WAP phones, developed by Genie in partnership with BT Cellnet. This was the moment when mobile internet shifted from being an expensive, niche add-on to something anyone could access for under £100. The service connected people directly to news, music, sport, and entertainment — and, crucially, to a growing ecosystem of content partners such as EMI, BSkyB, Freeserve and The Guardian.</p><p>The launch was headline news. Sky News covered it as a turning point for mobile technology, highlighting how consumers could now go online without a computer for the first time. As Peter Erskine, Managing Director of BT Cellnet, explained in the report: <em>“Suddenly, instead of buying a thousand-pound computer, people can access the internet just by buying a £99 phone. So suddenly people want the content that they can get.”</em></p><p>I followed by describing how quickly user behaviour would change once richer content became available: <em>“People have a mobile phone and a Sony Walkman. By next year, people will just have their mobile phone and will be listening to their music on their mobile phone. They won’t need two cumbersome devices.”</em></p><p>This shift wasn’t just about hardware, it was about behaviour. Once people experienced the convenience of checking headlines, sending messages, or browsing music on a device they carried everywhere, the mental model of what a phone could do changed forever. And once that shift happened, the demand for more sophisticated services—richer media, better usability, deeper integration — accelerated dramatically.</p><a href=""https://medium.com/media/a0eedc8be53180bb40916e6239012f7b/href"">https://medium.com/media/a0eedc8be53180bb40916e6239012f7b/href</a><p><em>Sky News report on the launch of the UK’s first pre-pay WAP phones, with commentary from Simon Robinson and BT Cellnet MD Peter Erskine on how mobile content and services were about to change consumer behaviour.</em></p><p>Looking back, this was more than a launch event; it marked a decisive turning point in customer perception. It showed that adoption depends as much on storytelling and value proposition as on technology, a lesson that would shape our thinking throughout Genie’s evolution.</p><h3>How the market likely valued Genie (1999–2001)</h3><p>In the dot-com era, portals and mobile data platforms were valued primarily for their <strong>strategic option value</strong> rather than present-day profits. Genie sat inside BT Cellnet as the face of future data revenue, with millions of registered users and nine-figure monthly WAP page views by mid-2001, and it was already expanding internationally across parts of Europe and Asia.</p><h3>Comparables to anchor the range</h3><ul><li><strong>Vizzavi (Vodafone + Vivendi, 2000–2001):</strong> Launched with an investment plan of ~€1.6 bn, later described as worth £2.5 bn+ at its peak narrative (and higher in some analyst commentary). This shows that credible, pan-European mobile portals attracted billion-scale valuations on strategy alone.</li><li><strong>mmO2 flotation (Nov 2001):</strong> On demerger from BT, mmO2, which absorbed Genie’s assets into O2 Online/O2 Active, opened with a market cap between £6.5 bn and £7.3 bn, depending on the reference price. Genie was not listed separately, but its users, services and brand equity were part of that story.</li></ul><h3>A cautious, internal-style valuation</h3><ul><li><strong>Conservative (“cost-plus + scarcity”):</strong> £0.5 bn–£1.0 bn — reflecting accumulated build and marketing cost for a functioning, growing portal, plus a scarcity premium in a pre-3G market with few credible assets.</li><li><strong>Strategic (“option value vs. Vizzavi”):</strong> £1.0 bn–£2.0 bn — benchmarked against Vizzavi’s billion-euro scale and the idea that Genie could become a primary gateway for messaging, entertainment and games across BT’s European footprint.</li></ul><p>There is no public filing that states “Genie was worth £X.” These figures synthesise comparable valuations, mmO2’s flotation, and Genie’s strategic role within BT Cellnet/BT — a realistic view of how a strategic finance team in 2000–2001 might have valued Genie internally.</p><h3>Results that moved the needles</h3><ul><li><strong>Engagement &amp; growth:</strong> By June 2001 Genie reported ~5.5 million registered users and ~103 million monthly WAP page impressions (BT listing documents).</li><li><strong>Lower churn / higher spend:</strong> In December 1999, BT Cellnet MD Peter Erskine told <em>The Independent</em> that Genie users spent more, were less likely to disconnect, and were expected to grow significantly.</li><li><strong>Industry recognition:</strong> <em>Campaign</em>’s 2001 Marketing Awards (Connections) named Genie <em>Best Use of Mobile Phones/WAP</em>.</li></ul><p>None of this meant we had it all figured out — we didn’t. But the metrics suggested we were pulling the right levers for that era’s constraints.</p><h3>Meanwhile at Vizzavi: brand scale without customer clarity</h3><p>Vizzavi launched as a high-stakes Vodafone–Vivendi joint venture to unify web and mobile portals across Europe, combining Vivendi’s content (music, film, games) with Vodafone’s distribution. The bet: centralise the platform, push a premium brand, and own the customer front door. And their marketing budget was many times higher than Genie’s.</p><a href=""https://medium.com/media/33c94f6e1c1c808e7f284c972af8b9e3/href"">https://medium.com/media/33c94f6e1c1c808e7f284c972af8b9e3/href</a><p><em>The sales film that was played in Vodafone stores across the UK. Directed and produced by David Goodwin, it featured The Beatles’ Day in the Life with altered lyrics</em></p><p>Here’s how it played out:</p><ul><li><strong>Operational fragility:</strong> A widely reported email outage during a core upgrade in December 2000 eroded user trust.</li><li><strong>Economic misalignment:</strong> Vivendi’s model relied on selling content; Vodafone bundled access, leaning toward “free to users” to drive network adoption — undercutting content margins.</li><li><strong>Strategic endgame:</strong> By August 2002 Vodafone bought out Vivendi’s stake, dropped the Vizzavi brand, and folded services into Vodafone live! (launched October 2002).</li></ul><p><strong>Takeaway:</strong> Scale is not a strategy. Without a clear customer job, a mega-portal becomes a cost centre looking for a purpose.</p><h3>Side-by-side: the two playbooks</h3><p>It’s easier to see the underlying patterns when you compare them directly. The table below shows how Genie and Vizzavi diverged across six critical dimensions — and how those choices determined their success or failure.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*rfbp3Bm3BKX4_DKclp2dYQ.png"" /></figure><p><em>Figure 1 — A side-by-side comparison of Genie and Vizzavi across six strategic dimensions.</em></p><h3>A brief postscript: the giffgaff echo</h3><p>Years later, giffgaff would demonstrate a similar mindset: community-centred, online-only, and operating with a lean, agile model (launched in 2009 as an MVNO on O2). It was a different era, but the same bias toward simplicity and direct customer connection.</p><h3>Seeing Genie Through the Lens of Customer Centricity</h3><p>To understand why Genie succeeded where others stumbled, it helps to view the story through the structure of the <a href=""https://medium.com/@srerobinson/a-new-framework-to-elevate-customer-centric-strategy-9e8dc8f99627"">Customer Centricity Strategy Framework</a> — a way of thinking developed by Maria Moraes Robinson and I that grew directly out of this work.</p><figure><img alt=""Diagram of the Customer Centricity Strategy Framework, showing how organisations can align vision, value propositions, design, and delivery around the customer lifecycle."" src=""https://cdn-images-1.medium.com/max/1024/1*tmi5KrZpN8G5_8y0naDi-g.jpeg"" /><figcaption>The Customer Centricity Strategy Framework — a model born from Genie’s approach to building products, services and experiences around the customer lifecycle.</figcaption></figure><p>At the time, we didn’t set out to “create a framework.” We were simply trying to build something that mattered to people. But over time, the logic behind those decisions became clear: we were designing intentionally around the <em>customer lifecycle</em> — not treating it as a marketing funnel, but as the central driver of strategy.</p><p>Every choice we made — from the earliest prototypes to our pricing model — was aimed at influencing that lifecycle: attracting users, building habits, deepening engagement, reducing churn and extending lifetime value.</p><h4>1. Scanning future horizons</h4><p>Genie’s origins lay in horizon-scanning. Even before the portal existed, we were exploring prototypes and scenarios for early smartphones, anticipating how connectivity, devices and user expectations would evolve. The goal was not to predict the future but to <em>prepare for it</em>.</p><h4>2. Crafting a clear value proposition</h4><p>Our value proposition was unambiguous: mobile phones were changing. They were no longer just for calls or texts — now, you could <em>surf the BT Cellnet</em>. This wasn’t about listing features; it was about reframing what a mobile phone <em>was</em>and what it <em>could do</em>.</p><h4>3. Leading organisational change</h4><p>Transformation is never purely technical — it’s organisational and cultural too. We faced significant tensionstransitioning from a small team inside BT Cellnet to an independent startup. Our solution was deliberate: wemoved to our own office in Richmond-upon-Thames, a strategic firewall against head-office politics andcorporate bureaucracy. While the Vodafone-Vivendi joint venture slowed under the weight of reconciling brands,budgets, and bureaucracy, Genie operated with the velocity of a startup, maintaining a rapid, agile decision cycle — the essential prerequisite for breakthrough innovation. In today’s tech race, this same agility drives customer-centric wins. For example, it means aligning teams to prioritise user-friendly AI outputs over model complexity — think Grok’s conversational clarity over raw compute.</p><h4>4. Designing strategy across people, processes and partners</h4><p>We didn’t just set product targets — we mapped our strategy holistically across <em>people</em>, <em>processes</em>, <em>marketing</em> and <em>partnerships</em>. We built agile development cycles to release updates rapidly. We forged pioneering partnerships, such as the XY Network, that brought cultural relevance and fresh content. And we designed marketing around behaviours we wanted to encourage — not just around campaigns.</p><h4>5. Putting experience before technology</h4><p>Perhaps the most important principle was sequencing. We started with the experience we wanted to create and worked backwards to the technology required to deliver it. Vizzavi did the reverse — building a platform first and then searching for a purpose. That difference shaped everything: culture, speed, adoption and, ultimately, outcomes.</p><h3>Practical Takeaways for Today’s Builders</h3><p>The story of Genie offers enduring lessons that apply far beyond the mobile industry. These principles, drawn from what we learned two decades ago, are just as relevant whether you’re designing an AI-driven service, launching a SaaS product, or leading change inside a large organisation.</p><ul><li><strong>Mindset Trumps Money: Capital is not Strategy.</strong> Don’t be intimidated by the war chests of large incumbents. Genie achieved superior results with roughly 1/20th of the funding Vizzavi commanded, proving that agility, a superior experience model, and focus on customer habit are far more valuable than a massive, misdirected investment.</li><li><strong>Make it Open by Default.</strong> Openness maximizes your surface area for learning, feedback, and growth — long before a final monetization model is ready. Don’t build walls unless they are essential for your core value proposition.</li><li><strong>Price to Encourage Exploration.</strong> Just as we used flat-rate plans to encourage mobile browsing, your pricing model should act as customer R&amp;D, revealing real jobs-to-be-done rather than punishing early experimentation or metered usage.</li><li><strong>Program the Medium, Not Your Aspirations.</strong> Design services that work <em>with</em> the fundamental constraints of the underlying technology, not against them. In the age of Generative AI, this means recognizing an LLM’s propensity to hallucinate and designing the customer experience to manage verification, rather than forcing the model to act as a perfect, verifiable knowledge base.</li><li><strong>Ship Habits, Not Platforms.</strong> Focus on delivering ten real, sticky user behaviors quickly. This iterative approach creates more cumulative value than waiting years to launch one grand, perfect platform vision.</li><li><strong>Treat Timing as a Feature.</strong> If the enabling technology or market is not ready for the full vision, don’t kill the idea — change the plan. Adapt your scope and scale until technology adoption or infrastructure can catch up to the original vision.</li><li><strong>Align Incentives in Partnerships.</strong> Misaligned business models or conflicting partner incentives will tear even the best product apart. Ensure every partner — and every internal team — is motivated by the same measure of customer success.</li><li><strong>Let Results Speak for You.</strong> In a saturated market, adoption metrics, behavioral data, and organic growth speak louder than marketing adjectives. Focus on building something so valuable that the usage itself proves the strategy.</li><li><strong>Design for Real Behavior, Not Assumed Demand.</strong> Usage data and observed real-world customer actions must be the ultimate guide for your roadmap. Internal assumptions about what customers <em>should</em> want are the fastest path to irrelevance.</li></ul><h3>Looking Forward — Lessons That Still Matter</h3><p>The story of Genie isn’t just a piece of telecoms history — it’s a blueprint for how transformative innovation happens. Every major technological shift — from mobile to cloud to AI — begins with a change in how we think about customers, value and organisational agility. We were experimenting with behaviours that hadn’t yet formed, building services for devices that didn’t quite exist, and designing for a future that was only just becoming possible.</p><p>That mindset — exploratory, adaptive and deeply customer-centred — remains the key to navigating today’s most complex innovation challenges. As the next wave of transformation unfolds, from AI-driven services to spatial interfaces, the opportunity is the same: to build not just technology, but meaningful experiences that people truly care about.</p><p>The future is never invented in theory. It’s built step by step — through experimentation, iteration and a relentless focus on real human needs. And it’s shaped not by technology itself, but by the experiences we design around it.</p><p><strong>So the challenge for today’s builders is this:</strong> don’t just launch products — shape possibilities. Start with the experience, keep the customer at the centre of every decision, and you might just build the breakthrough the future has been waiting for.</p><h3>References</h3><h4>Core Genie milestones &amp; context</h4><ul><li>The Guardian (Jul 2000) <a href=""https://www.theguardian.com/business/2000/jul/04/internet.efinance"">Upwardly mobile commerce: The arrival of wireless internet access is breeding a second wave of web portals</a> (Genie launch, subscriber numbers)</li><li>BBC News (Feb 1999). <a href=""http://news.bbc.co.uk/2/hi/business/285508.stm""><em>Cellnet dials up Internet first</em></a><em>.</em> (Genie launch; “wireless Internet” and “killer applications”).</li><li>WAP Forum / Yahoo! Europe (Sep 2000). <a href=""https://www.wapforum.org/new/20000906166Yah.htm""><em>Yahoo! Europe and Genie announce portal agreement</em></a><em>.</em> (Notes Genie as UK’s mobile Internet leader; “first free-access Mobile ISP” and first working commercial pre-pay WAP service).</li><li>TechMonitor (Nov 2000). <a href=""https://techmonitor.ai/technology/bt_genie_your_wish_for_unmetered_mobile_internet_is_my_command""><em>BT Genie: your wish for unmetered mobile Internet is my command</em></a><em>.</em> (First unmetered £20/month mobile internet).</li><li>Campaign (May 1997). <a href=""https://www.campaignlive.co.uk/article/cellnet-users-gain-access-internet-genie-launch/27078""><em>Cellnet users gain access to Internet with Genie launch</em></a><em>.</em></li><li>BT Group (Listing Particulars, Sep 2001). <a href=""https://www.bt.com/bt-plc/assets/documents/investors/financial-reporting-and-news/listing-history/listing-particulars.pdf""><em>Genie metrics</em></a><em> (~5.5m registrations; ~103m monthly WAP page impressions).</em></li></ul><h4>Programming &amp; services</h4><ul><li>PRWeek (May 2000). <a href=""https://www.prweek.co.uk/article/100836/media-xy-brings-music-mobile-users""><em>MEDIA: XY brings music to mobile users</em></a><em>.</em> (XY Network; Somethin’ Else; audio with GPRS timing).</li><li>The Guardian (May 2001). <a href=""https://www.theguardian.com/media/2001/may/09/channel4.broadcasting""><em>Channel 4 plans Big Brother radio show</em></a><em>.</em> (“Mobile customers on all UK networks will be able to access the free services…”)</li><li>Campaign (May 2001). <a href=""https://www.campaignlive.co.uk/article/cellnets-shops-design-fly-slots-big-brother/39902""><em>Cellnet’s shops design fly slots for Big Brother</em></a><em>.</em> (Genie as WAP provider).</li><li>Picofun / Cision (Jul 2001). <a href=""https://news.cision.com/se/picofun/r/picofun-bakom-storsta-spelsuccen-hittills-i-europa,c45206""><em>Picofun bakom största spelsuccén hittills i Europa</em></a><em>.</em> (Big Brother–Lifestylers: ~2.5m play-minutes in 5 weeks; ~60k active players).</li></ul><h4>Recognition</h4><ul><li>Campaign (2001). <a href=""https://www.campaignlive.co.uk/article/marketing-awards-connections-2001-best-use-mobile-phones-wap-winner-genie/79081""><em>Marketing Awards (Connections): Best use of mobile phones/WAP — Winner: Genie</em></a><em>.</em></li></ul><h4>Impact on churn &amp; spend</h4><ul><li>The Independent (Dec 11, 1999). <a href=""https://www.the-independent.com/news/business/news/bt-cellnet-aims-to-double-users-to-12m-by-2003-740806.html""><em>BT Cellnet aims to double users to 12m by 2003</em></a><em>.</em> (Erskine: Genie users spend more and are less likely to disconnect).</li></ul><h4>Device exploration</h4><ul><li>Mobile Phone Museum. <a href=""https://www.mobilephonemuseum.com/phone-detail/one-orbitor""><em>Nortel — One (Orbitor)</em></a><em> (1998).</em></li><li>York University Computer Museum. <a href=""https://museum.eecs.yorku.ca/items/show/345""><em>Nortel Europa</em></a><em> / “Orbitor” background.</em></li></ul><h4>Vizzavi / Vodafone context</h4><ul><li>DLGB (personal account). <a href=""https://dlgb.net/vizzavi.html""><em>My Vizzavi Story</em></a><em>.</em></li><li>The Register (Dec 2000). <a href=""https://www.theregister.com/2000/12/19/vizzavi_bungles_upgrade/""><em>Vizzavi bungles upgrade: leaves thousands without email</em></a><em>.</em></li><li>The Guardian (Aug 19 &amp; Aug 30, 2002). <a href=""https://www.theguardian.com/media/2002/aug/19/vivendi.citynews1""><em>Vodafone comes clean over Vizzavi transfer</em></a> / <a href=""https://www.theguardian.com/media/2002/aug/30/newmedia.citynews""><em>Vodafone pulls plug on Vizzavi brand</em></a> / <a href=""https://www.theguardian.com/business/2002/aug/30/citynews.vivendi""><em>Vodafone buys Vizzavi stake for £90m</em></a><em>.</em></li><li>Telecompaper (Oct 24, 2002). <a href=""https://www.telecompaper.com/news/vodafone-launches-vodafone-live-service--322333""><em>Vodafone launches Vodafone live!</em></a></li></ul><h4>Related / later echoes</h4><ul><li>Wikipedia: <a href=""https://en.wikipedia.org/wiki/Giffgaff""><em>giffgaff</em> </a>(UK MVNO; launched 2009).</li></ul><h4>Personal background &amp; additional context</h4><ul><li>Simon Robinson (2018). <a href=""https://medium.com/@srerobinson/the-danger-trap-of-dual-transformation-for-internal-startups-e1dd611e8b8e""><em>The Danger Trap of Dual-Transformation for Internal Startups</em></a><em>.</em></li><li>Simon Robinson (2013). <a href=""https://transitionconsciousness.wordpress.com/2013/03/18/a-brief-and-personal-history-of-mobile-telephony-1992-2002/""><em>A Brief (and Personal) History of Mobile Telephony 1992–2002</em></a><em>.</em></li></ul><h3>Author</h3><p>Simon Robinson is CEO (Worldwide) of Holonomics and a global thought leader on customer experience, systems thinking and strategic transformation. He is the co-author of several books, including <a href=""https://a.co/d/9qwv0fv""><em>Designing Customer Experiences with Soul</em></a> and <a href=""https://a.co/d/5xxmxZ5""><em>Deep Tech and the Amplified Organisation</em></a>.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0ab1513b81dc"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/start-with-the-experience-0ab1513b81dc"">Start with the experience</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/failing-fast-with-ai-e30887321ef5?source=rss----138adf9c44c---4,1758886768,Failing fast with AI,"Failing fast with AI

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/failing-fast-with-ai-e30887321ef5?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*I8db_56Ds5RsRgtvyvumBw.png"" width=""3368"" /></a></p><p class=""medium-feed-snippet"">Why failing fast is essential to the era of AI-assisted design/dev prototyping.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/failing-fast-with-ai-e30887321ef5?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/is-imitation-theft-or-apprenticeship-fc145f3f3a31?source=rss----138adf9c44c---4,1758878915,Is imitation theft or apprenticeship?,"Is imitation theft or apprenticeship?

<h4>What two forgotten thinkers can teach us about voice, intent and AI-assisted work.</h4><figure><img alt=""A 19th-century oil painting shows a young apprentice painter standing beside a senior artist, carefully copying the master’s work onto his own canvas. The studio is dimly lit but detailed, with wooden floors, high windows, and art supplies scattered around. The apprentice appears focused, while the master, seated nearby, observes with quiet authority. The scene captures the traditional method of learning through imitation and side-by-side practice."" src=""https://cdn-images-1.medium.com/max/1024/1*fxMgjDsG3Ym1H1RevBFf2Q.png"" /><figcaption>Image created by author</figcaption></figure><p>In 18th-century Europe, aspiring painters learned to paint by copying other artists.</p><p>They spent years in studios reproducing sketches and practicing technique. The point was to learn through repetition, and copying helped these aspiring artists understand what good looked like. Imitation was just part of the process.</p><p>Only after years of apprenticeship did painters begin to branch off.</p><p>Today, we’re talking about voice and style — something we used to develop through practice and feedback. Now that we have tools that help us produce faster than ever, we’ve failed to teach what good work looks like along the way.</p><p>When something feels like it was produced with AI, we discount its quality. We often blame the tool, or worse, we blame the person using it.</p><p>To bring some clarity, we’re bringing back two forgotten thinkers: <a href=""https://www.britannica.com/biography/Anna-Laetitia-Barbauld"">Anna Laetitia Barbauld</a> and <a href=""https://www.britannica.com/biography/Richard-Bentley"">Richard Bentley</a>. Together, they offer a path forward.</p><p>I’m <a href=""https://www.linkedin.com/in/natesowder/"">Nate Sowder</a>, and this is <strong>unquoted, installment 8</strong>,<strong> </strong>a series about the people behind the ideas we can’t afford to forget.</p><figure><img alt=""Black-and-white engraved portrait of Anna Laetitia Barbauld, shown in profile facing left. She wears a ruffled cap with dark ribbons and a simple gown with a high neckline and lace collar. The shading is soft and sketch-like, giving the image a delicate, textured quality."" src=""https://cdn-images-1.medium.com/max/1024/1*i4OUBAAlj7v2fbgDo0hzDw.jpeg"" /><figcaption>Engraving of Anna Laetitia Barbauld by Henry Hoppner Meyer, 1822. (Public Domain)</figcaption></figure><h3>Barbauld and the practice of imitation</h3><p>In the late 1700s, Anna Laetitia Barbauld was writing poems and essays. She also was teaching at a time when few women had access to formal intellectual training.</p><p>She taught at Warrington Academy, a progressive school in England that served students excluded from elite institutions. Many of her pupils had never been taught how to write with structure or style.</p><p>Her method was simple: Start by copying existing essays and poems. Over time, that helped students develop a sense of their own style by first understanding others’.</p><blockquote>“The mind must be fed by imitation before it can create.”</blockquote><p>To Barbauld, imitation was the path to originality.</p><figure><img alt=""Engraved portrait of Richard Bentley, an 18th-century English classical scholar. He is shown seated, facing slightly to the left, with long curly hair, wearing clerical robes and a white collar. His right hand rests on a closed book, which he holds at the bottom edge. The background is plain and shaded, emphasizing his face and attire."" src=""https://cdn-images-1.medium.com/max/1024/1*HDZRDgC3rKubmS3_gneIqA.jpeg"" /><figcaption>Bentley, Richard (1662–1742) (Public Domain)</figcaption></figure><h3>Bentley and the structure of style</h3><p>While Barbauld was helping students find their voices, Richard Bentley was working to detect where voice had gone missing.</p><p>Bentley was a classical scholar in the early 1700s who built a reputation on his ability to <a href=""https://www.britannica.com/topic/textual-criticism"">spot forgery</a>. His most famous takedown was <em>The Letters of Phalaris</em>, a widely admired collection of ancient Greek writings once believed to be authentic. Bentley read them and disagreed.</p><p>When the syntax didn’t match, he realized the voice of the piece was all wrong. The references were off and the structure lacked consistency with the rest of the canon. Bentley could hear when something didn’t belong. He didn’t need proof in reference materials and records. Instead, he looked for a pattern he could follow.</p><p>He treated style as evidence and voice as something you could trace.</p><h3>Why it matters</h3><p>When you replace the process of developing expertise with productivity tools, you stop teaching people how to build their voice. Instead, you hand them Mad Libs, templates and mandates like “use AI” but never define how, how much or to what end.</p><p>And then, when the work feels too clean or too unlike the person who wrote it, we don’t ask what the person was trying to say.</p><p>We ask if they cheated.</p><p>That kind of suspicion kills growth. It tells people: Try this, but only in exactly the right way (whatever that means). And when they get it wrong, they don’t get coached. They get judged.</p><p>If AI becomes a source of shame, I think a lot of people will stop using it. They’ll avoid new opportunities, hide their process and aim for ‘safe and small’ outcomes.</p><h3>What to do instead</h3><p>This problem doesn’t fix itself. If we want people to use AI well, we have to define what that means, not just urge adoption and <em>hope</em> for the best. That means setting clear boundaries, offering real feedback and helping people grow into a voice that’s theirs (which can’t happen in a vacuum).</p><p><strong>Barbauld gave us a blueprint for that kind of growth.</strong><br />She showed that imitation, when guided, builds fluency. It helps people understand how ideas flow, how style works and how meaning holds together.</p><p><strong>Bentley gave us the tools to listen.</strong><br />He showed that voice isn’t invisible. It leaves a trail that can be studied, taught and refined (if we care enough to notice it).</p><p>Together, their teaching offers something AI tools can’t:<br /><strong>A path for learning how to sound like yourself.</strong></p><p>We need less suspicion and more systems that help people build toward authorship.</p><p>Voice and style matter. Put in the work to develop your own.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fc145f3f3a31"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/is-imitation-theft-or-apprenticeship-fc145f3f3a31"">Is imitation theft or apprenticeship?</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4,1758821283,The timeless Apple “hello” logo,"The timeless Apple “hello” logo

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/772/1*7u06zeblW0tCidijNrro6g.png"" width=""772"" /></a></p><p class=""medium-feed-snippet"">The understated beauty and whimsy of pixel art typography &#x1f3a8; &#x1f3ae;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-timeless-apple-hello-logo-7126f1d061d0?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4,1758796015,Don’t make me blush: Are machines truly capable of emotion?,"Don’t make me blush: Are machines truly capable of emotion?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1920/1*RzKnBbop38qmtAgiSQER3Q.jpeg"" width=""1920"" /></a></p><p class=""medium-feed-snippet"">Can technology truly experience emotion, or only mimic it convincingly?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/dont-make-me-blush-are-machines-truly-capable-of-emotion-ab38b3d80f73?source=rss----138adf9c44c---4"">Continue reading on UX Collective »</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/vibe-code-straight-from-your-website-ce52eef25d95?source=rss----138adf9c44c---4,1758795859,Vibe code straight from your website,"Vibe code straight from your website

<h4>Skip Figma and prototype where your product already lives</h4><p>Prototyping and testing new product features or concepts usually means starting from scratch with a blank design canvas. The workflow looks a little like this: UX designers build product screens in Figma, pass the designs for feedback, then developers recreate the same screens in code. Though this is the traditional design and development process we’re used to, the workflow can be slow and redundant.</p><p><strong>Not only does this established process cause inefficiency in product development, but it’s disconnected from the actual product, losing context and real user-interaction behavior.</strong></p><p>But what if you can adapt your design and development workflow to skip the unnecessary rework and keep the user’s context? Being able to prototype directly on your live website’s product pages, like tweaking layouts or exploring features, allows you to cut the time and resources needed to implement and test new ideas.</p><figure><img alt=""Vibe coding with Anima’s “Web-to-code” feature with the AI chat on the left and code preview on the right"" src=""https://cdn-images-1.medium.com/max/1024/1*yF0WH6JRq6nAnWjpMQisWg.png"" /><figcaption>Vibe coding with <a href=""https://chromewebstore.google.com/detail/web-to-code-by-anima/paddhneaanoeljlmdepnheehdkaegblo"">Anima’s “Web-to-code”</a> feature</figcaption></figure><p><strong>By vibe coding straight from your website, you keep the design process realistic to the user’s experience, and keep design and implementation in sync from the start.</strong></p><p>You may be thinking of ways you can streamline your own design-development process or if vibe coding is right for you and your team. To answer these questions, let’s explore vibe coding’s benefits and limits when using live websites, demo tools that enable this workflow, and review use cases to determine where this process can be integrated within the design process.</p><h3>Benefits and limits of vibe coding with your website</h3><p><strong>Instead of starting the vibe code process from Figma or Sketch designs, you can cut straight to your live product.</strong> Vibe coding directly on your website avoids duplicate effort (e.g., creating the same UI mockup with slight variations), and keeps the user’s context that gets lost in design tools. This results in prototypes that not only look realistic, but behave like the actual product — making them easier to validate with both users and stakeholders.</p><blockquote><em>For more of an introduction to vibe coding and how it fits in the UX process, check out this article: </em><a href=""https://uxdesign.cc/testing-your-ux-ideas-with-vibe-coding-8302620c17af""><em>“Testing your UX ideas with vibe coding.”</em></a></blockquote><h4>Benefits to your website</h4><ul><li><strong>Speed</strong>: By modifying spacing, colors, or users flows right on your site, you eliminate the extra steps of remaking your product screens in any design tool — cutting hours (or even days) from the iteration cycle.</li><li><strong>Accuracy</strong>: Vibe coding in your website keeps behaviors like hover states, responsiveness, and navigation (typically lost in design tools), so the prototype reflects real user interactions with the product.</li><li><strong>Testing confidence</strong>: Because changes are made on top of real product flows, usability testing offers reliable feedback (which you don’t get from artificial prototypes in Figma or Sketch).</li></ul><figure><img alt=""Patagonia’s home page at a mobile breakpoint from Chrome’s dev tools on a desktop screen"" src=""https://cdn-images-1.medium.com/max/1024/1*4Ew1U1pkaYa1Bs2Hlq72iQ.png"" /><figcaption>Using a site to vibe code allows you to view mobile and desktop breakpoints; via <a href=""https://www.patagonia.com/home/"">Patagonia</a></figcaption></figure><h4>Limits with vibe coding</h4><ul><li><strong>Messy code</strong>: Depending on the tool, vibe coding can generate code that’s great for exploration but is not production-ready; developers will need to evaluate and possibly rebuild the code.</li><li><strong>Security risks</strong>: When working with live sites or sites with required user sign-in, you need to be careful about exposing sensitive data like user info, tokens, or private content.</li><li><strong>Not scalable for large systems</strong>: Vibe coding works well for small tweaks and user flows, but is not a replacement for building complex features or keeping consistency across platforms.</li></ul><figure><img alt=""Slack’s login page to sign in with a company email"" src=""https://cdn-images-1.medium.com/max/1024/1*5F12b9_n-luEuqBcDO0byQ.png"" /><figcaption>Vibe coding with authenticated sites can pose security issues; via <a href=""https://slack.com/get-started#/createnew"">Slack</a></figcaption></figure><h3>How to start vibe coding with your site</h3><p>There are plenty of vibe coding tools out there today, but not many let you vibe code directly from your live website. Most focus on creating one to multi-page user flows from a few design mockups from Figma or from AI prompts. These prototypes and the AI-generated code can be helpful, but keep you one step removed from your actual product.</p><p>Let’s get into Anima’s “web to code” feature and Chrome extension to demo how you can vibe code directly from your (or any public) website, then look into other similar tools that offer vibe coding from your live site.</p><h4>“Web to code” demo</h4><ol><li>Copy your website’s URL and paste it into <a href=""https://dev.animaapp.com/?framework=react&amp;language=typescript&amp;styling=tailwind&amp;l2cEngine=auto&amp;importType=link"">Anima’s web to code tool</a></li><li>Choose your preferred framework, language, and styling (or keep the default options), then select the “arrow” icon button</li></ol><blockquote>Note<em>: Anima automatically recognizes your Design System’s UI components; when it creates additional pages, it will reuse the components to maintain consistency.</em></blockquote><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*AIExuPUd4fhrx-oZ5ICf6g.png"" /><figcaption>Copy and paste any public website URL into Anima to generate design and code</figcaption></figure><p>3. After selecting the arrow icon button, you’re asked if you’re using the website as inspiration or if you own/ have right to the website; select the applicable option</p><blockquote>Note<em>: For the purpose of the demo, I used </em><a href=""https://www.eventbrite.com/""><em>Eventbrite’s website</em></a><em> so I selected “Use as inspiration.” You can use any public website in addition to your personal or company website.</em></blockquote><p>4. The tool scans and builds the site page from the URL; this can take a couple minutes depending on the website’s asset complexity</p><p>5. Once the build is finished, compare the URL to the output for any discrepancies (Anima’s output is pretty consistent with the input)</p><figure><img alt=""Comparison between the original website and Anima’s output, which shows a consistent match"" src=""https://cdn-images-1.medium.com/max/1024/1*lXR1JI6J2wQpJX6xO-142w.png"" /><figcaption>Anima’s output is pretty consistent with the original input</figcaption></figure><p>6. Prompt the AI assistant for any needed tweaks; I prompted, “Make the grid section a list view” and “Add a sidebar to filter events by category”</p><blockquote>Note<em>: Make smaller, bite-sized adjustments at a time so the prompts are more clear to the AI assistant — giving better results.</em></blockquote><figure><img alt=""Prompting the AI chat for changes to make to the Eventbrite website in Anima"" src=""https://cdn-images-1.medium.com/max/1024/1*tZW0yT94XXXLgtp-vucx6g.png"" /><figcaption>Prompting the AI chat for changes to make to the Eventbrite website</figcaption></figure><p>7. Continue to make adjustments until the output is good-to-go, then select “Publish” for the prototype link or select “Download code” (depending on if you’re user testing or pushing code into a repository)</p><p>There is also a <a href=""https://chromewebstore.google.com/detail/web-to-code-by-anima/paddhneaanoeljlmdepnheehdkaegblo"">Web-to-code Chrome extension</a> to select a specific page from any public website and generate its code-build in Anima’s playground. So instead of toggling back-and-forth between Anima and your site, you can move directly from the site to Anima.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*PTQ1NsEC57wzDuHdCIRN3g.png"" /><figcaption>Anima’s Chrome extension tool to go straight from the site to code generation</figcaption></figure><h4>Other tools to explore</h4><ul><li><a href=""https://chromewebstore.google.com/detail/html-to-framer/haijifigpgpndcnbbjooffflaceedhdp""><strong>HTML to Framer</strong></a>: Framer offers a Chrome extension that lets you copy one to multiple design elements from any public website, then paste it into your Framer project. This is dependent on if you house your website in Framer (and also doesn’t allow for code modifications), but is an easy way to grab design elements as starting points.</li></ul><figure><img alt=""HTML to Framer’s Chrome extension allows copying elements from the site"" src=""https://cdn-images-1.medium.com/max/1024/1*ZAQHRylnyBju-60gvVG66g.png"" /><figcaption>HTML to Framer’s Chrome extension allows copying elements from the site</figcaption></figure><ul><li><a href=""https://chromewebstore.google.com/detail/mockflow-wireframepro/ghkgfdamcfjiflldnfiollnhkdjilmde?hl=en""><strong>Mockflow’s URL to wireframe</strong></a>: Mockflow offers a feature to convert sections or full pages from live websites into editable wireframes. This feature is similar to Anima’s web-to-code feature since it provides an easy way to explore ideas, but Mockflow doesn’t produce editable code like Anima does.</li></ul><figure><img alt=""Mockflow’s Chrome extension creates wireframes from URLs to import to a canvas in Mockflow"" src=""https://cdn-images-1.medium.com/max/1024/1*cDsnk3xhMyt8oMJD5FCh1Q.png"" /><figcaption>Mockflow’s Chrome extension creates wireframes from URLs</figcaption></figure><ul><li><a href=""https://wireframeit.com/""><strong>Wireframeit</strong></a>: The Wireframeit Chrome extension also converts live websites into editable designs that can be exported into Figma or as images. Again, this tool doesn’t focus on code production or output, but offers a way to extract design assets from your browser to Figma.</li></ul><figure><img alt=""Wireframeit’s Chrome extension creates wireframes on top of the browser"" src=""https://cdn-images-1.medium.com/max/1024/1*czfkr9NMvz2ABl0jjQ7Ouw.png"" /><figcaption>Wireframeit’s Chrome extension creates wireframes on top of the browser</figcaption></figure><h3>Where vibe coding fits in your workflow</h3><p>Vibe coding isn’t about replacing Figma (or your favorite design tool), wireframes, or high-fidelity prototypes; it’s about complementing them. Vibe coding speeds up specific points in the workflow where product teams usually get stuck. For instance, designers can generate and test small design tweaks from their existing website without remaking each UI mockup, as well as validate ideas with prototypes that provide real interactions.</p><p>By integrating vibe coding into your design-development process, you can cut unnecessary steps while gaining the output from traditional prototypes. Let’s look into where product teams can most benefit, then look at when vibe coding shouldn’t be used.</p><h4>For designers</h4><ul><li><strong>Ideate with user context</strong>: Instead of designing mockups on static canvases or creating artificial prototypes, you can generate changes on your actual product pages and see how they behave.</li><li><strong>Validate with users</strong>: Using vibe-coded prototypes for user testing gets more realistic feedback versus clickable prototypes made in Figma or Sketch (also prevents “glitchy” prototypes).</li><li><strong>Avoid design tool integration</strong>: Many vibe coding tools are integrated with only Figma (excluding other design tools); with live-site prototyping, designers without Figma can still vibe code.</li></ul><figure><img alt=""Builder.io’s home page asking designers to submit a Figma file to start using the tool"" src=""https://cdn-images-1.medium.com/max/1024/1*ZO6lPrS9ZOQ5SwIVgmQLxg.png"" /><figcaption>Builder.io requires designers to start with a Figma file</figcaption></figure><h4>For developers</h4><ul><li><strong>Experiment faster</strong>: Vibe coding lowers the barrier to testing since developers can make edits without creating a new dev environment each time; so you can validate the change before committing code.</li><li><strong>Prototype without damage</strong>: Since developers are working in a “playground” environment, they can try new things without worrying about breaking the main repository (or anything else).</li></ul><h4>For product teams</h4><ul><li><strong>Close the handoff gap</strong>: Since designers and developers are working from the same context, there are fewer misinterpretations compared to developers implementing from design files and specs.</li><li><strong>Condense design cycles</strong>: Vibe coding eliminates redundant steps, like recreating the same UI mockup over and over again, so ideas can move from concept to testable prototype in a day or two instead of weeks.</li></ul><figure><img alt=""Modified Eventbrite prototype generated with Anima including changes requested in the demo"" src=""https://cdn-images-1.medium.com/max/1024/1*S4RkOzydArhP-KfN6jNvfA.png"" /><figcaption>Modified Eventbrite prototype generated with Anima</figcaption></figure><h4>When not to use vibe coding</h4><ul><li>​​<strong>Brand new features</strong>: When there is no existing product page or user flow to build from in the existing website, you need to start with wireframes in design tools instead of vibe coding.</li><li><strong>Complex user journeys</strong>: For multi-step user flows or branching paths, traditional prototyping helps you map everything clearly because vibe coding may miss important context.</li><li><strong>Design Systems</strong>: Design libraries require structured, reusable foundations to create UI components and patterns that are better defined and used in tools like Figma.</li><li><strong>High-level concepts</strong>: When you need to present and communicate abstract ideas or early-stage concepts to stakeholders, low-fidelity wireframes or static user journeys are often more effective.</li></ul><h3>Conclusion</h3><p>Vibe coding directly on your live website changes how teams can explore new ideas. This process reduces the redundant work in traditional design-to-dev workflows, while keeping user interactions accurate and in-context.</p><p>Not only is vibe coding from your website a workflow shift, it aligns design and implementation from the start of any iteration cycle — balancing quality, speed, and collaboration while building a better product experience.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce52eef25d95"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/vibe-code-straight-from-your-website-ce52eef25d95"">Vibe code straight from your website</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/from-products-to-systems-the-agentic-ai-shift-eaf6a7180c43?source=rss----138adf9c44c---4,1758749690,From products to systems: The agentic AI shift,"From products to systems: The agentic AI shift

<h4><em>Agents are here, how we build and use them is challenging many of the foundations for building software that we established over the last few decades — and even the very idea of what a product is.</em></h4><figure><img alt=""Abstract illustration of humans and abstracted AI agents collaborating on a complex system"" src=""https://cdn-images-1.medium.com/max/1024/1*ATfGSozp4wJyENvP5ocGiw.jpeg"" /><figcaption>Prompt by the author, image by Sora.</figcaption></figure><p><em>This article is a continuation of previous explorations on the theme of how AI is impacting design and product (</em><a href=""https://uxdesign.cc/design-in-the-age-of-vibes-8a761d2fe21f""><em>Vibe-code designing</em></a><em>, </em><a href=""https://uxdesign.cc/the-future-of-ai-design-navigating-challenges-and-opportunities-2170c92d80bd?sk=cfcc997fa7c1de3641bbe6194356f9bf""><em>Evolving roles</em></a><em>), and is based on a presentation delivered at ‘</em><a href=""https://toomuch.parallel.systems/""><em>The Age of TOO MUCH</em></a><em>’ exhibition in Protein studios, as part of London Design Week 2025.</em></p><p>There’s a <a href=""https://www.youtube.com/watch?v=v-xh_gq8sbk"">scene</a> in one of my favorite movies, Interstellar, where the characters are on a remote, water-covered planet. In the distance there is what initially appears to be a large landmass, but as Cooper, the main character, looks on, he realizes that they aren’t in fact mountains, but enormous waves steadily building and towering ominously over them.</p><figure><img alt=""The wave scene from interstellar, with AI tools overlaid on top, bearing down on an astronaut. This is a metaphor for how it has felt being a designer over the last few years."" src=""https://cdn-images-1.medium.com/max/640/1*nbUDmK6VRwjlDpBK3HnwYg.gif"" /><figcaption>Interstellar wave scene: ‘<a href=""https://www.youtube.com/watch?v=v-xh_gq8sbk"">Those aren’t mountains, those are waves </a>‘ — Cooper</figcaption></figure><p>With AI, it feels like we’ve had a similarly huge wave building on the horizon for the last few years. I wrote previously about how <a href=""https://uxdesign.cc/design-in-the-age-of-chatgpt-3c80e6fc8cf7?source=friends_link&amp;sk=461b4bc8bb082e00c2c2db113c73f52d"">Generative AI</a> and <a href=""https://john-moriarty.medium.com/design-in-the-age-of-vibes-8a761d2fe21f?source=friends_link&amp;sk=b54cfe4bd68a9f9faea2258765fa38a9"">Vibe Coding</a> are changing how we design. In recent months it feels like another seismic shift is underway with agentic AI. So what exactly is this wave, and how is it reshaping the landscape we thought we knew?</p><p>I lead the product design team at <a href=""https://www.datarobot.com/"">DataRobot</a>, an enterprise platform that helps teams build, govern and operate AI models and agents at scale. From this vantage point, I’m seeing these changes reshape not just how we design, but also many long-held assumptions about what products <em>are</em> and how they’re built.</p><h3>What’s actually changing</h3><p>Agents are a fundamentally different paradigm to predictive and generative AI. What sets them apart, aside from being multimodal and capable of deep reasoning, is their <em>autonomous</em> nature. It sounds deceptively simple, but when software has agency — the ability to make decisions and take actions on its own — the results can be quite profound.</p><p>This creates a fundamental challenge for companies integrating AI software, which is traditionally built for <em>deterministic</em>, predictable workflows. Agentic AI is inherently <em>probabilistic</em> — the same input can produce different outputs, and agents may take unexpected paths to reach their goals. This mismatch between deterministic infrastructure and probabilistic behavior creates new design challenges around governance, monitoring, and user trust. These aren’t just theoretical concerns, they’re already playing out in enterprise environments. That’s why we partnered with <a href=""https://www.nvidia.com/en-us/on-demand/session/gtc25-S72261/"">Nvidia </a>to build on their AI Factory design and delivered as agentic apps embedded directly into <a href=""https://www.datarobot.com/solutions/partners/sap/"">SAP</a> environments, so customers can run these systems securely and at scale.</p><p>But even with this kind of hardened infrastructure, moving from experimentation to impact remains difficult. Recent<a href=""https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/""> MIT research</a> found that 95% of enterprise generative AI pilots fail to deliver measurable impact, highlighting an industry-wide challenge in moving from prototype to production. Our ‘AI Expert’ service — where specialised consultants work directly with customers to deploy and run agents — delivers outstanding results through personalized support. To extend this level of guidance to a broader customer base, we needed to develop scalable approaches that could address complexity barriers at scale.</p><figure><img alt=""Screenshot of the DataRobot homepage"" src=""https://cdn-images-1.medium.com/max/1024/1*rmSUGY7cXdvQpzrUk-UHwQ.png"" /><figcaption><a href=""https://www.datarobot.com/"">Datarobot</a> homepage</figcaption></figure><p>Moving from AI experimentation to production involves significant technical complexity. Rather than expecting customers to build everything from the ground up, we decided to flip the offering and lead instead with a series of <a href=""https://docs.datarobot.com/en/docs/workbench/wb-apps/app-templates/index.html"">agent and application templates</a> that give them a head start.</p><p>To use a food analogy, instead of handing customers a pantry full of raw ingredients (components and frameworks), we now provide something closer to ‘HelloFresh’ meal kits: pre-scaffolded agent and application templates with prepped components and proven recipes that work out of the box. These templates codify best practices across common customer use cases and frameworks. AI builders can clone them, then swap out or modify components using our platform or in their preferred tools via API.</p><figure><img alt=""Illustration showing an architectural diagrm of DataRobot agentic application templates on one side, with sample front-end interfaces on the other side, to illustrate what’s included in these application templates."" src=""https://cdn-images-1.medium.com/max/1024/1*37NA6kRGLHFwuJeKZTwtVQ.png"" /><figcaption><em>Use case specific </em>Agentic Application Templates</figcaption></figure><p>This approach is changing how AI practitioners use our platform. One significant challenge is creating front-end interfaces that consume the agents and models — apps for forecasting demand, generating content, retrieving knowledge or exploring data.</p><p>Larger organisations with dedicated development teams can handle this easily. But smaller organisations often rely on IT teams or our AI experts to build these interfaces, and app development isn’t their primary skill.</p><p>We mitigated this by providing customisable <a href=""https://docs.datarobot.com/en/docs/workbench/wb-apps/app-templates/index.html"">reference apps</a> as starting points. These work if they are close to what you need, but they’re not straightforward to modify or extend. Practitioners also use open-source frameworks like Streamlit, but the quality of these often falls short of enterprise requirements for scale, security and user experience.</p><p>To address this, we’re exploring solutions that use agents to generate dynamic applications — dashboards with complex user interface components and data visualizations, tailored to specific customer needs, all using the DataRobot platform as the back-end. The result is that users can generate production-quality applications in days, not weeks or months.</p><a href=""https://medium.com/media/1c5c875292b4c38002fa61e15fab4140/href"">https://medium.com/media/1c5c875292b4c38002fa61e15fab4140/href</a><p>This shift towards autonomous systems raises a fundamental question: how much control should we hand over to agents, and how much should users retain? At the product level, this plays out in two layers: the infrastructure AI practitioners use to create and govern workflows, and the front-end apps people use to consume them. Our customers are now building both layers simultaneously — guidance agents configure the platform scaffolding while different generative agents build the React-based applications that sit on top.</p><p>These aren’t prototypes — they’re production applications serving enterprise customers. AI practitioners who might not be expert app developers can now create customer-facing software that handles complex workflows, rich data visualization, and business logic. The agents handle React components, layout and responsive design, while the practitioners focus on domain logic and user workflows.</p><p>We are seeing similar changes in other areas too. Teams across the organisation are using new AI tools to build compelling demos and prototypes using tools like<a href=""https://v0.dev/""> V0</a>. Designers are working alongside front-end developers to contribute production code. But this democratization of development creates new challenges; now that anyone can build production software, the mechanisms for ensuring quality and scalability of code, user experience, brand and accessibility need to evolve. Instead of checkpoint-based reviews, we need to develop new systems that can scale quality to match the new pace of development.</p><figure><img alt=""Animated GIF showing an example of a DataRobot front-end application for forecasting talent attrition in a fictional company."" src=""https://cdn-images-1.medium.com/max/1024/1*B-SiD2yK-cUbOq8t-_hkvA.gif"" /><figcaption><em>An example of an app built by our field team using </em><a href=""https://v0.dev/""><em>V0</em></a><em> that leverages agent-aware design system docs.</em></figcaption></figure><h3>Learning from the control paradox</h3><p>There are lessons from our AutoML (automated machine learning) experience that apply here. While AutoML workflows helped democratize access for many users, some experienced data scientists and ML engineers felt control was being taken away. We had automated the parts they found most rewarding — the creative, skilled work of selecting algorithms and crafting features — while leaving them with the tedious infrastructure work they actually wanted to avoid.</p><figure><img alt=""Screenshot of the DataRobot user interface from approximately 2012, showing data uploded an a ‘start’ action button."" src=""https://cdn-images-1.medium.com/max/1024/1*LGiOcy4h1eOCe6MHiFmaiA.png"" /><figcaption><em>Earlier version of the DataRobot UI that focused on democratizing access to machine learning</em></figcaption></figure><p>We’re applying this lesson directly to how we build agentic applications. Just as AutoML worked when it automated feature engineering but not always model interpretation, our customers will succeed when agents handle UI implementation while AI/ML experts retain control over the agentic workflow design. The agents automate what practitioners don’t want to do (component wiring, state management) while preserving agency over what they do care about (business logic, user experience decisions).</p><p>Now, with agentic AI, this tension plays out at a much broader scale with added complexity. Unlike the AutoML era when we primarily served data scientists and analysts, we now target a broader range of practitioners including App developers who might be new to AI workflows, along with the agents themselves as end users.</p><p>Each group has different expectations about control and automation. Developers are comfortable with abstraction layers and black-box systems — they’re used to frameworks that handle complexity under the hood, but they still want to debug, extend, and customise when needed. Data scientists still want explainability and intervention capabilities. Business users just want results.</p><p>But there’s another user type we’re designing for: the agents themselves. This represents a fundamental shift in how we think about user experience. Agents aren’t just tools that humans use — they’re collaborative partners that need to interact with our platform, make decisions, and work alongside human practitioners.</p><figure><img alt=""Visual representation of the different DataRobot practitioner archetypes, mapped along a vertical axis of ‘code maturity’ and a horizontal axis of ‘AI/ML maturity’."" src=""https://cdn-images-1.medium.com/max/1024/1*xnKXPra7MJxuwjYOzHsKPg.png"" /><figcaption><em>Overview of the users who interact with the DataRobot platform</em></figcaption></figure><p>When we evaluate new features now, we ask: will the primary user be human or agent? This changes everything about how we approach information architecture, API design, and even visual interfaces (if required). Agents need different types of feedback, different error handling, and different ways to communicate their reasoning to human collaborators.</p><p>Looking ahead, it’s possible agents may emerge as primary users of enterprise platforms. This means designing for human-agent collaboration rather than just human-computer interaction, creating systems where agents and humans can work together effectively, each contributing their strengths to the workflow.</p><h3>From designing flows to architecting systems</h3><p>These changes challenge fundamental assumptions about what a product <em>is</em>. Traditionally, products are solutions designed to solve specific problems for defined user groups. They usually represent a series of trade-offs: teams research diverse user needs, then create single solutions that attempt to strike the best balance of multiple use cases. This often means compromising on specificity and simplicity to achieve broader appeal.</p><p>Generative AI has already begun disrupting this model by enabling users to bypass traditional product design and development processes entirely. Teams can now get to an approximation of an end result almost instantaneously, then work backward to refine and perfect it. This compressed timeline is reshaping how we think about iteration and validation.</p><p>But agentic AI offers something more fundamental: the ability to generate products and features on demand. Instead of static experiences that try to serve a broad audience, we can create dynamic systems that generate specific solutions for specific contexts and audiences. Users don’t just get faster prototypes — they get contextually adaptive experiences that reshape themselves based on individual needs.</p><figure><img alt=""Illustration of different product development processs, such as waterfall, agile and AI, using vehicles as an analogy for how they work."" src=""https://cdn-images-1.medium.com/max/1024/1*F5vDEkRuurvkLcRVen8jxQ.png"" /><figcaption><em>How the product development process is evolving with AI. Credit unknown.</em></figcaption></figure><p>This shift changes the role of design and product teams. Instead of executing individual products, we become architects of systems that can create products. We curate the constraints, contexts, and components that agents use to generate experiences while maintaining brand guidelines, product principles, and UX standards.</p><p>But this raises fundamental questions about interaction design. How do affordances work when interfaces are generated on demand? Traditional affordances — visual cues that suggest how an interface element can be used — rely on consistent patterns that users learn over time. Interestingly, AI tools like <a href=""https://cursor.com/"">Cursor</a>, V0, and Lovable address this challenge by leveraging well-established UX frameworks like Tailwind and ShadCN. Rather than creating novel patterns that users need to learn, these tools generate interfaces using robust, widely-adopted design systems that provide familiar starting points. When agents generate interfaces contextually using these established frameworks, users encounter recognizable patterns even when the specific interface is new.</p><p>At DataRobot, we’ve approached this challenge by systematizing our design process and standards as agent-aware artifacts. We’ve converted our Figma design system into machine-readable markdown files that agents can consume directly. Using Claude, we translated our visual design guidelines, component specifications, and interaction principles into structured text that can be dropped as context into AI tools like Cursor, V0, and Lovable.</p><figure><img alt=""Visual represetnation titled  ‘agent aware artifacts’ showing a figma design system on the left, with an arrow pointing to a ‘claude ai’ icon and another pointing to a screenshot of a coding tool with a markdown file loaded, titled ‘design-system.md’ to communicate how design artifacts are being translated into formats for agent consumption."" src=""https://cdn-images-1.medium.com/max/1024/1*HVd30Uc-MS7DzkxPATxsHg.png"" /><figcaption><em>Translating design files into agent-aware artifacts like markdown files.</em></figcaption></figure><p>This approach allows us to maintain design quality at scale. Instead of manually reviewing every generated interface, we encode our design standards upstream, ensuring that agents generate consistent, accessible, and brand-appropriate experiences by default.</p><p>We’re already seeing this in action within DataRobot itself. Our AI Experts use these agent-aware design artifacts when building agentic applications, maintaining design consistency through our systematized guidelines while focusing on the unique business logic and user workflows.</p><h3>What this means for product &amp; design leaders</h3><p>I previously wrote about how the <a href=""https://john-moriarty.medium.com/the-future-of-ai-design-navigating-challenges-and-opportunities-2170c92d80bd?source=friends_link&amp;sk=cfcc997fa7c1de3641bbe6194356f9bf"">boundaries between disciplines are blurring</a>. What shape the product triad will take, or if it remains a triad at all, is unclear. While it’s likely that design will absorb many front-end development tasks (and vice-versa), and some PMs will take on design tasks, I don’t think any roles will disappear <em>entirely</em>. There will always be a need for specialists; while individuals can indeed do a lot more than before, there is only a certain amount of context that we can all retain.</p><p>So while we might be able to execute more, we still need people who can go deep on complex problems along with a level of craft that becomes increasingly valuable as a differentiator. In a world where anyone can create anything, the quality of execution and depth of understanding that comes from specialization will be what separates good work from exceptional work.</p><blockquote><strong>The companies that are going to distinguish themselves are the ones that show their craft. That they show their true understanding of the product, the true understanding of their customer, and connect the two in meaningful ways.</strong></blockquote><p>— <a href=""https://www.youtube.com/watch?v=QaDsk4iH1aw"">Krithika Shankarraman</a> (Product, OpenAI)</p><figure><img alt=""Animated gif showing the traditional product triad of product, engineering and UX design that blurs in and out, suggesting the boundaries between these roles are blurring."" src=""https://cdn-images-1.medium.com/max/1024/1*LcnWd3ZVITmmmsVBgGvAfQ.gif"" /><figcaption>The blurring boundaries of the product triad.</figcaption></figure><p>As these boundaries blur and new capabilities emerge, it’s worth remembering what remains constant. The hard problems remain hard:</p><ul><li>Understanding people and their needs within complex contexts. <br /><em>What unmet needs are we addressing?</em></li><li>Building within interdependent systems and enterprise constraints. <br /><em>Will this work with existing architectures?</em></li><li>Aligning technical capabilities to business value. <br /><em>Is this solving a problem that matters?</em></li></ul><p>Our role as design leaders is evolving from crafting individual experiences to architecting systems that <em>generate</em> experiences. We’re evolving from designing screens to designing systems that can make contextual decisions while maintaining design integrity.</p><p>This changes our methodology fundamentally. Instead of designing for personas or generalised scenarios, we’re designing systems that adapt to individual contexts in real-time. Rather than creating single user journeys, we’re building adaptive frameworks that change pathways based on user intent and behavior.</p><p>User research also evolves: we still need to understand human needs, but now we must translate those insights into rules and constraints that agents can interpret. The challenge isn’t just knowing what users want, but encoding that knowledge to maintain design quality across infinite interface variations.</p><a href=""https://medium.com/media/0adf05b68982681f7579e5f9734e2af3/href"">https://medium.com/media/0adf05b68982681f7579e5f9734e2af3/href</a><p>This fundamental truth doesn’t change — but our methods for translating human understanding into actionable systems do. The uniquely human work of developing deep contextual understanding becomes more valuable, not less, as we learn to encode that wisdom for AI systems to use effectively.</p><h3>Design quality in an agent-first world</h3><p>This shift toward agent-generated experiences creates new design challenges. If agents are creating interfaces on demand, how do you maintain coherence across an organisation? How do you ensure accessibility compliance? How do you handle edge cases that training data didn’t capture?</p><p>We believe that part of the answer lies in creating foundational artifacts that both humans and agents can consume. At DataRobot, we are currently exploring:</p><ul><li>Making documentation agent-aware using formats like <a href=""https://www.anthropic.com/news/model-context-protocol"">MCP</a>, <a href=""https://agents.md/"">agents.md</a> and <a href=""https://langchain-ai.github.io/langgraph/llms-txt-overview/"">llms.txt</a>.</li><li>Converting our design system into foundational markdown files that codify principles and patterns, for use in AI development tools.</li><li>Creating automated checks for UI language, accessibility standards, and interaction patterns.</li></ul><p>This approach enables others in our organisation to build compelling applications with AI tools while adhering to our design system and brand consistency. But here’s the crucial insight: while these AI-generated applications might look impressive, the polish can mask underlying UX challenges. As Preston notes:</p><a href=""https://medium.com/media/1deda45b93d917a65c099af08ac55b7e/href"">https://medium.com/media/1deda45b93d917a65c099af08ac55b7e/href</a><p>AI tools excel at execution, but they don’t replace the difficult UX work required to ensure you’re executing <em>the right thing</em>.</p><p>This creates a new challenge for design teams: when everyone is a builder, how do we ensure we build the right things and ensure we meet quality standards? We’ve struggled with knowing when to lean in. There are times, like creating demos or throwaway prototypes, when it’s fine for design to be less involved. But there are critical moments when our involvement <em>is</em> important, otherwise poor quality experiences can ship to production. Our customers don’t care about how or who created the products they interact with.</p><p>The key is catching issues as far upstream as possible. This means the documentation and enablement materials that guide how people use and customise our templates have become the new ‘products’ our design team is responsible for. By creating thorough agent-aware guidelines and design system documentation, we can ensure higher quality output at scale.</p><p>But we still need quality checks without slowing down the process too much. We’re still learning how to balance speed with standards — when to trust the system we’ve built and when human design judgment is a must have.</p><h3>Riding the wave</h3><p>The last few years have felt like a rollercoaster because they have been. But I believe our job as designers is to lean into uncertainty, to make sense of it, shape it, and help others navigate it.</p><p>Like Cooper in Interstellar, we’ve recognised that what seemed like distant mountains are actually massive waves bearing down on us. The question isn’t whether the wave will hit, it’s already here. The question is whether we’ll be caught off guard or whether we’ll have prepared ourselves to harness its power.</p><p>Here’s what we’ve learned so far at DataRobot, for anyone navigating this transition:</p><ul><li><strong>Embrace the change &amp; challenge orthodoxies</strong><br />Try new tools and workflows outside your traditional lane. As roles blur, staying relevant means expanding your capabilities</li><li><strong>Build systems, not just products</strong> <br />Focus on creating the foundations, constraints, and contexts that enable good experiences to emerge, rather than crafting every detail yourself</li><li><strong>Focus on the enduring hard things</strong><br />Double down on the uniquely human work of understanding needs, behaviours, and contexts that no algorithm can fully grasp.</li><li><strong>Exercise (your) judgment</strong> <br />Use AI for speed and capability, but rely on your experience and values to decide what’s right.</li></ul><p>AI doesn’t make design irrelevant. It makes the uniquely human aspects of design more valuable than ever. The wave is here, and those who learn to harness it will find themselves in an incredibly powerful position to shape what comes next. This isn’t about nostalgia for how design used to work, it’s about taking an optimistic stance and embracing what’s possible with these technologies, doing things and going further than we ever could before. As <a href=""https://www.acquired.fm/episodes/adapting-episode-3-intel"">Andy Grove</a> put it perfectly:</p><blockquote><strong>Don’t bemoan the way things were, they will never be that way again. Pour your energy — every bit of it — into adapting to your new world, into learning the skills you need to prosper in it, and into shaping it around you.</strong></blockquote><p><a href=""https://www.johnmoriarty.me/""><em>John Moriarty</em></a><em> leads the design team at </em><a href=""https://www.datarobot.com/""><em>DataRobot</em></a><em>, an enterprise AI platform that helps AI practitioners to build, govern and operate agents, predictive and generative AI models. Before this, he worked in Accenture, HMH and Design Partners.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eaf6a7180c43"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/from-products-to-systems-the-agentic-ai-shift-eaf6a7180c43"">From products to systems: The agentic AI shift</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/building-trust-in-opaque-systems-ce38cef741b6?source=rss----138adf9c44c---4,1758712552,Building trust in opaque systems,"Building trust in opaque systems

<h4>Why the better AI gets at conversation, the worse we get at questioning it</h4><figure><img alt=""Illustration of a magic 8 ball used as a crystal ball"" src=""https://cdn-images-1.medium.com/max/1024/1*1Hye8aYVK6-cw367zTTNDg.png"" /><figcaption>illustration by author</figcaption></figure><p>How do we know when to trust what someone tells us? In person conversations give us many subtle cues we might pick up on, but when they happen with AI system designed to sound perfectly human, we lose any sort of frame of reference we may have.</p><p>With every new model, conversational AI sounds more and more genuinely intelligent and human-like, so much so that every day, millions of people chat with these systems as if talking to their most knowledgeable friend.</p><p>From a design perspective, they’re very successful in the way they feel natural, authoritative and even empathetic, but this very naturalness becomes problematic as it makes it hard to distinguish when outputs are true or simply just plausible.</p><p>This creates exactly the setup for misplaced trust: trust works best when paired with critical thinking, but the more we rely on these systems, the worse we get at it, ending up in this odd feedback loop that’s surprisingly difficult to escape.</p><h3>The illusion of understanding</h3><p>Traditional software is straightforward — click this button, get that result. AI systems are something else entirely because they’re unpredictable as they can make new decisions based on their training data. If we ask the same question twice we might get completely different wording, reasoning, or even different conclusions each time.</p><p>How this<em> thing</em> thinks and speaks in such human ways, <a href=""https://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html"">feels like magic</a> to many users. Without understanding what’s happening under the hood, it’s easy to miss that those “magical” sentences are ‘simply’ the most statistically probable chain of words, making these systems something closer to a ‘<a href=""https://www.ft.com/content/9029cc1c-4a3f-42ca-9939-f3ef8e8336ae"">glorified Magic 8 Ball</a>’.</p><p>Back in 2022 when ChatGPT opened to public, I was also admittedly mesmerised by it, and after it proved useful in a couple of real-world situations, I started reaching for it more and more, even for simple questions and tasks.</p><p>Until one day I was struggling with a presentation segment that felt flat compared to the rest and asked <a href=""https://claude.com/product/overview"">Claude</a> for ideas on how to make it more compelling. We came up with a story I could reference, one I was already familiar with, but there was this one detail that felt oddly specific, so I asked for the source.</p><figure><img alt=""Screenshot from a conversation with Claude"" src=""https://cdn-images-1.medium.com/max/1024/1*xmUNlpXiOUKjKpgrEXoyMQ.png"" /><figcaption>Part of the conversation with Claude (screenshot by author)</figcaption></figure><p>You can imagine my surprise when Claude casually mentioned it had essentially fabricated that detail for emphasis.</p><p>How I could have so easily accepted that made-up information¹ genuinely unsettled me and became the catalyst for me to really try and understand what I was playing with. What I didn’t know at the time was that this behaviour represents exactly what these systems are designed to do: generate responses that sound right, regardless if they’re actually true or not.</p><h3>Human-like, but not human</h3><p>The core problem when it comes to building trust in AI is that the end goal of these systems (utility) works directly against the transparency needed to establish genuine trust.</p><p>To maximise usefulness, AI needs to feel seamless and natural — nobody wants to talk to a robot, its assistance should be almost invisible. We wouldn’t consciously worry about the physics of speech during conversation, so why should we think about AI mechanics? We ask a question, we get an answer.</p><p>But healthy scepticism requires transparency, which inevitably introduces friction. We should pause, question, verify, and think critically about the information we receive. We should treat these systems as the sophisticated <em>tools</em> they are rather than all-knowing beings.</p><p>The biggest players seem to be solving for trust by leaning into illusion rather than transparency.</p><figure><img alt=""Screenshot from Claude’s interface showing “Gathering my thoughts, be right there…”"" src=""https://cdn-images-1.medium.com/max/1024/1*U3eHtyXa_507Z5yFS_1HwA.png"" /><figcaption>Claude thinking indicator (screenshot by author, Sept 2025)</figcaption></figure><p>One key technique is anthropomorphising the interface through language choices. For example, the many “thinking” indicators that appear while actually just preparing a response, it’s a deliberate attempt at building trust. This works brilliantly because these human-like touches make users feel <a href=""https://www.nngroup.com/articles/anthropomorphism/"">connected and understood</a>.</p><p>However, giving AI qualities like these thinking indicators, conversational tone, personality, and “empathy” creates two subtle yet critical problems:</p><h4>#1</h4><p>Giving AI human-like qualities, makes us lose the uncertainty signals that would normally help us detect when something is off. Humans naturally show <em>knowing what they don’t know</em> through hesitation, qualifying statements (like “I think…” “maybe…”), or simply by admitting uncertainty. These are very <a href=""https://medium.com/personal-growth/epistemic-humility-dont-expect-to-know-enough-to-be-sure-of-anything-b9db217d0299"">helpful signals</a> that let us know when to be more careful about trusting what someone is saying.</p><p>AI systems however, rarely do this — they can sound equally confident whether they’re giving you the population of Tokyo (which they probably know) or making up a detail about a case study (which they definitely don’t know). That’s why detecting a mistake or a “lie” in these cases can be extremely hard.</p><h4>#2</h4><p>On top of this, users <a href=""https://crestresearch.ac.uk/comment/emotional-over-trust-in-ai-technology/"">are more likely to assume the AI will perform better</a> while feeling a deeper connection to it. So we end up trusting it based on how it <em>feels</em> rather than how well it actually works.</p><p>The industry calls this <a href=""https://pair.withgoogle.com/chapter/explainability-trust/"">trust calibration</a>, which is about finding the right level of trust so that users rely on AI systems appropriately, or in other words, in just the right amount based on what those systems can <em>actually</em> do. This is no easy feat in general, but because AI often sounds confident while being opaque and inconsistent, getting this balance right is extremely challenging.</p><p>So how are companies currently attempting to solve this calibration problem?</p><h3>The limits of current solutions</h3><p>As a solution, there’s a lot of talk around <a href=""https://pair.withgoogle.com/chapter/explainability-trust/"">explainability</a>. This refers to turning AI systems’ hidden logic into something humans can make sense of, helping users decide when to trust the output (and more importantly, when not to do so).</p><p>Yet, this information only appears spontaneously in scenarios like medical or financial advice, or when training data is limited. In more routine interactions — brainstorming, seeking advice — users would need to actively prompt the AI to reveal the reasoning (as I had to do with Claude).</p><p>Imagine constantly interrupting a conversation to ask someone where they heard something. The chat format creates an illusion of natural conversation that ends up discouraging the very critical thinking that explainability is meant to enable.</p><p>Recognising these challenges, companies <a href=""https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails"">implement various other guardrails</a>: refusal behaviours for harmful tasks, contextual warnings for sensitive topics, or straight up restriction of certain capabilities. These aim to prevent <a href=""https://www.forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/"">automation bias</a>: our tendency to over-rely on automated systems.</p><p>These guardrails, tho, have significant limitations. Not only are there <a href=""https://futurism.com/researchers-discover-chatgpt-jailbreak"">known workarounds</a>, but they fail to account for how these tools are actually used by millions of people with vastly different backgrounds and technical literacy.</p><p>The contradiction becomes obvious when you notice where warnings actually appear. ChatGPT’s disclaimer that it “can make mistakes. Check important info” sits right below the input field, yet I wonder how many people actually see it, and of those who do, how many take that advice. After all that effort to anthropomorphise the interface and create connection, a small grey disclaimer hardly feels like genuine transparency.</p><figure><img alt=""Screenshot from Claude’s interface showing that Claude can make mistakes"" src=""https://cdn-images-1.medium.com/max/1024/1*a5BFiRLHdhtP7f_sODIvLA.png"" /><figcaption>Although tiny, Claude’s disclaimer appears more contextually within the last reply provided (screenshot by author, Sept 2025)</figcaption></figure><p>Companies invest heavily in making AI feel more human and trustworthy through conversational interfaces, while simultaneously expecting users to maintain critical distance through small warnings and occasional guardrails. The result is that these become another form of false reassurance allowing companies to claim plausible deniability while essentially paying lip service to transparency and trust.</p><h3>Scaffolding over crutches</h3><p>This reveals a fundamental flaw in the current approach: they’re asking users to bear the weight of responsible use while providing tools designed to discourage the very scepticism they require. This, not only contradicts established UX principles about designing for your users’ actual capabilities and contexts, but also ignores how trust is actually formed.</p><p>In fact, trust isn’t built through one single intervention, but rather systematically across many touchpoints. So how might we approach this problem differently?</p><figure><img alt=""Black and white photograph of scaffoldings"" src=""https://cdn-images-1.medium.com/max/1024/0*s_UHoBZqO5j9rTxy"" /><figcaption>Photo by <a href=""https://unsplash.com/@rgaleriacom?utm_source=medium&amp;utm_medium=referral"">Ricardo Gomez Angel</a> on <a href=""https://unsplash.com?utm_source=medium&amp;utm_medium=referral"">Unsplash</a></figcaption></figure><p>A first step, I believe, would be ditching the seamless approach and rethinking friction. What if, instead of treating transparency as friction to reduce, design treated it as a capability to build upon? Instead of hiding complexity to fast-track utility, interfaces could gradually build users’ ability to work effectively with AI systems — eventually teaching them not only how to use them responsibly, but when to trust them as well.</p><p>As a parallel, think scaffolding versus crutches. Current AI systems function more like crutches — they provide so much support that users become dependent on them. Users lean on AI for answers without developing the skills to evaluate them, and much like actual crutches, this helps in the moment but prevents underlying capabilities (critical thinking, in this case) from getting stronger over time.</p><h3>Designing transparency as scaffolding</h3><p><a href=""https://odettejansen.nl/scaffolding-as-a-ux-method-for-designing-better-products/"">In a scaffolding model</a> instead, AI systems could be much more flexible and adaptable so to surface transparency and guidance based on the user’s developing skills and the stakes of the decision.</p><p>For example, we could imagine having different modes. A “learning mode” could surface uncertainty more explicitly within responses — alerts prompting users to verify claims the AI cannot back up directly, or inviting users to take answers with a grain of salt. This could happen in expandable sections so as not to intrude on the conversation flow, and as users interact with these components, the interface could gradually reduce explicit prompts while maintaining the underlying safeguards.</p><figure><img alt=""Interface explorations on how a learning mode could look like"" src=""https://cdn-images-1.medium.com/max/1024/1*WWrWy5pc5syiXJEPP-risg.png"" /><figcaption>Quick and dirty explorations of a “learning mode” (by author)</figcaption></figure><p>For high-stakes decision, the interface could default to maximum transparency, like for example requiring users to verify factual claims with external sources before accessing final outputs. Visual indicators could distinguish between trained knowledge, recent search results, and generated examples, helping users understand where information comes from.</p><p>This approach would treats AI as temporary support that builds user capabilities rather than replacing them, and instead of optimising for immediate task completion, scaffolding design would help fostering long-term competence by helping users develop verification habits and critical thinking skills.</p><figure><img alt=""Screenshot from Gemini showing an inline tip on how to refine images"" src=""https://cdn-images-1.medium.com/max/1024/1*2WR2u7ct_2J1649QW4g5Bg.png"" /><figcaption>Google’s Gemini offers inline tips while images are being generated and then persist them on screen. This type of content is clearly distinguishable from the rest of the conversation and provides useful and contextual information based on the task the user is performing (screenshot by author, Sept 2025)</figcaption></figure><h3>A trade-off worth making</h3><p>Much of this goes against conventional product design principles around maximising ease of use. Adding these steps and indicators might seem like deliberate obstacles to user engagement… because they are, but that’s the point.</p><p>The friction introduced in this case, would serve a different purpose than arbitrary barriers — it’s protective and educational rather than obstructive. If designed mindfully, friction can help users treat AI tools as scaffolding rather than crutches, by developing the judgment skills needed to work safely with these systems.</p><p>That conversation with Claude taught me something crucial about the gap between how these systems are presented and what they actually are. <br />We face a choice between immediate utility while undermining our critical thinking, or building people up rather than making them dependent by accepting some friction as the price of maintaining our ability to think independently. The path forward isn’t avoiding AI, but demanding better design that teaches us to use these tools wisely rather than depending on them entirely.</p><p><strong>Footnotes<br /></strong>¹ <em>I’m aware that my example here is a pretty silly one compared to the amount of misinformation, bad advice and just factually incorrect tidbits people are potentially exposed to everyday through these interactions. But aha moments work in mysterious ways</em></p><p><strong>Suggested reads<br />- </strong><a href=""https://uxdesign.cc/lifting-the-fog-co-constructing-intent-with-ai-agents-fbb503599ac0"">Co-constructing intent with AI agents</a> by <a href=""https://medium.com/u/76a7b6e47e41"">TenoLiu</a><br />- <a href=""https://blog.prototypr.io/the-psychology-of-trust-in-a-world-where-products-keep-breaking-promises-3491fafc5b74"">The Psychology Of Trust In A World Where Products Keep Breaking Promises</a> by <a href=""https://medium.com/u/16993edcb922"">Mehekk Bassi</a><br />- <a href=""https://uxdesign.cc/from-journey-maps-to-control-maps-17aac58b9dd9"">Designing for control in AI UX</a> by <a href=""https://medium.com/u/1e7ee2935e64"">Rob Chappell</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce38cef741b6"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/building-trust-in-opaque-systems-ce38cef741b6"">Building trust in opaque systems</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/interview-with-lan-johnson-senior-designer-at-square-530d9054fde6?source=rss----138adf9c44c---4,1758627064,"Interview with Lan Johnson, Senior Designer at Square","Interview with Lan Johnson, Senior Designer at Square

<figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*gsgg-nvGihveBtvYa0v6UQ.png"" /></figure><p>Lan Johnson is a Senior Product Designer at Square. We met over 10 years ago in 2014 in Dallas, at Tekzenit where we both worked as user experience designers.</p><p>Lan is a military brat and grew up in Japan and South Korea, and Guam. Lan’s father retired in Las Vegas and then they eventually moved to Dallas.</p><p>Lan currently lives in Seattle, Washington with her boyfriend and their dog.</p><p>You can find Lan on <a href=""https://www.linkedin.com/in/lanjhnson/"">LinkedIn</a>.</p><p><strong>What was your journey getting into product design?<br /></strong>I actually started out thinking I wanted to be a graphic designer. I was really into anime as a kid, and when I got my hands on a (very outdated and pirated) copy of Photoshop 6 at around age 11, I was hooked. In high school, I also taught myself how to code, which opened the door to doing small freelance jobs here and there while I was still in school.</p><p>Eventually, I joined a startup in New York, before moving back to Dallas to finish my degree. From there, I spent about 10 years in consulting, working across different agencies and design shops. That period was fun and full of variety, but I found myself missing the feeling of being deeply connected to a single product.</p><p>In 2020, just a few weeks before the pandemic hit, I made the leap to go in-house. I stayed almost two years in that role, and now I’m continuing my journey at Square.</p><p><strong>For better or worse, how do you think your parents, family, or friends influenced how you approach problem solving in your day to day work?<br /></strong>I had to learn how to problem-solve on my own from a young age, which made me very independent. My family moved around a lot, so I was constantly rebuilding my support system and adapting to new cultures. That experience shaped the way I work today — it taught me how to be flexible, resilient, and comfortable walking into unfamiliar environments.</p><p>Those skills came in handy when I moved into consulting. I had no trouble starting conversations, building relationships quickly, and feeling at ease in different rooms. In high school, I went to a Department of Defense school in East Asia with only about a thousand students total from kindergarten through senior year. With so few people, it felt like being in a small startup — you had to be resourceful, self-sufficient, and figure things out because there weren’t always obvious answers. That mindset has carried through into my approach to design and problem-solving today.</p><p><strong>How would you describe your background at Capital One, Project202 and Tekzenit?<br /></strong>Each place was really different and shaped me in unique ways. At Tekzenit, I was just starting out. It was in the telecom space, and honestly, I was still figuring out how to navigate the corporate world while learning an industry that didn’t end up being directly relevant to me later. But it was an important first step.</p><p>At Project202, I had the chance to work across a wide range of industries and clients. For example, I worked with Southwest Airlines, learning how they assign pilots and cabin crew, which gave me insight into complex scheduling and logistics. I also helped JCPenney retrofit their site to be mobile and desktop friendly, back when responsive design was still a big shift. That variety really sharpened my ability to adapt quickly and problem-solve across different domains.</p><p>Capital One was especially interesting because of how structured and unionized their systems were. They had this massive scheduling platform that auto-generated crew schedules, but it always had to be corrected by hand. Once a year or so, pilots and crew reps from the union would come in to review and debate the schedules, approving what worked and pushing back on what didn’t. It gave me a fascinating look into how large-scale systems intersect with human needs and negotiations.</p><p><strong>How would you describe your current role and experience at Square?<br /></strong>Stepping away from management, I joined Square as an individual contributor, and I’m really happy with that shift. At my last four jobs I was in management, so it feels good to be back in the weeds, hands-on with the work again.</p><p>Previously, I worked on identity verification, so moving into printers recently has been a big jump, but a good one. I think what I missed most in management was the craft. In consulting especially, so much of the role was about selling the work and managing stakeholders, rather than actually building. I enjoyed mentoring and growing talent, but I often felt pulled away from the fun of shipping products with a team.</p><p>At Square, I feel like I’ve come full circle. I get to contribute directly, push projects over the finish line, and rediscover the parts of design that made me love this work in the first place.</p><p><strong>What are the biggest challenges you are currently facing at work?<br /></strong>Right now, my biggest challenge is onboarding into the world of printers. There are so many nuances I didn’t anticipate, especially since I focus on food and beverage, where every kitchen has very specific needs for how things run. Navigating those requirements has been a steep but interesting learning curve.</p><p>Another challenge is balancing engineering costs, business priorities, and what’s ultimately best for the end user. Like all teams, we’re constantly deciding whether to patch immediate issues or invest in longer-term fixes that will pay off later. We’re making progress, but it’s definitely a journey.</p><p><strong>What are some ways that you leverage AI in your workflow?<br /></strong>AI is a big focus for us. Our CEO, Jack Dorsey, is very forward-looking when it comes to future technologies like Bitcoin and decentralized identity, so adopting AI has become a company-wide initiative. We use a tool called Goose that allows us to automate some tasks. It saves me from having to wait on a data team to pull stats I can access the information I need instantly, which is incredibly helpful.</p><p>Personally, I also use ChatGPT for writing tasks since it’s just more efficient, and I’ve been experimenting with v0 to prototype. That tool can be a little frustrating at times, but it’s also fun and pushes me to think about design workflows in new ways.</p><p><strong>What are parts of your job where you find using AI unnecessary or inefficient?<br /></strong>AI is mostly useful as a baseline. I don’t rely on it heavily in my day-to-day design work, since it can’t really handle more sophisticated tasks. Where I do find it helpful is when teammates who aren’t as design focused, like PMs, use it to get their ideas across. Even if the output isn’t perfect, it gives us something concrete to react to.</p><p>Recently, I organized a V0 prototyping workshop where participants used AI to create solutions for the same problem. None of the prototypes were perfect, but I was able to pull useful pieces from each. So while AI isn’t my main tool, it does provide a good starting point.</p><p><strong>What are the most important aspects of pitching your design work to stakeholders?<br /></strong>For me, the most important part is setting the right context. I’ve found that when I take the time to explain the problem, why it matters, and the broader landscape we’re working within, stakeholders are naturally more aligned with my design decisions. Jumping straight into the solution can leave gaps, but grounding the conversation in the “why” builds trust and clarity.</p><p>I often include a few introductory slides or notes at the beginning of my Figma files for this reason. It gives everyone a shared foundation and makes the actual design discussion more productive.</p><p><strong>Where do you get your design inspiration from?<br /></strong>I use Dribbble a lot, but lately I’ve been really inspired by the resurgence of 90s aesthetics. I especially love 35mm film because it feels so raw and honest. Square has been leaning into that vibe too, with a stronger focus on photography and visual storytelling that highlights our sellers. I’m excited to see our design move more in that direction.</p><p><strong>What’s one failure or misstep that taught you something invaluable?<br /></strong>I learned a lot during my time at AT&amp;T, which often felt like trial by fire. The work environment was chaotic, and I made the mistake of pushing myself too hard, working while sick, putting in extra hours, and sacrificing balance. In hindsight, none of that effort really mattered, because it wasn’t appreciated and didn’t change the outcome. That experience taught me the importance of work-life balance and setting boundaries.</p><p>I also got my first crash course in corporate politics. I had to learn how to navigate different personalities, especially difficult ones. For example, there was a teammate who constantly needed to feel important, and if you didn’t give him that, he could make things unnecessarily difficult. I eventually figured out how to work through a proxy to get what I needed. As frustrating as it was, it taught me how to manage around egos and still get work done, something I carry with me today.</p><p><strong>When you start on a new design team, where do you spend your time and energy?<br /></strong>When I join a new team, the first thing I do is dig through all the files I can get my hands on: org charts, Figma files, documentation, anything available. That exploration helps me form better questions and makes my one-on-ones more productive.</p><p>I also schedule 1:1s with my core team, partners, and anyone I’ll be working closely with. A lot of those conversations are informal, just getting to know each other on a personal level, which I find really valuable. But when it comes to PMs or engineering leads, I’ll bring specific questions based on what I’ve already uncovered. That way, instead of a vague chat, I walk away with concrete answers or more resources to dive into.</p><p><strong>Do you work on any side projects outside of work?<br /></strong>Lately, I’ve been struggling to enjoy my hobbies the way I used to, but I’ve been trying to make space for them again. Drawing has always been a big part of my creative life; it’s actually what led me into design in the first place. I’m especially drawn to food illustration, and I’ve been experimenting with watercolors, alcohol markers, and colored pencils to get back into it.</p><p>I’ve also been getting into photography. I recently picked up a film camera and I’m looking forward to bringing it with me on upcoming trips to New York and San Francisco. For me, these side projects are less about output and more about reconnecting with the creative activities that inspire me outside of work.</p><p><strong>What are the most important qualities you look for in a design leader?<br /></strong>Humility is the big one. Of course, a good leader should know their craft and be able to guide a team, but at this level those qualities are often a given. What really stands out to me is whether they can say no and whether they can admit when they’re wrong. If a leader can do those two things, chances are they’re strong in the other areas that matter too.</p><p><strong>How do you balance business goals with design integrity when they’re at odds?<br /></strong>I think about it the same way I think about relationships. Compromise alone doesn’t really solve anything. If one side simply gives in, it often leads to resentment. Instead, I try to collaborate closely with the team to understand the trade-offs and find a solution that works for everyone. There are usually many ways to slice an experience: some features can be a fast follow, or we can plan milestones that eventually reach the same outcome in a more balanced way.</p><p>Of course, there are cases where trade-offs are unavoidable, like when legacy code ties everyone’s hands. In those situations, it’s about recognizing the limitation and planning for the larger migration effort that will ultimately make better solutions possible.</p><p><strong>What skills do you find relevant to product design that are not taught in school?<br /></strong>One of the biggest lessons I had to learn early on was how to protect myself in the workplace. As a younger designer, I often felt taken advantage of, and no one had prepared me for that. I always encourage people to read up on employment laws and understand their rights. Ideally, you’ll also have a manager or senior teammate who can help you navigate those situations.</p><p>Another important skill is knowing when not to overwork. In product design, we’re rarely saving lives, so putting in constant overtime doesn’t necessarily create better results. In fact, protecting your peace and maintaining balance makes you a better creative, because good decisions and strong design work come from clarity and energy, not burnout.</p><p><strong>What are the most common aspects in designer portfolios that bother you?<br /></strong>One thing I’ve noticed is that many portfolios still lean on process checklists, showing every step of the design process without really explaining the thinking behind it. What I’m really looking for is decision-making: why you chose a certain methodology, what you learned, where you failed, and the trade-offs you had to make along the way. Every project involves trade-offs, and understanding those is often more valuable than a polished checklist.</p><p>I’ll admit, writing case studies is tough, and I don’t always enjoy it myself. One tip I picked up at Square is to keep a “hype doc,” a running log of your accomplishments, metrics you moved, and decisions you influenced. If you spend even an hour a month updating it, you’ll have a backlog of material that makes writing case studies so much easier later. I struggle to keep it up myself, but it’s an invaluable habit.</p><p><strong>Do you have any tips for designers trying to break into the product design world?<br /></strong>When you’re starting out, the biggest challenge is building work you can actually show in applications. My advice is to pick a problem you personally care about and design a solution end to end. Avoid random problem generators; when the problem is real to you, your work will feel more authentic. You can even use tools like V0 to prototype without needing engineering support, which makes it easier to bring your ideas to life.</p><p>I’ve seen great examples of this. At Tekzenit, one intern designed an app to help their sister manage diabetes. It wasn’t just a design exercise; it was personal and meaningful. Projects like that stand out.</p><p>Beyond the work itself, do your homework. Learn about your rights as an employee, research salary ranges so you can advocate for yourself, and come prepared to interviews. And don’t underestimate the power of networking. Reach out to people on LinkedIn who work at companies you admire and ask for 15–30 minutes of their time. Even better if they’re local, because those connections can turn into ongoing mentorship.</p><p><strong>Have you gotten your jobs through referrals or cold applications?</strong></p><p>Almost every job I’ve had has come through a referral. The one exception was early in my career when I cold-applied to an agency that focused on lawyers. I only stayed there for a few months because the environment was really toxic.</p><p>After that, I started leaning on my network more. I ended up working at the same company as my brother, who needed a WordPress developer, and then moved on to Tekzenit after a referral from JK (our mutual friend), who I had almost hired at my previous role. Later, I joined Project202 by following Andy and Ryan, who I knew from Texas. Building those connections made each transition much smoother than applying cold.</p><p><strong>How do you see the product designer role evolving in the next few years?<br /></strong>I think product design will continue to shift beyond just creating visuals and flows and move more toward empathy and problem-solving. In many ways, our role already overlaps with product management, but we bring a different lens by championing the user. That perspective is still something many organizations struggle to fully embrace.</p><p>AI will likely take on more of the executional work, but I believe the real value of designers will be in weaving stories, framing decisions, and making sure user needs stay at the center. That is the part of the role I do not see being automated anytime soon, and hopefully what will keep us not just relevant but essential.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=530d9054fde6"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/interview-with-lan-johnson-senior-designer-at-square-530d9054fde6"">Interview with Lan Johnson, Senior Designer at Square</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
