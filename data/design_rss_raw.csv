source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/beyond-generative-rise-agentic-ai-user-centric-design/,1769086800,Beyond Generative: The Rise Of Agentic AI And User-Centric Design,"Beyond Generative: The Rise Of Agentic AI And User-Centric Design

Developing effective agentic AI requires a new research playbook. When systems plan, decide, and act on our behalf, UX moves beyond usability testing into the realm of trust, consent, and accountability. Victor Yocco outlines the research methods needed to design agentic AI systems responsibly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/rethinking-pixel-perfect-web-design/,1768903200,Rethinking â€œPixel Perfectâ€ Web Design,"Rethinking â€œPixel Perfectâ€ Web Design

Amit Sheen takes a hard look at the â€œPixel Perfectâ€ legacy concept, explaining why itâ€™s failing us and redefining what â€œperfectionâ€ actually looks like in a multi-device, fluid world."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/smashing-animations-part-8-css-relative-colour/,1768384800,Smashing Animations Part 8: Theming Animations Using CSS Relative Colour,"Smashing Animations Part 8: Theming Animations Using CSS Relative Colour

CSS relative colour values are now widely supported. In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk/) shares practical techniques for using them to theme and animate SVG graphics."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/ux-product-designer-career-paths/,1768212000,UX And Product Designerâ€™s Career Paths In 2026,"UX And Product Designerâ€™s Career Paths In 2026

How to shape your career path for 2026, with decision trees for designers and a UX skills self-assessment matrix. The only limits for tomorrow are the doubts we have today. Brought to you by <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/penpot-experimenting-mcp-servers-ai-powered-design-workflows/,1767859200,Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows,"Penpot Is Experimenting With MCP Servers For AI-Powered Design Workflows

[Penpot](https://penpot.app/?utm_source=SmashingMagazine&amp;utm_medium=Article&amp;utm_campaign=MCPserver) is experimenting with MCP (Model Context Protocol) servers, which could lead to designers and developers being able to perform tasks in Penpot using AI thatâ€™s able to understand and interact with Penpot design files. Daniel Schwarz explains how [Penpot MCP](https://github.com/penpot/penpot-mcp) servers work, what they could mean for creating and managing designs in Penpot, and what you can do to help shape their development."
rss,smashingmagazine.com,https://smashingmagazine.com/2026/01/pivoting-career-without-starting-from-scratch/,1767780000,PivotingÂ Your Career Without Starting From Scratch,"PivotingÂ Your Career Without Starting From Scratch

Most developers spend their days fixing bugs, shipping features, and jumping into the next sprint without even thinking about it. After a while, you begin to ask yourself, â€œIs this still what I want to be doing?â€ This article looks at how you can move into a new direction in your career without starting from scratch, and how the skills you already use, like problem-solving, communication, and empathy, can open new doors."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/desktop-wallpaper-calendars-january-2026/,1767171600,Countdown To New Adventures (January 2026 Wallpapers Edition),"Countdown To New Adventures (January 2026 Wallpapers Edition)

Whether 2026 has already begun as youâ€™re reading this or youâ€™re still waiting for the big countdown to start, how about some new wallpapers to get your desktop ready for the new year? Weâ€™ve got you covered."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-design-for-with-deaf-people/,1767088800,How To Design For (And With) Deaf People,"How To Design For (And With) Deaf People

Practical UX guidelines to keep in mind for 466 million people who experience hearing loss. More design patterns in <a href=""https://smart-interface-design-patterns.com/"">Smart Interface Design Patterns</a>, a **friendly video course on UX** and design patterns by Vitaly."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/giving-users-voice-virtual-personas/,1766484000,Giving Users A Voice Through Virtual Personas,"Giving Users A Voice Through Virtual Personas

Turn scattered user research into AI-powered personas that give anyone consolidated multi-perspective feedback from a single question."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/,1766138400,How To Measure The Impact Of Features,"How To Measure The Impact Of Features

Meet TARS â€” a simple, repeatable, and meaningful UX metric designed specifically to track the performance of product features. Upcoming part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today)."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/smashing-animations-part-7-recreating-toon-text-css-svg/,1765965600,Smashing Animations Part 7: Recreating Toon Text With CSS And SVG,"Smashing Animations Part 7: Recreating Toon Text With CSS And SVG

In this article, pioneering author and web designer [Andy Clarke](https://stuffandnonsense.co.uk) shows his techniques for creating [Toon Text titles](https://stuffandnonsense.co.uk/toon-text/index.html) using modern CSS and SVG."
rss,uxdesign.cc,https://uxdesign.cc/generated-ui-building-a-chatgpt-app-how-top-companies-use-ai-d52bf45b9fcf?source=rss----138adf9c44c---4,1769429605,"Generated UI, building a ChatGPT App, how top companies use AI","Generated UI, building a ChatGPT App, how top companies use AI

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://uxdesign.cc/what-makes-generated-ui-worth-keeping-96b44ade04a1""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*2sFkUJUC8085LgCG.png"" /></a></figure><p>â€œThis is simply a mismatch between how UI is generated in AI tools and how products are actually built. So instead of avoiding constraints such as branding and data, they need to be integrated into the generation process. This way, the UI becomes more valuable and can be used to continue to iterate past a demo or proof of concept (POC)Â phase.â€</p><p><a href=""https://uxdesign.cc/what-makes-generated-ui-worth-keeping-96b44ade04a1""><strong>What makes generated UI worth keeping?</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/b2f44e1879c9"">AllieÂ Paschal</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/what-if-ai-lies-about-you-d5d0697c9604?sk=7e5dbc71e733f7e7bd84f2c116bb1cb5""><strong>What if AI lies about you?</strong></a><strong> â†’</strong><br />How do we correct misinformation before it spreads?<br />By <a href=""https://medium.com/u/8ab653ea27a6"">DaleyÂ Wilhelm</a></li><li><a href=""https://uxdesign.cc/field-notes-from-building-a-chatgpt-app-as-a-non-technical-builder-2b2b1201b65e""><strong>Building a ChatGPT app</strong></a><strong> â†’</strong><br />Field notes from a non-technical builder.<br />By <a href=""https://medium.com/u/a816b22ada01"">FloraÂ Ghnassia</a></li><li><a href=""https://uxdesign.cc/todays-organisations-don-t-have-an-ai-problem-they-have-a-thinking-problem-4ed649c063e8?sk=4db899a1210bb6760ef7a30f3aae3353""><strong>A thinking problem</strong></a><strong> â†’</strong><br />Todayâ€™s organisations donâ€™t have an AI problem.<br />By <a href=""https://medium.com/u/369251176104"">@dalladay</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://aresluna.org/the-hardest-working-font-in-manhattan/?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*q_SrHr2LTxd8uxx9.png"" /></a></figure><p><a href=""https://aresluna.org/the-hardest-working-font-in-manhattan/?ref=sidebar""><strong>The hardest working font in Manhattan</strong></a><strong> â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://dri.es/software-as-clay-on-the-wheel?ref=sidebar""><strong>Software as clay on the wheel</strong></a><strong> â†’</strong><br />â€œWhy? Because carrying everything with you all the time is a great way to stop getting anywhere. If youâ€™re going to work on a problem for hundreds of iterations, things start to pile up. As tokens accumulate, the signal can get lost in noise. By flushing context between iterations and storing state in files, each run can startÂ clean.â€</li><li><a href=""https://veen.com/jeff/archives/coding-agents-design.html?ref=sidebar""><strong>On coding agents and the future of design</strong></a><strong> â†’</strong><br />â€œRecently, many non-developers, myself included, have found that using Claude Code with files locally can be an incredibly effective way to get work done. My social feed is filled with people sharing their use cases: setting the agent to work on an Obsidian vault, managing email and calendars, finally getting value from smart home devices.â€</li><li><a href=""https://terriblesoftware.org/2026/01/05/creating-your-own-opportunities/?ref=sidebar""><strong>Creating your own opportunities</strong></a><strong> â†’</strong><br />â€œTwo things, though. One, complaining about it probably isnâ€™t going to change much. Two, even the best manager in the world can only do so much for you. And sometimes, they just have a big, boring project that you need to do that wonâ€™t do much for your career, but it needs to be doneÂ anyway.â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/feelings-are-the-new-features-5d027a50bdaf?sk=70087e64c763674309c03d6f16bd772b""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*IZGiF0YxfrfApmFo.png"" /></a></figure><p><a href=""https://uxdesign.cc/feelings-are-the-new-features-5d027a50bdaf?sk=70087e64c763674309c03d6f16bd772b""><strong>Feelings are the new features</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/f6e6bae9ccc9"">VadymÂ Grin</a></p><figure><a href=""https://uxdesign.cc/how-i-stopped-worrying-and-learned-to-love-the-terminal-c8914be0e306?sk=24fa35948a78b2acd38b87c0c8eaec5b""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*ExlZA-C4AQs1b6pe.png"" /></a></figure><p><a href=""https://uxdesign.cc/how-i-stopped-worrying-and-learned-to-love-the-terminal-c8914be0e306?sk=24fa35948a78b2acd38b87c0c8eaec5b""><strong>How I stopped worrying and learned to love the terminal</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/7f968435c6b9"">PabloÂ Stanley</a></p><figure><a href=""https://uxdesign.cc/why-instagrams-ad-breaks-feel-worse-than-ads-c53376ca8777?sk=cc0053d1e53cebc26c1fa26ea2b95ec7""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*xSPrG4uDxGg3xGMC.png"" /></a></figure><p><a href=""https://uxdesign.cc/why-instagrams-ad-breaks-feel-worse-than-ads-c53376ca8777?sk=cc0053d1e53cebc26c1fa26ea2b95ec7""><strong>Why Instagramâ€™s ad breaks feel worse than ads</strong></a> â†’<br />By <a href=""https://medium.com/u/8797adcdd8a8"">FabriziaÂ Ausiello</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/how-top-companies-are-using-ai-in-their-design-workflows-d10ec40fb6af""><strong>How top companies use AI</strong></a><strong> â†’</strong><br />Using AI in UX design, Interactions, Motion, &amp; Marketing.<br />By <a href=""https://medium.com/u/b55da24329d6"">PunitÂ Chawla</a></li><li><a href=""https://uxdesign.cc/hyperlegible-sans-a-free-open-source-font-for-accessible-design-7b3c823692fb""><strong>Hyperlegible Sans</strong></a><strong> â†’</strong><br />A free, open-source font for accessible design.<br />By <a href=""https://medium.com/u/a886516f3861"">MatthewÂ Stephens</a></li><li><a href=""https://uxdesign.cc/design-tokens-with-confidence-862119eb819b?sk=a2bb75c70743f654130b884bcde7886b""><strong>Design tokens with confidence</strong></a><strong> â†’</strong><br />Why the W3C design token standard is your new foundation.<br />By <a href=""https://medium.com/u/80cd3f2b2e6e"">Lukas Oppermann</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-mob1"">this weekâ€™s sponsor</a> to support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d52bf45b9fcf"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/generated-ui-building-a-chatgpt-app-how-top-companies-use-ai-d52bf45b9fcf"">Generated UI, building a ChatGPT App, how top companies use AI</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/what-ai-has-done-to-me-as-a-writer-8df51e11e77c?source=rss----138adf9c44c---4,1769423456,What AI has done to me as a writer,"What AI has done to me as a writer

<h4>On stepping away and leaningÂ in.</h4><figure><img alt=""My daughter and dog enjoying a moment of mid-winter sun in our living room"" src=""https://cdn-images-1.medium.com/max/1024/1*g_vT1T-rZIBhhKEika0DIw.jpeg"" /><figcaption>My daughter and dog, enjoying a moment of mid-winter sun in our living room while I writeÂ this</figcaption></figure><p>We donâ€™t talk enough about <a href=""https://medium.com/design-bootcamp/help-ai-is-making-me-feel-too-many-things-3aa1f6126636"">how we feel</a> about creating in the age of AI. I feel a lot, as a writer by profession andÂ heart.</p><p>Iâ€™ve gone through the seven stages of grief with AI a couple ofÂ times.</p><p>Shock. It can write better thanÂ many.</p><p>Denial. Itâ€™s not going to affectÂ me.</p><p>Anger. When my first clients started using it instead of paying me toÂ write.</p><p>Guilt. When I started using itÂ myself.</p><p>Depression. Realizing what itâ€™s done to the quality of writing. Experiencing the downside of giving everybody a cheap tool to post whatever they want, without a human edit, everywhere I scroll. Its impact on the environment, people, theÂ economy.</p><p>Acceptance. I have to deal with it; there is no turningÂ back.</p><p>Hope. Some days, like today, I have a glimmer ofÂ hope.</p><p>Maybe, between the repetitive phrasing and slightly off tone, maybe, somewhere between the word â€œgroundbreakingâ€ and exhaustive punctuation, there it is: an opportunity for writers to claim back theirÂ art.</p><p>To finally separate writing as a <em>tool</em> to create content, from writing, the art, the act itself, theÂ beauty.</p><p>This post is about how to getÂ there.</p><h4>It doesnâ€™t have to be perfect. It has to beÂ real.</h4><p>Iâ€™ve always loved writing, and Iâ€™ve always been frustrated with the number of typos that get away from me. My brain thinks quickly. I hate re-reading what Iâ€™ve written, so it happens. People might think Iâ€™m dumb for correcting typos too late or not at all, especially in the days of auto-correct. But I have embraced the typo. Itâ€™ll be there, maybe next to a comma thatâ€™s in the wrong place, but instead of thinking Iâ€™m no skilled writer, I hope you appreciate that I actually did write that. I didnâ€™t tell a machine to. It came out as intended. It lived aÂ little.</p><p>A lot of our linguistic developments originate from typos and that <em>laziness</em> that makes you not want to write certain words: definitly (how do you spell that?) becomes def, to be honest, becomes tbh, going to gonna, because to cuz. Other changes stem from a word not fully saying what it has to say: girl becomes gurl or giiiirl. Meaning on a â€œif you know you know basisâ€. That <em>if </em>is what makes us human. That nuance is realness.</p><p>A machine simply knows, or itÂ doesnâ€™t.</p><p><strong>How to embrace this</strong>: Apply fewer filters to your own writing and more to the writing youÂ consume.</p><h4>Format matters.</h4><p>For me, the worst thing about AI writing isnâ€™t the takeover of the em dash, or that everything sounds the same, itâ€™s that so much is written that really shouldnâ€™t be. Why write about your rebrand when you can show me? Why tell me about your course when you could just give me a snippet of your teaching?</p><p>With AI, itâ€™s easier to create content that passes most peopleâ€™s bar for whatâ€™s good enough. And so more content is created. We scroll our way through it. We barely take it in. Most of that content shouldnâ€™t be. Or it could be something else. Just because writing is easy doesnâ€™t mean thatâ€™s what you should beÂ doing.</p><p><strong>How to embrace this:</strong> Ask yourself (or your boss) does this have to be? And if yes, how does this have toÂ be?</p><h4>Effort is a goodÂ thing.</h4><p>Imagine writing would take the effort it used to take: coming up with an idea for what you want to put out there. Thinking of what you want to say. Breaking it down into pieces. Structuring it. Finding the right tone. Drafting it. Editing it. Putting parts of yourself in there. Wondering if that sentence comes across right or if you should use a different wordÂ there.</p><p>If this were still the required effort, you might post less. Companies would too: if every piece of content they published still took a few hours to create, sign-off and distribute, theyâ€™d think twice before creatingÂ it.</p><p><strong>How to embrace this</strong>: Remind yourself that effort is good. Keep a personal bar for quality and donâ€™t let the pressure of <em>easier with AI</em> get toÂ you.</p><p>I try to only write stuff that I think is worth the effort. Why would AI changeÂ that?</p><h4>Believe in yourÂ voice.</h4><p>Everything AI writes does sound the same. Itâ€™s recognizable for most. If youâ€™re a writer, you can easily spot the patterns. If you arenâ€™t, you can still senseÂ them.</p><p>Thatâ€™s not inherently a bad thing. AI writing follows certain formats and structures because those have been proven to be easy to read, fast to take in, and drive the point home. Itâ€™s learned from the best: Hemingway to copywriters, accessibility specialists to lyricists.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*JX65AmZNI55dBeyzO-4v-Q.png"" /><figcaption>Just as I was writing this post, I got this suggestion. Ironic, isnâ€™tÂ it?</figcaption></figure><p>The thing is: writing was never supposed to be the sum of its bestÂ parts.</p><p>Writing is meant to be personal.</p><p>Thatâ€™s why even today, companies invest in tone and voice, trying to find a way to create content that feels like them, that others can recognize. Thatâ€™s why you like some writers, and canâ€™t get through a page byÂ others.</p><p>What makes reading AI content tiresome is not the mass; itâ€™s the lack of meaning, intention, personality, and yes, also humility.</p><p><strong>How to embrace this</strong>: Turn off Grammarly, auto-correct, and donâ€™t ask ChatGPT to edit your work. Just write. Edit it yourself or ask a friend or colleague. Make a deliberate effort not to let AI touch your output and (re)learn how <em>you</em> write. And remind yourself: itâ€™s OK to be unsure and say (write)Â that.</p><h4>Exit the machine andÂ consume.</h4><p>Even before AI, I would seek inspiration in the analog. Iâ€˜d read poetry, write some of my own, pen on paper. Iâ€™d read books from various authors about different things, cultures, times: Dostoevsky. Kafka. Didion.Â Kerouac.</p><p>I almost always go back to my favorite recommendation for any writer, <a href=""https://en.wikipedia.org/wiki/Letters_to_a_Young_Poet"">Rilkeâ€™s Letters to a Young Poet</a>, a quick (re)read.</p><p>It works with other forms of media and art too: Ingmar Bergman movies, music from past decades, artÂ museums.</p><p>If you have the means to, go beyond media. Travel. Visit museums. Talk to strangers. Learn a new skill. Cook a complicated meal (not something you found onÂ TikTok).</p><p>Turn off your phone. Itâ€™s going to feel uncomfortable and wrong. Trust me, itâ€™s right. Especially if you want to create something meaningful.</p><p>The internet may be artificial intelligenceâ€™s turf â€“ but thatâ€™s all itÂ has.</p><p>We have everything and everywhere else.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/683/1*cpd2ewynUmYbgwahCIphlw.jpeg"" /><figcaption>Robin Williamsâ€™ character in the Dead Poets Society: â€œBut poetry, beauty, romance, love, these are what we stay aliveÂ fo.râ€</figcaption></figure><h4>AI has made me a greaterÂ writer.</h4><p>Thatâ€™s what itâ€™s done toÂ me.</p><p>Not because it makes my work faster or easier. And not because it suggests different terms or corrects my punctuation. But because it has forced me to create with more intention than ever before. To reconsider each word carefully, to ensure it means what I want it to mean. To think, in every syllable,<em> is thisÂ human?</em></p><p>I write slower now than I have inÂ years.</p><p>Thatâ€™s made meÂ better.</p><p>Itâ€™s helped me separate creating content from <em>creating</em>. Itâ€™s the distinction that makes all the difference.</p><p>In a world held together by doomscrolling and fake news, stepping away is a privilege. Creating isÂ power.</p><p>Allow yourself.</p><p>Nicole is a Content Designer turned Design Director based in Stockholm, Sweden. She potters, writes poetry, and raises little girls in a house by a meadow. You can follow her writing here or get it directly to your inbox via her publication, <a href=""https://eggwoman.substack.com/"">eggwoman</a>. Nicole is on <a href=""https://www.linkedin.com/in/nicoletells/"">Linkedin</a>.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8df51e11e77c"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/what-ai-has-done-to-me-as-a-writer-8df51e11e77c"">What AI has done to me as a writer</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-most-popular-experience-design-trends-of-2026-3ca85c8a3e3d?source=rss----138adf9c44c---4,1769423309,The most popular experience design trends of 2026,"The most popular experience design trends of 2026

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-most-popular-experience-design-trends-of-2026-3ca85c8a3e3d?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2000/1*31CHrk_EB0aCQTOC3Ai6XQ.jpeg"" width=""2000"" /></a></p><p class=""medium-feed-snippet"">In 2026, I&#x2019;m predicting that designing for intent, Machine Experience (MX) design, designing better prompts, and AI generated Design&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-most-popular-experience-design-trends-of-2026-3ca85c8a3e3d?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/how-top-companies-are-using-ai-in-their-design-workflows-d10ec40fb6af?source=rss----138adf9c44c---4,1769193490,How top companies are using AI in their design workflows,"How top companies are using AI in their design workflows

<h4>Using AI in UX design, Interactions, Motion, &amp; Marketing.</h4><figure><img alt=""AI Hat"" src=""https://cdn-images-1.medium.com/max/1024/1*UJH-70_fdENoXr8UHWpGyQ.jpeg"" /></figure><p>Recently top companies have publicly come out to share their processes implemented by senior designers and entire creative teams. Some notable companies like Meta and Atlassian stood out. Not only are these companies building their own AI workflows, but they are spending millions of dollars to train their employees on them. From watching interviews to reading lengthy articles, here is what Iâ€™ve learnt about their carefully crafted AI workflows.</p><h3>Atlassianâ€™s design-to-prototype workflow, powered byÂ AI</h3><figure><img alt=""Atlassian AI workflow"" src=""https://cdn-images-1.medium.com/max/1024/1*4fZ32GccUsAaebh-zYfjBg.jpeg"" /></figure><p>The famous software company has to build large scale tools and software for some of the biggest enterprises in the world. AI is the perfect companion for their team to design and testÂ faster.</p><p>In a recent <a href=""https://youtu.be/CqMZTg7L-wE?si=Nue1uhN51uMVgBJ3"">hands-on session</a> with their design team, the wonderful people at Dive Club who interviewed them, shared exactly the methods that work for them. PS. Itâ€™s all about the balanceÂ here.</p><h4><strong>Using a pre-built template strategy:</strong></h4><p>The Atlassian team realized that AI was often messing up core elements and not completely understanding complex commands. So they created a sort of â€œdesign systemâ€ for their AI led prototyping. Here they feed a page with pre-coded elements which AI doesnâ€™t change, but lets the tool work on other elements which are open to interpretation in aÂ way.</p><h4><strong>They built instruction files:</strong></h4><p>Unlike most designers who just ask AI tools to code in a certain programming language or use a certain framework, their team has created certain instruction files to â€œguide the AIâ€. This instructions file (essentially a text file) might have a specific instruction to use a design system element, variable or certain token in case the AI encounters a certain type ofÂ element.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*u6dpoZI88gIqb_QfvirDcg.png"" /><figcaption>Their template file in Figmaâ€Šâ€”â€ŠThese are written instruction for the AI toÂ follow</figcaption></figure><p>In <a href=""https://youtu.be/CqMZTg7L-wE?si=Nue1uhN51uMVgBJ3"">the interview</a>, their team discusses using tailwind (a CSS framework), but writing specific instructions to <em>only use their own design components</em> in certain areas. This is essentially an <strong>over-ride instruction</strong>, where the AI skips certain actions in order to fulfill theirÂ prompts.</p><h4>Recipes over hardÂ work:</h4><p>A complex business like Atlassian requires simplified workflows to make life easier. The team just uses the copy-paste strategy to add pre-baked instructions to their prompts. The team talks about how most of their products consists of a dark mode switch. So, whenever they prototype a new page or product, they just add a dark mode switch command in their prompts. Itâ€™s barbaric, but itÂ works!</p><h4>They calibrate AI to seeÂ better:</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*8yxOdybbjgNqV-x8RFV7IQ.png"" /><figcaption>Calibrating the AI to learn their style &amp; components</figcaption></figure><p>Custom software production needs custom AI. When training their AI, they feed their design elements in and ask the AI what it sees. If the AI is accurate they move on, but if the AI gets an element wrong, they correct it to avoid future issues. This also fixes the screenshot-to-code conversion that they use in theirÂ company.</p><h3>Designers at Meta are adopting AI at allÂ levels</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/780/0*RXUAbEMhSvc9JSHL.jpg"" /></figure><p>A slew of designers across different departments at Meta are scrambling to incorporate AI and supercharge their workflows. Theyâ€™ve stated how AI currently is only for mundane tasks, while manual human-centered processes rule the more important steps like user research and strategy.</p><h4>Automating execution:</h4><p>VP of monetization designâ€Šâ€”â€Š<a href=""https://medium.com/u/474193af24c"">(JJ) Jhilmil Jain</a> states how designers at meta are using AI for generating quick screens and even coded components for better hand-off. However, they are focused on more manual, age-old ways of working when it comes to product intuition and strategy. They are also more focused on the userâ€™s POV to ensure they are going in the correct direction. You should check out her articleÂ <a href=""https://medium.com/@jhilmil.jain/how-ai-is-reshaping-product-design-leadership-and-what-to-do-about-it-9125d5af750c"">here</a>.</p><h4>Using playbooks for better adoption:</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*o5ZkX2r-PSlbiRaru_XQyA.jpeg"" /><figcaption>Companies are using Metaâ€™s Llama model to customize AI workflows</figcaption></figure><p>Much like Atlassian, they are building sets of instructions and playbooks for designers to follow when using AI. Recording and documenting processes early and setting a standard has beenÂ crucial.</p><h4>Changing roles:</h4><p>A product manager at Meta recently shared how his role at the company has shifted from a generic PM to a true product owner. Being able to give code has given him â€œsuperpowersâ€, he explained on aÂ <a href=""https://open.spotify.com/episode/3XBzlIzna8dZP2l32NZGfs?si=8nvqBeuTR7WcT0LoiJCqzQ&amp;context=spotify%3Ashow%3A2dR1MUZEHCOnz1LVfNac0j&amp;t=0"">podcast</a>.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*JVCSIVgsiImYp69ou82Xsw.png"" /><figcaption>Zevi Arnovitz with Lenny showcasing his workflow inÂ Claude</figcaption></figure><blockquote>His statement saying, â€œeveryone is going to be a builderâ€ stood out toÂ me.</blockquote><p>He further dives deeper by sharing that he now sets up the basic UI design and vibe codes a concept to handover to the developers directly. He clarifies that heâ€™s only taking over smaller tasks rather than completely removing designers from the equation. According to the PM, a majority of roles at these companies are collapsing, and one person needs to do muchÂ more.</p><h3>Tesco designers are vibe coding their own FigmaÂ plugins</h3><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/750/1*G_-I9J7BZXsjYVEN3z1P5g.png"" /><figcaption>Tesco is publicly using Adobe AI &amp;Â Firefly</figcaption></figure><p>In a <a href=""https://youtu.be/ISoolpPvIyU?si=IdNcG_8w8KqCeLz2"">recent interview</a> with Tescoâ€™s senior designer, it was revealed that they developed their own powerful Figma plugins to get the most out of theÂ tool.</p><p>Theyâ€™ve created a Figma plugin that connects directly to the data of their website. So whenever the team wants to populate their prototypes with real data, the plugins fetches information from their live websiteâ€Šâ€”â€Šimages, product descriptions, ratings, etc. and inserts it into different UI components at once. This saves so much time and also keeps the designs true to the actual products listed on their platforms.</p><figure><img alt=""Tesco senior designer creates his own Figma plugin"" src=""https://cdn-images-1.medium.com/max/1024/1*D2XbNH53ioSntV8ruqzbJA.png"" /><figcaption>Tesco senior designer showcasing his internalÂ plugins</figcaption></figure><p>The designer reveals the tools that he usedâ€Šâ€”â€ŠCursor for vibe coding, and the Figma MCP server to ensure that the results stay onÂ brand.</p><p>I actually explored building my own Figma plugin myself, check the video out if that is something youâ€™re interested inâ€Šâ€”â€Š<a href=""https://youtu.be/A0lCwgRtAWU?si=wgkKqphagto149Av"">watchÂ video</a>.</p><h3>Designers at Faire are researching usingÂ AI</h3><figure><img alt=""Faire AI"" src=""https://cdn-images-1.medium.com/max/1024/0*yspmjJDFNZzSGx1a"" /><figcaption>Large data requires AI filtering atÂ Faire</figcaption></figure><p>Faire is a popular platform that connects wholesale retailers to customers, and research is an absolute necessity for them. The quality of research data defines their future in aÂ way.</p><p>In a detailed <a href=""https://craft.faire.com/leveraging-ai-in-design-work-464f0f39922e"">Medium article</a>, Jess Brown reveals the techniques they use at the company to gather data and connect with usersÂ faster.</p><h4>Implementing AI Chat-bots</h4><p>The team released an AI chat-bot called Fairey for internal purposes, which can quickly fetch user queries and tickets and help them make out the problems and issues being faced by their users from a distance. She states that whenever she has a question about their users or brands working with them, they just ask the chat-bot. A good example of these questions isâ€Šâ€”â€Šâ€œ<em>Can you find support tickets from brands about our Top Shop program in the last six months?</em>â€.</p><figure><img alt=""Faire team at Toronto Tech Week"" src=""https://cdn-images-1.medium.com/max/1024/0*W_pQi8zsxLxS13GQ"" /><figcaption>The Faire team at Toronto Tech Week revealing their use ofÂ AI</figcaption></figure><p>This is a great way to do primary UX research, without the hassle of reaching out to customers directly or doing expensive interviews. Since they have such a vast set of customers from different regions and use cases, the chat-bot helps filter out the right information.</p><h4>Raw Data to ReadableÂ Content</h4><p>Now synthesizing interviews can be a long process, sometimes taking more time than actually collecting data. This laborious task was replaced at Faire with ChatGPT with a security layer of course. Whenever they conduct real interviews, the transcript data is inserted into the tool, and a concise prompt is given to get organized information.</p><p>Here is what a <strong>prompt template</strong> at Faire looksÂ like:</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*IM5DT2rDMJRoj2EdEO9LrA.jpeg"" /></figure><p>This is a series I intend to keep on doing, so make sure you <a href=""https://medium.com/@punitweb"">follow me</a> for more articles likeÂ this!</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d10ec40fb6af"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/how-top-companies-are-using-ai-in-their-design-workflows-d10ec40fb6af"">How top companies are using AI in their design workflows</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/how-i-stopped-worrying-and-learned-to-love-the-terminal-c8914be0e306?source=rss----138adf9c44c---4,1769170864,How I stopped worrying and learned to love the terminal,"How I stopped worrying and learned to love the terminal

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-i-stopped-worrying-and-learned-to-love-the-terminal-c8914be0e306?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1200/0*Zm8niOLMIbn-PB2A.jpeg"" width=""1200"" /></a></p><p class=""medium-feed-snippet"">From a designer who started using the CLI instead of traditional design tools</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-i-stopped-worrying-and-learned-to-love-the-terminal-c8914be0e306?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/field-notes-from-building-a-chatgpt-app-as-a-non-technical-builder-2b2b1201b65e?source=rss----138adf9c44c---4,1769170847,Field notes from building a ChatGPT app as a non-technical builder,"Field notes from building a ChatGPT app as a non-technical builder

<h4>What it really takes to build a product inside ChatGPT while the ecosystem is still forming (and without an engineering team)</h4><figure><img alt=""Illustration of a hand pressing the ChatGPT logo, surrounded by abstract shapes, nodes, and connecting lines on a blue background, suggesting interaction within a networked system."" src=""https://cdn-images-1.medium.com/max/1024/1*0B3_mRr5_B3ZZYMtsXm6RA.png"" /></figure><h3>Building in a space that doesnâ€™t existÂ yet</h3><p>A ChatGPT app isnâ€™t an app in the way weâ€™ve learned to think about software.</p><p>It doesnâ€™t ship with a standalone interface or a familiar navigation model. It lives inside a conversational surface, where <a href=""https://blog.uxtweak.com/conversational-ux/?utm_source=chatgpt.com"">language, intent, and orchestration shape how a product is experienced</a> just as much as UI does. Still, companies are moving quickly to integrate, sensing that showing up inside these systems will soon be table stakes for discovery.</p><p>The moment feels familiar. In the early 2010s, <a href=""https://resources.latana.com/post/mobile-first-brands-level-up/"">teams rushed to become mobile-first</a> before fully understanding what mobile would demand of product, design, or infrastructure. Large language models are triggering a similar shiftâ€Šâ€”â€Šexcept this time the interface is conversational, the distribution layer is centralized, and many of the constraints are still undefined.</p><p>Participating in this new layer requires more than exposing an API. Products need a way to express what they do, how they should be used, and under which conditions they should be invoked. <a href=""https://getsquid.ai/blog/what-are-mcps"">MCP</a>s are one emerging attempt to make products legible to language models, though the standard itself is still takingÂ shape.</p><figure><img alt=""Modal titled â€œNew Connector (Beta)â€ with fields for name, description, MCP server URL, authentication type set to OAuth, and a warning indicating the connector is not verified."" src=""https://cdn-images-1.medium.com/max/1024/1*vuiQNBn2oJH3kx0Ndm_1Rg.png"" /><figcaption>Adding connectors in ChatGPT developer mode. Full breakdown of stepsÂ <a href=""https://platform.openai.com/docs/guides/developer-mode"">here</a></figcaption></figure><p>What stands out most is how early this ecosystem feels.</p><p>Tools are appearing faster than shared mental models. Founders are building in parallel toward very different interpretations of what a â€œChatGPT integrationâ€ actually is. For non-technical buildersâ€Šâ€”â€Šdesigners, product thinkers, operatorsâ€Šâ€”â€Šthe promise of access exists alongside real uncertainty about control, responsibility, andÂ realism.</p><p>This article is a set of field notes from trying to build a ChatGPT app early, without a technical background, while the space itself is still inÂ flux.</p><h3>A platform shift that pulled meÂ in</h3><p>I started paying attention to this space out of curiosity more thanÂ mandate.</p><p><a href=""https://openai.com/index/developers-can-now-submit-apps-to-chatgpt/"">When OpenAI released the ChatGPT app ecosystem</a> to direct submissions in Dec 2025, it felt like the opening of a new product surfaceâ€Šâ€”â€Šone that would quietly reshape how discovery works and how products are understood. Conversational interfaces were no longer just answering questions; they were influencing what users saw, compared, and actedÂ on.</p><figure><img alt=""ChatGPT â€œApps (Beta)â€ directory screen showing a featured â€œCreate with Canvaâ€ card, category tabs, and a list of integrated apps such as Adobe Photoshop, Airtable, and Booking.com."" src=""https://cdn-images-1.medium.com/max/1024/1*97ppIXhA8gP73ShHZ0l6qA.png"" /><figcaption>ChatGTPâ€™s Apps directory as of DecÂ 2025</figcaption></figure><p>It was obvious that <a href=""https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-agentic-commerce-opportunity-how-ai-agents-are-ushering-in-a-new-era-for-consumers-and-merchants?utm_source=chatgpt.com"">surfacing inside ChatGPT would matter, and quickly</a>. Not as a simple presence, but as a product that could be interpreted, ranked, and differentiated within a conversational flow.</p><p>I wanted to understand what that actually meant in practice.</p><p>Rather than speculating from the outside, I started exploring the space by trying to build something concrete: a prototype that behaved like a real app inside ChatGPT, constrained by its strict UX &amp; UI guidelines, its invocation patterns, and itsÂ rules.</p><figure><img alt=""Flow mapping document titled â€œProduct selection &amp; handoff,â€ showing a multi-row UX analysis with labeled sections, notes, and a large embedded property listing interface on the right."" src=""https://cdn-images-1.medium.com/max/1024/1*NmpIfEnyO5qXNr0ppEOuGg.png"" /><figcaption>My initial research led my to observe &amp; analyze flows and patterns of behavior around the very first ChatGTP partner apps (hereÂ Zillow)</figcaption></figure><p>That exploration pulled me into an ecosystem I didnâ€™t fully understand yet, but one that felt important to experience from theÂ inside.</p><h3>The constraint: moving fast without being technical</h3><p>I approached this as a product designerâ€Šâ€”â€Šsomeone whose value comes from shaping behavior and orchestrating systems, not writing production code. That constraint became clarifying: it forced me to focus on the product questions that actually mattered. At the start, my mental model was incomplete: I didnâ€™t yet understand where code actually lived, how APIs differed from MCPs, or how invocation worked once a product entered a conversational system.</p><p>What I did have was urgency, and a strong drive to understand theÂ space.</p><p>Waiting for engineering availability wasnâ€™t realistic. No-code tools became leverageâ€Šâ€”â€Ša way to maintain velocity while the ecosystem was stillÂ forming.</p><p>I expected the process to be relatively fluid. That these tools would absorb complexity and make experimentation easier.</p><p>Instead, I encountered a fast-growing ecosystem full of ambition, pressure, and partial solutions. Many platforms promised to bridge the gap between non-technical builders and ChatGPT integration. Very few actually reduced the friction involved.</p><h3>Entering the frontier: a fragmented ecosystem</h3><p>My exploration started with a straightforward question: which tools could realistically help me export an MCP and demo a functioning ChatGPTÂ app?</p><p>I did my due diligences and experimented first with general no-code and AI-assisted platforms like <a href=""https://cursor.com/agents"">Cursor</a> and <a href=""https://lovable.dev/"">Lovable</a> in order to get a reference.</p><p>Cursor, while powerful, assumed familiarity with local development environments, file systems, and publishing semantics that werenâ€™t obvious without a development background. â€œNo-codeâ€ didnâ€™t remove complexityâ€Šâ€”â€Šit required architectural intuition most designers simply do not have. The recent emergence of various <a href=""https://adplist.notion.site/cursor-for-designers"">courses</a> &amp; <a href=""https://www.youtube.com/watch?v=faezjTHA5SU"">tutorials </a>explicitly aimed at making Cursor more approachable to designers reinforces that this gap is structural, not personal.</p><figure><img alt=""Screenshot from a marketing video displaying a Cursor interface, with a design inspector panel open on the right showing component properties, and an embed chat UI panel on the left."" src=""https://cdn-images-1.medium.com/max/1024/1*4j2r_Pa-lBy5prbKnf0q_g.png"" /><figcaption>Cursor introduces their <a href=""https://cursor.com/blog/browser-visual-editor"">visual editor</a> end of 2025 in an attempt to make its software more accessible to non-coders</figcaption></figure><p>Lovable, as I had rightfully assumed, assisted in creating beautiful and realistic enough visuals when carefully prompted but never could extend beyond the role of ingenious prototype.</p><p>I then quickly moved on to exploring several early platforms attempting to solve this problem specifically, including <a href=""https://chippy.build/"">Chippy</a>, <a href=""https://fractalmcp.com/"">Fractal</a>, <a href=""https://noodleseed.com/"">NoodleSeed</a> and <a href=""https://manifest.build/"">Manifest</a>.</p><figure><img alt=""Four landing pages arranged in a grid, each promoting tools for building or deploying apps inside ChatGPT, with headings, call-to-action buttons, and product interface previews."" src=""https://cdn-images-1.medium.com/max/1024/1*TeDhUZwtkXCTyugG8cQgMw.png"" /></figure><p>In conversations with <a href=""https://www.linkedin.com/in/colinmatthews-pm/"">Colin Matthews</a>, founder of <a href=""https://chippy.build/"">Chippy</a> and instructor at <a href=""https://maven.com/tech-for-product/ai-prototyping-for-product-managers"">Maven</a>, he described the value as enabling teams to â€œexport code, view sharable specs, and run evals directly within the platform to facilitate cross-functional handoffs.â€ That made sense for what I was trying to doâ€Šâ€”â€Šbridging design intent and implementation without owning production code.</p><p>Each of these emerging tool approached the problem differently. Some were strong on prototyping but struggled when pushed toward something deployable. Others required a level of technical investment that conflicted with my constraints. A few were promising but blocked by access limitations, incomplete products, or early-stage instability.</p><p>Nearly everything I tried was inÂ beta.</p><p>Platforms were buggy. Context was frequently lost. Documentation was thin. Many tools assumed users already knew how to prompt effectively, how to reason about conversational flows, or how to debug hallucinations when thingsÂ broke.</p><p>Alongside the tooling, I spent time talking directly with founders building in this space. Those conversations became just as informative as the products themselves.</p><p>Even when tools looked similar on the surface, the underlying visions were very different. Builders had conflicting ideas on who the primary user was, what MCPs should represent, and whether this layer was fundamentally about infrastructure, product creation, or distribution.</p><p>You could feel that divergence in how each platformÂ behaved.</p><h3>Where thingsÂ broke</h3><p>As I kept experimenting, patterns began toÂ repeat.</p><p>Hallucinations showed up in different formsâ€Šâ€”â€Šincluding code that looked convincing but simply didnâ€™t hold up. Some abstractions accelerated early progress, only to break under real constraints. Context loss meant restating intent again andÂ again.</p><p>In several cases, MCPs appeared to work inside builder environments but failed to surface at all inside ChatGPT. In others, the system repeatedly reported successâ€Šâ€”â€Šchanges â€œapplied,â€ actions â€œcompletedâ€â€Šâ€”â€Šwhile nothing had actually changed. Debugging became conversational: repeatedly prompting the system to self-diagnose. When that failed, progress depended on reaching out directly to founders to investigate issues that werenâ€™t visible from theÂ surface.</p><figure><img alt=""Split screen showing an error message while creating a custom connector on the left, and a ChatGPT conversation on the right explaining that live event data cannot be verified."" src=""https://cdn-images-1.medium.com/max/1024/1*tKa5E30Fiwa0arbzoYTF2w.png"" /><figcaption>Left: MCP fails to connect altogether despite numerous attempts at self-diagnosis | Right: Although app is connected it fails to respond whenÂ invoked</figcaption></figure><p>These issues arenâ€™t unique to any one tool. Theyâ€™re <a href=""https://openai.com/index/why-language-models-hallucinate/"">well documented</a> across current LLM platforms and early-stage developer tooling, particularly when systems rely heavily on generative output without strong validation layers.</p><p>The harder part was understanding where responsibility sat.</p><p>When behavior deviated from expectations, it wasnâ€™t obvious whether the issue came from the platform, the MCP configuration, or the tool itself. There was very little support for reasoning across thoseÂ layers.</p><p>I also realized that I had more influence than I initially thoughtâ€Šâ€”â€Šover ChatGPT-native layout, conversational flow, and follow-up questionsâ€Šâ€”â€Šbut that influence was rarely surfaced clearly. It lived behind structured inputs and assumptions that were easy to miss if you didnâ€™t already know they existed. That realization forced me to get more deliberate about what I was actually optimizing for.</p><h3>How I learned toÂ choose</h3><p>Facing this level of fragmentation and instability, I needed a way to evaluate what actually mattered.</p><p>I stopped optimizing for comprehensiveness and started optimizing for learning velocity. That shift required being explicit about tradeoffsâ€Šâ€”â€Šwhat I was willing to sacrifice and what IÂ wasnâ€™t.</p><p>The framework thatÂ emerged:</p><p>Speed to behavioral validation over perfect infrastructureâ€Šâ€”â€ŠI cared more about seeing how something behaved in ChatGPT than building it â€œcorrectly.â€ Mock data, hardcoded responses, simplified flowsâ€Šâ€”â€Šwhatever got me to a testable embedded interaction fastest.</p><figure><img alt=""Split screen showing screengrab from various softwares. User flow diagram titled â€œUser Flowsâ€Šâ€”â€Šâ€˜show me eventsâ€™,â€ illustrating interactions between a user, ChatGPT, a public tool, and a mock events service, with steps labeled read, invoke, and render."" src=""https://cdn-images-1.medium.com/max/1024/1*XviqEjJpD5X8LC5TEPxNLQ.png"" /><figcaption>Top left: I limited my toolset to 6 in Fractal | Top right: I created one simple flow using Chippy | Bottom: I mimicked a mock checkout flow inline throughÂ Manifest</figcaption></figure><p>Conversational coherence over feature completenessâ€Šâ€”â€ŠA narrow interaction that felt natural mattered more than a wide feature set that felt mechanical. Iâ€™d rather ship one well-orchestrated flow than ten that worked but felt boltedÂ on.</p><p>Debuggability over abstraction eleganceâ€Šâ€”â€ŠWhen something broke, I needed to understand why. Tools that hid complexity behind beautiful abstractions became liabilities. I favored visibility, even if it meant more manualÂ work.</p><p>This hierarchy shaped everything: which tools I abandoned, which compromises I accepted, and how I structured the interaction modelÂ itself.</p><h3>Patterns that emerged across tools and conversations</h3><p>Looking across tools and conversations, a few themes stoodÂ out.</p><p>Guidance was mostly under-designed. Many platforms offered powerful capabilities but assumed a level of prompt literacy and architectural intuition that designers donâ€™t naturally start withâ€Šâ€”â€Šand that the tools themselves didnâ€™tÂ teach.</p><p>â€œNo-codeâ€ didnâ€™t remove the need for systems thinking. It redistributed it. I found myself reasoning about flows, tool invocation, compliance, system architecture and boundaries, even without writing production code.</p><figure><img alt=""Dashboard-style interface showing six configuration panels labeled Attachments, Connectors, Filters, Model management, Modes, and Parameters, each describing options for controlling data sources, model selection, interaction modes, and prompt settings."" src=""https://cdn-images-1.medium.com/max/1024/1*tqfV5fo1MGgNWpJ9KDLfdg.png"" /><figcaption>Tuners, as described by <a href=""https://www.linkedin.com/in/emmiecampbell/"">Emily Campbell</a> in the <a href=""https://www.shapeof.ai/"">Shape ofÂ AI</a></figcaption></figure><p>The biggest source of friction was translation. Enterprise assetsâ€Šâ€”â€ŠAPIs, design systems, UI kits, brand and photography guidelinesâ€Šâ€”â€Šarenâ€™t LLM-ready by default. Converting them into something that could be safely and predictably invoked required manual judgment at nearly everyÂ step.</p><p>ChatGPT<a href=""https://developers.openai.com/apps-sdk/concepts/ui-guidelines/""> UI guidelines</a> added another layer of ambiguity. It wasnâ€™t always clear what was disallowed, what was risky, and what simply needed adaptation. Validating those decisions ahead of review remained difficult, even when an app appeared to work. That ambiguity isnâ€™t accidentalâ€Šâ€”â€Šit reflects a space where standards, responsibilities, and even product definitions are still being negotiated.</p><figure><img alt=""Slide showing a question about implementing brand colors in ChatGPT UI, alongside two panels outlining a â€œBrand Colorsâ€Šâ€”â€ŠImplementation Plan,â€ with color tokens, SDK-compliant areas, gray areas, and sections marked â€œkeep as-is.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*LM8ZeYvQmVFZ_3zSyWOlWg.png"" /><figcaption>Screenshot from Chippy illustrating ambiguity in ChatGPT UI compliance due to unclear SDK guidance.</figcaption></figure><p>At the same time, it became obvious that the space hasnâ€™t converged yet. Founders are building toward different futures, and that lack of alignment shows up directly in the products.</p><h3>What the workflowÂ revealed</h3><p>Over time, I stopped expecting the tools to define the experience forÂ me.</p><p>Progress came from taking ownership of the interaction model: deciding which results to surface, how they should appear, and what kind of conversational path felt intentional rather than reactive. I worked with mock data instead of real APIs to focus on behavior beforeÂ scale.</p><p>Visual control required additional effort. UI components &amp; the data they should contain were thought through and designed separately, exported as structured assets, and reintroduced into the platforms to better align with each productâ€™s unique requirements.</p><figure><img alt=""Side-by-side comparison of two content cards, one showing restaurant listings with images, ratings, addresses, and selectable reservation times, and the other showing hotel listings with photos, review scores, amenities icons, pricing per stay, and â€œView on Booking.comâ€ buttons."" src=""https://cdn-images-1.medium.com/max/1024/1*9SgFgdIcq_QK1bwFx6iDEw.png"" /><figcaption>Left: ChatGTPâ€™s inline carousel widget template | Right: Booking.comâ€™s interpretation</figcaption></figure><p>Testing always happened inside ChatGPT itself. Differences between builder environments and real platform behavior were common, and those gaps often surfaced the mostÂ insight.</p><p>What this workflow ultimately revealed was less about process and more about role. Building in this space required judgment across design, systems, and platform interpretation. The work sat somewhere between product design and infrastructure awareness, even without owning production code.</p><h3>What this shift changes about who gets toÂ build</h3><p>This experience clarified something: the line between â€œproductâ€ and â€œtechnicalâ€ work is dissolving.</p><p>In an informal conversation I had with <a href=""https://www.linkedin.com/in/noamsegal/"">Noam Segal</a>â€Šâ€”â€ŠAI Insights Lead at Figmaâ€Šâ€”â€Šhe framed it simply: â€œdesigners in this space have to agree to tinker, fail often, and share those failures in order to learn.â€ Even without owning production code, I had to understand how tools connect, how data flows, and how decisions propagate through an LLM-driven product. These arenâ€™t optional skills for designers working in AIâ€Šâ€”â€Štheyâ€™re foundational.</p><p>Prompting felt less like creative expression and more like intent specification. Over time, it became clear that this skill will likely be absorbed into tooling rather than remain a standalone practice.</p><p>For designers, this shift is significant. The work moves away from static artifacts and toward shaping behavior in uncertain systems. Comfort with experimentation, ambiguity, and failure matters more than deep mastery of any singleÂ tool.</p><p>Finally, product leadership too, is shifting. Outcomes matter more than mechanics. Adaptability matters more than precedent. And direct visibility into how products behave in the world matters more than perfectly polishedÂ specs.</p><h3>Open questions and forward-looking bets</h3><p>This exploration surfaced more questions than it resolvedâ€Šâ€”â€Šand that feels appropriate for a space still takingÂ shape.</p><ul><li>Where does responsibility sit when hallucinations slipÂ through?</li><li>How much control will non-technical builders retain as governance tightens?</li><li>How do teams meaningfully validate products when preview environments remain incomplete?</li></ul><p>At the same time, a few patterns feel durable enough to betÂ on:</p><p>The translation layer will become its own discipline. Converting enterprise systems into LLM-legible interfaces isnâ€™t a one-time technical taskâ€Šâ€”â€Šitâ€™s an ongoing design problem that requires new kinds of judgment.</p><figure><img alt=""Composite interface showing Slack-style messages, an audio digest player titled â€œQ4 projectsâ€Šâ€”â€ŠWeekly Insights,â€ and a â€œConfigure digestâ€ panel with fields for title and destination channels."" src=""https://cdn-images-1.medium.com/max/1024/1*m0v180qrT0PFk_rGKVWKZw.png"" /><figcaption>Rather than replacing existing tools, AI products are increasingly embedded within themâ€Šâ€”â€Šshifting the design challenge toward translation and orchestration, from Design Patterns For AI Interfaces course, by <a href=""https://www.smashingmagazine.com/author/vitaly-friedman/"">VitalyÂ Friedman</a></figcaption></figure><p>Conversational coherence will matter more than feature count. Products that nail follow-up flows, contextual memory, and invocation timing will outlast those with more capabilities but clumsy orchestration.</p><p>This space is still forming. The constraints are shifting, and the standards are unsettled. Building while that uncertainty exists has become part of the workâ€Šâ€”â€Šand, increasingly, part of theÂ role.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2b2b1201b65e"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/field-notes-from-building-a-chatgpt-app-as-a-non-technical-builder-2b2b1201b65e"">Field notes from building a ChatGPT app as a non-technical builder</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/todays-organisations-don-t-have-an-ai-problem-they-have-a-thinking-problem-4ed649c063e8?source=rss----138adf9c44c---4,1769085625,Todayâ€™s organisations donâ€™t have an AI problemâ€Šâ€”â€Šthey have a thinking problem,"Todayâ€™s organisations donâ€™t have an AI problemâ€Šâ€”â€Šthey have a thinking problem

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/todays-organisations-don-t-have-an-ai-problem-they-have-a-thinking-problem-4ed649c063e8?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*eMikXd-FOHxlyXdLERjOBQ.jpeg"" width=""6240"" /></a></p><p class=""medium-feed-snippet"">AI has made work faster almost everywhere. But, are many organisations confusing sheer speed for actual organisational intelligence?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/todays-organisations-don-t-have-an-ai-problem-they-have-a-thinking-problem-4ed649c063e8?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-most-important-ai-mindset-shift-no-one-is-talking-about-0a34182e776e?source=rss----138adf9c44c---4,1769075239,The most important AI mindset shift no one is talking about,"The most important AI mindset shift no one is talking about

<h4><em>Itâ€™s not about adding AI, itâ€™s about solving problems better thanÂ before.</em></h4><p>Lately, I've seen a shift in the marketâ€¦ one that gives me hope for the future. Instead of asking, <em>&quot;How can we put AI into our product?&quot;</em> the new question to ask is, <em>&quot;How might we solve customer problems withÂ AI?&quot;</em></p><figure><img alt=""Two sales people from the sketch comedy show, Portlandia, with the phrase, &quot;Put a bird on it.&quot;"" src=""https://cdn-images-1.medium.com/max/1024/1*5uSmq93bQqBjA9TpYR-Tpw.jpeg"" /><figcaption>Put a bird on itâ€Šâ€”â€ŠPortlandia, SourceÂ <a href=""https://imgur.com/gallery/put-bird-on-xugExlK"">imgur</a></figcaption></figure><p>This seemingly subtle difference represents a massive mindset shift because one question is driven by hype, and the other is driven byÂ value.</p><p>The first question, â€œHow can we add AI?â€ is <em>trend-chasing</em>. It puts technology before purpose, and often leads to bloated features no one asked for, wasted development time, money, and opportunity cost of building something desired and innovative instead.</p><p>The second, â€œHow can we solve a real problem better with AI?â€ is <em>value creation</em>. It puts the customer at the center and treats AI as a tool, not aÂ trophy.</p><p>Thatâ€™s the shift weâ€™re seeing. And itâ€™s the difference between shipping gimmicks and building enduring solutions.</p><h3>Put some AI inÂ it!</h3><p>Since the start of the AI revolution, we've been doing research with both Big Tech and smaller AI-based startups to help them understand their customers and their response to AI-based products and services.</p><p>The initial request was simply to, &quot;Put some AI into the product.&quot; It makes sense: it's a new, emerging technology and it's important to stay competitiveâ€¦</p><p>What it looked like in real life was a different story: It became more of a race to integrate a chatbot into the product than a process of determining whether a chatbot is really the solution to aÂ problem.</p><p>I mean, unless the business problem is have a chatbot because my competitors also have aÂ chatbot.</p><p>If you remember the sketch comedy show, <a href=""https://en.wikipedia.org/wiki/Portlandia""><em>Portlandia</em></a>, then you might recall the sketch, &quot;<a href=""https://www.youtube.com/watch?v=GNpIOlDhigw"">Put a bird onÂ it</a>.&quot;</p><p>In the sketch, two well-meaning artists try to help struggling businesses by literally adding birds to random products:</p><blockquote>&quot;Look at this sad little tote bagâ€¦ I know, I'll put a bird on it!&quot; easily becomes, &quot;Look at this sad Pre-GenAI productâ€¦ I know, I'll put some AI onÂ it!&quot;</blockquote><p>Itâ€™s funny because itâ€™s true. And itâ€™s tragic because itâ€™s happening.</p><p>That sketch nails the problem with trend-first thinking: itâ€™s surface-level. Aesthetic over substance. AI becomes a sticker, not a solution. When you chase a trend, you decorate. When you pursue end-user value, youÂ solve.</p><p>And solving is where the real growthÂ is.</p><p>(Continue watching as it devolves hysterically at your ownÂ risk).</p><a href=""https://medium.com/media/6b7299b7cee614d163f78c79d427538f/href"">https://medium.com/media/6b7299b7cee614d163f78c79d427538f/href</a><h4>You aren't asking the rightÂ question</h4><p>Having spent my career helping companies uncover deep customer pain points and design real solutions, this wave of â€œjust add a chatbotâ€ feels like watching innovation on autopilot.</p><p>It wasnâ€™t strategic. It wasnâ€™t solving for anything. It was tech for techâ€™s sake fueled by FOMO (Fear of missing out). The real question that drives long-term growth isÂ this:</p><blockquote>â€œAre we solving our customerâ€™s most urgent problem better than anyoneÂ else?â€</blockquote><h4>AI is a means to anÂ end</h4><p>Simply adding AI is like when the internet exploded in the mid-90s saying that we needed to add some HTML into our product. Or, to have a website. But a website to do what? To solve whatÂ problem?</p><p>AI can help answer that question. But it doesnâ€™t replace the question itself. AI is a means to an end, not the end in itself. And to be clear: the end goal is happy customers that purchase your product orÂ service.</p><p>This is where the mindset shift comes in: It's not about <em>adding AI </em>as much as it's about <em>solving customer problems.</em></p><h3>The mindsetÂ shift</h3><p>&quot;I have a new tool in my toolbox. It's called AI. Or Agentic AI. Or anÂ LLM.&quot;</p><p>Ok, cool, what are you going to do withÂ it?</p><p>The real shift is this: instead of jamming AI into an already bloated product roadmap, teams are starting to ask a smarter question:</p><blockquote>â€œWhere can this tool help us solve a customer problem in a better way than we couldÂ before?â€</blockquote><p>This may sound obvious, but the implications are transformative.</p><p>The best companies arenâ€™t leading with the tool. Theyâ€™re leading with the outcome. AI is a means, not the mission. A lever, not the solutionÂ itself.</p><p>Think of it this way: You used to have a hammer, maybe it was a really good hammer, but it was really good at nails. Now you also have a screwdriver. It's flashy and helps you solve new problems because not every problem is aÂ nail.</p><figure><img alt=""Quote from Star Wars: &quot;These aren't the droids you're looking for.&quot; Obi-Wan Kenobi."" src=""https://cdn-images-1.medium.com/max/500/1*wYrXWxbixlOW_G__CcIiig.png"" /><figcaption>Obi-wan from Star WarsÂ (<a href=""https://en.wikipedia.org/wiki/These_aren%27t_the_droids_you%27re_looking_for"">Source</a>)</figcaption></figure><p>The shift isnâ€™t just about what tools are available, itâ€™s about what problem youâ€™re solving and whatâ€™s now possible because of this new AIÂ toolset.</p><p>The leading Tech companies understand this shift because it comes from a place of power. By reframing the problem and the approach, you're able to stop playing catch-up and start leading the market with your new, innovative approach.</p><p>Leveraging AI for what it does best allows product development teams to focus on what they do best: designing and developing solutions, now with more options on how to solve problems.</p><h3>Taking action</h3><p>If youâ€™re building with AI, hereâ€™s your first step: pause and reframe the question.</p><p>Donâ€™t start with, â€œWhere can I use AI?â€ Instead, startÂ with:</p><blockquote><strong>â€œWhat is the biggest, most urgent, and most underserved problem our customers face? And what is now uniquely possible because ofÂ AI?â€</strong></blockquote><p>To help you shift into this problem-first mindset, try this simple diagnostic:</p><ul><li>Whatâ€™s the #1 frustration your customers keep bringingÂ up?</li><li>What do they wish they could do but currently canâ€™t?</li><li>If you could wave a magic wand, what would you remove, automate, or radically improve?</li></ul><p>Now ask yourself: does AI give us a new advantage to solveÂ that?</p><p>If the answer is Yes: Great! Keep going and build with intentionality.</p><p>If not: donâ€™t force a square peg into a round hole. This isn't the screw your AI-screwdriver is lookingÂ for.</p><h4><strong>Now it's yourÂ turn</strong></h4><p>Putting the <em>most </em>AI into your product isnâ€™t a winning strategy. Instead, itâ€™s being <em>intentional</em> and <em>selective</em> about when, where, and why you chose to incorporate AI into yourÂ product.</p><p>This is your opportunity to lead the shift inside your team, your company, your product. Solve real problems by being the one who helps your team make the mindset shift and asks the better question.</p><p>Thatâ€™s how meaningful innovation and growth happens. And you can be theÂ change.</p><p><strong>Josh LaMar</strong> is the Co-Founder and CEO of <a href=""https://amplinate.com/"">Amplinate</a>, an international agency focusing on cross-cultural Research &amp; Design. As the Chief Strategy Officer of <a href=""https://www.joshlamar.com/"">JoshLaMar Consult</a>, he helps Entrepreneurs grow their business through ethical competitive advantage.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0a34182e776e"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-most-important-ai-mindset-shift-no-one-is-talking-about-0a34182e776e"">The most important AI mindset shift no one is talking about</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/hyperlegible-sans-a-free-open-source-font-for-accessible-design-7b3c823692fb?source=rss----138adf9c44c---4,1769035469,"Hyperlegible Sans: a free, open-source font for accessible design","Hyperlegible Sans: a free, open-source font for accessible design

<h4>An accessibility-focused evolution of Inter that blends modern geometry with hyperlegible design principles.</h4><figure><img alt=""Cover image showing the name â€œHyperlegible Sansâ€ on a dark background, with supporting text describing it as an accessibility-focused evolution of Interâ€™s modern aesthetic, including version number 1.0, open-source license, and available weights (regular, medium, bold)."" src=""https://cdn-images-1.medium.com/max/1024/1*cYZPrBJzp61844wdgTnRSg.png"" /><figcaption>Hyperlegible Sans, a free, open-source typeface designed as an accessibility-focused evolution of Inter. Version 1.0 includes Regular, Medium, and BoldÂ weights.</figcaption></figure><p><a href=""https://github.com/matthewlarn/hyperlegible-sans/releases/latest""><strong>Download LatestÂ Font</strong></a></p><p>Iâ€™ve used <a href=""https://rsms.me/inter/"">Inter</a> for years. Itâ€™s been my default across dozens of projects and, in my opinion, represents the best of open-source typography. Its clean geometry, strong engineering, and consistent rhythm have made it a staple of modern design systems. Over time, especially while working on accessibility-focused products, I began noticing small limitations. Certain glyphs blurred together at smaller sizes, some bowls felt tight in low-vision contexts, and characters like I, l, and 1 werenâ€™t distinct enough for readers who rely on extra clarity. None of this diminished my respect for Inter, it simply highlighted areas where accessibility could be improved.</p><p>Because of these legibility challenges, when I started doing product work for <a href=""https://loudandclear.io/""><em>Loud + Clear</em></a>, an app designed for people with Parkinsonâ€™s, I turned to <a href=""https://www.brailleinstitute.org/freefont/"">Atkinson Hyperlegible</a>. Itâ€™s one of the most thoughtfully designed accessibility fonts available, with radically open forms and unmistakable glyph shapes that prioritize clarity. For low-vision users, itÂ excels.</p><p>But I missed Interâ€™s visual aesthetic, its modern geometry, contemporary rhythm, and the familiarity designers expect in UI typography. I admired Atkinsonâ€™s readability and Interâ€™s overall look, and kept wishing there were a way to bring the strengths of both into a singleÂ design.</p><p><strong>Hyperlegible Sans</strong> is the result. Itâ€™s an open-source fork of Inter that preserves its modern character while incorporating hyperlegible principles inspired by Atkinson. It isnâ€™t meant to replace either font, just to offer another option, one that didnâ€™t existÂ before.</p><p>What I changed (andÂ why)</p><p>The philosophy behind Hyperlegible Sans is simple: keep the visual identity of Inter intact, but reduce ambiguity wherever it appears. That meant making targeted, deliberate adjustments rather than redrawing the font fromÂ scratch.</p><p>Here are the most impactful changes:</p><figure><img alt=""Comparison image showing Inter on the left and Hyperlegible Sans on the right, with highlighted letters demonstrating clearer apertures, improved differentiation between I, l, and 1, a wider capital O, and a slashed zero in Hyperlegible Sans."" src=""https://cdn-images-1.medium.com/max/1024/1*ZLD_DI4KANEeF9uaOSqhmQ.png"" /><figcaption>Side-by-side comparison of Inter and Hyperlegible Sans, highlighting changes to ambiguous glyphs, including a, e, I, O, and 0, to improve character differentiation and legibility.</figcaption></figure><h4>Capital I</h4><p>I added subtle top and bottom bars. This keeps it visually aligned with Interâ€™s geometry while removing its similarity to lowercase l and numeral 1. Low-vision readers rely on disambiguation, and this single change dramatically improves clarity without altering the overallÂ feel.</p><figure><img alt=""Side-by-side comparison of the capital letter I, with Inter on the left as a plain vertical stroke and Hyperlegible Sans on the right with added top and bottom bars to increase clarity and differentiation."" src=""https://cdn-images-1.medium.com/max/1024/1*13DkDS1Lg5mmu5y9oR_qlg@2x.png"" /><figcaption>Capital I comparison demonstrating the addition of subtle top and bottom bars in Hyperlegible Sans to improve distinction from lowercase l and numeralÂ 1.</figcaption></figure><h4>Lowercase l</h4><p>I added a small baseline spur. This makes it unmistakable as a lowercase letter and prevents confusion with 1. It also provides more visual stability inside dense UIÂ strings.</p><figure><img alt=""Side-by-side comparison of the lowercase letter l, with Inter on the left as a simple vertical stroke and Hyperlegible Sans on the right featuring a small baseline spur for clearer identification."" src=""https://cdn-images-1.medium.com/max/1024/1*Hf9uflQ_kG2hmDbAonbjRg.png"" /><figcaption>Lowercase l comparison showing the addition of a small baseline spur in Hyperlegible Sans to reduce confusion with the numeralÂ 1.</figcaption></figure><h4>Zero</h4><p>I added a slash. A slashed zero is simply more readable for everyone. It avoids the O/0 problem entirely, especially in interfaces that rely heavily on numeric input or one-timeÂ codes.</p><figure><img alt=""Side-by-side comparison of the numeral zero, with Inter on the left showing an unmarked zero and Hyperlegible Sans on the right showing a slashed zero for improved character differentiation."" src=""https://cdn-images-1.medium.com/max/1024/1*Fz6HgU8NOM5ggOOjt0usBg@2x.png"" /><figcaption>Zero comparison illustrating the addition of a slashed zero in Hyperlegible Sans to clearly distinguish it from the letterÂ O.</figcaption></figure><h4>Capital O</h4><p>I widened it slightly. Interâ€™s O is balanced and elegant, but too close to the zero for accessibility-first interfaces. A slightly wider form keeps its beauty while improving distinction.</p><figure><img alt=""Side-by-side comparison of the capital letter O, with Inter on the left and Hyperlegible Sans on the right, showing a slightly wider, more open shape in Hyperlegible Sans for improved legibility."" src=""https://cdn-images-1.medium.com/max/1024/1*GTRQG2pWFaBpIbcbrP9fHQ@2x.png"" /><figcaption>Capital O comparison showing a slightly wider form in Hyperlegible Sans to improve differentiation from zero and reduce visual ambiguity at smallÂ sizes.</figcaption></figure><h4>a andÂ e</h4><p>I opened both apertures. The two-storey a and the eâ€™s crossbar were always a bit tight for low-vision readers. Opening these shapes makes them more readable at small sizes and more resistant toÂ blur.</p><figure><img alt=""Side-by-side comparison of lowercase letters a and e, with Inter on the left and Hyperlegible Sans on the right, showing more open apertures and reduced crowding in Hyperlegible Sans."" src=""https://cdn-images-1.medium.com/max/1024/1*spyM_Rvju-1JN-9O9w143g@2x.png"" /><figcaption>Lowercase a and e comparison highlighting more open apertures in Hyperlegible Sans for improved clarity in low-vision and small-size reading.</figcaption></figure><h4>The NumberÂ 8</h4><p>I adjusted the structure of the numeral 8 by reducing the symmetry and tightening the relationship between its upper and lower bowls. In Inter, the 8 is balanced and elegant, but at small sizes or under blur it can collapse into a dense, indistinct shape.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*MIJfi85F25mf8WbAP35PCQ.png"" /></figure><h3>Rethinking spacing and kerning for accessibility</h3><p>While Interâ€™s spacing and kerning are excellent for general-purpose design, accessibility requires a subtle shift in philosophy. Crowding can become a barrier. Certain letter combinations can merge when users read with lowÂ acuity.</p><p>I added additional kerning space to pairs that commonly collapse:</p><ul><li>rn, ri,Â rl</li><li>fi, fl, ft,Â tt</li><li>ii, ll, il,Â li</li><li>la</li></ul><figure><img alt=""Side-by-side image comparing Inter and Hyperlegible Sans kerning for letter pairs such as rn, ri, rl, fi, fl, ft, tt, ii, ll, il, li, and la, with Hyperlegible Sans showing increased spacing to improve clarity and prevent visual merging."" src=""https://cdn-images-1.medium.com/max/1024/1*9SjhTB_ThOhCqilQGem5jQ.png"" /><figcaption>Comparison of kerning-sensitive letter pairs in Inter and Hyperlegible Sans, showing increased spacing for combinations that commonly collapse in low-vision or dense UIÂ text.</figcaption></figure><p>These are small changes, but small changes can have large effects. Hyperlegibility is often achieved through a series of minor adjustments that build up to meaningful improvements inÂ clarity.</p><h3>The design belief behind thisÂ project</h3><p>Accessibility shouldnâ€™t require compromising aesthetics.</p><p>A font shouldnâ€™t look â€œspecialâ€ or â€œdifferentâ€ to be inclusive. Good typography should simply work for everyone.</p><p>Hyperlegible Sans reflects a belief I carry into every project: <strong>design can be both beautiful and accessible</strong>.</p><p>We donâ€™t need to choose between modern geometry and clear letterforms. We can haveÂ both.</p><p>Design is full of these false choices, and part of the work is expanding the range of tools available so designers can choose what best fits their intentions.</p><h3>Whatâ€™s next for Hyperlegible Sans</h3><p>This is only version 1. The roadmap includes:</p><ul><li>additional weights</li><li>a full variableÂ font</li><li>expanded punctuation</li><li>broader languageÂ support</li><li>refinements for dark mode and low-contrast environments</li></ul><p>And like Inter, this project is open-source. Iâ€™m uploading the complete files to GitHub, along with documentation on the changes and a roadmap for future versions.</p><p>My hope is simple: that this font becomes another tool in the accessibility toolkit. Something UI designers, developers, and product teams can reach for when they need both clarity and beauty, when they want typography that reflects how modern design shouldÂ work.</p><p>Not less beautiful. Not more clinical. Just clearer, easier, moreÂ humane.</p><p><a href=""https://github.com/matthewlarn/hyperlegible-sans""><strong>View â€œHyperlegible Sansâ€ onÂ Github</strong></a></p><figure><img alt=""Text layout titled â€œWhy Legibility Matters,â€ explaining how clear letterforms and spacing improve readability, reduce cognitive effort, and support comfortable reading in conditions such as small sizes, low contrast, or motion."" src=""https://cdn-images-1.medium.com/max/1024/1*A0mM6d5g12cE1BdBg-qr7A.png"" /><figcaption>Legibility-focused text sample demonstrating how clearer letterforms, consistent spacing, and strong character differentiation reduce cognitive load and improve readingÂ comfort.</figcaption></figure><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7b3c823692fb"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/hyperlegible-sans-a-free-open-source-font-for-accessible-design-7b3c823692fb"">Hyperlegible Sans: a free, open-source font for accessible design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/what-if-ai-lies-about-you-d5d0697c9604?source=rss----138adf9c44c---4,1769035266,What if AI lies about you?,"What if AI lies about you?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/what-if-ai-lies-about-you-d5d0697c9604?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1000/0*hlABmUM_CRstZPVr.jpg"" width=""1000"" /></a></p><p class=""medium-feed-snippet"">We know AI gets it wrong. How do we correct misinformation before it spreads?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/what-if-ai-lies-about-you-d5d0697c9604?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
