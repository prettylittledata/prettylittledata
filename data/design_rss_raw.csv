source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/accessible-ux-research-ebook-release/,1765296000,"Accessible UX Research, eBook Now Available For Download","Accessible UX Research, eBook Now Available For Download

eBook versions of â€œAccessible UX Research,â€ a new Smashing Book by Michele A. Williams, are now available for download! Which means soon the book will go to the printer. Order the eBook for instant download now or <a href=""https://www.smashingmagazine.com/printed-books/accessible-ux-research/"">reserve your print copy at the presale price.</a>"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/state-logic-native-power-css-wrapped-2025/,1765274400,"State, Logic, And Native Power: CSS Wrapped 2025","State, Logic, And Native Power: CSS Wrapped 2025

CSS Wrapped 2025 is out! Weâ€™re entering a world where CSS can increasingly handle logic, state, and complex interactions once reserved for JavaScript. Here is an unpacking of the standout highlights and how they connect to the bigger evolution of modern CSS."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/how-ux-professionals-can-lead-ai-strategy/,1765180800,How UX Professionals Can Lead AI Strategy,"How UX Professionals Can Lead AI Strategy

Lead your organizationâ€™s AI strategy before someone else defines it for you. A practical framework for UX professionals to shape AI implementation."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/beyond-black-box-practical-xai-ux-practitioners/,1764946800,Beyond The Black Box: Practical XAI For UX Practitioners,"Beyond The Black Box: Practical XAI For UX Practitioners

Explainable AI isnâ€™t just a challenge for data scientists. Itâ€™s also a design challenge and a core pillar of trustworthy, effective AI products. Victor Yocco offers practical guidance and design patterns for building explainability into real products."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/12/masonry-things-you-wont-need-library-anymore/,1764669600,Masonry: Things You Wonâ€™t Need A Library For Anymore,"Masonry: Things You Wonâ€™t Need A Library For Anymore

CSS Masonry is almost here! Patrick Brosset takes a deep dive into what this long-awaited feature means for web developers and how you could make use of it in your own work."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/desktop-wallpaper-calendars-december-2025/,1764493200,A Sparkle Of December Magic (2025 Wallpapers Edition),"A Sparkle Of December Magic (2025 Wallpapers Edition)

With December just around the corner, how about some new desktop wallpapers to welcome the last month of the year â€” and the holiday season, if youâ€™re celebrating? Our latest edition of monthly wallpapers has got you covered. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/accessibility-problem-authentication-methods-captcha/,1764237600,The Accessibility Problem With Authentication Methods Like CAPTCHA,"The Accessibility Problem With Authentication Methods Like CAPTCHA

CAPTCHAs were meant to keep bots out, but too often, they lock people with disabilities out, too. From image classification to click-based tests, many â€œhuman checksâ€ are anything but inclusive. Thereâ€™s no universal solution, but understanding real user needs is where accessibility truly starts."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/design-system-culture/,1764093600,Design System Culture: What It Is And Why It Matters (Excerpt),"Design System Culture: What It Is And Why It Matters (Excerpt)

Weâ€™re so happy to announce that â€œMaturing Design Systemsâ€â€”a Smashing book by Ben Callahan &mdash; will soon be joining the Smashing Library! Benâ€™s insights and advice are so powerful, we thought you might like to read an excerpt from the book. <a href=""https://www.smashingmagazine.com/the-smashing-newsletter/"">Subscribe to our Smashing newsletter</a> to be notified when orders are open."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/designing-for-stress-emergency/,1763989200,Designing For Stress And Emergency,"Designing For Stress And Emergency

Practical guidelines on designing time-critical products that prevent errors and improve accuracy. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today). With a <a href=""https://smashingconf.com/online-workshops/workshops/vitaly-friedman-impact-design/"">live UX training</a> starting next week."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/keyframes-tokens-standardizing-animation-across-projects/,1763712000,Keyframes Tokens: Standardizing Animation Across Projects,"Keyframes Tokens: Standardizing Animation Across Projects

Animations can be one of the most joyful parts of building interfaces, but without structure, they can also become one of the biggest sources of frustration. By consolidating and standardizing keyframes, you take something that is usually messy and hard to manage and turn it into a clear, predictable system."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/simplifying-server-management-ai-automation/,1763460000,From Chaos To Clarity: Simplifying Server Management With AI And Automation,"From Chaos To Clarity: Simplifying Server Management With AI And Automation

Server chaos doesnâ€™t have to be the norm. AI-ready infrastructure and automation can bring clarity, performance, and focus back to your web work."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/css-gamepad-api-visual-debugging-css-layers/,1763125200,CSS Gamepad API Visual Debugging With CSS Layers,"CSS Gamepad API Visual Debugging With CSS Layers

Debugging controllers can be a real pain. Hereâ€™s a deep dive into how CSS helps clean it up and how to build a reusable visual debugger for your own projects."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/older-tech-browser-stack/,1763020800,Older Tech In The Browser Stack,"Older Tech In The Browser Stack

There are many existing web features and technologies in the wild that you may never touch directly in your day-to-day work. Perhaps youâ€™re fairly new to web development and are simply unaware of them because youâ€™re steeped in the abstraction of a specific framework that doesnâ€™t require you to know it deeply, or even at all. Bryan Rasmussen looks specifically at XPath and demonstrates how it can be used alongside CSS to query elements."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/effectively-monitoring-web-performance/,1762855200,Effectively Monitoring Web Performance,"Effectively Monitoring Web Performance

There are lots of tips for [improving your website performance](https://www.debugbear.com/blog/improve-website-performance?utm_campaign=sm-10). But even if you follow all of the advice, are you able to maintain an optimized site? And are you targeting the right pages? Matt Zeunert outlines an effective strategy for web performance optimization and explains the roles that different types of data play in it."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/smashing-animations-part-6-svgs-css-custom-properties/,1762527600,Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties,"Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties

SVG is one of those web technologies thatâ€™s both elegant and, at times, infuriating. In this article, pioneering author and web designer Andy Clarke explains his technique for animating SVG elements that are hidden in the Shadow DOM."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/practical-guide-ux-strategy/,1762347600,Six Key Components of UX Strategy,"Six Key Components of UX Strategy

Letâ€™s dive into the building blocks of UX strategy and see how it speaks the language of product and business strategy to create user value while achieving company goals. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today)."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/how-leverage-component-variants-penpot/,1762250400,How To Leverage Component Variants In Penpot,"How To Leverage Component Variants In Penpot

With component variants, design systems become more flexible, letting you reuse the same component while adapting its look or state with ease. In this article, Daniel Schwarz demonstrates how design tokens can be leveraged to manage components and their variations using <a href=""https://penpot.app?utm_source=SmashingMag&amp;utm_medium=Article&amp;utm_campaign=Variants"">Penpot</a>, the open-source tool built for scalable, consistent design."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/desktop-wallpaper-calendars-november-2025/,1761912000,Fading Light And Falling Leaves (November 2025 Wallpapers Edition),"Fading Light And Falling Leaves (November 2025 Wallpapers Edition)

The new month is just around the corner, and that means: Itâ€™s time for some new desktop wallpapers! All of them are designed by the community for the community and can be downloaded for free. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/javascript-for-everyone-iterators/,1761570000,JavaScript For Everyone: Iterators,"JavaScript For Everyone: Iterators

Here is a lesson on Iterators. Iterables implement the iterable iteration interface, and iterators implement the iterator iteration interface. Sounds confusing? Mat breaks it all down in the article."
rss,uxdesign.cc,https://uxdesign.cc/productionizing-design-prototypes-addressing-the-design-engineering-gap-with-ai-coding-tools-fb3924f83da1?source=rss----138adf9c44c---4,1765360403,Addressing the design-engineering gap with AI coding tools,"Addressing the design-engineering gap with AI coding tools

<h4>How shadow repos and data layer helped me move from design handoffs to working prototypes that ship inÂ hours</h4><figure><img alt=""Illustration of two overlapping circles representing â€œDesignâ€ and â€œEngineering,â€ with the overlap shaded to show the shared space between the disciplines."" src=""https://cdn-images-1.medium.com/max/1024/1*iKZi1S4e49osr-hGUIZDDw.png"" /></figure><p>Over the past few months, I have noticed a quiet shift in how we build products. You start noticing design and engineering overlapping at scale much earlier, pretty much as soon as a feature moves from research into the ideationÂ stage.</p><figure><img alt=""Screen recording of an AI-powered analytics prototype. A user types a prompt asking for a pie chart of attack success counts, and the interface generates a chart and insights based on evaluation data. It demonstrates how natural-language queries turn into visualizations and analysis."" src=""https://cdn-images-1.medium.com/max/1024/1*OyLE3y-V5eOwrJ6zIPGfEw.gif"" /><figcaption>I built this AI-powered prototype for a feature with ClaudeÂ Code</figcaption></figure><p>This is one of the recent features where I built the entire flow end-to-end with a different workflow. I designed the experience, developed the UI with ShadCN components, built the interaction patterns, and connected it to real logic in the background. The prototype pulled data through Supabase MCP calls and interacted with OpenAI APIs to generate adaptive UI components, so the whole thing behaved close to the final product experience rather than a typical mock orÂ demo.</p><p>This shift in how I solve problems pushed me beyond prototyping. I started productionizing my work inside the codebase, learning engineering patterns every day, and developing a clearer sense of how the product should function from end to end across the entireÂ system.</p><blockquote>It moved me from being a designer to becoming a maker, and it is now shaping me into a <strong>context-aware builder</strong>.</blockquote><p>This article is a reflection of that journey, how it improved the velocity, the challenges I encountered, and what we should anticipate, that could define the next chapter of product design development.</p><h3>The Problem I Kept RunningÂ Into</h3><p>When the <a href=""https://spin.atomicobject.com/designers-vibe-coding/"">vibe coding culture</a> started appearing everywhere, I saw significant people from the design community building retro games, dashboards, weather widgets, note apps, and many experiments powered by AI-generated code. It was encouraging to see designers making ideas work, but it reminded me of the famous <a href=""https://dribbble.com/"">Dribbble</a> phase where everything looked beautiful but very little made it into real products.</p><p>I kept askingÂ myself:</p><blockquote>Is this just another playground? Or can this way of working eventually influence production software?</blockquote><p>The understanding of what sits under the hood among the community was still early, and most prototypes focused more on exploration than real functionality. It felt like the community is just beginning to scratch the surface of what is possible.</p><p>The bigger issue was not the experiments themselves. It was that designers still did not have a functional layer to work in. This gap between design and development has been <a href=""https://webdesignerdepot.com/the-designer-developer-handoff-is-still-broken-why/"">well-documented</a>, with many teams struggling to move from static mockups to functional products. Figma, the most common tool designers use, sits in an isolated space. Even with custom plugins, Code Connect, and dev mode, the influence on the codebase is minimal. Most of it feels like a workaround. The design mocks rarely have the ability to test with real or dynamicÂ data.</p><p>The other challenge is<strong> feature fragmentation</strong>.</p><figure><img alt=""Figma project view showing a grid of separate design files, illustrating how individual features are organized into their own design files."" src=""https://cdn-images-1.medium.com/max/1024/1*dzXHJTKOo0BIsQkJrOcUpg.png"" /></figure><p>In Figma, each feature is usually worked on in a separate file. It gives clarity for design, but it does not reflect how a real product works. In an actual product, features live together, share context, depend on each other, and behave as a single system. Moving across flows should feel natural and connected, not scattered across isolatedÂ files.</p><p>If you look at the distribution, the user interacts with the final product. Testers have staging and UAT environments. Developers have a full git workflow with branches and review layers. <strong>Designers do not have anything equivalent. </strong>There is no layer that lets us build with a real functional context.</p><h3>Where I Started: TwoÂ Paths</h3><p>My initial integration of AI into my workflow was actually quite practical. I was trying to optimize some design operations and design system workflows, and I did not have enough bandwidth to fit all of it into my routine. There was no AI integration inside IDEs at that time. Everything was manual, disconnected, and very experimental. So used AI generated scripts for these automations.</p><figure><img alt=""Side-by-side graphic showing an early AI-assisted workflow. On the left is a JavaScript script used to classify and extract color formats from CSS. On the right is a spreadsheet containing hundreds of color definitions generated from that script."" src=""https://cdn-images-1.medium.com/max/1024/0*Dbrv3k8YWwdNbM9Y"" /></figure><p>Seeing the potential, I wanted to understand the full range of AI API offerings beyond prompt-based code generation. During the same timeline, I was exploring prototyping with Origami and wanted to see if I could bring AI capability directly into the prototype. I experimented with building an Origami prototype that used the OpenAI API for chat completion requests and audio-to-text conversion</p><figure><img alt=""Animated gif of music controller touch interface where interaction emerges without visible buttons and purely based on contextual feedback and motion."" src=""https://cdn-images-1.medium.com/max/956/1*0yMZrq2MCBYpNd-BHvKbYg.gif"" /><figcaption>Whisper API from Open AI for converting song audio intoÂ lyrics</figcaption></figure><figure><img alt=""Animated prototype gif of live camera feed, where the user drag to select any region. The prototype sample the color and retrieve the hex code."" src=""https://cdn-images-1.medium.com/max/960/1*yN9Rq_VuJ_x3V_iEgKrYkQ.gif"" /><figcaption>Color picker through camera to get description about theÂ color</figcaption></figure><p><em>Check out these prototypes </em><a href=""https://www.pratheep.design/prototyping""><em>here</em></a></p><p>This exploration revealed twoÂ paths:</p><ol><li><strong>Using AI to build the prototype itself</strong></li><li><strong>Enabling the prototype with AIÂ features</strong></li></ol><p>This distinction between using AI as a tool to build versus integrating AI into features aligns with what <a href=""https://medium.com/design-bootcamp/vibe-coding-as-a-designer-what-ive-learned-so-far-029c1cc4636d"">Wyatt Kay describes</a> as the dual nature of AI-powered design work where the technology serves both as creation medium and feature component. Understanding this separation became an important part of how I now approach prototyping ideas.</p><h3>Finding the RightÂ Tools</h3><p>As I started building more rigorously, I needed to settle on tools that matched my workflow. I explored several options including <a href=""https://v0.app/"">v0</a> for quick layouts and <a href=""https://cursor.com/"">Cursor</a> for its smooth IDE experience, but token exhaustion rate became a practical constraint.</p><p><a href=""https://claude.com/product/claude-code"">Claude Code</a> stood out for its efficiency. Using the same Sonnet model across different tools, Claude Code handled tokens far better and stayed lightweight for repeated everyday use. It began as a simple terminal interface but quickly became my primary tool because it fit the way I build products everyÂ day.</p><p>The rise of MCPs (Model Context Protocol) also meant that most missing features could be achieved across different AI-powered IDEs anyway. What mattered more was finding a tool that matched my cost and workflow needs for sustained use.</p><h3>Where I Arrived: The Shadow RepoÂ Approach</h3><p>I came across a <a href=""https://x.com/nayakkayak/status/1958677324863328643?s=20"">tweet</a> by Aatish Nayak, VP product at Harvey, about building an entire frontend using vibe coding. He called it a <strong>shadow repo</strong>, and the idea made immediate sense. The concept addresses what <a href=""https://smart-interface-design-patterns.com/articles/design-handoff/"">Dan Mall and Brad Frost call the â€˜Hot Potato Processâ€™</a>, rapid iteration between designers and developers that eliminates traditional handoff friction.</p><p>Think of it like this: if staging/UAT is where testers validate features, a shadow repo is where designers validate functionality. This approach creates breathing room to experiment with full product context and lessÂ risk.</p><p>A real git branch carries engineering expectations, reviews, and risk. A shadow repo removes that pressure. You can try ideas, break things, and test with real or mock data without touching the product codebase.</p><p>Here is how I shaped workflow with this shadowÂ repo:</p><ul><li>Build a repo that mirrors the real app structure</li><li>Follow production component patterns</li><li>Use Figma for skeleton and visual direction</li><li>Translate with Figma MCP, applying coded design systemÂ rules</li><li>Refine through manual edits and prompting</li><li>Use Notion MCP for handoff reviewÂ notes</li><li>Port to production with developer review and proper APIÂ wiring</li></ul><figure><img alt=""Flow diagram showing how design and code inputs feed into a shadow repository. A â€œDesign Fileâ€ flows into the shadow repo through Figma MCP, and a â€œComponent Libraryâ€ flows in through ShadCN MCP. Both inputs merge into the â€œShadow Repo Codebase,â€ which then connects to Notion MCP, producing a final â€œHandoff Specâ€ for developer review."" src=""https://cdn-images-1.medium.com/max/1024/1*edDAUJWubwolp4UKfolOGg.png"" /></figure><h3>Solving the DataÂ Problem</h3><p>Early shadow repo prototypes relied on local storage, placeholder JSONs, and fake values. This breaks down when replicating a full product experience.</p><p>I created a shadow backend using Supabase. Supabaseâ€™s free tier plus <a href=""https://supabase.com/docs/guides/getting-started/mcp"">Supabase MCP tools </a>were perfect for this: quick tables, simple edge functions, instant data edits, predictable structure. This made the shadow repo feel complete.</p><blockquote>This enabled: Functional UI + Coded Interactions + RealÂ Data</blockquote><figure><img alt=""Flow diagram showing how three inputs feed into a shadow repo workflow. A â€œDesign Fileâ€ flows into the system through Figma MCP, a â€œData Layerâ€ flows in through Supabase MCP, and a â€œComponent Libraryâ€ flows in through ShadCN MCP. All three converge into the â€œShadow Repo Codebase,â€ which then connects to Notion MCP to generate the final â€œHandoff Spec.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*7QVOgioibRVv58O_6ZbcTQ.png"" /></figure><p>Why not use the actual API of theÂ product?</p><ul><li>Unmoderated calls are expensive</li><li>Prototypes trigger unpredictable requests</li><li>And I did not want to risk touching production backend systems at thisÂ point.</li></ul><h3>Enabling AI Features Within Prototypes</h3><p>Once the data layer was in place, I could explore the second path: enabling prototypes with AI features themselves.</p><p>At Dynamo AI, our tools rely heavily on AI systems. My prototypes needed to behave like AI-powered products. I integrated lightweight OpenAI API calls to replicate real-world feature responses.</p><p>Supabase made this efficient. I could store conversation history, manage state, and handle AI responses without complex backend logic. MCP tools connected everything seamlessly for defining actual API calls, response processing, and dynamic interface updates.</p><p>And for inspecting within the browser by the agent during active development, the <a href=""https://developer.chrome.com/blog/chrome-devtools-mcp"">Chrome Dev Tools MCP</a> solves it with my ClaudeÂ setup.</p><h3>What I Gained from Building Functionally</h3><p>This approach doesnâ€™t require designers to become full engineers, a <a href=""https://www.toptal.com/designers/ux/designers-coding"">decades-old debate</a> that often misses the point. As <a href=""https://capwatkins.com/blog/why-designers-really-should-learn-to-code"">Cap Watkins argues</a>, learning to code isnâ€™t about independence but about deepening collaboration and shared understanding.</p><p>With this setup, I was able to prototype working features and ship much faster. In one instance, the developers reviewed the prototype code and had the production version ready for testing in a single evening. That was the moment I realized this workflow is quite practical, scalable and increase the velocity to a greater extent. I was no longer handing off design files. I was handing off a working prototype with a higher probability of accurately representing the idea into production quickly.</p><figure><img alt=""Animated neon illustration of two outlined human heads facing each other, with glowing brains connected by looping, pulsating energy bands."" src=""https://cdn-images-1.medium.com/max/500/0*69dzyRxN3kU5bKMx.gif"" /></figure><p>These are some of the shifts I noticed in my approach:</p><p><strong>Better fine-tuning of UI component architecture: </strong>Seeing components run with real variants, props, and constraints helped me refine the architecture upfront and create cleaner, more scalable patterns.</p><p><strong>Handling Edge Cases Early:</strong> AI made it easier to surface edge cases and logical gaps early, long before engineering touchedÂ them.</p><p><strong>Thinking Through the Data Layer:</strong> Working with real-like data broadened my thinking on structuring payloads and designing interface for efficient API usage and holistic thinking of how data flows through the entire system functionally.</p><p><strong>Enabling AI Features to Augment Capabilities:</strong> Integrating actual AI behavior into prototypes changed how I think about product features. Instead of designing around static functionality, I started considering how AI could augment existing capabilities.</p><h3>How This Changed My Role in ProblemÂ Solving</h3><p>This entire experiment changed my perspective on what it means to be a designer.</p><p>When you understand how data flows, how components are structured, what triggers API calls, and what engineers worry about, your design decisions become grounded inÂ reality.</p><blockquote>You stop thinking like someone who â€œhands offâ€ and start thinking like someone whoÂ builds.</blockquote><figure><img alt=""Animated gif of minimalist illustration of an open hand holding a simple outlined 3D house shape resting on a flat platform"" src=""https://cdn-images-1.medium.com/max/1024/0*Wt8AEi9FyLKbiqZY.gif"" /></figure><h3>The Challenges That Come WithÂ It</h3><p>AI coding tools are powerful, but they also come with real headaches:</p><p><strong>The rabbit-hole edits:</strong> AI produces the first version well, but small edits sometimes break the entire flow and get you into an unnecessary loop ofÂ issues.</p><p><strong>Pattern-level mistakes:</strong> With React components, I have faced unnecessary hooks, redundant functions, nested components, strange abstractions, and recursive APIÂ calls.</p><p><strong>AI fingerprints:</strong> AI often generates the same UI patterns for the same problem and ignores existing components.</p><p><strong>Overbuilding:</strong> It is easy to drift into solving engineering problems and lose sight of the actual userÂ problem.</p><p>However, these challenges eventually can be addressed by defining rules that you can mention in your AI tool. In Claude, this is supported by <a href=""https://www.anthropic.com/engineering/claude-code-best-practices"">Claude.md</a> and <a href=""https://www.claude.com/blog/skills"">Claude Skills</a>, which are project-agnostic and allow you to define explicit conditions and rules that guide how the AI should approach your programming tasks.</p><h3>What This Means GoingÂ Forward</h3><p>The way we build products is shifting steadily. AI coding tools are changing the relationship between design and engineering. Shadow repos and vibe-coded prototypes let designers get much closer to reality. Complexity becomes easier to reason about. Ideas get validated faster.</p><blockquote>Teams spend less time interpreting and more time building.</blockquote><p>We are moving from designer to maker to builder through changes in capability.</p><p>This mirrors what <a href=""https://www.uxtigers.com/post/vibe-coding-vibe-design"">Jakob Nielsen describes as â€˜vibe designâ€™</a>, where AI enables rapid prototyping and designers work more iteratively with functional interfaces rather than static deliverables.</p><p>The shadow repo approach might not be a permanent solution. It is a good transitional framework that works while the industry figures out what the next generation of product-building tools should be. Right now, this framework works well for our team to build functionally without the constraints of traditional tools or the risks of production systems.</p><p>The industry is figuring this out together. If you are exploring similar territory or approaching these problems differently, letâ€™s connect and learn from eachÂ other.</p><p><em>If you are curious to see more of my work, check out my </em><a href=""https://www.pratheep.design""><em>portfolio</em></a><em> where I have documented some of these experiments.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fb3924f83da1"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/productionizing-design-prototypes-addressing-the-design-engineering-gap-with-ai-coding-tools-fb3924f83da1"">Addressing the design-engineering gap with AI coding tools</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/building-systems-that-strengthen-product-discovery-judgment-984aafbc839a?source=rss----138adf9c44c---4,1765360056,Building systems that strengthen product discovery judgment,"Building systems that strengthen product discovery judgment

<h4>Moving from accidental learning to deliberate capability development.</h4><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*vp3jzP0mKvpYW8zZh5x68Q.jpeg"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>The retrospective felt like a breakthrough. The team diagnosed exactly where their reasoning broke down, mapped the root causes, and committed to doing better. Three months later, they repeated the same mistakes.</p><p>The diagnosis was accurate. What was missing was a system to turn awareness into development. Diagnosis alone doesnâ€™t createÂ change.</p><p>Most improvement efforts fail not from lack of insight, but from lack of judgment infrastructure. Teams recognize that they skip assumption testing or misinterpret customer feedback. But recognition without practice is just self-awareness thatÂ fades.</p><p>In my previous article, â€œ<a href=""https://medium.com/user-experience-design-1/the-anatomy-of-product-discovery-judgment-0cb28b28cc7c"">The anatomy of discovery judgment</a>,â€ I mapped the 19 critical judgment points where human reasoning determines whether teams build the rightÂ things.</p><p>This article introduces the remaining components of the Discovery Judgment Framework: how to <em>measure</em> judgment quality, the <em>practices</em> that systematically strengthen it, and the <em>maturity model</em> that tracks your progress overÂ time.</p><h3><strong>Measuring Your Progress: Four Quality Dimensions</strong></h3><p>You canâ€™t develop what you canâ€™t see. Teams track velocity, output, and outcomesâ€Šâ€”â€Šbut the quality of judgment remains hidden. Yet judgment determines whether that velocity produces value orÂ waste.</p><p>Where the 19 judgment points show where to focus, these four dimensions show how well youâ€™re reasoning at each point. Think of each as a 1â€“5 scale: low-judgment teams typically score 1.5â€“2, while high-judgment teams scoreÂ 4â€“4.5.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*hTCjYVDTQjpgdZK6souu7Q.png"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>Use the diagram to rate your team honestly on each dimension. Without clear feedback loops and deliberate reflection, teams miss critical learning opportunitiesâ€Šâ€”â€Ša pattern White (2021) identified in his research on reflection in design practice.</p><h4><strong>Example of judgment quality inÂ action</strong></h4><p><strong>Low judgment</strong>: â€œWe decided to build feature Xâ€ (no documented reasoning)</p><p><strong>High judgment</strong>: â€œWe prioritized feature X over Y because: (1) it tests our riskiest assumption about user adoption, (2) engineering complexity is 2 weeks vs 6 months, (3) three customers said theyâ€™d pilot it immediately, giving us rapid validation.â€</p><p>Most teams operate with low judgment quality without realizing it. Making these four dimensions visible is the first step to improvement.</p><h3>Your Journey: The MaturityÂ Model</h3><p>Think of judgment development as a maturity curve, not a binary state. The Discovery Judgment Frameworkâ€™s fourth component shows how capability evolves.</p><figure><img alt=""A diagram illustrating a five-level maturity model, progressing from â€œLevel 1: Unconsciousâ€ at the bottom-left to â€œLevel 5: Self-Improvingâ€ at the top-right. Each level includes a description and a typical timeframe."" src=""https://cdn-images-1.medium.com/max/1024/1*k1YN4KOJ3IGCri46DoBQ7g.png"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>Most teams begin at Levels 1â€“2 and progress to Levels 3â€“4 within 6â€“18 months through consistent practice. Reaching Level 5 may take years, but it becomes self-reinforcing.</p><p>Maturity models provide teams with clear progression paths. BallarÃ­nâ€™s (2022) work on UX maturity for Scrum teams shows how these frameworks help identify where to focus capability development next.</p><h3>Where are youÂ now?</h3><p>Honestly assess your teamâ€™s currentÂ level:</p><ul><li><strong>Level 1â€Šâ€”â€ŠUnaware</strong>: We donâ€™t have a systematic approach to discovery. We canâ€™t explain why we made past decisions. Learning happens by accident.</li><li><strong>Level 2â€Šâ€”â€ŠAware</strong>: We recognize judgment matters. We sometimes employ practices such as assumption mapping or evidence tracking, but not consistently. Weâ€™re starting to document reasoning.</li><li><strong>Level 3â€Šâ€”â€ŠPracticing</strong>: We consistently use 2â€“3 core practices. We can trace most decisions back to evidence. Reflection is becoming routine. Weâ€™re deliberate about judgment development.</li><li><strong>Level 4â€Šâ€”â€ŠSystematic</strong>: All five practices are integrated into our workflow. We measure judgment quality routinely. Learning compounds across cycles. Judgment development is no longer specialâ€Šâ€”â€Šitâ€™s how weÂ work.</li><li><strong>Level 5â€Šâ€”â€ŠSelf-Improving</strong>: Judgment development feels natural. New team members absorb these capabilities through osmosis. We continuously refine our approach. The system reinforces itself.</li></ul><p>In my experience working with product teams, most start at Level 1 or 2. The practices below move you to Level 3â€“4 over 6â€“18Â months.</p><h3>The Five Practices That Strengthen Judgment</h3><p>Moving up the maturity curve requires systematic practicesâ€Šâ€”â€Šthe frameworkâ€™s third component. These work with whatever process frameworks you use (Agile, Design Thinking, OKRs). The question isnâ€™t what tools you use, but whether they enable judgment development.</p><p>Start with one core practice (Evidence Tracking, Assumption Mapping, or Experiment Design). Add integration practices (Decision Documentation and Reflection Practice) as youÂ mature.</p><h4>Three core practices</h4><p>These three practices generate and test insights:</p><p><strong>1. Evidence Tracking</strong> maintains the lineage from raw data to decisionsâ€Šâ€”â€Šcustomer quotes connect to insights, opportunities, and ultimately decisions.</p><p><strong><em>Example</em></strong><em>:</em> After conducting 12 interviews, you identify â€œcontext loss during handoffsâ€ as a recurring issue. Your evidence trail: 8 of 12 mentioned it, 6 used similar language (â€œblack holeâ€), 40% of support escalations involve missing information. You can trace decisions to specific evidenceâ€Šâ€”â€Šand if solutions fail, review whether you misinterpreted evidence or solved the wrongÂ problem.</p><p><strong>2. Assumption Mapping</strong> makes implicit beliefs explicit and testableâ€Šâ€”â€Šbefore building anything, articulate what must be true for success across five categories: Desirability, Feasibility, Viability, Usability, Ethics.</p><p>As Christopher (2024) explains in his Bootcamp article on UX mapping techniques, assumption mappingâ€Šâ€”â€Štypically used at project kickoffâ€Šâ€”â€Šhelps teams identify which assumptions are significant unknowns requiring validation versus unimportant factors that can be deferred.</p><p><strong><em>Example</em></strong>: Your assumption map reveals: â€œExecutives will log in dailyâ€ (riskiest), â€œWe can build real-time sync in 2 sprints,â€ â€œThis drives $500K in upsell.â€ After 2 weeks of testing, adoption stays below 40%. You pivotâ€Šâ€”â€Šexecutives prefer email summaries. That 2-week test saved $Â 180,000.</p><p><strong>3. Experiment Design</strong> structures learning so each test produces actionable insightâ€Šâ€”â€Šeach experiment has a clear hypothesis, success criteria, and decision threshold.</p><p><strong><em>Example</em></strong><em>:</em> Instead of an 18-month overhaul, you test a 2-week experiment with a simple template. After two weeks, adoption is 55%â€Šâ€”â€Šmanagers use it, but team members often forget the details. Youâ€™ve learned the fundamental constraint in two weeks for minimal investment, not 18 months and $2 millionÂ later.</p><h4>Two integration practices</h4><p>These practices capture and compound learning:</p><p><strong>4. Decision Documentation</strong> records not just what was decided, but the reasoning behind it. Capture supporting evidence, assumptions carried forward, alternatives rejected, and confidence level. This creates institutional memory and enables the extraction of learning.</p><p><strong>5. Reflection Practice</strong> closes the learning loop. The key is examining what you learned about both the customer <em>and your own reasoning</em>â€Šâ€”â€Šthe double-loop learning introduced in my article â€œ<a href=""https://medium.com/user-experience-design-1/it-seems-anyone-can-build-software-now-how-do-you-build-the-right-software-182057dfa122"">When building software became easier with AI, deciding becameÂ harder.</a>â€</p><p>Single-loop learning solves problems within existing systems; double-loop learning challenges the underlying beliefs and assumptions themselves. Overeem (2021) frames this as the difference between doing things right and questioning whether youâ€™re doing the right things. Discovery judgment requires this deeper reflectionâ€Šâ€”â€Šnot just asking â€œDid this work?â€ but â€œWere our assumptions valid? Should we be asking different questions entirely?â€</p><p>Schedule regular reflectionâ€Šâ€”â€Šafter launches, retrospectives, or quarterlyâ€Šâ€”â€Što examine: What surprised us? What would we do differently? What did this reveal about how weÂ think?</p><h3>How the Framework Components WorkÂ Together</h3><p>The four components work as an integrated system: diagnose weak points, measure quality, apply practices, and track maturity. Each cycle strengthens both customer understanding and reasoning capability.</p><p><strong>Example</strong>: Identify Evidence Interpretation as weak (Component 1) â†’ assess quality (Component 2) â†’ implement Evidence Tracking (Component 3) â†’ progress from Level 2 to Level 3 over 6â€“12 months (Component 4).</p><p>The five practices form a continuous cycle: Evidence Tracking â†’ Assumption Mapping â†’ Experiment Design â†’ Decision Documentation â†’ Reflection Practice.</p><figure><img alt=""A circular diagram showing the five practices connected in a continuous cycle. Arrows flow from Evidence Tracking to Assumption Mapping, to Experiment Design, to Decision Documentation, and then to Reflection Practice, before returning to Evidence Tracking. At the center, text reads â€œEach cycle strengthens judgment about customers and reasoning.â€ The circular flow illustrates how practices integrate and compound learning over time."" src=""https://cdn-images-1.medium.com/max/960/1*7n4sEFRTjcrc_DV1y3X9Pg.png"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><h3>Putting It IntoÂ Practice</h3><p>Judgment develops through two complementary approachesâ€Šâ€”â€Šand the integration of both creates sustainable capacity:</p><p><strong>Learning by doing</strong>: Apply practices to real discovery work. Learn from cycles. Find internal mentors who share their reasoningâ€Šâ€”â€Šnot just decisions, but how they think about problems, what signals they watch for, what tradeoffs they consider.</p><p><strong>Structured learning</strong>: Targeted training on specific judgment points and practices. Deliberate skill-building. Systematic coverage of areas you might miss through experience alone.</p><p>The most effective approach combines both. Structured learning provides principles; experiential learning embeds them. Training teaches assumption mapping; projects teach which assumptions matter in your context. Neither alone creates lasting changeâ€Šâ€”â€Šintegration creates professionals who reason systematically and apply judgment contextually.</p><h4>Your implementation roadmap</h4><p>Regardless of where you are, start with the same firstÂ step.</p><p><strong>1. Today: Choose ONE practice that addresses your weakÂ point:</strong></p><ul><li>Weak at Evidence Interpretation? â†’ Start EvidenceÂ Tracking</li><li>Weak at Assumptions? â†’ Start Assumption Mapping</li><li>Weak at Validation? â†’ Start Experiment Design</li></ul><p><strong>2. This sprint: Implement that practice:</strong></p><ul><li>Set up the system (tools, templates, workflows)</li><li>Apply it to one activeÂ decision</li><li>Document what youÂ learn</li></ul><p><strong>3. 30 days from now: Assess improvement using the four dimensions:</strong></p><ul><li>Can you trace the reasoning better? (Reasoning Transparency)</li><li>Are decisions more evidence-based? (Evidence Rigour)</li><li>Did you catch biases earlier? (Bias Awareness)</li><li>What changed in how you think? (Learning Depth)</li></ul><p><strong>4. After validation: Expand to a second practice or deepen theÂ first.</strong></p><p>Whether working alone or as part of a team, the fundamentals remain the sameâ€Šâ€”â€Šbut each practice requires specificÂ habits:</p><ul><li><strong>For Evidence Tracking:</strong> Keep a simple log linking each decision to specific customer quotes or data points. When a decision proves wrong, trace back to see where the interpretation failed.</li><li><strong>For Assumption Mapping:</strong> Before each sprint, list three assumptions that could invalidate your current direction. Rank them by risk and design oneÂ test.</li><li><strong>For Reflection:</strong> After each cycle, write one paragraph on what outcomes revealed about your reasoning processâ€Šâ€”â€Šnot just about customers, but about how you interpreted signals and made tradeoffs.</li></ul><p>AI can surface patterns you might miss during reflectionâ€Šâ€”â€Šcontradictions in your reasoning, gaps in your evidence, assumptions you havenâ€™t tested. But determining which patterns matter, and what they mean for your next decision, remains yoursÂ alone.</p><p>The goal isnâ€™t perfect discoveryâ€Šâ€”â€Šitâ€™s learning to decide better with eachÂ cycle.</p><h3>Your NextÂ Move</h3><p>Youâ€™re facing a real decisionÂ here.</p><p>One approach is to keep your focus on execution. When everything feels uncertain, doubling down on what you know how to do makes sense. Itâ€™s not wrongâ€Šâ€”â€Šitâ€™s how most people willÂ respond.</p><p>Another approach: Use this uncertainty to develop judgment incrementally. Begin with one practice at a single judgment point. Build the capacity while pressure is still manageable, before it becomesÂ urgent.</p><p>Hereâ€™s whatâ€™s worth considering: As AI makes execution more efficient, organizations will need fewer people executing tasks and more people making informed decisions. The question isnâ€™t whether to develop judgmentâ€Šâ€”â€Šitâ€™s whether to start now, while you can do it gradually, or later when the pressure isÂ higher.</p><p>You donâ€™t need to be brave. You donâ€™t need to transform your organization. You donâ€™t even need to tell anyone youâ€™re doing this. Just pick one practice and apply it to one decision thisÂ week.</p><p>Thatâ€™s how judgment developsâ€Šâ€”â€Šthrough small, deliberate actions repeated over cycles. Start now, and in a year youâ€™ll have skills most of your peers will take years to developâ€Šâ€”â€Šif they develop them at all. Speed and judgment used to be a tradeoff. Now theyâ€™re both requiredâ€Šâ€”â€Šand only one can be automated.</p><p><strong><em>The future belongs to those who decide well, not just deliver fast. That future can startÂ now.</em></strong></p><h3>Key Takeaways</h3><ul><li>Four quality dimensions make judgment visible and measurable: Evidence Rigour, Reasoning Transparency, Bias Awareness/Ethical Alignment, and LearningÂ Depth.</li><li>Teams progress through 5 maturity levelsâ€Šâ€”â€Šmost start at Level 1â€“2 and can reach Level 3â€“4 in 6â€“18 months through consistent practice.</li><li>Five practices strengthen judgment: three core practices (Evidence Tracking, Assumption Mapping, Experiment Design) plus two integration practices (Decision Documentation, Reflection Practice). Start with one core practice.</li><li>Two learning pathways work together: experiential learning through real-world projects and structured learning through targeted training. The integration of both creates lastingÂ change.</li><li>Start narrow: one practice, one judgment point, prove value, thenÂ expand.</li></ul><h3>References</h3><p>BallarÃ­n, A. (2022). How to increase the UX maturity of Scrum teams. <em>UX Collective</em>. <a href=""https://uxdesign.cc/how-to-increase-ux-design-maturity-for-scrum-teams-d26b4311eaa9"">https://uxdesign.cc/how-to-increase-ux-design-maturity-for-scrum-teams-d26b4311eaa9</a></p><p>Christopher, A. (2024). 16 UX mapping techniques to improve your Product development process. <em>Bootcamp</em>. <a href=""https://medium.com/design-bootcamp/15-ux-mapping-techniques-to-improve-your-product-development-process-31daa493587f"">https://medium.com/design-bootcamp/15-ux-mapping-techniques-to-improve-your-product-development-process-31daa493587f</a></p><p>Overeem, B. (2021). Amplify learning in your team with more double-loop learning. <em>The Liberators</em>. <a href=""https://medium.com/the-liberators/amplify-learning-in-your-team-with-more-double-loop-learning-eb5208e6414d"">https://medium.com/the-liberators/amplify-learning-in-your-team-with-more-double-loop-learning-eb5208e6414d</a></p><p>White, J. (2021). The role of Reflection in the design process. <em>UX Collective</em>. <a href=""https://uxdesign.cc/the-role-of-reflection-in-the-design-process-6ede3d727ca5"">https://uxdesign.cc/the-role-of-reflection-in-the-design-process-6ede3d727ca5</a></p><h3>About GaleÂ Robins</h3><p>I help software teams and solo founders strengthen discovery judgmentâ€Šâ€”â€Šthe ability to decide whatâ€™s worth building when AI makes building faster and cheaper. My product discovery approach combines methods such as Jobs-to-Be-Done, Opportunity Solution Tree, Assumption Mapping, and applying double-loop learning with evidence-based reasoning to make discovery judgment development systematic rather than accidental.</p><p><strong>Connect</strong>:<a href=""http://www.linkedin.com/in/galerobins""> www.linkedin.com/in/galerobins</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=984aafbc839a"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/building-systems-that-strengthen-product-discovery-judgment-984aafbc839a"">Building systems that strengthen product discovery judgment</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-business-is-the-only-stakeholder-that-matters-c0fbb110d632?source=rss----138adf9c44c---4,1765289986,The business is the only stakeholder that matters,"The business is the only stakeholder that matters

<h4><strong>Why UX and Market Research should stop fighting and start working together.</strong></h4><figure><img alt=""Stacks of money"" src=""https://cdn-images-1.medium.com/max/1024/1*p9g1anRJZ3oBky8i5CRiSQ.jpeg"" /><figcaption>Photo by <a href=""https://unsplash.com/@mufidpwt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"">Mufid Majnun</a> onÂ <a href=""https://unsplash.com/photos/stack-of-books-on-table-LVcjYwuHQlg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"">Unsplash</a></figcaption></figure><p>Itâ€™s a debate Iâ€™ve been dragged into so many times, I've lost track: UX vs. Market Research? Qual vs. Quant? Who owns the insights? Who make the decisions? Who drives the strategy? Who makes the â€œrealâ€Â impact?</p><p>I've been a UX Researcher for over 20 years and my thinking is deeply rooted in building meaningful products and services that solve real human problemsâ€¦ (As opposed to fake problemsâ€¦ you know, the kinds of problems that we invent in order to justify the product we're building-alas, I digress).</p><p>Over the last 5 years, my perspective has shiftedÂ greatly.</p><p>After founding Amplinate, working across Big Tech and other industries, consulting with CEOs and Entrepreneurs, and most importantly, collaborating directly with one of the top business coaches in the world, <a href=""https://www.abraham.com/"">Jay Abraham</a>, Iâ€™ve come to a humbling conclusion about Research:</p><blockquote>Itâ€™s not about methods. Itâ€™s not about disciplines or roles. Itâ€™s about making the BusinessÂ money.</blockquote><p>Thatâ€™s the only way research becomes indispensable. And if we fail to do that? We become expendable. And thatâ€™s <em>exactly</em> whatâ€™s happening now.</p><h3>The disciplinary distraction: UX vs. MarketÂ Research</h3><p>This article builds on my response to a recent discussion in the <a href=""https://mrxpros.com/"">Market Research Pros GoogleÂ Group</a>.</p><p>The original post brought up the difference between Market Research and UX Research, and did a really good job at delineating the difference between the two in terms of focus and scope and method. I agreed with theÂ post.</p><p>But after spending more time with Market Researchers in the past 5 years, and working with Marketing Legend, Jay Abraham, I started to see more commonalities than differences in our disciplines.</p><figure><img alt=""Josh LaMar and Jay Abraham"" src=""https://cdn-images-1.medium.com/max/1024/1*uVdrJDSPf5oBqyrjqbqwIQ.jpeg"" /><figcaption>Josh LaMar and JayÂ Abraham</figcaption></figure><p>We are both trying to understand customers and position products/services to meet their needs, either through positioning (Market Research) or through Designing and building the product (UX Research). The goal is theÂ same.</p><p>And yet, the inevitable turf war started coming upâ€¦ &quot;I do this, you do that.&quot; or, &quot;This is my lane! You stay in yourÂ lane!&quot;</p><p>Meanwhile, the business keeps moving ahead and amidst rounds of layoffs, there's a truth that we're not acknowledging:</p><blockquote>Research is irrelevant if it doesn't serve the Business.</blockquote><h3>The methods distraction: Quant vsÂ Qual</h3><p>As the conversation progressed, we got back to the tried and true Quant vs. Qual debate, this time, with the nuance that &quot;Market Research works mainly in Quant&quot; and &quot;UX Research works mainly in Qual.&quot; Maybe itÂ does.</p><p><strong>And maybe, it doesn't actually matter at all.</strong> I've seen Quant-focused UX studies (like Jobs to be Done) and Qual-focused ethnographic Market Research studies (Ever notice that Marketing always have more budget than the productÂ teams?).</p><p>Mixed methods researchers claim they can do both. And itâ€™s true. We toggle between qual and quant to answer different questions as the need arises... But it's still missing theÂ point.</p><p>Why does ownership of methods matter to practitioners? It doesnâ€™t matter to your CEO, thatâ€™s for certain. The deeper question is: What decisions are we trying to inform? And who ultimately benefits?</p><blockquote>What actually matters? Making data-informed decisions<strong> </strong>that fuel business outcomes.</blockquote><p>The reality is that researchers are not just out there gathering data that we present as insights and recommendations. We influence decisions about the product. And in todayâ€™s economic landscape, every decision that matters is, ultimately, a <em>business</em> decision.</p><h3>Product decisions are business decisions</h3><p>This point deserves its own sectionâ€¦ The question came up next as to how to define &quot;Research.&quot; Ok, here's myÂ attempt:</p><blockquote><em>Research (Both UX and Market Research) is</em> <em>the process</em> <em>of collecting, analyzing, and interpreting Customer and Product data to make Business decisions.</em></blockquote><p>This triad (Customer, Product, Business), comes together in <em>Product Truth</em>. Itâ€™s the intersection between what customers need your product to do, what you promise it does, and what it actually delivers.</p><figure><img alt=""Venn diagram of product truth showing the intersections of Business, Product, and Customer"" src=""https://cdn-images-1.medium.com/max/1024/1*f4OjHPoamhImzyLjmUc1sw.jpeg"" /></figure><p>When there is alignment between these three: Great! You're on the path to success. But when there's a breakdownâ€¦ WatchÂ out!</p><p>When you build products using only one or two of the lenses, you risk making flawed decisions:</p><ul><li>Business + Product (without Customer): Leads to commercially viable but irrelevant products.</li><li>Business + Customer (without Product): Creates desirable but unfeasible solutions.</li><li>Product + Customer (without Business): Results in great UX with no path to profitability.</li></ul><p>Misalignment can lead to product failure. But Research plays a unique role: it illuminates the missing perspectives, allowing insights to become a bridge into business strategy.</p><h3>Tough love</h3><p>If I could go back in time, I wouldnâ€™t tell my younger self to learn another methodology or get better at stakeholder management.</p><blockquote>If I could go back in time, Iâ€™d give myself one piece of advice: â€œCare more about the business.â€</blockquote><p>I used to think my job was to advocate for the user. And while thatâ€™s still true, but itâ€™s a smaller part of the equation than I thought. Advocating for users without understanding the business context is like drawing a map without knowing where your destination is.</p><h3>Want to become essential?</h3><p>I think we all want to be seen as essential to the businessâ€¦ to grow in our careers, to thrive, and to make more money ourselves. And the first step is reallyÂ simple:</p><ul><li>You want job security? <strong>Help the business makeÂ money.</strong></li><li>You want more influence on product decisions? <strong>Help the business makeÂ money.</strong></li><li>You want to create more ethical, human-centered products? <strong>Help the business make money</strong>, ideally, in a way that <a href=""https://uxdesign.cc/human-flourishing-in-the-age-of-ai-b456b1de31c7"">supports human flourishing</a>.</li></ul><p>Thatâ€™s how you become essential.</p><p>Thatâ€™s how you stay in theÂ loop.</p><p>And thatâ€™s how you go from being perceived as a cost center to being a profit centerâ€¦ In essence, a <em>strategic partner</em>.</p><h3>Stop arguing and focus on theÂ business</h3><p>This is the moment for UX and Market Research to unite under a shared mission: Helping businesses make human-centered decisions that driveÂ growth.</p><p>We are not against each other. We are collaborators in solving the same problem from different angles, sometimes using the same methods, and always bringing our unique education and background experience to the table to inform how we interpret and make sense of Customer and ProductÂ data.</p><p>It's time to stop arguing about who owns the data or which method or discipline is superior.</p><p>Instead, letâ€™s focus on building a future where data is at the core of every strategic business decision.</p><p>Because thatâ€™s the only way we all win: Together.</p><p><strong>Josh LaMar</strong> is the Co-Founder and CEO of <a href=""https://amplinate.com/"">Amplinate</a>, an international agency focusing on cross-cultural Research &amp; Design. As the Chief Strategy Officer of <a href=""https://www.joshlamar.com/"">JoshLaMar Consult</a>, he helps Entrepreneurs grow their business through ethical competitive advantage.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c0fbb110d632"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-business-is-the-only-stakeholder-that-matters-c0fbb110d632"">The business is the only stakeholder that matters</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/how-to-approach-creating-design-alternatives-in-a-sustainable-way-197c6b875f0a?source=rss----138adf9c44c---4,1765284250,How to approach creating design alternatives in a sustainable way,"How to approach creating design alternatives in a sustainable way

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/how-to-approach-creating-design-alternatives-in-a-sustainable-way-197c6b875f0a?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/2600/1*igWW7-wKPUARp40ug8Z2jA.jpeg"" width=""6000"" /></a></p><p class=""medium-feed-snippet"">The rule of 3 in design isn&#x2019;t feasible anymore, unless you do this</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/how-to-approach-creating-design-alternatives-in-a-sustainable-way-197c6b875f0a?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/is-there-such-a-thing-as-mindful-scrolling-0852ab37c404?source=rss----138adf9c44c---4,1765228402,Is there such a thing as mindful scrolling?,"Is there such a thing as mindful scrolling?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/is-there-such-a-thing-as-mindful-scrolling-0852ab37c404?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*2YFDsTprfIe67TKfLAd-hA.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">What happens when you apply mindfulness to a mindless experience?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/is-there-such-a-thing-as-mindful-scrolling-0852ab37c404?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/thought-shaped-ui-sigma-%CF%83-shaped-designers-figmas-new-ds-features-f25284dffb46?source=rss----138adf9c44c---4,1765196027,"Thought-shaped UI, sigma (Î£) shaped designers, Figmaâ€™s new DS features","Thought-shaped UI, sigma (Î£) shaped designers, Figmaâ€™s new DS features

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://uxdesign.cc/we-are-entering-the-era-of-thought-shaped-software-108313ff4401""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*sC4Bvf3N1hZbqzIF.png"" /></a></figure><p>â€œWe have a big choice to make: weâ€™re about to jump into a new era of technologyâ€Šâ€”â€Šmeaning different values, expectations, and powersâ€Šâ€”â€Šand we need to choose what it looks like.*1 The transition itself is unavoidable, but the details are up toÂ us.</p><p>Today we must choose between a) a future where our software environment has a thought-shaped interface on top of all the old kludge, or b) a future where software is built from the ground up to represent our thoughts, not twist or controlÂ them.â€</p><p><a href=""https://uxdesign.cc/we-are-entering-the-era-of-thought-shaped-software-108313ff4401""><strong>We are entering the era of thought-shaped software</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/c9fe1ab036c1"">Oliver MeredithÂ Cox</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/unfit-for-uncertainty-rethinking-decision-making-for-missions-4936e04dc78a""><strong>Unfit for uncertainty</strong></a><strong> â†’</strong><br />Rethinking decision-making for missions.<br />By <a href=""https://medium.com/u/e1ffebbf296c"">JackÂ Strachan</a></li><li><a href=""https://uxdesign.cc/designing-for-signals-how-intent-instrumentation-shape-ai-powered-experiences-7ed2da879795""><strong>Designing for signals</strong></a><strong> â†’</strong><br />How intent &amp; instrumentation shape AI experiences.<br />By <a href=""https://medium.com/u/8f9c79748da9"">BradlyÂ Zavakos</a></li><li><a href=""https://uxdesign.cc/the-ai-era-needs-sigma-%CF%83-shaped-designers-not-t-or-%CF%80-82034f34ec54?sk=cd2d54b9537e3e8c8a76b27e7833fee6""><strong>Sigma (Î£) shaped designers</strong></a><strong> â†’</strong><br />Why the AI era requires a different type of skillset.<br />By <a href=""https://medium.com/u/17dab133f2ba"">DarrenÂ Yeo</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://order.design/project/work-and-co?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*se-U2w2lfhxWLDvc.png"" /></a></figure><p><a href=""https://order.design/project/work-and-co?ref=sidebar""><strong>A dozen years of Work &amp; Co</strong></a><strong>Â â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://www.brookings.edu/articles/we-should-all-be-luddites/?ref=sidebar""><strong>We should all be Luddites</strong></a><strong> â†’</strong><br />â€œFor the past two centuries, invoking the term â€œLudditesâ€ was shorthand for technological backwardness or fear of innovationâ€Šâ€”â€Ša sneer aimed at anyone who dared question the march of progress. But the real Luddites werenâ€™t afraid of machines; they were afraid of the social and economic impacts of the new technology on peopleâ€Šâ€”â€Šand of who controlled the terms of technological change.â€</li><li><a href=""https://staysaasy.com/strategy/2025/11/25/own-a-graph.html?ref=sidebar""><strong>Own a graph</strong></a><strong> â†’</strong><br />â€œOne of the quickest ways to get better at your job is to own a graph. There are many ways to do work that donâ€™t matter and there are many ways to do work that matters but fail to articulate that value well. Owning a graph solves both of these problems.â€</li><li><a href=""https://hvpandya.com/systems-stables-stars?ref=sidebar""><strong>Systems, stables and stars</strong></a><strong> â†’</strong><br />â€œYou know how large organizations with very mature systems and talent distribution still end up pulling in the same top 5 or 10 people to work on their most pressing problems?â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/biophilic-design-is-the-wellness-revolution-happening-all-around-us-d896346da3c3""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*nMZS2WnS82qYtnFt.png"" /></a></figure><p><a href=""https://uxdesign.cc/biophilic-design-is-the-wellness-revolution-happening-all-around-us-d896346da3c3""><strong>Biophilic design is the wellness revolution happening all around us</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/965c39841cc8"">TimÂ Daniels</a></p><figure><a href=""https://uxdesign.cc/the-ux-behind-screen-time-guilt-f4d4dfaca1e8?sk=d4f725855fdbf86580ec131d36e16591""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*unVId5s8OVqIbrMa.png"" /></a></figure><p><a href=""https://uxdesign.cc/the-ux-behind-screen-time-guilt-f4d4dfaca1e8?sk=d4f725855fdbf86580ec131d36e16591""><strong>The UX behind screen time guilt</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/8797adcdd8a8"">FabriziaÂ Ausiello</a></p><figure><a href=""https://uxdesign.cc/the-product-designers-lens-8511246a7984?sk=d6a6d872d84f296ae034a4bed26a48db""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*747PFkgnJ-CR9a4h.png"" /></a></figure><p><a href=""https://uxdesign.cc/the-product-designers-lens-8511246a7984?sk=d6a6d872d84f296ae034a4bed26a48db""><strong>The product designerâ€™s lens</strong></a> â†’<br />By <a href=""https://medium.com/u/6e211b28ed59"">DaleenÂ Rabe</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/what-do-figmas-updates-mean-for-design-systems-323fb0cc8495""><strong>Figmaâ€™s new DS features</strong></a><strong> â†’</strong><br />What do Figmaâ€™s updates mean for Design Systems?<br />By <a href=""https://medium.com/u/b2f44e1879c9"">AllieÂ Paschal</a></li><li><a href=""https://uxdesign.cc/why-you-need-design-maturity-in-a-product-organisation-and-how-to-get-it-9f45fd4e20c3""><strong>Design maturity</strong></a><strong> â†’</strong><br />Why you need it and how to get it.<br />By <a href=""https://medium.com/u/44c1b36a36ce"">danramsden</a></li><li><a href=""https://uxdesign.cc/designing-decisions-behavioral-psychology-that-moves-users-e5fb08e7917a""><strong>Designing decisions</strong></a><strong> â†’</strong><br />Behavioral psychology that moves users.<br />By <a href=""https://medium.com/u/161b4eee2ac1"">MaximÂ Kich</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://design.penpot.app/#/auth/login?utm_source=Design-Tokens&amp;utm_medium=Newsletter&amp;utm_campaign=UXCollective"">this weekâ€™s sponsor</a> to support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f25284dffb46"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/thought-shaped-ui-sigma-%CF%83-shaped-designers-figmas-new-ds-features-f25284dffb46"">Thought-shaped UI, sigma (Î£) shaped designers, Figmaâ€™s new DS features</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-ai-era-needs-sigma-%CF%83-shaped-designers-not-t-or-%CF%80-82034f34ec54?source=rss----138adf9c44c---4,1764965227,The AI era needs Sigma (Î£) shaped designers (Not T or Ï€),"The AI era needs Sigma (Î£) shaped designers (Not T or Ï€)

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-ai-era-needs-sigma-%CF%83-shaped-designers-not-t-or-%CF%80-82034f34ec54?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*BAfllc4BX5oh9c9RW-fAEw.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">For years, design and tech teams have relied on shape metaphors to describe expertise. We had T-shaped people (one deep skill, broad&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-ai-era-needs-sigma-%CF%83-shaped-designers-not-t-or-%CF%80-82034f34ec54?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/the-stories-that-keep-us-obedient-b1eac97329cd?source=rss----138adf9c44c---4,1764965199,The stories that keep us obedient,"The stories that keep us obedient

<h4>James Baldwin on protection, avoidance, and the limits weÂ inherit.</h4><figure><img alt=""Black-and-white portrait of James Baldwin looking directly at the camera with a slightly furrowed brow and a measured, skeptical expression. His head is tilted slightly forward, and the background is plain and light, keeping the focus on his face."" src=""https://cdn-images-1.medium.com/max/1024/1*jIlOmpINB0KlHodPMK5CZg.png"" /><figcaption>James Baldwin</figcaption></figure><p><strong>Whatâ€™s the balance between protection andÂ control?</strong></p><p>Early on, the difference is hard to see. A rule tightens, choices narrow, and it still feels like someone watching out for us. But the moment weâ€™re told which questions are acceptable, the story stops being something we believe and becomes something weâ€™re permitted toÂ follow.</p><p><em>Iâ€™m </em><a href=""https://www.linkedin.com/in/natesowder/""><em>Nate Sowder</em></a><em>, and this is </em><strong><em>unquoted, installment 14</em></strong><em>. This week, weâ€™re looking at</em><a href=""https://www.britannica.com/biography/James-Baldwin""><em> James Baldwin</em></a><em> and the dynamics of controlling systems.</em></p><h3>Baldwin beforeÂ Baldwin</h3><p>James Baldwin grew up in Harlem in the 1930s, in a neighborhood where the church was often the only institution offering structure, identity and a sense of direction. His stepfather was a preacherâ€¦ strict, volatile, convinced the world was dangerous and that discipline was the only defense against it. Baldwin was taught early that love and fear could sound the same from the pulpit, and that protection could arrive in a tone that felt indistinguishable fromÂ control.</p><p>By adolescence, he was already <a href=""https://www.poetryfoundation.org/poets/james-baldwin"">writing</a>, already watching, already noticing how authority behaves when itâ€™s anxious. He saw how parents and pastors tightened their grip (not because they were strong, but) when they were afraidâ€¦ afraid of the world outside, afraid of losing their children to it, afraid of questions that didnâ€™t have answers prescriptively laidÂ out.</p><p>The punchline is that Baldwin left the church, but he never stopped studying its logic: the way belief gets inherited, the way fear gets institutionalized (let that sink in), and the way people learn to live inside systems that claim to protect them while shaping them into somethingâ€¦ relatively insignificant.</p><p>What made Baldwin, <a href=""https://press.princeton.edu/ideas/james-baldwins-reckless-idea?srsltid=AfmBOoq3aGh7HlIOybdMwX47r4Ou62HOfMIWk2vdBNKZ2AiU4RtFowoI"">Baldwin wasnâ€™t doctrine or theory. </a>Instead, it was his ability to see how systems (families, churches, nations, etc.) reveal their deepest insecurities in how they try to keep people â€œsafeâ€. And how, in doing so, they confuse protection with control until the two become nearly indistinguishable.</p><figure><img alt=""Black-and-white photo of James Baldwin standing in a dim room with one hand on his hip. He faces the camera directly, framed by a cluttered mantel on the left and a stacked bookshelf on the right. Drawings, books, and papers fill the space around him, giving the room a lived-in, intellectual feel. The light casts his shadow across the wall behind him."" src=""https://cdn-images-1.medium.com/max/1024/1*nSgJEuyNPhgi6gSGa3mJAg.jpeg"" /><figcaption>James Baldwin in Saint-Paul-de-Vence, France, in 1979. Photo: Pierre Boulat/Cosmos</figcaption></figure><h3>What BaldwinÂ saw</h3><p>What Baldwin carried out of that childhood was clarity about how authority behaves when it feels uneasy. He noticed that the strictest rules often appeared when the people enforcing them felt threatened. When grips tightened, it wasnâ€™t because the world required it; it was because the adults in charge didnâ€™t know what to do with their own uncertainty.</p><p>He grew up watching beliefs passed down without examination, repeated out of habit, fear, or duty. Questioning them didnâ€™t feel dangerous because of the ideas themselves, it felt dangerous because of what those questions exposed: How fragile the underlying certainty reallyÂ was.</p><p><a href=""https://theconstitutionalist.org/2021/08/19/learning-to-love-like-james-baldwin/"">Baldwin learned that control often exposes the very vulnerability it intends toÂ hide.</a></p><p>This became the thread running through his work. Whether he was writing about families, churches, or nations, he kept returning to the same observation: Systems that depend on obedience are rarely confident in their foundations. They appeal to safety, stability, or virtue, but what they are really protecting is the comfort of not having to reconsider themselves.</p><p>Baldwin didnâ€™t need to catalogue every rule or doctrine. It was sufficient enough studying what people do when theyâ€™re afraid to face their own reflection.</p><h3>When fear becomesÂ policy</h3><p>The dynamics Baldwin observed in the church werenâ€™t confined to pulpits or families. You can see the same architecture anywhere a system confuses order with virtue and obedience with stability. Some cultures call it tradition, others morality, and some simply call it policy. But the structure is identical: fear becomes the rationale, and protection becomes theÂ excuse.</p><p>You see it in countries where dissent is treated as contamination. The state offers â€œsafetyâ€ in exchange for silence, promising harmony while making independent thought feel hazardous. Citizens learn to measure their words before they measure their ideas. Over time, people donâ€™t become loyal; they become cautious. And while caution is easy to manage, history has shown this isnâ€™t a foundation for stability.</p><p>You see it in religious movements convinced the world is deteriorating and that only strictness can save the next generation. Rules multiply. Curiosity becomes a liability. Children are raised not to understand their beliefs, but to repeat them as if conviction can survive without the capacity to question. It looks devout from the outside, but inside, itâ€™s a culture afraid of the very people it claims to shepherdâ€Šâ€”â€Šheld together by the oldest tool available: shame.</p><p>And you see it in political strategies designed to produce dependency. Systems remove options not because citizens canâ€™t handle them, but because the system canâ€™t. Policies become tight, resources shrink and the message becomes unmistakable: trust us, not yourself. The promise sounds like protection or worse: Equality. The effect feels more like containment, and the longer someone stays inside it, the harder it becomes to imagineÂ leaving.</p><p>Across these contexts, fear has the opposite intended effect. It organizes around compliance rather thanÂ unity.</p><p>And compliance, once internalized, becomes something far more difficult to undo than force: <strong>it becomesÂ normal.</strong></p><h3>Why control feels necessary</h3><p>Controlling systems (and people buying into it) rarely see themselves as controlling. They see themselves as managing risk. Uncertainty becomes the problem to solve, and predictability becomes the measure of whether the solution is working. Once that logic takes hold, the system begins to interpret any deviation (any question, new idea, independent choice, etc.) as evidence that the threat hasnâ€™t been contained.</p><p>This is how control becomes rationalized.<br />Not moral, not ideologicalâ€¦ <em>rational</em>.<br /> <br />A system anxious about its own stability starts treating unpredictability as danger, even when nothing dangerous is happening. Order becomes a proxy for safety. Obedience becomes a proxy for belonging, and the more fragile the system feels internally, the more rigid its rules become externally.</p><ul><li>In families, this shows up as an insistence that â€œgood choicesâ€ are the ones that avoid discomfort.</li><li>In organizations, it shows up as leaders mistaking silence for alignment.</li><li>In societies, it shows up as policies built to prevent change rather than manageÂ it.</li></ul><p>The irony is always the same: The tighter a system tries to hold things together, the more it reveals how afraid it is of letting peopleÂ grow.</p><p>Control is a thing because a system doubts it can surviveâ€¦ not because a system isÂ strong.</p><p><strong>In the end, control survives not on strength, but on the fear of what might happen withoutÂ it.</strong></p><h3>The stories avoidance handsÂ down</h3><p>Oddly enough, avoidance isnâ€™t neglect. Avoidance is the explanation of which questions are allowed and which ones should never be asked. Every controlling system depends on stories that make it feel responsible. These are stories inherited so early and repeated so often that questioning them starts to feel like a breach. To Baldwin, these werenâ€™t ideas or lessons. These were boundaries.</p><p>You can probably see where this isÂ going.</p><p>The first layer is <strong>tradition</strong>. It hands us practices and expectations framed as stability. But tradition often survives because it saves people from having to examine what might change if they let themselves reconsiderâ€¦ wellâ€¦ tradition. Avoidance hides neatly inside continuity.</p><p><strong>History</strong> is next. Not as a record, but as a curated reassurance. A society (in power) decides which parts of its past are useful, and arranges them <strong>(or deletes them, as you might notice)</strong> accordingly. Once that arrangement feels authoritative, uncertainty becomes harder to entertain. Questioning the narrative reads as destabilizing, even when the narrative was assembled to prevent destabilization in the first place (if you can believeÂ it).</p><p>Then <strong>morality</strong> steps in to seal the deal. Guidance becomes doctrine, doctrine becomes obligation, and obligation becomes a performance of virtue that relies on predictability rather than understanding. Baldwin saw how easily morality can be drafted into the service of avoidance. <strong>What I mean here, is how often systems reward people not for being thoughtful, but for being steady and compliant.</strong></p><p>And now we have a pattern. Avoidance becomes normal. The stories people inherit teach them to not ask questions. They close the space in which doubt can occur, and treat uncertainty as a sign of <strong>personal failure</strong>. The more these habits embed, the less the system needs to enforce anything. People maintain the limits themselves.</p><p>Baldwinâ€™s clarity cuts cleanly here: O<strong>bedient systems train people to fear questions until avoiding them starts to feel like character.</strong></p><p><strong>If this feels like the moment everything clicksâ€¦ good. Weâ€™re notÂ done.</strong></p><h3>What control reallyÂ creates</h3><p>Once avoidance becomes the operating logic of a system, something predictable happens to the people inside it: They stop developing the instincts they would need to live without the systemâ€™s protection. For Baldwin, this was the tragedy of control. It doesnâ€™t just limit what people can do. It limits what they believe themselves capable of understanding.</p><p>When questions are treated as disruptions, people learn to ignore the parts of their lives that donâ€™t fit the approvedÂ story.</p><p>People stop examining their assumptions. They stop trusting their own judgment and stop exploring ideas that might complicate the version of themselves the systemÂ prefers.</p><p>You know the consequences better than me. People grow uncomfortable with uncertainty. They choose predictability. They confuse obedience with maturity because obedience is the only behavior the system ever rewarded. And when faced with something that requires imagination, or skepticism, or self-direction, they hesitateâ€¦</p><p>I donâ€™t think they hesitate because they lack intelligence. I think they hesitate because of a horrible failure that has taken a really long time to takeÂ effect.</p><p>Baldwinâ€™s warning was never about the severity of limits. It was about their effect. <strong>Control produces people who expect someone else to name boundaries for them. </strong>Once that expectation settles in, the system doesnâ€™t need to impose its authority. It simply waits for people to stay inside the lines on theirÂ own.</p><h3>The cost of making obedience aÂ virtue</h3><p>The longer a system depends on avoidance, the harder it becomes to see the trade-off being made. Over time, people forget that their certainties were handed to them. They begin to speak as though they reached those conclusions on their own. Thatâ€™s how avoidance starts looking like conviction.</p><p>This is where I think the damage shows up. Systems built on obedience donâ€™t need to enforce much. People begin to manage themselves long after the original authority fades off. They sidestep questions that would be unsettling to the story they inherited. Theyâ€™re able to seek out and maintain a stability they never chose and participate in their own containment because the alternative (actual examination) feels disloyal to the world that taught them not to question.</p><p>Baldwin leaves us with a hard truth:<br /><strong>Control doesnâ€™t secure a system; It reduces the scale of the people insideÂ it.</strong></p><p>Once that reduction feels normal, the system has very little to maintain. Avoidance passes from one generation to the next, each one repeating the scripts that make obedience sound eerily similar to maturity.</p><p>We tell ourselves weâ€™re protecting whatÂ matters.</p><p>But protection without examination is something else entirely. Itâ€™s the refusal to imagine what someone might become if they were trusted with their own questions.</p><p><em>Unquoted is a series about the people and their ideas we canâ€™t afford toÂ forget.</em></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b1eac97329cd"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-stories-that-keep-us-obedient-b1eac97329cd"">The stories that keep us obedient</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-anatomy-of-product-discovery-judgment-0cb28b28cc7c?source=rss----138adf9c44c---4,1764965156,The anatomy of product discovery judgment,"The anatomy of product discovery judgment

<h4>The 19 critical decision moments where human judgment determines whether teams build the rightÂ things.</h4><figure><img alt=""Split illustration: left side shows teal circuit board patterns with data icons representing AI automation; right side shows coral-colored hands reaching toward a decision tree, representing human collaboration and judgment. The image visualizes how AI pattern-based reasoning and human meaning-based judgment work together."" src=""https://cdn-images-1.medium.com/max/1024/1*Pyk6n9NXC25HwSt2nWjYJg.jpeg"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>I watched a talented software team present three major features theyâ€™d shipped on time, hitting all velocity metrics. When I asked, â€œWhat problem do these features solve?â€ silence followed. They could describe what theyâ€™d built and how they'd built it. But they couldnâ€™t articulate why any of it mattered to customers.</p><p>It wasnâ€™t incompetence, but rather a loss of clarity in the rush to deliverâ€Šâ€”â€Ša failure of judgment, not execution. Iâ€™ve been in that room beforeâ€Šâ€”â€Šon the other side. Iâ€™ve watched teams I led ship features that solved problems no one had previously identified. The hard lesson: executing speed without clear judgment gets you to failure faster. Of course, timely execution remains vital, but discovery judgment has become the actual constraint.</p><p>Teams emphasize that judgment canâ€™t be automated. Yet, AI clearly performs tasks that resemble judgment, such as identifying patterns, flagging contradictions, and synthesizing insights across dozens of interviews. So whatâ€™s the distinction thatÂ matters?</p><p>AI excels at <strong>pattern-based reasoning</strong>: recognizing correlations in data, clustering similar themes, and optimizing within defined parameters. Humans provide <strong>meaning-based judgment</strong>: interpreting what patterns signify about real needs, deciding which correlations reveal causation, and determining whatâ€™s worth pursuing given purpose andÂ values.</p><p>The Discovery Judgment Framework helps teams systematically develop this capability. This article focuses on the frameworkâ€™s first component: the 19 judgment points where meaning-based judgmentâ€Šâ€”â€Šnot just pattern recognitionâ€Šâ€”â€Šdetermines whether teams build the rightÂ things.</p><h3>The Discovery Judgment Framework</h3><p>If youâ€™re skeptical about â€œyet another framework,â€ that skepticism is earned. Youâ€™ve probably worked with Lean, Agile, Design Thinking, Jobs-to-Be-Done, OKRs, and dozens of others. Each contributes valueâ€Šâ€”â€Šimproving alignment, efficiency, and collaboration. But even the best frameworks cannot substitute for the quality of judgment applied within them. Framework fatigue typically occurs when teams adopt them without developing the judgment to use them effectively.</p><p>The <strong>Discovery Judgment Framework</strong> is different. It makes invisible judgment visible and systematically developable through four integrated components:</p><ol><li><strong>Judgment Points (Diagnostic)</strong>: Where judgment matters across the discovery-delivery-learning cycle.</li><li><strong>Quality Dimensions (Measurement)</strong>: How to assess judgmentÂ quality.</li><li><strong>Core Practices (Development)</strong>: How to strengthen judgment systematically.</li><li><strong>Maturity Model (Progression)</strong>: How judgment capability evolves.</li></ol><p>This doesnâ€™t replace your existing discovery frameworks; it makes them more effective by revealing the quality of judgment theyÂ apply.</p><h3>Why These Judgment Points MatterÂ Now</h3><p>As AI makes execution radically faster and cheaper, teams can now build the wrong things at unprecedented speed. What once took six months of misguided effort now takes six weeks, or with AI, sixÂ days.</p><p>As Teixeira and Braga (2025) warn in UX Collectiveâ€™s State of UX in 2025 report, weâ€™re witnessing â€œa fundamental shift in responsibilities and a transfer of design control from designers to a complex network of algorithms, automated tools, and business stakeholders.â€ The troubling trend? Teams are â€œslowly swapping user research for automated A/B tests, and gradually letting the data make decisions on our behalf.â€ This abdication of human judgment is precisely theÂ problem.</p><p>Judgment density increases as AI accelerates deliveryâ€Šâ€”â€Šthe number of consequential decisions teams face per week skyrockets. Improving judgment quality isnâ€™t optional; itâ€™s the only scalable control mechanism for preventing algorithms from deciding what toÂ build.</p><p>Teams committed to better discovery still struggle with a fundamental question: Where exactly do you apply judgment? Which decisions actually determine success orÂ failure?</p><p>AI can now synthesize interviews in minutes, but only humans provide the judgment to interpret what patterns signify and decide whatâ€™s worth pursuing. Each judgment point is a moment where AI can either accelerate good judgment or amplify bad judgment. When humans interpret AI-generated insights, bias creeps inâ€Šâ€”â€Šwe tend to confirm what we already believe and selectively interpret patterns.</p><p>Consider a typical moment where AI accelerates pattern recognitionâ€Šâ€”â€Šbut judgment still decides whatÂ matters.</p><p>A team building project management software conducts eighteen customer interviews. AI analysis flags that thirteen participants mentioned â€œestimates are alwaysÂ wrong.â€</p><p>The team noticed what AI couldnâ€™t: nine engineering managers were frustrated that their teams underestimated technical complexity, while four product managers were frustrated that stakeholders underestimated scope. Same symptom, opposing causesâ€Šâ€”â€Šone group needs better bottom-up estimation tools, the other needs better top-down scope definition.</p><p>Their decision: Interview three people from each group separately to understand the distinct jobs before proposing any solution.</p><p>AI accelerated pattern recognition from days to minutes. Only humans can judge that identical complaints mask fundamentally different problems that require separate discovery paths. As Gecis (2021) emphasizes in the Jobs-to-Be-Done framework, understanding the underlying â€œjobâ€ customers are trying to accomplishâ€Šâ€”â€Šnot just surface-level feature requestsâ€Šâ€”â€Šis essential for meaningful product decisions.</p><h3>The 19 Critical JudgmentÂ Points</h3><p>Iâ€™ve mapped the moments where discovery judgment determines outcomes. These judgment points will continue to evolve as practice deepens. Understanding them gives teams a way to see their reasoning, not just results. Discovery isnâ€™t one decisionâ€Šâ€”â€Šitâ€™s a cascade of 19 interconnected judgment calls organized into fourÂ domains:</p><p><strong>Framing Judgment</strong>: defining the right problems to solve. Focuses on <em>what</em> and <em>why</em>: identifying customers, uncovering unmet needs, clarifying desired outcomes, mapping assumptions, and aligning on the opportunity worth pursuing.</p><p><strong>Solution Judgment</strong>: exploring and choosing how to solve them. Centers on <em>how</em> to generate and evaluate alternative approaches, balancing feasibility and value, sequencing risks, and deciding what to testÂ first.</p><p><strong>Validation Judgment</strong>: interpreting evidence and learning from experiments. Addresses <em>whatâ€™s true</em>: setting confidence thresholds, interpreting results objectively, and deciding when to pivot, persist, orÂ stop.</p><p><strong>Post-Delivery Judgment</strong>: learning from what happens after launch. Closes the loop: selecting which signals to track, recognizing emerging patterns, interpreting success or failure, and feeding insights back into discovery cycles.</p><figure><img alt=""A visual diagram showing 19 critical judgment points organized into four domains: Framing Judgment (purple), Solution Judgment (blue), Validation Judgment (green), and Post-Delivery Judgment (orange). Arrows show how judgment cycles continuously from discovery through delivery and back through post-delivery learning. Each domain contains 4â€“5 specific judgment points where human reasoning has the most significant influence on product outcomes."" src=""https://cdn-images-1.medium.com/max/960/1*QXnk5BOUTqwAxF49Yowvjw.png"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>This diagnostic map illustrates where human reasoning has the most significant influence on product outcomes across four domains: Framing, Solution, Validation, and Post-Delivery. The arrows illustrate how judgment cycles: decisions feed forward through discovery and delivery, and loop back through post-delivery learning.</p><p>Teams donâ€™t always apply all 19 judgment points in practice, but being aware of each one is essentialâ€Šâ€”â€Šwhatâ€™s unseen canâ€™t be improved.</p><p>Hereâ€™s how this plays out in real productÂ work.</p><h3>Two Example Judgment Points inÂ Action</h3><p><strong>Scenario</strong>: A cross-functional product team is developing a Team Handoff Trackerâ€Šâ€”â€Ša tool designed to mitigate the chaos that occurs when work â€œfalls between teams.â€ Theyâ€™ve heard complaints about tasks â€œdisappearing into a black holeâ€ and assume the main problem is a lack of visibility across departments.</p><h4>1. Assumption Identification &amp; Risk Assessment</h4><p><strong>The judgment</strong>: What assumptions are you making, and which are riskiest?</p><p><strong>Poor approach</strong>: Treat â€œvisibilityâ€ as an obvious need. Jump to dashboards and progress indicators without testing whether users actually value visibility.</p><p><strong>Strong approach</strong>: List assumptions explicitly: â€œUsers lack visibility into task ownership,â€ â€œA dashboard will solve that,â€ â€œTeams will update it regularly.â€ Test the riskiest first. Result: Users donâ€™t want more visibilityâ€Šâ€”â€Šthey want more transparent accountability.</p><p>As Krawczyk (2022) notes in his article on identifying product assumptions, teams are susceptible to confirmation bias (the longer it takes to test an assumption, the more we want it to be true) and commitment bias (the more effort we invest, the harder it is to pivot). Making assumptions explicit and testing the riskiest ones first protects against theseÂ biases.</p><h4>2. Evidence Interpretation</h4><p><strong>The scenario continues</strong>: Three months later, early pilot feedback appears promising. Users rate the tool â€œvery helpfulâ€ and mention â€œclarity.â€</p><p><strong>The judgment</strong>: What does this feedback actuallyÂ mean?</p><p><strong>Poor approach</strong>: Interpret positive feedback as validation of the visibility hypothesis. Plan feature expansions. Miss that â€œclarityâ€ meant something differentâ€Šâ€”â€Šusers valued knowing who to contact, not seeing every taskâ€™sÂ status.</p><p><strong>Strong approach</strong>: Review qualitative comments line by line. Ask: â€œWhen you say â€˜clarity,â€™ what kind?â€ Discover that the real need is accountability, not visibility. Pivot to emphasize ownership cues and handoff confirmations.</p><p><strong>Lesson</strong>: If those two judgment points seem small, consider what happens when even one goesÂ wrong.</p><h3>How Judgment ErrorsÂ Compound</h3><p>These judgment points donâ€™t exist in isolationâ€Šâ€”â€Šthey ripple across the system like dominoes.</p><p>A SaaS company interviews only enterprise clients, despite SMBs accounting for 70% of its revenue. This Customer Selection error cascades through Problem Framing, Solution Judgment, Feature Prioritization, and Evidence Interpretationâ€Šâ€”â€Šaccumulating $315K over 10 months. The real need could have been validated in three weeks for underÂ $10K.</p><figure><img alt=""A flowchart showing how a single poor judgment decision cascades through multiple stages. Starting with â€œCustomer Selectionâ€ error (interviewing only enterprise clients), the diagram shows dominoes falling through Problem Framing, Solution Judgment, Feature Prioritization, and Evidence Interpretation. Each stage shows increasing cost and time investment, ending with $315K spent over 10 months to solve the wrong problem when the real solution could have been validated in 3 weeks for under $10K."" src=""https://cdn-images-1.medium.com/max/960/1*bJm6WJGE0uzRp6pehjP3GQ.png"" /><figcaption>Diagram created by author using Google Gemini AI text-to-image creator</figcaption></figure><p>Now consider AIâ€™s impact: With AI-powered development, that same cascade might occur in five months instead of 10 monthsâ€Šâ€”â€Šyou fail twice as fast, yet at the same total cost. AI doesnâ€™t make bad judgment cheaper or less damagingâ€Šâ€”â€Šit just accelerates how quickly those judgment errors compound.</p><p>The same cascade works in your favour when early judgment is sound. A clear problem definition shortens solution cycles, tightens validation loops, and compounds learning.</p><p>This is why cross-functional judgment mattersâ€Šâ€”â€Šdifferent perspectives catch different errors. Diverse perspectives help teams identify flaws in assumptions and uncover alternative interpretations. A user researcher identifies Evidence Interpretation issues. An engineer identifies Technical Approach problems. A designer notices Problem Framing gaps. A customer success rep recognizes Opportunity Selection misalignment. Each perspective is a checkpoint against cascading failure.</p><p>(In smaller teams, these roles may overlap or not exist as separate positionsâ€Šâ€”â€Šone person might play multiple roles. What matters isnâ€™t the org chart, but ensuring these different perspectives inform decisions. The 19 judgment points remain critical regardless of team size or structure.)</p><h3>Discovery as Continuous Practice</h3><p>Most teams treat discovery as a phase; the best treat it as a habit. Discovery doesnâ€™t stop at launch. Itâ€™s continuous: discover â†’ deliver â†’ learn â†’ discoverÂ again.</p><p>After shipping, teams face a flood of signals. The challenge isnâ€™t finding feedbackâ€Šâ€”â€Šitâ€™s making sense of it. Each post-delivery judgment point informs the next discovery cycle: Signal Selection shapes Customer Selection, Pattern Recognition refines Problem Framing, and Learning Extraction improves Evidence Interpretation.</p><p>As Beyer (2025) demonstrates in his guide to Teresa Torresâ€™ Opportunity Solution Trees framework, continuous discovery requires ongoing customer touchpoints and systematic experimentation. Teams that treat discovery as continuous develop judgment faster. Every cycle sharpens judgment for the next cycleâ€™s 19 judgment points. Over time, teams that make these decision points visible move from individual judgment to shared judgmentâ€Šâ€”â€Ša collective sensemaking muscle that compounds learning.</p><h3>Assessing Your Teamâ€™sÂ Judgment</h3><p>Use this quick self-assessment to identify where your teamâ€™s judgment most often fallsÂ short.</p><p>Many teams skip several judgment decisions, letting process and habit decide by default. This assessment makes themÂ visible.</p><h4>Framing Judgment</h4><ul><li>Do we validate the problem before building solutions?</li><li>Can we articulate the job our customers are trying toÂ do?</li><li>Have we explicitly mapped assumptions?</li><li>Do we know which customer segments weâ€™re serving andÂ why?</li></ul><h4>Solution Judgment</h4><ul><li>Do we test the riskiest assumptions first?</li><li>Can we explain why we rejected alternatives?</li><li>Do we prioritize based on risk and learning?</li><li>Have we generated multiple solution approaches before committing toÂ one?</li></ul><h4>Validation Judgment</h4><ul><li>Do we interpret evidence objectively?</li><li>Do we have explicit confidence thresholds?</li><li>When we pivot, can we articulate what evidence prompted theÂ change?</li><li>Do we distinguish between what users say and what theyÂ mean?</li></ul><h4>Post-Delivery Judgment</h4><ul><li>Do we track the right signals afterÂ launch?</li><li>Do we extract learning systematically from outcomes?</li><li>How quickly do we incorporate post-launch insights into the discovery process?</li><li>Can we explain what success or failure taught us about our reasoning?</li></ul><p>Many teams find theyâ€™re stronger in some domains than others, and that balance shifts over time. The goal isnâ€™t perfectionâ€Šâ€”â€Šitâ€™s visibility and deliberate improvement.</p><p>Focus on the domain that most needs strengthening. For <strong>Framing judgment</strong>: understand the underlying progress customers seek, not just what they say. For <strong>Solution judgment</strong>: generate three distinct approaches before committing. For <strong>Validation judgment</strong>: make confidence thresholds explicit and, as Nousis (2019) demonstrates, systematically test your biggest unknowns. For <strong>Post-Delivery judgment</strong>: track the right signals, extract insights, and feed them back into the discovery process.</p><p>Knowing which parts of your judgment need strengthening is the first step toward improvementâ€Šâ€”â€Šand self-awareness is where progressÂ begins.</p><h3>Your NextÂ Move</h3><p>You now have a diagnostic tool. YouÂ can:</p><ul><li>See where your teamâ€™s judgment is strong versus where it needs strengthening</li><li>Identify which judgment points youâ€™re skippingÂ entirely</li><li>Trace which judgment points have caused your biggestÂ failures</li><li>Map how poor decisions early cascadeÂ later</li></ul><p>Hereâ€™s your three-step actionÂ plan:</p><ol><li><strong>Review the 19 judgment points with your team.</strong> Identify which points youâ€™re skipping and which have caused your biggest failures.</li><li><strong>Pinpoint the three judgment points that most need strengthening.</strong> Use the assessment questions to diagnose where judgment breaks down mostÂ often.</li><li><strong>Choose ONE judgment point to address in your next sprint.</strong> Donâ€™t try to fix everything. Start with your most prominent blindÂ spot.</li></ol><h3>Key Takeaways</h3><ul><li>The Discovery Judgment Frameworkâ€™s diagnostic componentâ€Šâ€”â€Šthe 19 Judgment Pointsâ€Šâ€”â€Šmaps where meaning-based judgment determines success across Framing, Solution, Validation, and Post-Delivery domains.</li><li>AI excels at pattern-based reasoning, identifying correlations and clustering themes, but only humans provide meaning-based judgment to interpret what patterns signify and decide whatâ€™s worth pursuing.</li><li>As AI increases judgment density, the number of consequential decisions risesâ€Šâ€”â€Šmaking judgment quality the highest-leverage area for improvement.</li><li>Judgment points cascadeâ€Šâ€”â€Šearly errors compound, but strong early framing multiplies learning andÂ value.</li><li>Cross-functional judgment catches cascading errorsâ€Šâ€”â€Šdiverse perspectives spot different failures at different points.</li><li>Start with diagnosis: identify the three judgment points that most need strengthening before trying to strengthen allÂ 19.</li></ul><h3>References</h3><p>Beyer, S. (2025). Mastering Opportunity Solution Trees: A step-by-step guide. <em>Bootcamp</em>.<a href=""https://bootcamp.uxdesign.cc/the-blueprint-for-opportunity-solution-trees-9aa449cb9d76""> https://bootcamp.uxdesign.cc/the-blueprint-for-opportunity-solution-trees-9aa449cb9d76</a></p><p>Gecis, Z. (2021). 8 things to use in â€œJobs-To-Be-Doneâ€ framework for product development. <em>UX Collective</em>.<a href=""https://uxdesign.cc/8-things-to-use-in-jobs-to-be-done-framework-for-product-development-4ae7c6f3c30b""> https://uxdesign.cc/8-things-to-use-in-jobs-to-be-done-framework-for-product-development-4ae7c6f3c30b</a></p><p>Krawczyk, B. (2022). How to identify product assumptions. <em>UX Collective</em>.<a href=""https://uxdesign.cc/how-to-identify-product-assumptions-8e4588ad8bea""> https://uxdesign.cc/how-to-identify-product-assumptions-8e4588ad8bea</a></p><p>Nousis, I. (2019). Introducing the Riskiest Assumption Canvas. <em>UX Collective</em>.<a href=""https://uxdesign.cc/riskiest-assumption-canvas-73ec0e2e0abc""> https://uxdesign.cc/riskiest-assumption-canvas-73ec0e2e0abc</a></p><p>Teixeira, F., &amp; Braga, C. (2025). The State of UX in 2025. <em>UX Collective</em>.<a href=""https://trends.uxdesign.cc/""> https://trends.uxdesign.cc/</a></p><h3>About GaleÂ Robins</h3><p>I help software teams and solo founders strengthen discovery judgmentâ€Šâ€”â€Šthe ability to decide whatâ€™s worth building when AI makes building faster and cheaper. My approach combines methods such as Jobs-to-Be-Done, Opportunity Solution Tree, Assumption Mapping, and applying double-loop learning with evidence-based reasoning to make judgment development systematic rather than accidental.</p><p><strong>Connect</strong>:<a href=""http://www.linkedin.com/in/galerobins""> www.linkedin.com/in/galerobins</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0cb28b28cc7c"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-anatomy-of-product-discovery-judgment-0cb28b28cc7c"">The anatomy of product discovery judgment</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/silicon-clay-how-ai-is-reshaping-ux-design-42cb0de93680?source=rss----138adf9c44c---4,1764878519,Silicon clay: how AI is reshaping UX design,"Silicon clay: how AI is reshaping UX design

<h4>What do the last five years of academic research tell us about how design is changing?</h4><figure><img alt=""Slightly abstract clay sculpture of a human head, with a serious tone"" src=""https://cdn-images-1.medium.com/max/1024/0*eSMmoOfViZP5xEds"" /><figcaption>AI is reshaping the UX practitioner. Photo by <a href=""https://unsplash.com/@elijahbcrouch?utm_source=medium&amp;utm_medium=referral"">ElijahÂ Crouch</a></figcaption></figure><p>It would be something of an understatement to say AI has impacted the world of UXÂ design.</p><p>But how, <em>exactly</em>, has it affected UX and its practitioners?</p><p>The answer isnâ€™t straightforward, as every new AI development is accompanied by social media hype, hot takes and flexing, as designers try to prove to the worldâ€Šâ€”â€Šand possibly themselvesâ€Šâ€”â€Šthat <em>they</em> know what the latest bleeding-edge model means forÂ design.</p><p>Thatâ€™s a lot of noise. How can we cut through the static to see the realÂ picture?</p><p>Enter academia.</p><p>Over the past five years, numerous academic journal papers have been published about AI and UX design. While the wheels of academia turn slowly, we get a significant trade-off for its glacial pace: objectivity and methodical rigour.</p><p>In other words: a healthy dose of perspective.</p><p>The goal of this article is to summarise academic findings relating to four questions:</p><ol><li>Where is AI being used in the UX designÂ process?</li><li>What are the advantages and drawbacks of using AI in UXÂ design?</li><li>How do UX design practitioners feel about usingÂ AI?</li><li>What are the takeaways for future use of AI in UXÂ design?</li></ol><p>The key sources for this article are two <a href=""https://library.leeds.ac.uk/info/1404/literature-searching/15/systematic-reviews"">systematic reviews</a> from 2025: one <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">published in <em>Advances of Human-Computer Interaction</em></a>, and another <a href=""https://arxiv.org/abs/2507.04469"">available on the open-access scholarly platform ArXiv</a>. In total, this article summarises findings from 17 academic sources which are referenced at the end. Typically, these studies base their findings on surveys, interviews, focus groups and other research methods to collect insights from UX and HCI practitioners.</p><p>So forget everything youâ€™ve read from LinkedIn hype merchants, â€˜thought leadersâ€™ or doom-mongers.</p><p>Letâ€™s summarise what the scienceÂ says.</p><h3>1. Where AI is used in the designÂ process</h3><p>The highest usage of AI in UX design is in the <strong>testing</strong> phase, suggests <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">one of our 2025 systematic reviews</a>. According to this paper, 58% of studied AI usage in UX is in either the testing or discovery stage. This maybe shouldnâ€™t be surprising, considering generative AI for visual ideation and UI prototyping has lagged behind text generation.</p><figure><img alt=""Diagram showing number of studies looking at AI usage in UX design"" src=""https://cdn-images-1.medium.com/max/600/1*68bsGgzn3STeRh1mRsJtEA.jpeg"" /><figcaption>AI usage in the UX design process (Luo,Â 2025)</figcaption></figure><p>Hereâ€™s what AIâ€™s commonly being used for in each designÂ stage:</p><h4>Discovery</h4><ul><li>Identifying designÂ problems</li><li>Understanding user needs and behaviours</li><li>Creating userÂ personas</li></ul><h4>Ideation</h4><ul><li>Co-creating solutionÂ concepts</li><li>Exploring design alternatives</li><li>Predicting productÂ values</li></ul><h4>Prototyping</h4><ul><li>Generating UIÂ designs</li><li>Converting sketches to prototypes</li><li>Checking for GUI guideline violations</li></ul><h4>Testing</h4><ul><li>Predicting user experience</li><li>Identifying usability issues (e.g. heuristic evaluations)</li><li>Planning and analysing userÂ testing</li></ul><p>In terms of what AI tools UX practitioners are using, hereâ€™s a breakdown which is both informative but already slightly out ofÂ date:</p><figure><img alt=""Graph showing AI usage in UX design with ChatGPT leading the way"" src=""https://cdn-images-1.medium.com/max/1024/1*prI1D36s13QeOnnQG-taug.png"" /><figcaption>Frequency of AI models used across UI/UX design studies (Ahmed and Imran,Â 2025)</figcaption></figure><h4>Summary</h4><p>UX practitioners are clearly making use of AI across the design process, with ChatGPT being the most popularÂ tool.</p><p>However, while ideation and prototyping with AI gains a lot of attention, itâ€™s the <em>testing</em> phase where the most studies have examined utilising AIâ€Šâ€”â€Šand itâ€™s also significantly studied in the discovery phase. This disparity may even out as AI continues to improve at generating UIÂ designs.</p><h3>2. Advantages and drawbacks of using AI in UXÂ design</h3><p>Iâ€™ve grouped these insights from academic papers into broad themes. You can see that for every benefit of using AI in the UX design process, there are risks and pitfalls toÂ avoid.</p><h4>Speed, cost andÂ quality</h4><p><strong>Advantages: </strong>AI can speed up UX design in numerous ways, from research and ideation to prototyping and testing. For example, it can <a href=""https://dl.acm.org/doi/10.1145/3658619.3658628"">accelerate concept iteration</a> in the early stages of the design process compared to traditional UX methods. This has obvious implications in terms of <a href=""https://ieeexplore.ieee.org/document/10115412"">reducing delivery timeframes and projectÂ costs</a>.</p><figure><img alt=""Seahorse design concept generated by the AI tool Midjourney"" src=""https://cdn-images-1.medium.com/max/1024/1*AJ0q0Q62hV8bx5KL984ECQ.png"" /><figcaption>Concept co-creation with Midjourney (Maceli, Smith and Bhakta,Â 2024)</figcaption></figure><p><strong>Drawbacks:</strong> AI generated design ideas can be <a href=""https://dl.acm.org/doi/10.1145/3613904.3642114"">homogeneous, generic and lacking in consistency</a>, meaning the time and cost of human input must be considered to ensure the final designs are sufficiently distinct and cohesive. (That is, if we care about designing betterâ€Šâ€”â€Šor simply goodâ€Šâ€”â€Šsolutions, and not just <em>faster </em>solutions.)</p><h4>Efficiency versus innovation</h4><p><strong>Advantages: </strong>The use of AI can <a href=""https://dl.acm.org/doi/10.1145/3613904.3642114"">relieve UX designers from mundane and tedious tasks</a>, allowing them to concentrate on activities that require more critical thinking and emotional engagement. Essentially, there are huge opportunities to offload a lot of grunt work to AI systems. But designers need to be careful about this,Â becauseâ€¦</p><p><strong>Drawbacks: </strong>Over-reliance on AI designs could lead to <a href=""https://dl.acm.org/doi/10.1145/3409120.3410638"">fixation on minor optimisations rather than out-of-the-box thinking</a>. This means designers need to find a balance between efficiency and innovationâ€Šâ€”â€Šby avoiding dependence on AI where human creativity and agency would add value leading to better solutions.</p><figure><img alt=""Diagram showing what AI can and cannot do in the design process"" src=""https://cdn-images-1.medium.com/max/1024/1*kAEQ1IPqJKQJX2eDBMU65g.png"" /><figcaption>What AI can and canâ€™t do (Li et al.,Â 2024)</figcaption></figure><h4>Skills and development</h4><p><strong>Advantages: </strong>Thereâ€™s clear <a href=""https://dl.acm.org/doi/10.1145/3404983.3405506"">potential for AI to lower the skill threshold required for designers</a> in UX. Which makes sense, as prompting is easier to learn than all the features and functionality of Figma. This change allows a wider range of people to contribute design ideas without traditional visual design toolÂ skills.</p><figure><img alt=""Series of sketched, designed and generated UI screens"" src=""https://cdn-images-1.medium.com/max/1007/1*lKKQRvtXf8KGR-nH2anUPQ.png"" /><figcaption>Sketched input versus manual design and generated AI output (Buschek, Anlauff and Lachner,Â 2020)</figcaption></figure><p><strong>Drawbacks: </strong>Over-dependence on generative AI tools might impede development for UX novices, as <a href=""https://dl.acm.org/doi/10.1145/3615335.3623035"">repetitive tasks help cultivate UX design skills and judgement</a>. Junior designers might be at higher risk of negative cognitive effects from AI generally, as <a href=""https://www.mdpi.com/2075-4698/15/1/6"">young people exhibit higher dependence on AI tools and lower critical thinkingÂ skills</a>.</p><h4>Summary</h4><p>Itâ€™s a mixed bag, basically. For all the opportunities that AI brings to UX design, there are plenty of challenges and traps practitioners can fall into. Some of these issues will be solved by technology improving, but others require skilful and mindful integration of AI into UX design processes.</p><figure><img alt=""Bar chart showing challenges using AI in UX design with hallucinations at the top"" src=""https://cdn-images-1.medium.com/max/1024/1*kmOGmOvjO0jbcZVAOwLvGQ.png"" /><figcaption>AI challenges in UX design (Ahmed and Imran,Â 2025)</figcaption></figure><h3>3. How UX practitioners feel about usingÂ AI</h3><p>These are reflections from UX professionals about their experiences of using AI in the design process. Iâ€™ve categorised them as either positive or negative sentiments, adding a few comments of my own (in parentheses).</p><h4>Positives</h4><ul><li>Using AI in the design process can make <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">UX practitioners feel both more effective and efficient</a>. (I hesitate to use the phrase â€˜super-poweredâ€™, as The Incredibles tells us: when everyoneâ€™s super, no-oneÂ is.)</li><li>Designing with AI helps develop skills in prompting, which is <a href=""https://arxiv.org/abs/2507.04469"">emerging as a core design skill</a>. (Itâ€™s surely only a matter of time before we start seeing <em>Prompting is Designing</em> UX books hitting the shelves.)</li><li>Generating design variants with <a href=""https://dl.acm.org/doi/10.1145/3643834.3661624"">AI avoids the â€˜blank pageâ€™ problem</a>, where UX designers struggle to get started. (Even for professionals, the blank canvas of a design file can sometimes be intimidating.)</li><li>Collaboration with AI can<em> </em>feel like a <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">complementary partnership between human cognition and AI technology</a>. (Similar to a senior designer guiding a junior designer.)</li><li>Using <a href=""https://dl.acm.org/doi/10.1145/3643834.3660703"">AI helps facilitate collaboration with stakeholders</a> by streamlining idea sharing and exploration. (Basically, AI can help make the sometimes arcane practice of UX clearer and more accessible to stakeholders.)</li></ul><figure><img alt=""Four photos from a design focus group on AI, showing people with colourful sticky notes"" src=""https://cdn-images-1.medium.com/max/1012/1*zmWAQEFMce3Ca1vsl6AkyQ.png"" /><figcaption>Focus group on AI and UX collaboration (Wang et al.,Â 2024)</figcaption></figure><h4>Negatives</h4><ul><li>Designing with AI can also feel like being a <a href=""https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1404647/full"">client commissioning a contractor rather than <em>designing</em></a>. (In other words: designers can feel like the AI is doing the fun, creative bits while they write theÂ brief.)</li><li>When UX designers feel like theyâ€™ve outsourced creative tasks, it can lead to <a href=""https://dl.acm.org/doi/10.1145/3491101.3503564"">diminished sense of ownership over the results</a>. (How invested can you be if you didnâ€™t even draw a single rectangle?)</li><li>Creating an effective prompt can be a <a href=""https://arxiv.org/abs/2507.04469"">time-intensive process with a high cognitive burden</a>. (Although in future this could be mitigated by refining prompting templates and support resources.)</li></ul><h4>Summary</h4><p>The positives outweigh the negatives, but there are clear issues to resolve. This includes UX practitionersâ€™ sense of identity as designers, as well as the time and mental effort required to craft effective prompts, generate outputs and carry out continual refinements.</p><h3>4. Takeaways for future use of AI in UXÂ design</h3><p>Iâ€™ve tried to categorise these suggestions into meaningful themes. They typically crop up in the discussion and conclusion sections of academicÂ papers.</p><h4>AI increases efficiency, but people stillÂ matter</h4><p>The biggest impact of AI in UX design is the <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">increased efficiency across the design process</a>. However, AI cannot replace human interpersonal communication, collaboration, creativity or originality; therefore itâ€™s important to <a href=""https://dl.acm.org/doi/10.1145/3613904.3642114"">balance pursuing efficiency while preserving the human-centred nature of UXÂ design</a>.</p><h4>Humans need to remain in theÂ loop</h4><p>UX designers should adopt a <a href=""https://cloud.google.com/discover/human-in-the-loop"">human-in-the-loop</a> approach to validate AI output, improve model performance and <a href=""https://ieeexplore.ieee.org/document/10034833"">avoid overreliance on automated systems</a>. However, designers should be mindful that <a href=""https://dl.acm.org/doi/10.1145/3512943"">AI tools could potentially <em>reinforce</em> their existing biases</a> instead of challenging them. This is an area where critical thinking skills are absolutely, well, critical.</p><figure><img alt=""Word cloud with prompt engineering, real-time feedback and modular design featuring prominently"" src=""https://cdn-images-1.medium.com/max/980/1*RurZhxCwxTpuUlk--9Yg1w.png"" /><figcaption>Word cloud of best practices for AI and UI/UX design (Ahmed and Imran,Â 2025)</figcaption></figure><h4>AI policies are needed for ethicalÂ practice</h4><p>Adoption of AI <a href=""https://arxiv.org/abs/2507.04469"">must be ethical and inclusive as well as efficient</a>. To alleviate concerns about ethics, data privacy, ownership, and accountability, organisations should <a href=""https://dl.acm.org/doi/10.1145/3643834.3660720"">set up and communicate policies on AI usage</a>. Too many UX practitioners are still driving ahead, often alone, without clear internal strategies or policies for generative AI.</p><h4>UX designers need specific AIÂ training</h4><p>To successfully integrate AI into design team processes and workflows, UX practitioners would <a href=""https://ieeexplore.ieee.org/document/10382802"">benefit from training to develop proficiency</a> in crafting and refining prompts, assessing and criticising AI-generated output, and accounting for AI intricacies and limitations. Thereâ€™s a world of difference between dabbling with AI in design and using it as effectively as possible.</p><h3>Conclusion</h3><p>So whatâ€™s the story? How <em>is</em> AI impacting UXÂ design?</p><p>Well, itâ€™s clear from the academic studies that traditional design methods are being innovated: UX practitioners are harnessing AI, leading to efficiencies and lowering costs for organisations in the process. The benefits are undeniable. UX design has fundamentally changed in the past 2â€“3 years, and itâ€™s probably career suicide to denyÂ that.</p><p>In fact, more UX designers might need to let go of conventional design stages and activities to <a href=""https://onlinelibrary.wiley.com/doi/10.1155/ahci/3869207"">allow for even <em>more</em> innovative processes empowered by AI</a>. For example, strictly adhering to established workflows and handover processes ignores the potential to go from concept to functional, testable solution rapidly withÂ AI.</p><p>However, there are potential drawbacks if AI usage in UX design is over-relied on, and used mindlessly. Without sufficient critical thinking, we can easily end up with generic, biased designs that donâ€™t actually solve user problems. In some cases, we might even spend too much time on prompting and vibing with AI when we could have simply sketched or prototyped something ourselvesâ€Šâ€”â€Šcreating more sense of ownership in theÂ process.</p><p>Many of these findings might feel obvious to a lot of people. But of course the point of rigorous research is often to validate what you <em>think </em>you already know. This deep dive into academia shows us what we really <em>do </em>know, for sure. ForÂ now.</p><h3>Sources</h3><p>Ahmed, A. and Imran, A. S. (2025) â€˜The role of large language models in UI/UX design: a systematic literature reviewâ€™, <em>arXiv</em>. Available at: <a href=""https://doi.org/10.48550/arXiv.2507.04469"">https://doi.org/10.48550/arXiv.2507.04469</a></p><p>Batch, A., et al. (2023) â€˜uxSense: supporting user experience analysis with visualization and computer visionâ€™, <em>IEEE Transactions on Visualization and Computer Graphics</em>, 30(7), pp. 3841â€“3856. Available at: <a href=""https://doi.org/10.1109/tvcg.2023.3241581"">https://doi.org/10.1109/tvcg.2023.3241581</a></p><p>Bilgram, V. and Laarmann, F. (2023) â€˜Accelerating innovation with generative AI: AI-augmented digital prototyping and innovation methodsâ€™, <em>IEEE Engineering Management Review</em>, 51(2), pp. 18â€“25. Available at: <a href=""https://doi.org/10.1109/emr.2023.3272799"">https://doi.org/10.1109/emr.2023.3272799</a></p><p>Buschek, D., Anlauff, C. and Lachner, F. (2020) â€˜Paper2Wire: a case study of user-centred development of machine learning tools for UX designersâ€™, In <em>Proceedings of Mensch und Computer 2020 (MuC â€˜20)</em>, pp. 33â€“41. Available at: <a href=""https://doi.org/10.1145/3404983.3405506"">https://doi.org/10.1145/3404983.3405506</a></p><p>Ebel, P., Brokhausen, F. and Vogelsang, A. (2020) â€˜The role and potentials of field user interaction data in the automotive UX development lifecycle: an industry perspectiveâ€™, In <em>12th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI â€˜20)</em>, pp. 141â€“150. Available at: <a href=""https://doi.org/10.1145/3409120.3410638"">https://doi.org/10.1145/3409120.3410638</a></p><p>Fan, M., et al. (2022) â€˜Human-AI collaboration for UX evaluation: effects of explanation and synchronizationâ€™, <em>Proceedings of the ACM on Human-Computer Interaction, 6(CSCW1)</em>, pp. 1â€“32. Available at: <a href=""https://doi.org/10.1145/3512943"">https://doi.org/10.1145/3512943</a></p><p>Gerlich, M. (2025) â€˜AI tools in society: impacts on cognitive offloading and the future of critical thinkingâ€™, <em>Societies</em>, 15(1), 6. Available at: <a href=""https://doi.org/10.3390/soc15010006"">https://doi.org/10.3390/soc15010006</a> (Accessed: 12 September 2025).</p><p>Jiang, E., et al. (2022). â€˜PromptMaker: prompt-based prototyping with large language modelsâ€™, <em>CHI Conference on Human Factors in Computing Systems Extended Abstracts, </em>35, pp. 1â€“8. Available at: <a href=""https://doi.org/10.1145/3491101.3503564"">https://doi.org/10.1145/3491101.3503564</a></p><p>Li, J., et al. (2024) â€˜User experience design professionalsâ€™ perceptions of generative artificial intelligenceâ€™, In <em>Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI â€˜24)</em>, 381, pp. 1â€“18. Available at: <a href=""https://doi.org/10.1145/3613904.3642114"">https://doi.org/10.1145/3613904.3642114</a></p><p>Luo, Y. (2025) â€˜Designing with AI: a systematic literature review on the use, development, and perception of AIâ€enabled UX design toolsâ€™, <em>Advances in Human-Computer Interaction</em>, 2025(1). Available at: <a href=""https://doi.org/10.1155/ahci/3869207"">https://doi.org/10.1155/ahci/3869207</a></p><p>Maceli, M., Smith, N. and Bhakta, G. (2024) â€˜Incorporating unanticipated uses of generative AI into HCI educationâ€™, In <em>Proceedings of the 6th Annual Symposium on HCI Education (EduCHI â€˜24)</em>, 5, pp. 1â€“7. Available at: <a href=""https://doi.org/10.1145/3658619.3658628"">https://doi.org/10.1145/3658619.3658628</a></p><p>Padmasiri, P., et al. (2023) â€˜AI-driven user experience design: exploring innovations and challenges in delivering tailored user experiencesâ€™, <em>2023 8th International Conference on Information Technology Research (ICITR), Colombo, Sri Lanka</em>, pp. 1â€“6. Available at: <a href=""https://doi.org/10.1109/ICITR61062.2023.10382802"">https://doi.org/10.1109/ICITR61062.2023.10382802</a></p><p>Takaffoli, M., Li, S. and MÃ¤kelÃ¤, V. (2024) â€˜Generative AI in user experience design and research: how do UX practitioners, teams, and companies use genAI in industry?â€™, <em>Designing Interactive Systems Conference</em>, pp. 1579â€“1593. Available at: <a href=""https://doi.org/10.1145/3643834.3660720"">https://doi.org/10.1145/3643834.3660720</a></p><p>Uusitalo, S., et al. (2024) â€˜â€œClay to play withâ€: generative AI tools in UX and industrial design practiceâ€™, <em>Designing Interactive Systems Conference</em>, 9, pp. 1566â€“1578. Available at: <a href=""https://doi.org/10.1145/3643834.3661624"">https://doi.org/10.1145/3643834.3661624</a></p><p>Wang, Z., et al. (2024) â€˜Exploring the impact of artificial intelligence-generated content (AIGC) tools on social dynamics in UX collaborationâ€™, <em>Designing Interactive Systems Conference</em>, pp. 1594â€“1606. Available at: <a href=""https://doi.org/10.1145/3643834.3660703"">https://doi.org/10.1145/3643834.3660703</a></p><p>York, E. (2023) â€˜Evaluating ChatGPT: generative AI in UX design and web development pedagogyâ€™, In <em>Proceedings of the 41st ACM International Conference on Design of Communication (SIGDOC â€˜23)</em>, pp. 197â€“201. Available at: <a href=""https://doi.org/10.1145/3615335.3623035"">https://doi.org/10.1145/3615335.3623035</a></p><p>Zhu, Z., et al. (2024) â€˜AI assistance in enterprise UX design workflows: enhancing design brief creation for designersâ€™, <em>Frontiers in Artificial Intelligence</em>, 7. Available at: <a href=""https://doi.org/10.3389/frai.2024.1404647"">https://doi.org/10.3389/frai.2024.1404647</a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=42cb0de93680"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/silicon-clay-how-ai-is-reshaping-ux-design-42cb0de93680"">Silicon clay: how AI is reshaping UX design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
