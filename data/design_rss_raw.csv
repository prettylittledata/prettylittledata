source,domain,url,created_utc,title,text
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/css-gamepad-api-visual-debugging-css-layers/,1763125200,CSS Gamepad API Visual Debugging With CSS Layers,"CSS Gamepad API Visual Debugging With CSS Layers

Debugging controllers can be a real pain. Hereâ€™s a deep dive into how CSS helps clean it up and how to build a reusable visual debugger for your own projects."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/older-tech-browser-stack/,1763020800,Older Tech In The Browser Stack,"Older Tech In The Browser Stack

There are many existing web features and technologies in the wild that you may never touch directly in your day-to-day work. Perhaps youâ€™re fairly new to web development and are simply unaware of them because youâ€™re steeped in the abstraction of a specific framework that doesnâ€™t require you to know it deeply, or even at all. Bryan Rasmussen looks specifically at XPath and demonstrates how it can be used alongside CSS to query elements."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/effectively-monitoring-web-performance/,1762855200,Effectively Monitoring Web Performance,"Effectively Monitoring Web Performance

There are lots of tips for [improving your website performance](https://www.debugbear.com/blog/improve-website-performance?utm_campaign=sm-10). But even if you follow all of the advice, are you able to maintain an optimized site? And are you targeting the right pages? Matt Zeunert outlines an effective strategy for web performance optimization and explains the roles that different types of data play in it."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/smashing-animations-part-6-svgs-css-custom-properties/,1762527600,Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties,"Smashing Animations Part 6: Magnificent SVGsÂ With `<use>`Â And CSS Custom Properties

SVG is one of those web technologies thatâ€™s both elegant and, at times, infuriating. In this article, pioneering author and web designer Andy Clarke explains his technique for animating SVG elements that are hidden in the Shadow DOM."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/practical-guide-ux-strategy/,1762347600,Six Key Components of UX Strategy,"Six Key Components of UX Strategy

Letâ€™s dive into the building blocks of UX strategy and see how it speaks the language of product and business strategy to create user value while achieving company goals. Part of the <a href=""https://measure-ux.com/"">Measure UX &amp; Design Impact</a> (use the code ğŸŸ <code>IMPACT</code> to save 20% off today)."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/11/how-leverage-component-variants-penpot/,1762250400,How To Leverage Component Variants In Penpot,"How To Leverage Component Variants In Penpot

With component variants, design systems become more flexible, letting you reuse the same component while adapting its look or state with ease. In this article, Daniel Schwarz demonstrates how design tokens can be leveraged to manage components and their variations using <a href=""https://penpot.app?utm_source=SmashingMag&amp;utm_medium=Article&amp;utm_campaign=Variants"">Penpot</a>, the open-source tool built for scalable, consistent design."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/desktop-wallpaper-calendars-november-2025/,1761912000,Fading Light And Falling Leaves (November 2025 Wallpapers Edition),"Fading Light And Falling Leaves (November 2025 Wallpapers Edition)

The new month is just around the corner, and that means: Itâ€™s time for some new desktop wallpapers! All of them are designed by the community for the community and can be downloaded for free. Enjoy!"
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/javascript-for-everyone-iterators/,1761570000,JavaScript For Everyone: Iterators,"JavaScript For Everyone: Iterators

Here is a lesson on Iterators. Iterables implement the iterable iteration interface, and iterators implement the iterator iteration interface. Sounds confusing? Mat breaks it all down in the article."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/ambient-animations-web-design-practical-applications-part2/,1761138000,Ambient Animations In Web Design: Practical Applications (Part 2),"Ambient Animations In Web Design: Practical Applications (Part 2)

Motion can be tricky: too much distracts, too little feels flat. Ambient animations sit in the middle. Theyâ€™re subtle, slow-moving details that add atmosphere without stealing the show. In part two of his series, web design pioneer Andy Clarke shows how ambient animations can add personality to any website design."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/ai-ux-achieve-more-with-less/,1760688000,AI In UX: Achieve More With Less,"AI In UX: Achieve More With Less

A simple but powerful mental model for working with AI: treat it like an enthusiastic intern with no real-world experience. Paul Boag shares lessons learned from real client projects across user research, design, development, and content creation."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/how-make-ux-research-hard-to-ignore/,1760619600,How To Make Your UX Research Hard To Ignore,"How To Make Your UX Research Hard To Ignore

Research isnâ€™t everything. Facts alone donâ€™t win arguments, but powerful stories do. Hereâ€™s how to turn your research into narratives that inspire trust and influence decisions."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/the-grayscale-problem/,1760349600,The Grayscale Problem,"The Grayscale Problem

From A/B tests to AI slop, the modern web is bleeding out its colour. Standardized, templated, and overoptimized, itâ€™s starting to feel like a digital Levittown. But it doesnâ€™t have to be."
rss,smashingmagazine.com,https://smashingmagazine.com/2025/10/smashing-animations-part-5-building-adaptive-svgs/,1759755600,"Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries","Smashing Animations Part 5: Building Adaptive SVGs With `<symbol>`, `<use>`, And CSS Media Queries

SVGs, they scale, yes, but how else can you make them adapt even better to several screen sizes? Web design pioneer Andy Clarke explains how he builds what he calls â€œadaptive SVGsâ€ using ``, ``, and CSS Media Queries."
rss,uxdesign.cc,https://uxdesign.cc/is-addiction-the-responsibility-of-ux-bb9d1186b39e?source=rss----138adf9c44c---4,1763417335,Is addiction the responsibility of UX?,"Is addiction the responsibility of UX?

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/is-addiction-the-responsibility-of-ux-bb9d1186b39e?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1600/1*6rciJNl1zG6F88MEgoAX4Q.png"" width=""1600"" /></a></p><p class=""medium-feed-snippet"">Is infinite scrolling a dark pattern? What&#x2019;s the most effective intervention for screen addiction?</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/is-addiction-the-responsibility-of-ux-bb9d1186b39e?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/ai-remembers-everything-the-future-of-ethical-design-the-color-reflex-02ed5c31a561?source=rss----138adf9c44c---4,1763385007,"AI remembers everything, the future of ethical design, the color reflex","AI remembers everything, the future of ethical design, the color reflex

<h4>Weekly curated resources for designersâ€Šâ€”â€Šthinkers andÂ makers.</h4><figure><a href=""https://www.doc.cc/articles/we-must-forget""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*xqiUG3hGi0m-EpJ8.png"" /></a></figure><p>â€œImagine your best friend (weâ€™ll call her Mary), had a perfect, infallible memory.</p><p>At first, it feels wonderful. She remembers your favorite dishes, obscure movie quotes, even that exact shade of sweater you casually admired months ago. Dinner plans are effortless: â€œBooked us Giorgioâ€™s again, your favoriteâ€Šâ€”â€Štruffle ravioli and Cabernet, like last time,â€ Mary smiledÂ warmly.</p><p>But gradually, things become less appealing. Your attempts at variety or exploring something new are gently brushed aside: â€œHeard about that new sushi place, should we try it?â€ you suggest. Mary hesitates, â€œRemember last year? You said sushi wasnâ€™t really your thing. Giorgioâ€™s is safe. Why riskÂ it?â€â€</p><p><a href=""https://www.doc.cc/articles/we-must-forget""><strong>To grow, we must forgetâ€¦ but now AI remembers everything</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/521187168e40"">Amy Chivavibul</a></p><h3>Editor picks</h3><ul><li><a href=""https://uxdesign.cc/let-designers-think-82721f458b73?sk=2b52457a30483bd2868de6052a5e3715""><strong>Let designers think</strong></a><strong> â†’</strong><br />How Thinking + Designing need to be practiced outside AI.<br />By <a href=""https://medium.com/u/f813ce86db80"">Chris RÂ Becker</a></li><li><a href=""https://uxdesign.cc/what-we-lose-when-we-lose-the-creative-struggle-09ad3a5df2c9?sk=8da5d3e0a79ea2fea9c5689bb893738d""><strong>What we lose when we lose the creative struggle</strong></a><strong> â†’</strong><br />How removing friction removes meaning.<br />By <a href=""https://medium.com/u/8797adcdd8a8"">FabriziaÂ Ausiello</a></li><li><a href=""https://uxdesign.cc/the-evolution-of-youtube-how-every-platform-evolves-into-an-ad-machine-9e6032ff2d20""><strong>The evolution of Youtube</strong></a><strong> â†’</strong><br />How every platform evolves into an ad machine.<br />By <a href=""https://medium.com/u/e7efcd3b7bd3"">Allan MacDonald</a></li></ul><p><em>The UX Collective is an independent design publication that elevates unheard design voices and helps designers think more critically about theirÂ work.</em></p><figure><a href=""https://www.nomadstudio.com/work/f37-holborn?ref=sidebar""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*ZuOC8ctyaRE3yjHM.png"" /></a></figure><p><a href=""https://www.nomadstudio.com/work/f37-holborn?ref=sidebar""><strong>A typographic time-splice of Holborn</strong></a><strong>Â â†’</strong></p><h3>Make meÂ think</h3><ul><li><a href=""https://longform.asmartbear.com/mission-vision/?ref=sidebar""><strong>Mission, vision, poTAYto, poTAHto</strong></a><strong> â†’</strong><br />â€œBy the time the company is large, there are teams of peopleâ â€Šâ€”â€Šprobably in marketingâ â€Šâ€”â€Šcarefully sculpting these things as sentence fragments in large serif fonts on â€œAbout Usâ€ pages that no one reads and no one believes. And by no one, I mean not employees, not customers, and not investors. Phrases that sound grand but are just grandiose.â€</li><li><a href=""https://alfy.blog/2025/10/31/your-url-is-your-state.html?ref=sidebar""><strong>Your URL is your state</strong></a><strong> â†’</strong><br />â€œThis got me thinking: how often do we, as frontend engineers, overlook the URL as a state management tool? We reach for all sorts of abstractions to manage state such as global stores, contexts, and caches while ignoring one of the webâ€™s most elegant and oldest features: the humbleÂ URL.â€</li><li><a href=""https://den.dev/blog/full-stack-person/?ref=sidebar""><strong>You need to become a full stack person</strong></a><strong> â†’</strong><br />â€œBut you know whatâ€Šâ€”â€Ševen if and when that day comes, I still see LLMs as idea implementation vehicles and not a replacement for creativity, agency, and taste. They are not a substitute for craft and actually knowing what youâ€™re talking about, which is what I wanted to write down some ideasÂ on.â€</li></ul><h3>Little gems thisÂ week</h3><figure><a href=""https://uxdesign.cc/what-designers-can-learn-from-zohran-mamdanis-historical-campaign-11f92007e873""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*LzK4DfHfJ7QrqhxG.png"" /></a></figure><p><a href=""https://uxdesign.cc/what-designers-can-learn-from-zohran-mamdanis-historical-campaign-11f92007e873""><strong>What designers can learn from Zohran Mamdaniâ€™s historical campaign</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/ea49f56cc320"">Merilin Ekzarkova</a></p><figure><a href=""https://uxdesign.cc/guiding-the-future-of-ethical-design-796e7cc3c9b1""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*PA8ZbhjGwebJ8-Mz.png"" /></a></figure><p><a href=""https://uxdesign.cc/guiding-the-future-of-ethical-design-796e7cc3c9b1""><strong>Guiding the future of ethical design</strong></a><strong> â†’<br /></strong>By <a href=""https://medium.com/u/491633cab109"">MichaelÂ Buckley</a></p><figure><a href=""https://uxdesign.cc/everything-i-know-about-behavioral-design-i-learned-at-orange-julius-bfa8720054f3?sk=f2755a7df8d8b785b0681a290a5d4a97""><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/0*v6_29vVbT56ON713.png"" /></a></figure><p><a href=""https://uxdesign.cc/everything-i-know-about-behavioral-design-i-learned-at-orange-julius-bfa8720054f3?sk=f2755a7df8d8b785b0681a290a5d4a97""><strong>Everything I know about behavioral design I learned at Orange Julius</strong></a> â†’<br />By <a href=""https://medium.com/u/89afb89252ee"">SamÂ Liberty</a></p><h3>Tools and resources</h3><ul><li><a href=""https://uxdesign.cc/the-color-reflex-psychology-that-fires-before-you-think-e5e6556919da""><strong>The color reflex</strong></a><strong> â†’</strong><br />Psychology that fires before you think.<br />By <a href=""https://medium.com/u/161b4eee2ac1"">MaximÂ Kich</a></li><li><a href=""https://uxdesign.cc/synthetic-developer-the-solo-designers-best-friend-947ec304c9f4""><strong>Synthetic developer</strong></a><strong> â†’</strong><br />The solo designerâ€™s best friend?<br />By <a href=""https://medium.com/u/984338775b80"">AnnaÂ Lefour</a></li><li><a href=""https://uxdesign.cc/from-design-to-direction-bridging-product-design-and-ai-thinking-1d372707472d""><strong>From design to direction</strong></a><strong> â†’</strong><br />Bridging product design and AI thinking.<br />By <a href=""https://medium.com/u/8f9c79748da9"">BradlyÂ Zavakos</a></li></ul><h3>Support the newsletter</h3><p>If you find our content helpful, hereâ€™s how you can supportÂ us:</p><ul><li>Check out <a href=""https://bit.ly/uxc-div11"">this weekâ€™s sponsor</a> to support their workÂ too</li><li>Forward this email to a friend and invite them to <a href=""https://newsletter.uxdesign.cc/"">subscribe</a></li><li><a href=""https://uxdesigncc.medium.com/sponsor-the-ux-collective-newsletter-bf141c6284f"">Sponsor anÂ edition</a></li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=02ed5c31a561"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/ai-remembers-everything-the-future-of-ethical-design-the-color-reflex-02ed5c31a561"">AI remembers everything, the future of ethical design, the color reflex</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/mind-the-story-gap-why-great-ideas-fail-without-meaningful-narratives-3cb5678a40e1?source=rss----138adf9c44c---4,1763374961,Mind the story gap: Why great ideas fail without meaningful narratives,"Mind the story gap: Why great ideas fail without meaningful narratives

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/mind-the-story-gap-why-great-ideas-fail-without-meaningful-narratives-3cb5678a40e1?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1920/1*RnZz5vpPKQpqgHxvoqej_w.jpeg"" width=""1920"" /></a></p><p class=""medium-feed-snippet"">How powerful stories turn hidden value into something people can see, feel, and believe in.</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/mind-the-story-gap-why-great-ideas-fail-without-meaningful-narratives-3cb5678a40e1?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/patterns-your-brain-cant-unsee-gestalt-psychology-in-design-c34d6772fc36?source=rss----138adf9c44c---4,1763374950,Patterns your brain canâ€™t unsee: Gestalt psychology in design,"Patterns your brain canâ€™t unsee: Gestalt psychology in design

<p>They are the invisible grammar behind every interface, the logic that makes visual language readable and coherent.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*x3nVSM4Rj4e0jClaHh5a8Q.png"" /><figcaption><a href=""https://en.wikipedia.org/wiki/Ebbinghaus_illusion"">Ebbinghaus illusion</a>â€Šâ€”â€ŠExample created by MaximÂ Kich</figcaption></figure><p>Welcome, my dear reader! Perhaps, just like me, youâ€™ve searched the internet for different sources about the Gestalt principles and found that there are many, each slightly different from the others. Thatâ€™s why I decided to bring several of them together, analyze and group them, and highlight the fundamental ones, the core laws that we, as designers, can confidently rely on when creating ourÂ work.</p><p>But letâ€™s start from the beginning, where these principles came from, and why they are, in fact, more of a science than just an observation.</p><h3>The History of Gestalt Principles</h3><p>Gestalt psychology emerged in Germany at the very beginning of the 20th century as a response to the then-dominant, and in fact the first, school of psychologyâ€Šâ€”â€Š<a href=""https://en.wikipedia.org/wiki/Structuralism_(psychology)"">Structuralism</a>. Structuralism viewed consciousness as something that could be deconstructed into individual elements: sensations, images, and feelings; to understand how the mind is built from its smallestÂ parts.</p><figure><img alt=""Black-and-white portrait of a man with glasses, a full beard, and a serious expression, wearing a suit and white collar."" src=""https://cdn-images-1.medium.com/max/274/0*StoYieZSdCa2uo0p.jpg"" /><figcaption>Edward Bradford Titchener (1867â€“1927) is founder of Structuralismâ€Šâ€”â€Š<a href=""https://en.wikipedia.org/wiki/Edward_B._Titchener#/media/File:Edward_B._Titchener.jpg"">ImageÂ Source</a></figcaption></figure><p><a href=""https://en.wikipedia.org/wiki/Gestalt_psychology"">Gestalt psychology</a>, on the other hand, saw perception as an inherently holistic process: our consciousness emerges from the organization of those parts into meaningful wholes, but unlike structuralism, it does not attempt to view perception as the sum of itsÂ parts.</p><p>Where structuralism tried to analyze the structure of experience, Gestalt focused on the patterns that give experience its unity andÂ sense.</p><p>The Gestalt principles we use in design today were first studied in their earliest form by Gestalt psychology founders <a href=""https://en.wikipedia.org/wiki/Max_Wertheimer"">Max Wertheimer</a>, <a href=""https://en.wikipedia.org/wiki/Wolfgang_K%C3%B6hler"">Wolfgang KÃ¶hler</a>, and <a href=""https://en.wikipedia.org/wiki/Kurt_Koffka"">Kurt Koffka</a>. They explored and expanded upon each otherâ€™s work on how the human brain perceives visual images not as a collection of separate elements, but as unified, structured wholes. Thatâ€™s where the term â€œGestaltâ€ comes fromâ€Šâ€”â€Šthe German word for â€œformâ€ or â€œstructure.â€</p><figure><img alt=""Black-and-white portrait of a man with a beard and receding hairline, wearing a dark coat and posing with arms crossed against a dark background."" src=""https://cdn-images-1.medium.com/max/256/0*-7bNwJ1VdkNU9UIm.jpg"" /><figcaption>Max Wertheimer (1880â€“1943)â€Šâ€”â€Š<a href=""https://en.wikipedia.org/wiki/Max_Wertheimer#/media/File:Max_Werheimer_(1880-1943).jpg"">ImageÂ Source</a></figcaption></figure><p>The main idea was that the mind automatically organizes sensory information into meaningful forms, even when parts of the data are missing or distorted. Because of the growing popularity of psychology in the early days of marketing, these principles quickly became the foundation for understanding composition, object grouping, and visual hierarchy, concepts we still actively apply in interface designÂ today.</p><p>Over the past hundred years, countless interpretations and variations of these laws and principles have been written and discussed. Originally, Max Wertheimer identified only nine principles, which he didnâ€™t even call <em>â€œprinciplesâ€</em> at the time. He referred to them as <em>â€œfactorsâ€</em> that determine how humans perceive groups of objects. It was only later that these factors were reformulated and became known as the Gestalt principles.</p><h3><strong>Why Gestalt is more than just observation</strong></h3><p>What made Gestalt psychology truly revolutionary was that it proved its claims through controlled experiments, not just philosophical speculation or introspection.</p><p>Max Wertheimerâ€™s study of the <a href=""https://en.wikipedia.org/wiki/Phi_phenomenon"">phi phenomenon</a> was among the first to show that the mind can perceive movement where none exists: two still images flashing in sequence were seen as continuous motion. This finding demonstrated that perception is an active process of construction, not passive reception. And it is this principle that underlies animation and cinema, as well as, the transitions we create inÂ design.</p><figure><img alt=""A sequence of twelve black-and-white photographs showing a horse and rider in motion, illustrating the phases of a gallop, with grid lines and the title â€œThe Horse in Motionâ€ by Eadweard Muybridge."" src=""https://cdn-images-1.medium.com/max/1024/0*70V1TnUbPL5pk-D1.jpg"" /><figcaption>The Horse in Motion by Eadweard Muybridgeâ€Šâ€”â€Š<a href=""https://commons.wikimedia.org/w/index.php?curid=57260211"">ImageÂ Source</a></figcaption></figure><p>Wolfgang KÃ¶hlerâ€™s <a href=""https://pigeon.psy.tufts.edu/psych26/kohler.htm"">experiments with apes</a> later reinforced this idea. Chimpanzees were placed in situations where food was visible but out of reach. Instead of relying on random trial and error, they would suddenly grasp how to combine available objects, for example stacking boxes or using a stick to solve the problem. KÃ¶hler called this moment of sudden understanding insight.</p><figure><img alt=""Black-and-white photo showing chimpanzees in an enclosure, with one climbing onto boxes and reaching upward toward an object while others look on or raise their arms."" src=""https://cdn-images-1.medium.com/max/297/0*0Y1c0R3E0iZWFs0I.JPG"" /><figcaption>Photo from The Mentality of Apesâ€Šâ€”â€Š<a href=""https://pigeon.psy.tufts.edu/psych26/kohler.htm"">imageÂ source</a></figcaption></figure><p>That is precisely what happens in great UX. When an interface is well-designed, users donâ€™t have to memorize steps or instructions; they see how things fit together. Their mental model of the system reorganizes itself into something coherent and intuitive. Good design, like KÃ¶hlerâ€™s insight, doesnâ€™t teach butÂ reveals.</p><p>Together, these and other first studies gave Gestalt psychology an empirical foundation, transforming it from a set of visual curiosities into one of the earliest scientifically validated theories of perception.</p><h3>Our focus forÂ today</h3><p>For this article, weâ€™ll focus on three modern interpretations of these principles, and original paper of Max Wertheimer, <a href=""https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm""><em>Laws of Organization in Perceptual Forms</em></a>. Our other reference sources for todayÂ are:</p><ul><li><a href=""https://www.interaction-design.org/literature/topics/gestalt-principles""><em>What are the Gestalt Principles?</em></a><strong> </strong>by<strong> Interaction Design Foundation </strong>(12 principles)<strong> </strong>is an excellent and by far the most comprehensive list Iâ€™ve come across, complete with clear examples not only through abstract visuals but also real interface designs. The article presents these principles in a more academic yet design-focused way, linking them directly to design thinking and practical application.</li><li><a href=""https://www.figma.com/resource-library/gestalt-principles/""><em>What are the Gestalt Principles?</em></a><strong> </strong>by<strong> Figma </strong>(11 principles) offers a concise yet accurate definition of the principles, with a strong focus on their visual aspect, without delving deeply into how theyâ€™re applied in UX contexts.</li><li><a href=""https://maze.co/blog/gestalt-principles/""><em>Gestalt Principles: A Guide to the Psychology Behind Stellar UX</em></a><strong> </strong>by<strong> Maze </strong>(10 principles)<strong> </strong>is a wonderful and engaging interpretation, featuring highly memorable abstract examples alongside a dedicated section that demonstrates how these principles manifest directly in interface design.</li></ul><p>Iâ€™ve noticed that the number of Gestalt principles often varies across different sources, ranging anywhere from six to twelve. By combining and comparing all four of the sources, Iâ€™ve distilled 16 Gestalt principles, which Iâ€™ve grouped into three distinct categories. Itâ€™s important to note that these are not all existing Gestalt principles interpretations but rather the ones most commonly found and applied within the information-driven UI/UX designÂ context.</p><h3>Basic Gestalt principles ofÂ grouping</h3><p>These principles, in one form or another, appear across all four sourcesâ€Šâ€”â€Šwith only minor variations in interpretation.</p><h4><strong>Proximity</strong></h4><p>Elements that are placed close to each other are perceived asÂ related.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*UJjgVzM1J_PNh5PESqGlYA.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Four circles form a group because they are evenly spaced and positioned close to one another, while three other circles are set apart and do not visually belong to anyÂ group.</p><p><strong>Interface:</strong> Two buttons in a modal window appear as one group, whereas a separate button stands visually independent from them. We can use this principle to categorize actions for example, the button on the left might <em>close</em> or <em>cancel</em> the modal, while the grouped buttons on the right could represent <em>Save</em> and <em>Delete</em>. In the first case, the user does not affect the content; in the second, either action directly modifies the information.</p><h4><strong>Similarity</strong></h4><p>Objects that share similar color, shape, or size are perceived as belonging to the sameÂ group.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*A9NOIvnyctmytyOMIqp8vg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Four circles filled with a more saturated color stand out from the rest of the elements and are perceived as a single category.</p><p><strong>Interface:</strong> We apply this principle in UI design, for example, with CTAs in most apps or websites, all primary buttons share the same color and size, helping users instantly recognize them as elements of the same functional group.</p><h4><strong>Common fate</strong></h4><p>Elements that move in the same direction or manner are perceived as part of the sameÂ group.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*BvA0wbiXYlDxtFQ3XugkKg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> If we imagine the circles in motion, the two central circles moving together would naturally be perceived as belonging to a single category.</p><p><strong>Interface:</strong> A simple example of this is animated partner logos that automatically scroll in the same direction. They share a common movement, or quite literally, a commonÂ fate.</p><h4><strong>Continuity (or Continuation)</strong></h4><p>Our eyes naturally tend to follow a <strong>line or a directional flow</strong> when one is perceived.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*0zYmJjKQlWQCk0rhmuuP7g.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> We donâ€™t see ten separate circles placed on the image. We see a smooth curved line formed by thoseÂ circles.</p><p><strong>Interface:</strong> In this example, I removed the background from the navigation bar used in the <em>Similarity</em> example to show that we still perceive these elements as one continuous unit. Our visual system instinctively connects objects into lines or paths whenever possible.</p><h4><strong>Closure (Reification)</strong></h4><p>Our brain tends to perceive complete, unified shapes even when parts of them areÂ missing.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*4HwUUchtbiTxvOYDPOQGAQ.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Even if we â€œcut outâ€ straight segments from a circle, weâ€™ll still perceive it as a circle, our mind automatically fills in theÂ gaps.</p><p><strong>Interface:</strong> This principle allows us to create elements using dotted or dashed outlines, such as drop zones for uploadsor outlined buttons, which the user still recognizes as complete, interactive shapes.</p><h4><strong>Symmetry andÂ order</strong></h4><p>Symmetrical objects are naturally perceived as part of the same group. Symmetry also creates a sense of stability, balance, andÂ harmony.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*VLTiAhg5659nDeftcFR6Og.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Two groups of elements are arranged symmetrically and are perceived as belonging together.</p><p><strong>Interface:</strong> In my example, we automatically perceive the symmetrically aligned navigation items as a unified group. Menu points that are all assumed to be clickable in thisÂ context.</p><h4><strong>Parallelism</strong></h4><p>Elements that are positioned parallel to each other are perceived as related or part of the sameÂ group.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*llo-sPWpyVBYlnr8jwdMgQ.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Four lines made up of circles are perceived as two distinct groups of objects. Itâ€™s partly due to this very principle.</p><p><strong>Interface:</strong> Navigation menus often contain quite large elements with many items. In this case, we perceive three groups of elements within a dropdown menu because theyâ€™re arranged parallel to one another and perpendicular to the main navigation. This layout makes scanning much easier for the user than, for example, displaying one long list or aligning all items parallel to the main navigation, as often happens in secondary menus.</p><h4><strong>Common Region / SharedÂ Area</strong></h4><p>Elements placed within the same visual container or area are perceived as a singleÂ group.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*9hbTi5l2oLWebGotZjvcoA.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Even though all small circles are evenly spaced, we perceive them as two separate groups because they are enclosed within different areas.</p><p><strong>Interface:</strong> Buttons inside a modal window are perceived as part of the same group, while a navigation button (even if it has the same visual weight and is positioned on the same level) is perceived as belonging to another group, simply because itâ€™s outside that shared visualÂ region.</p><h4><strong>PrÃ¤gnanz (Simplicity)</strong></h4><p>The brain tends to perceive simple, concise, and stable formsÂ first.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*9m5_JWItTB5yhbkE9G1T6A.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> Despite the complex shape created using multiple circles and a glass-like effect, we primarily perceive it as one largeÂ circle.</p><p><strong>Interface:</strong> We structure page content into blocks because it makes scanning easier for the user. Instead of focusing on individual letters or images, the user first perceives the overall block structure. In my example, you can see a schematic of a video streaming page, where we instinctively recognize the main sections: navigation, video, recommendations, and description.</p><h4><strong>Focal point</strong></h4><p>An element that contrasts with its surroundings is the first to capture attention.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*uyuSSw1LRepf8xfTLSuYsw.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> A white circle stands out against the background of all other circles and becomes the primary focalÂ element.</p><p><strong>Interface:</strong> In my example, there are two elements that contrast with the rest of the interface: the button and the heroÂ image.</p><p>Contrast in UI isnâ€™t defined by color alone; itâ€™s important to remember that color itself has three attributes: Hue, Saturation, and Value/Brightness, each of which can influence perception differently. By adjusting any of these, you can shift the focal point of theÂ design.</p><p>We can also create contrast through size and shape, as demonstrated by the hero imageÂ example.</p><h4><strong>Figure-Ground</strong></h4><p>We distinguish an object based on its contrast with the background.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*uP7GsMzObz6J5VNISN7_kg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p>Our brain constantly tries to interpret two-dimensional images as three-dimensional scenes. Almost all modern sources reference the <a href=""https://en.wikipedia.org/wiki/Rubin_vase""><em>Rubinâ€™s Vase</em> </a>optical illusion since Edgar Rubinâ€™s research greatly influenced Max Wertheimer and Kurt Koffka, who were working on similar visual phenomena at theÂ time.</p><p><strong>Abstract:</strong> In my example, however, I decided to use simpler shapes to illustrate how our perception tends to arrange objects spatially. For instance, in a <strong>reversible/unstable</strong> type example, two semi-transparent circles overlap and whichever one you focus on appears to be in the foreground. But when one of the shapes becomes opaque, the perception becomes <strong>stable</strong>, because we can clearly identify which element is in front and which isÂ behind.</p><p><strong>Interface:</strong> In my interface example, you can see list items that share the same background color as the page itself but stand out due to shadows. We often apply this same principle in modal windows, where the background is darkened to visually separate the active layer from the rest of the interface.</p><h4><strong>Connectedness</strong></h4><p>Elements that are visually connected are perceived as part of the sameÂ group.</p><figure><img alt=""Abstract and interface diagrams demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*gIe7bK8PVsFwLiGyStiSEg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p><strong>Abstract:</strong> In my example, you see sixteen circles and itâ€™s easy to identify eight of them as belonging to the same group because they are physically connected by aÂ line.</p><p><strong>Interface:</strong> In design, we often apply this principle in steppers, forms, or as in my example in informational blocks that illustrate the stages of a process or present step-by-step instructions.</p><h3>How it actuallyÂ works</h3><p>Itâ€™s also important to note that each of these principles can and often does work in combination with others. Even the simplest element, like a hyperlink, can serve as an example of a <strong>multimodal Gestalt</strong>.</p><figure><img alt=""Image demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*CYrVDvlzy6LqCit1afzeUg.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p>In this example, several principles operate simultaneously, reinforcing oneÂ another:</p><ul><li><strong>Connectedness provides structure.</strong> The underline creates a visual link between all letters and elements. For instance, we perceive <em>â€œoptical illusionsâ€</em> as one connected unit, while <em>â€œDanishâ€</em> and <em>â€œpsychologistâ€</em> appear as two separateÂ ones.</li><li><strong>Similarity highlights the type.</strong> The color of the hyperlink differs from the rest of the text, signaling its interactive role.</li><li><strong>Continuity guides the eye,</strong> even with heavier visual elements nearby. Our gaze naturally flows from left to right, allowing us to read line byÂ line.</li><li>A stable <strong>Figureâ€“ground relationship ensures clear contrast</strong> between text and background, making the content both visible and readable.</li></ul><p>And youâ€™ve probably also seen the classic example of guiding the userâ€™s attention through theÂ text.</p><figure><img alt=""Image demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/1*vAJbUuzoxmSxBqhU2pEcUw.png"" /><figcaption>Example created by MaximÂ Kich</figcaption></figure><p>Even with a minimal set of tools, we can direct our userâ€™s focus by applying the basic laws of Gestalt: Proximity, Continuity, Focal point and Simplicity.</p><h3>Gestalt psychology of perceptual interpretation</h3><p>Youâ€™ll find these three principles only in the Interaction Design Foundationâ€™s list (out of our four main sources). And while they can be incredibly valuable and relevant for us as designers, theyâ€™re often left out of other summaries likely because they donâ€™t deal with how we group elements, but rather with how we perceive and interpret entire visual compositions.</p><p>Iâ€™d also like to note that these principles partially overlap with some of the ones weâ€™ve already discussed. Still, there are important differences between them though thatâ€™s probably a topic deserving its own separateÂ article.</p><h4><strong>Emergence</strong></h4><figure><img alt=""Illusion demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/0*gpK5M3OYrEt-Wrdc.png"" /><figcaption><a href=""https://www.interaction-design.org/literature/topics/gestalt-principles""><em>Â© Interaction Design Foundation</em></a></figcaption></figure><p>We perceive the overall shape before noticing the details. The whole image appears all at once, rather than as the sum of itsÂ parts.</p><h4><strong>Multistability</strong></h4><figure><img alt=""Illusion demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/0*3udmNRxhUmPgvzZ5.png"" /><figcaption><a href=""https://www.interaction-design.org/literature/topics/gestalt-principles""><em>Â© Interaction Design Foundation</em></a></figcaption></figure><p>The same image can be perceived in multiple ways. Our brain continuously switches between interpretations.</p><h4><strong>Invariance</strong></h4><figure><img alt=""Illusion demonstrating Gestalt principle."" src=""https://cdn-images-1.medium.com/max/1024/0*o1scsPxRWpLS0oSC.png"" /><figcaption><a href=""https://www.interaction-design.org/literature/topics/gestalt-principles""><em>Â© Interaction Design Foundation</em></a></figcaption></figure><p>We recognize objects even when their shape, angle, or size changes. We often encounter this principle in typography: no matter which typeface we choose, we can usually still read and understand the characters, unless the font becomes extremely stylized or abstract.</p><h3>The archaic roots of Gestalt principles</h3><h4><strong>Familiarity / Past Experience</strong></h4><p>The brain groups or interprets elements because it remembers the context in which they were previously encountered.</p><p>However, itâ€™s important to note that even Max Wertheimer mentioned this principle in a special context, emphasizing that itâ€™s not a primary law of organization, but rather a secondary factor that <em>can </em>influence perception.</p><blockquote>In some cases, past experience or familiarity may influence the perception of organization, but the primary laws of grouping remain independent of experience.</blockquote><blockquote>â€” Wertheimer, 1923</blockquote><p>For us as designers, â€œFamiliarityâ€ is not really a law of perception in its simplest interpretation, it aligns more closely with one of Jakob Nielsenâ€™s <a href=""https://www.nngroup.com/articles/ten-usability-heuristics/"">heuristic design principles</a>. In more complex frameworks, it becomes part of cognitive psychology, connecting to concepts such as <a href=""https://en.wikipedia.org/wiki/Mental_model""><em>Mental model</em></a><em> and </em><a href=""https://en.wikipedia.org/wiki/Affordance""><em>Affordance</em></a>.</p><h3>Gestalt principles as the grammar of visualÂ design</h3><p>Letâ€™s imagine interface design as a language. If color defines the tone of our message, Gestalt principles define its structure.</p><p>A designer who understands how the human brain groups, aligns, and interprets visual elements doesnâ€™t just make things â€œlook goodâ€ but builds meaning. Gestalt is what transforms shapes into hierarchy andÂ flow.</p><p>These principles arenâ€™t theories to debate. They became laws of perception we can rely on with confidence. But thereâ€™s always room to explore their interpretations and to experiment with how these principles interact, overlap, and sometimes even contradict oneÂ another.</p><p>Thatâ€™s why I encourage everyone who cares about users and about design as a craft to keep experimenting with the old and exploring the new in the pursuit of creating truly delightful and uniqueÂ design.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c34d6772fc36"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/patterns-your-brain-cant-unsee-gestalt-psychology-in-design-c34d6772fc36"">Patterns your brain canâ€™t unsee: Gestalt psychology in design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-illusion-of-unmoderated-ux-testing-503137621407?source=rss----138adf9c44c---4,1763308091,The illusion of unmoderated UX testing,"The illusion of unmoderated UX testing

<div class=""medium-feed-item""><p class=""medium-feed-image""><a href=""https://uxdesign.cc/the-illusion-of-unmoderated-ux-testing-503137621407?source=rss----138adf9c44c---4""><img src=""https://cdn-images-1.medium.com/max/1453/1*lrjUpSwINLE1yANldzaPIA.png"" width=""1453"" /></a></p><p class=""medium-feed-snippet"">I&#x2019;ve been testing the testing. Unmoderated and moderated UX tests with the same type of people on the same topic generate completely&#x2026;</p><p class=""medium-feed-link""><a href=""https://uxdesign.cc/the-illusion-of-unmoderated-ux-testing-503137621407?source=rss----138adf9c44c---4"">Continue reading on UX Collective Â»</a></p></div>"
rss,uxdesign.cc,https://uxdesign.cc/dear-llm-heres-how-my-design-system-works-b59fb9a342b7?source=rss----138adf9c44c---4,1763301560,"Dear LLM, hereâ€™s how my design system works","Dear LLM, hereâ€™s how my design system works

<h4>How to get production-ready code from AI by structuring Figma file, connecting your design system with Figma MCP, and writing betterÂ prompts.</h4><figure><img alt=""Overview of components like toggle, badges, buttons, data visualisation cards, forms and page header from Ivy Design System"" src=""https://cdn-images-1.medium.com/max/1024/1*4ecR3i5SgK488SMg3drtIA.png"" /><figcaption>Image by the author, overview of Ivy Design System components</figcaption></figure><p>Right, pull up a chair, grab your coffee. We need to talk about the new team member. Theyâ€™re brilliant, frankly, work all hours and can write boilerplate code in their sleep. Theyâ€™re also a bitâ€¦ literal. This new team member is an AI agent, and itâ€™s changing how we go from design toÂ code.</p><p>But hereâ€™s the reality check as <a href=""https://www.figma.com/blog/figma-2025-ai-report-perspectives/"">Figmaâ€™s recent AI report</a> â†— found that while 68% of developers are using AI to write code, only 32% actually trust the output. The problem isnâ€™t the AIâ€™s ability to write code, itâ€™s the AIâ€™s ability to understand context.</p><p>Now, we could spend a whole other coffee chat talking about how brilliant AI is for spinning up quick interactive prototypes for stakeholders and testing. And, indeed, itâ€™s a valid way to work. But to grow trust in AI to write real, production-ready code, we have to <strong>give it clean data with clear context to work with in the firstÂ place.</strong></p><p>So, how does this happen? Until recently, we could only give an AI a screenshot and hope for the best. Thatâ€™s changing with something called the <a href=""https://modelcontextprotocol.io/docs/getting-started/intro"">Model Context Protocol (MCP)</a> â†—. Think of the new Figma MCP server as an interpreter for your Figma files that sends rich, structured information to the LLM. The process looks simple: Figma file â†’ Figma MCP â†’ LLM. But for it to work, every step needs to be packed with meaning. <strong>Simply throwing a prompt and a Figma link at an AI agent and hoping for the best is not going toÂ work.</strong></p><h3>Build foundation inÂ Figma</h3><p>The foundation of any good design-to-code workflow, whether for a human or an AI, is a Figma file that clearly communicates its own intent. Every decision you make in how you structure your file can either bring clarity or create confusion.</p><p>First things first, master your <strong>structure hygiene</strong>. An AI reads your layer tree to understand your designâ€™s structure, so a messy tree leads to a messy DOM. Name everything with purpose. Instead of <em>Frame 74</em>, use names that describe what something <em>is</em> or what it <em>does</em>, like <em>CreateProjectModal</em> or <em>ProjectForm</em>. This directly influences the names of the components and elements the AI generates. While youâ€™re at it, try to keep your structure as flat as possible. Avoid deep, unnecessary nesting. If a group isnâ€™t serving a specific layout purpose, get rid of it. A flatter hierarchy is simply easier for everyone to understand.</p><figure><img alt=""A before-and-after comparison of a Figma layers panel, showing a messy structure with generic names like â€˜Frame 79â€™ being replaced by a clean, semantic structure with names like â€˜ProjectFormâ€™ and â€˜Group-DateRange"" src=""https://cdn-images-1.medium.com/max/1024/1*81rdmmTMHIezX1y46fuLag.png"" /><figcaption>Image by the author, showing the improvement from generic layer structure to a clean, semantically-named one</figcaption></figure><p>Next<strong> think and build components like a developer </strong>defining their API. Your layer order should reflect the visual hierarchy or, for the web, the DOM order. This is a massive help for accessibility and logical codeÂ output.</p><ul><li>Use variants for states like <em>State: Default | Hover | Disabled</em>. This maps directly to CSS pseudo-classes or stateÂ props.</li><li>Use a boolean property (Icon: True | False) to show or hide an element. Itâ€™s cleaner than separate variants and translates perfectly to a prop like <em>showIcon={true}</em>.</li><li><strong>Use the </strong><a href=""https://help.figma.com/hc/en-us/articles/35794667554839-What-s-new-from-Schema-2025#h_01K84PB569NTFMXBDS36C8DCPV""><strong>new slots</strong></a><strong> </strong>â†—<strong> feature from Figma to define flexible content areas.</strong> This is a massive improvement over simple instance swaps because it directly maps to the concept of â€œslotsâ€ or the children prop inÂ code.</li></ul><p>Letâ€™s be honest, <strong>Auto Layout</strong> should be your default for almost everything. Itâ€™s the clearest way to communicate layout intent. Use absolute positioning sparingly, keeping it for specific cases like notification badges or modal overlays. Weâ€™ve all seen the mess that older design-to-code tools made by sprinkling <em>position: absolute</em> everywhere.</p><p>Move beyond primitive names like <em>blue-500</em> and embrace <strong>semantic tokens</strong> that describe purpose. For example, <em>color-button-background-brand</em> tells the AI not just what color this is, but <em>why</em> it exists. This tells the AI <em>why</em> this color exists. <strong>For a masterclass on this, check out t</strong><a href=""https://medium.com/design-systems-collective/when-semantic-tokens-are-no-longer-semantic-d65ef16fadd7""><strong>he article series by Nate Baldwin</strong></a><strong>Â </strong>â†—</p><figure><img alt=""An infographic explaining semantic design tokens. It shows a table where raw hex codes are mapped to base tokens like â€˜brand-100â€™, which are then mapped to purpose-driven semantic tokens like â€˜bg-fill/brand/secondaryâ€™. The image also includes a diagram of the semantic naming structure and an example of the tokens applied to a UI component."" src=""https://cdn-images-1.medium.com/max/1024/1*B9GJkT08-NHbTWmM3IFquQ.png"" /><figcaption>Image by author, Visual breakdown of how to move from primitive color values to a purpose-driven semantic tokenÂ system</figcaption></figure><p>When some context canâ€™t be built, <strong>use Figmaâ€™s annotation tools</strong> or plugins like <a href=""https://www.figma.com/community/plugin/859894273811051899/annotate-it""><strong>Annotate It!</strong></a><strong> </strong><a href=""https://uxdesign.cc/feed""><strong>â†—</strong></a> to explicitly call out interaction details, accessibility requirements, or behavior. These notes will become part of the prompt eventually.</p><figure><img alt=""Screenshot of a Figma componentâ€™s annotations that includes details on interaction, development aand accessibility of â€œ_table header cellâ€"" src=""https://cdn-images-1.medium.com/max/1024/1*lnEgDXl3h46LV83M0Qy6_Q.png"" /><figcaption>Screenshot by the author, demonstrating component annotation inÂ Figma</figcaption></figure><p>While this may feel like a demanding level of detail, this very precision is a huge efficiency gain. <strong>By giving the LLM clear context from your designs, you help it use far fewer tokens to get the rightÂ answer.</strong></p><h3>Map designs toÂ codebase</h3><p>The gold standard is to explicitly map designs to code, and creating your own codebase. An AI should consume your existing components, not generate new ones. Without a direct link to your codebase, the AI relies on inaccurate searches that result in redundant code. Tools like <a href=""https://developers.figma.com/docs/figma-mcp-server/code-connect-integration/"">Figmaâ€™s Code Connect </a>â†— or third-party integrations with Storybook create this essential link, turning your Figma components into pointers to the real components in your repository.</p><figure><img alt=""A screenshot of the Code Connect UI feature linking a Figma component to its corresponding React code. Image from the official Figma developer documentation"" src=""https://cdn-images-1.medium.com/max/960/1*vDBzgtCiML2l4B5cQlmvRw.gif"" /><figcaption>A screenshot of the Code Connect UI feature linking a Figma component to its corresponding React code. Image from the <a href=""https://developers.figma.com/docs/code-connect/code-connect-ui-setup/"">official Figma developer documentation</a></figcaption></figure><h4>But what if you donâ€™t have a codebaseÂ yet?</h4><p>You can absolutely use these tools without a connected codebase. The AI will analyze your Figma file and generate new code from scratch that is great for quick prototypes or iterating on ideas. However, understand the trade-offs: you get generated code, not system code; itâ€™s less efficient; and it <strong>creates technical debt that a developer will have to refactorÂ later</strong>.</p><p>A practical middle ground is to <strong>use the AI to create a â€œscaffold.</strong>â€ Let it generate the initial components, then treat that output as the first version of your design systemâ€™s codebase. From there, you refine it, connect it back to Figma, and build a sustainable system.</p><h3>Extra: The ultimate source of truth with components asÂ data</h3><p>The ultimate source of truth is defining components as structured data (JSON), not as Figma drawings. For a deeper dive into this architectural approach, <a href=""https://medium.com/@nathanacurtis/components-as-data-2be178777f21""><strong>Nathan Curtisâ€™ article â€œComponents as Dataâ€</strong></a> â†— is an essential read. LLMs thrive on structured data, whereas the standard MCP workflow provides an <em>â€œincomplete and impreciseâ€</em> interpretation of your visual design. Tools like the <a href=""https://www.anova.design/""><strong>Anova plugin for Figma</strong></a><strong> </strong>â†— can help you get started. This data-first approach is the future of building AI-ready designÂ systems.</p><h3>Give your AI a â€œcheatÂ sheetâ€</h3><p>Whether youâ€™re connecting to code or defining components as data, you still need to guide the AIâ€™s behavior. This involves two skills: writing better prompts and creating a set of rules for the AI to follow. On moreÂ in-depth</p><h4>Write context-rich prompts</h4><p>Your prompt is your direct instruction. The more specific, theÂ better.</p><ul><li><strong>Instead of:</strong> â€œMake this a component.â€</li><li><strong>Try:</strong> â€œGenerate a React component for the selected frame using our design system library. Place the new file in src/components/ui/ and name it PricingCard.tsx.â€</li></ul><p><strong>Split your work into consumable bites</strong>: the nav bar, then the sidebar, then a content card. If you give them too much at once, AI agents can â€œchokeâ€ on the context and create a mess. Build your UI gradually.</p><h4>Set customÂ rules</h4><p>While one-off prompts are great for specific tasks, the real power comes from creating a permanent â€œcheat sheetâ€ that the AI can reference every singleÂ time.</p><p>In your project root, create a dedicated folder likeÂ <em>.docs/</em> orÂ <em>.ai/.</em> Inside, create your three core rules files: <em>README.md</em> file (for foundational rules), <em>design-system-rules.md</em> (for how to use our components), <em>figma-mcp-rules.md</em> (for the specific Figma MCP workflow).</p><figure><img alt=""Screenshot of Cursor IDE with project structure and particularly dedicated folder for AI rules that incudes README.md, design-system-rules.md, figma-mcp-rules.md files. README.md file is explicitly shown opened"" src=""https://cdn-images-1.medium.com/max/1024/1*dGI8HhOgtit-vfgQYv8LOA.png"" /><figcaption>Screenshot by the author of Cursor IDE with project structure and dedicated folder for AIÂ rules</figcaption></figure><p>In your IDE settings or at the start of every prompt, you now reference README.md file that instruct the AI on how to use them together.</p><p><strong>README.md<br /></strong>This file acts as the primary entry point. It defines the core tech stack and file structure, and most importantly, it instructs the AI to use the other two files as part of itsÂ context.</p><pre># AI Coding Guidelines: <br />This repo uses Figma MCP. For instructions, for styles, mappings and design of components you MUST read and strictly apply the rules from all three of the following files:<br />1.  This `README.md` file (for foundational rules).<br />2.  `design-system-rules.md` (for how to use our components).<br />3.  `figma-mcp-rules.md` (for the specific Figma-to-code process).---<br />## Core Principles &amp; Best Practices<br />- Expert Persona: Act as an expert senior frontend developer writing clean, accessible, and maintainable TypeScript and React.<br />- Accessibility: All components must meet WCAG 2.1 AA standards.<br />- Performance: Optimize for performance. Code should have linear time/space complexity where possible.<br />- Testing: Suggest testable code.<br />---<br />## Core Technologies (React &amp; Tailwind)<br />- Framework: React<br />- Language: TypeScript<br />- Styling:Tailwind CSS, configured via `tailwind.config.js`.<br />---<br />## File Structure &amp; Naming Conventions<br />- Components: Place all new components in `src/components/`.<br />  - Reusable UI Primitives:`src/components/ui/` (e.g., Button, Input).<br />  - Feature-Specific Components: `src/components/feature/` (e.g., `UserProfileCard`).<br />- Component Files: Use PascalCase for filenames. Each component must be in its own folder. (e.g., `src/components/ui/Button/Button.tsx`)<br />- Hooks: Custom hooks go in `src/hooks/` and should be named with the `use` prefix (e.g., `useUserData.ts`).</pre><p><strong>design-system-rules.md<br /></strong>This is the detailed guide on how to correctly use your custom components from your-design-system.</p><pre># Design System Usage Rules<br />This document outlines how to correctly implement components and styles from `your-design-system`.<br />---<br />## Component Architecture &amp; Styling<br />- Design System First: Always use existing components from the `your-design-system` package. Do not rebuild them.<br />- Layout Primitives: Always use layout components from `your-design-system` (e.g., ``, ``). Do not use raw `div`s with custom flexbox CSS.<br />- Styling with Tokens: Use Tailwind utility classes that are configured in our `tailwind.config.js`. Prefer our custom theme utilities (e.g., `bg-brand-primary`) over default Tailwind colors.<br />- Icons: Use the `` component from `your-design-system`, passing the appropriate icon name. Do not import raw SVGs.<br />- Props: Component props must be defined with a TypeScript `interface`.<br />---<br />## What to Avoid<br />- No Hardcoded Values: Do not use hardcoded strings (use translation files), URLs (use config files), or styling values (use tokens).<br />- No Inconsistent Naming: Follow the project's naming conventions.<br />- No Ignoring Errors: Do not ignore TypeScript errors.<br />- No Unnecessary DOM: Avoid unnecessary `div` wrappers.</pre><p><strong>figma-mcp-rules.md<br /></strong>This file is a specific, process-oriented set of instructions for the AI to follow whenever itâ€™s translating a design fromÂ Figma.</p><pre># Figma to Code Workflow Rules<br />When generating code from a Figma design, follow this specific process:<br />1.  Get Context First: Run `get_design_context` to fetch the structured representation of the Figma node.<br />2.  Get Visual Reference: Run `get_screenshot` for a visual reference.<br />3.  Implement: Only after you have both, begin implementation.<br />4.  Translate the MCP output (React + Tailwind) into our project's conventions, strictly following the rules defined in `README.md` and `design-system-rules.md`.<br />5.  Validate: Ensure the final UI has 1:1 visual parity with the Figma screenshot before completing.</pre><p>For a technical starting point, Figmaâ€™s developer documentation provides an excellent guide on how to <a href=""https://developers.figma.com/docs/figma-mcp-server/add-custom-rules/#example-prompt-to-generate-your-own-custom-rules""><strong>add custom rules</strong></a> â†—, including example prompts you can use to generate a baseline for theseÂ files.</p><h3>Putting it allÂ together</h3><p>Feeling overwhelmed? Donâ€™t be. Start small. Pick one component and make it â€œagent-ready.â€</p><ol><li><strong>Name everything semantically:</strong> Are your layers and components named for theirÂ purpose?</li><li><strong>Use auto layout and variables:</strong> Is your design intent baked into theÂ file?</li><li><strong>Annotate:</strong> Have you documented behaviors andÂ states?</li><li><strong>*Connect your components (if possible)Â :</strong> Link every system component to its code counterpart.</li><li><strong>Write a simple rules file:</strong> Can you create a basic README.md to guide theÂ AI?</li><li><strong>Prompt with generousÂ context</strong></li></ol><p>The teams that do this groundwork now are building the foundation for a future where design and development are in a constant, seamless loop. By treating our design systems as living sources of truth for both humans <em>and</em> machines, we can finally spend less time on tedious translation and more time building whatÂ matters.</p><p>Thanks for reading! I hope this sparked some ideas. Happy buildingÂ ğŸª´</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b59fb9a342b7"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/dear-llm-heres-how-my-design-system-works-b59fb9a342b7"">Dear LLM, hereâ€™s how my design system works</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-ship-of-theseus-problem-in-ai-writing-9435a4a370fa?source=rss----138adf9c44c---4,1763128228,The ship of Theseus paradox in AI-assisted writing,"The ship of Theseus paradox in AI-assisted writing

<h4>Turns out, the more feelings in your text, the weirder it feels to let AI touchÂ it.</h4><figure><img alt=""The Ship of Theseus reimagined: a vessel where each wooden plank is replaced with a silicon chip"" src=""https://cdn-images-1.medium.com/max/1024/1*MV2D6JbcFgdCKayve-w0rw.png"" /><figcaption>The Ship of Theseus reimagined: a vessel where wooden planks are being replaced with silicon chips. Generated inÂ Sora.</figcaption></figure><p>I use AI writing tools the way most people use spellcheck: casually, constantly, almost without thought. A typo here, a phrasing fix there, a quick â€œmake it flow better.â€ Over time, itâ€™s become second nature that I write <em>through</em> theÂ machine.</p><p>And thatâ€™s not unusual. Grammarly alone reports over <strong>40 million users</strong>, across <strong>50 thousand organizations</strong> and <strong>96 percent of the Fortune 500</strong> (<a href=""https://www.grammarly.com/about"">source: Grammarly.com</a>). The habit has gone mainstream, invisible, automatic, and everywhere.</p><p>But every so often, I pause over a polished paragraph and feel an odd flicker of detachment. The words look like mine, sound like mine, but theyâ€™ve passed through <strong>someone elseâ€™s hands</strong>. Or circuits. Or whatever metaphor fits. How many edits does it take before the voice that returns isnâ€™t meÂ anymore?</p><p>Itâ€™s the Ship of Theseus. Turns out Greek mythology still works in 2025. Swapping planks on a ship is just the new metaphor for rewriting yourself through syntax. Each replaced plank a synonym, each tightened sentence a substitution, until the vessel of thought sails on. The ship, and the writing, are familiar in shape butforeign inÂ soul.</p><p>And this anxiety about â€œlosing your voiceâ€ didnâ€™t arrive with ChatGPT. As others have noted, the fear of writing identity slipping away has circulated for years, long before AI became a default tool (see <a href=""https://medium.com/emma-identity/why-loss-of-writing-identity-is-a-myth-and-other-writing-debacles-85fda0b4b046"">Emma Identityâ€™s 2017 essay</a> on textual fingerprints). Whatâ€™s different now is how automated the erosionÂ feels.</p><h4>A Family-and-Friends FieldÂ Test</h4><p>I wanted to understand that uneasy drift between â€œmeâ€ and â€œmachine,â€ so I ran a small, human-scale test. A handful of volunteers, friends, family, and a few generous redditors who gave five minutes of their lives to a Qualtrics link joinedÂ in.</p><figure><img alt=""Flowchart showing participants providing three types of writing (casual text, essay paragraph, code snippet), sending each through an AI tool for ten iterative rewrites, and rating on a 1â€“7 scale how much the output still felt like â€œtheirs.â€"" src=""https://cdn-images-1.medium.com/max/1024/1*ut4rB0gbseUm7BDETSYkoQ.png"" /><figcaption>Diagram of the study procedure: participants wrote a casual text, an essay paragraph, and a code snippet, then passed each piece through an AI tool ten times and rated how much the rewritten text still felt like their own. Original illustration by theÂ author.</figcaption></figure><p>Each person worked across three familiar modes: a casual text, a short essay paragraph, and a code snippet. They wrote something genuine, then passed it through an AI writer of their choice ten times in a row. After each iteration, they rated it on a 1â€“7 scale: <strong>â€œHow much is this stillÂ mine?â€</strong></p><p>The survey itself ran on Qualtrics; I cleaned and visualized the data in R, using a simple mixed-effects model to trace how that sense of ownership decayed over time. Everyone consented, all responses were anonymized, and whatâ€™s shown here reflects only the aggregate picture.</p><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*tsdSUozOICLkG9w_oCeT-w.png"" /><figcaption>Perceived ownership steadily declines with each AI rewrite, dropping fastest for texting and slowest forÂ code.</figcaption></figure><p>Turns out, the ownership ratings <strong>fell off a cliff</strong> around the third or fourth rewrite for texting and essay writing, but held surprisingly steady in code. A spline model (R, lme4, three-knot natural spline) showed the steepest drop early on: texting collapsed fastest, essays followed, code barely flinched.</p><p>By theÂ numbers:</p><ul><li><strong>Texting:</strong> sharpest drop of â€“1.4 points around iteration 3.</li><li><strong>Essay:</strong> a slower, smaller decline (â€“1.25 points near iteration 5).</li><li><strong>Code:</strong> almost no falloff (â€“0.3 points around iteration 4).</li></ul><p>When asked when their text felt â€œmore AI than meâ€ (below a 4 on the 1â€“7 scale), people hit that midpoint at <strong>iteration 3 for texting</strong>, <strong>iteration 7 for essays</strong>, and <strong>never</strong> forÂ code.</p><p>This aligns with a broader cultural confusion around what â€œhuman-writtenâ€ even looks like. As <a href=""https://alpace.medium.com/unless-it-was-written-by-ryan-holiday-it-was-probably-written-by-ai-0b7099516d98"">Aaron Pace</a> recently wrote, the more polished a piece of writing is, the more likely AI detectors are to label it â€œmachine-made.â€ Today we see a strange modern reversal where professionalism now reads as artificial. My data shows the inverse feeling: the messier and more intimate the writing, the more its owner wants to keep machinesÂ out.</p><h4>What the HumansÂ Said</h4><p>After the survey, I spoke with a few participants again, some over Zoom, some across a kitchen table. Their reactions lined up quite cleanly with the numbers. <strong>The more personal the writing, the more wrong it felt to let an AI touchÂ it.</strong></p><p>When it came to texting, everyone hesitated. That space is messy and intimate. Youâ€™d use lowercase shorthand, inside jokes, typos, emojis that say more than syntax ever could. Watching an AI rewrite that kind of message felt invasive, like handing your phone to someone else mid-conversation.</p><p>Essay writing was easier to surrender. Participants said it felt â€œprofessional,â€ â€œdetached,â€ something meant to be polished anyway. The AIâ€™s edits felt like a second pair of eyes rather than a replacement ofÂ self.</p><p>And code, unless you were a computer science student who lives in it, wasnâ€™t personal at all. In fact, most people said they <em>needed</em> AI to even get started, describing the help as â€œwelcome,â€ â€œexpected,â€ or â€œhonestly, a relief.â€ For them, authorship was more functional than emotional. The machine wasnâ€™t rewriting their voice, it was scaffolding theirÂ logic.</p><p>One person linked their experience to the idea of <strong>vibe coding</strong><em>, </em>which, as <a href=""https://www.ibm.com/think/topics/vibe-coding"">an IBM article described</a>, is <em>the emerging practice of writing code by talking to AI using natural language prompts instead of lines of syntax</em>. They acknowledged that software engineers often dismiss it as unserious, even lazy, but for them, it was liberating. As a nonâ€“computer science student, they said vibe coding made the process less intimidating and more creative.</p><p>It echoed something <a href=""https://medium.com/contemplate/chatgpt-grammarly-and-hemingway-walked-into-a-bar-de2fa481022f"">Jasmine McCandless</a> captured: people donâ€™t pick the â€œbestâ€ writing tool, they pick the one that demands the least effort. But effort can manifest in many ways. And one of them is emotional risk. In my study, the more personal the writing, the more people resisted AI intervention. Once the task shifted into professional or functional territory, the comfort gap widened and AI quietly became the low-effort choice.</p><figure><img alt=""A person giving a robot directions on what to write"" src=""https://cdn-images-1.medium.com/max/1024/1*7PDMmFtdCzfA4b_6caHVuA.png"" /><figcaption>Collaboration between a human writer and an AI assistant. Original illustration by theÂ author.</figcaption></figure><h4>Takeaways for UXÂ Design</h4><p>The tension here is becoming infrastructural. <a href=""https://epiren.medium.com/trust-verify-and-write-using-grammarlys-authorship-in-the-age-of-ai-1778e015dea0"">RenÃ© Najera</a> recently wrote about Grammarlyâ€™s new Authorship feature, which records your keystrokes and generates a replay of how a document came together. Their point is simple: in an age of ubiquitous AI tools, writers now feel pressure not only to produce authentic work, but to <em>prove</em> they made it. My findings speak to the same impulse from the user side: authorship isnâ€™t just who typed the words, but how much of the process still feels human, intentional, and personally owned.</p><p>Maybe the real product insight here is that Grammarly should just buy Copilot and call it a day. One interface to smooth every sentence, human or machine. Beneath the joke, though, is a deeper cue for design: peopleâ€™s comfort with AI assistance scales with emotional distance.</p><p>Texting felt intimate, messy, and human. Thatâ€™s where participants pulled back. They didnâ€™t want the machine polishing what was meant to be personal. Essay writing lived in the middle zone, where improvement feels professional rather than invasive. Code, on the other hand, was almost depersonalized; help there felt efficient, not existential.</p><p>The takeaway isnâ€™t to build less AI assistance. Itâ€™s to build <strong>context-aware</strong> assistance. In spaces where expression carries identity (e.g., messages, creative writing, voice) AI needs to step lightly, amplifying rather than rewriting. In functional spaces such as emails, documentation, and code, it can take the wheel without moral friction.</p><p>Designing for this gradient of intimacy means giving users <strong>control over how much authorship theyâ€™re willing to trade</strong>. The future of AI writing UX isnâ€™t about raw capability. Itâ€™s about sensitivity: knowing when to finish your sentence, and when to leave your typosÂ alone.</p><p>In practice, this could lookÂ like:</p><ul><li><strong>Surface adjustable â€œAI intensityâ€ controls directly in writing surfaces.</strong><br />Let users slide between light-touch suggestions (â€œfix punctuation onlyâ€) and heavier rewrites (â€œrewrite for clarityâ€).</li><li><strong>Use mode-aware defaults.</strong><br />If the system detects texting-like language (emojis, slang, rapid back-and-forth), default to minimal intervention. For structured writing (docs, reports, code blocks), default to more active assistance.</li><li><strong>Show the </strong>Î”<strong><em>delta</em>Â , not just the final rewrite.</strong><br />Display what was changed and why. Visible authorship boundaries reduce the feeling of being overwritten.</li><li><strong>Offer reversible, granular edits.</strong><br />Let users accept or reject changes at the sentence or phrase level, rather than forcing an all-or-nothing rewrite.</li><li><strong>Preserve voice automatically.</strong><br />Train style models on the userâ€™s past writing and ensure AI edits mimic that tone rather than flattening it.</li><li><strong>Avoid â€œdominant toneâ€ suggestions in intimate spaces.</strong><br />Donâ€™t push â€œprofessional tone,â€ â€œconfident tone,â€ or â€œassertive toneâ€ suggestions inside chat or messaging contexts. It reads as intrusive.</li><li><strong>Let users lock sentences or paragraphs.</strong><br />If a line feels emotionally important or identity-revealing, users can mark it: â€œdonâ€™t rewriteÂ this.â€</li><li><strong>Respect the emotional labor of writing.</strong><br />When edits touch personal content, frame them as support (â€œWant help clarifying this?â€) rather than replacement (â€œHereâ€™s a better versionâ€).</li></ul><p>Thereâ€™s an <a href=""https://medium.com/technology-hits/why-your-niche-is-your-shield-the-types-of-writing-ai-struggles-to-replace-dad50e79a01c"">argument</a> that emotionally grounded writing acts as a kind of â€œshieldâ€ that AI canâ€™t easily penetrate, the kind of work rooted in lived experience, personal history, or emotional nuance that resists mechanization by its very nature. And maybe thatâ€™s the point: the parts of writing that matter most arenâ€™t the ones AI can smooth; theyâ€™re the ones only a human canÂ feel.</p><p><em>Alice Ji is a PhD researcher at UIUCâ€™s Institute of Communications Research, studying digital persuasion, attention, and interface design. Portfolio at </em><a href=""https://alice-ji.github.io/project.html""><em>https://alice-ji.github.io/project.html</em></a></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9435a4a370fa"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-ship-of-theseus-problem-in-ai-writing-9435a4a370fa"">The ship of Theseus paradox in AI-assisted writing</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/what-designers-can-learn-from-zohran-mamdanis-historical-campaign-11f92007e873?source=rss----138adf9c44c---4,1762989503,What designers can learn from Zohran Mamdani's historical campaign,"What designers can learn from Zohran Mamdani's historical campaign

<h4><em>How user-centered design principles transformed a grassroots political movement into a viral phenomenon and what it means for design practice.</em></h4><figure><img alt=""Logo with the words: Zohran for New York City in Orange with a blue background. Source: https://www.zohranfornyc.com/media-kit"" src=""https://cdn-images-1.medium.com/max/1024/1*buwhEL87lkuI_Q41zmNbBQ.jpeg"" /><figcaption><a href=""https://www.zohranfornyc.com/media-kit"">Zohran Mamdani Logo</a> designed by Aneesh Bhoopathy.</figcaption></figure><p>The year is 2025, and New York City, â€œThe Greatest City in The Worldâ€ has a 34-year-old, democratic socialist and Muslim mayor! Mamdaniâ€™s campaign has inspired millions, many of whom not New Yorkers and, most impressively, not even American or located inÂ America.</p><p>His campaign didnâ€™t just change politics, i<em>t offered a masterclass in user-centered design</em>.</p><h3>A Parks and Recreation campaign come toÂ life</h3><p>Mamdaniâ€™s campaign seemed (and continues to seem) something out of a Parks and Recreations episode. When Leslie Knope (played by Amy Poehler) decided to run for City council in season 4, she does so with her friends running every aspect of her campaign (after being let go by â€œofficialâ€ campaign managers), this gives her campaign an approachable, friendly and personal aspect that eventually led to herÂ victory.</p><p>Although specific names of the entire Mamdaniâ€™s campaign team are not extensively detailed in publicly available sources, it is known that the campaign operated with a community-driven approach characterized by deep community roots, and a decentralized yet well-coordinated volunteer network, with digital and field teams working closely to listen, test, and refine the outreach based on real-time input fromÂ voters.</p><figure><img alt=""Photograph of Zohran Mamdani speaking at a Fix the MTA press conference. Source: https://www.zohranfornyc.com/media-kit"" src=""https://cdn-images-1.medium.com/max/1024/1*mNzUIuCxNZEfjHtFn7haGw.jpeg"" /><figcaption><a href=""https://www.zohranfornyc.com/media-kit"">https://www.zohranfornyc.com/media-kit</a></figcaption></figure><h3>The team behind the viralÂ success</h3><p>The collaborators frequently mentioned in media coverage are Debbie Saslaw and Anthony DiMieri (for us Parks and Rec fans, thatâ€™s our Ben played by Adam Scott), co-founders and executive producers of <a href=""https://www.adweek.com/agencies/meet-melted-solids-the-scrappy-agency-behind-zohran-mamdanis-primary-winning-campaign/"">Melted Solids</a>, the firm behind many of the campaignâ€™s viral videos, they played a key role in shaping Mamdaniâ€™s message and managing his social media engagement, making this campaign the most viral political campaign in the past 50Â years.</p><blockquote>This lean, agile setup helped Mamdaniâ€™s campaign stay responsive and connected in a way that resonated broadly both locally and globally.</blockquote><figure><img alt=""Photo from an article in adweek: https://www.adweek.com/agencies/meet-melted-solids-the-scrappy-agency-behind-zohran-mamdanis-primary-winning-campaign/ of left to right: Anthony DiMieri, Kara McCurdy, Donald Borenstein, Zohran Mamdani and Debbie Saslaw."" src=""https://cdn-images-1.medium.com/max/1024/1*Va6OL1Z7DLivc58NtQRI8w.png"" /><figcaption>Left to right: Anthony DiMieri, Kara McCurdy, Donald Borenstein, Zohran Mamdani and Debbie Saslaw. Source: <a href=""https://www.adweek.com/agencies/meet-melted-solids-the-scrappy-agency-behind-zohran-mamdanis-primary-winning-campaign/"">https://www.adweek.com/agencies/meet-melted-solids-the-scrappy-agency-behind-zohran-mamdanis-primary-winning-campaign/</a></figcaption></figure><p><strong>Why design thinking matters in political campaigns</strong></p><blockquote>Why did Mamdaniâ€™s campaign resonate globally while better-funded opponents failed? The answer lies in principles every UX designer should understand but while keeping in mind questions of power, authenticity, and manipulation in digitalÂ spaces.</blockquote><p><a href=""https://medium.com/design-bootcamp/user-experience-politics-how-ux-can-be-applied-to-political-campaigns-4efe25435846"">Brad Oâ€™Conner</a> who transitioned into UX design after 15 years in political consulting, discovered that he had been practicing UX design principles in political campaigns long before transitioning into the field, writes &quot;The voters whom you are trying to reach are the users. The goal is to provide the voter with relevant information so that their decision to vote for your candidate or cause is made more accessible.â€</p><blockquote><strong><em>One key difference is that politics is also a lot more â€œmanipulativeâ€ thanÂ UX.</em></strong></blockquote><p>A study carried out by the <a href=""https://www.ox.ac.uk/news/2021-01-13-social-media-manipulation-political-actors-industrial-scale-problem-oxford-report"">Oxford Internet Institute</a> that documented organized social media manipulation campaigns in 81 countries, found that â€œgovernments and political parties â€œproduced misinformation on an industrial scale.â€ So as designers we must ask, <em>where does authentic transparency end and performance begin?</em></p><h3>1. Active listening as userÂ testing</h3><p>Mamdaniâ€™s campaign broke from the traditional political playbook by engaging directly with both supporters and critics on socialÂ media.</p><h4>The â€œultimatelyâ€ moment: iteration madeÂ visible</h4><p><a href=""https://www.instagram.com/zohrankmamdani/reel/DMBjabdOTPe/"">Zohran Kwame Mamdani on Instagram: &quot;I was given an ultimatum.&quot;</a></p><p><em>Alt text: Video of Zohran Mamdani catching himself mid-sentence about to say â€œultimatelyâ€ and self-correcting with humor</em> <em>Video credit: Zohran Mamdani Instagram / OriginalÂ creator</em></p><p>In one instance from July 2025, Zohran Mamdani, prompted by feedback from his communications team and voters, makes a conscious effort to stop himself from overusing the word â€œultimatelyâ€ during interviews and public appearances. In this light-hearted video, Mamdani acknowledges the feedback, shares clips illustrating his habit, and includes a segment whereâ€Šâ€”â€Šmid-sentenceâ€Šâ€”â€Šhe catches himself about to say â€œultimatelyâ€ and quickly redirects his phrasing.</p><blockquote><em>â€œI am listening, I am learning. Please keep sending me your feedback because ultimately, I will get better.â€<br />â€œIn response to my team and supporters pointing out that I say â€˜ultimatelyâ€™ a lot, I caught myself on camera correcting the habit. Keep holding me accountable. This is how we improve, together.â€ (ZohranÂ Mamdani)</em></blockquote><p>This approach mirrors what the <a href=""https://www.nngroup.com/articles/empathy-mapping/"">Nielsen Norman Group teaches about design thinking</a>: empathy mapping helps â€œdistill and categorize your knowledge of the user into one placeâ€ and â€œdiscover gaps in your current knowledge.â€ Mamdani essentially created a public empathy map of his own communication style, inviting collective feedback.</p><figure><img alt=""The User-Centered Design Loop: Mamdaniâ€™s Campaign as a Design Process. It shows a four-step circular loop labeled 1. Listen, 2. Analyze, 3. Iterate, 4. Ship, with arrows connecting each step around a central circle labeled â€œContinuous Improvement.â€ Each step includes short examples from Mamdaniâ€™s campaign, such as gathering voter feedback, reviewing patterns, adjusting speaking habits, and posting public updates. A note at the bottom reads: â€œKey Insight: Making the feedback loop visible builds&quot;"" src=""https://cdn-images-1.medium.com/max/1024/1*N1HgMHBwGYY0TvewMGXqpg.png"" /><figcaption>The User-Centered Design Loop: Mamdaniâ€™s Campaign as a DesignÂ Process.</figcaption></figure><h3>2. Building trust through transparency</h3><p>Mamdaniâ€™s response embraced feedback as a tool for self-improvement much like designers should seek out feedback and build on it in order to inspire trust in their designs. Furthermore, the transparency in documenting the process of listening and acknowledging the feedback is what inspired peopleâ€™s trust in him. This moment, in equal parts humorous and earnest, embodies the essence of user-driven iteration.</p><blockquote><strong><em>However</em></strong><em>, a question we, as designers, must ask ourselves is, how do we distinguish genuine transparency from performed authenticity? The Mamdani campaign appears to represent authentic engagement, and although their strategies are effective, they can also easily be replicated by good actors with bad intentions.</em></blockquote><blockquote><strong><em>Lessons for designers</em></strong><em>: Find the line between authentic iteration and manipulative performance and listen to your users, show them youâ€™re paying attention, and let the process of improvement happen in publicÂ view.</em></blockquote><h3>3. Small, agile teamsÂ win</h3><p>Mamdani did not have the funding for a large campaign nor was he backed by any billionaires. According to the official <a href=""https://www.nyccfb.info/vsapps/CandidateSummary.aspx?as_cand_id=2899&amp;as_election_cycle=2025&amp;cand_name=Mamdani"">campaign finance summary</a> from the New York City Campaign Finance Board for the 2025 election cycle, Zohran Mamdaniâ€™s total campaign spending was $12,794,272. His campaign raised $17,159,487 in total receipts, with over $4 million coming from private funds and significant additional support from public funds through matching programs. This is relatively lean compared to Cuomoâ€™s 40 million dollar budget which mostly came from super PACs and billionaire donors. Unlike Cuomoâ€™s traditional campaign operation, Mamdani relied on volunteers and a handful of core personnel to constantly iterate and connect at the groundÂ level.</p><h4>Hereâ€™s how an agile approach played out in practice:</h4><ul><li><strong>Culturally aware content</strong>: Mamdaniâ€™s team highlighted community through moments like salsa dancing in Bronx parks, sharing biryani with cabbies, or joining Tai Chi classes in Flushing. These resonated with the voters and quickly turnedÂ viral.</li></ul><figure><img alt=""Collage of eight campaign photos showing Zohran Mamdani at diverse community events including large crowd gatherings, group photos with supporters on steps and on motorcycles, media appearances on MSNBC Weekend, indoor community meetings, a Congresswoman Yvette Clarke endorsement poster, and candid moments speaking with constituents in outdoor settings Source: https://www.instagram.com/zohrankmamdani/"" src=""https://cdn-images-1.medium.com/max/1024/1*l4oBSYa9PKgbsRxCViYHDg.png"" /><figcaption>Collage of Mamdani at community events. Source: <a href=""https://www.instagram.com/zohrankmamdani/"">https://www.instagram.com/zohrankmamdani/</a></figcaption></figure><ul><li><strong>Collaborations born agile</strong>: Instead of focusing only on high-budget ad buys, Mamdani often teamed with social creators (like The Kid Mero and Subway Takes) and grassroots web series (â€œAre You Okay?,â€ â€œThe People Galleryâ€). These partnerships came together quickly, built on DMs and group chats rather than formal contracts.</li><li><strong>Volunteer-led feedback loops</strong>: The campaign harnessed a decentralized WhatsApp-powered network of volunteers for canvassing, â€œfriendraisers,â€ and â€œhouse parties.â€ First-time volunteers were rapidly trained and empowered to experiment, suggesting new neighborhoods to target, new stories to tell, and even filming spontaneous street interviews. This grassroots network was not only executing, but also feeding real-time insights and inspiration back to the campaignâ€™s creativeÂ leads.</li><li><strong>Prototyping at campaign speed</strong>: from valentineâ€™s day skits to a CTA in a box of chocolates, to working with rising and diverse artists like Aneesh Bhoopathy (whose branding drew from New Yorkâ€™s multicultural cityscapel), Wael Morcos of Morcos Key (who brought an Arabic inflection to the design for outreach in immigrant communities) and Rama Duwaji (Mamdaniâ€™s wife) a Syrian-American artist, all contributed creative input to the campaignâ€™s bold color palette and storytelling style. Together, these collaborators crafted a visual system that embodied the campaignâ€™s ethos: energetic, multicultural, and community-rooted.</li></ul><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/554/1*-cHRq1W7oDToc9LlXLl85g.png"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1024/1*qP_poKjabd5DdbvWcCKONg.png"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/538/1*n8JGlCWyY_n831nkV_arRQ.png"" /><figcaption>Campaign poster designs. Left to right: Arabic version (Wael Morcos/Morcos Key), Brooklyn/Staten Island/Manhattan/Queens/Bronx borough designs (Aneesh Bhoopathy), F<em>lower animation by Sarah Melawad. Source: </em><a href=""https://www.instagram.com/zohrankmamdani/"">https://www.instagram.com/zohrankmamdani/</a> &amp; <a href=""https://www.newsweek.com/inside-the-visual-strategy-that-won-nyc-for-zohran-mamdani-11023538"">https://www.newsweek.com/inside-the-visual-strategy-that-won-nyc-for-zohran-mamdani-11023538</a></figcaption></figure><p>Mamdaniâ€™s campaign proves that a small, nimble, empowered team listening, iterating, and acting in public, can beat even the biggest budget when it comes to building trust, resonance, and momentum.</p><blockquote><strong><em>Lesson for designers</em></strong><em>: Value nimbleness, rapid prototyping, and responsiveness over large, inflexible structures.</em></blockquote><blockquote><strong><em>However</em></strong><em>, While Mamdaniâ€™s agile appraoch proves effective we must acknowledge what </em><a href=""https://medium.com/@TarenSK/progressives-need-a-ux-design-revolution-195aa2c12894""><em>Taren Stinebrickner-Kauffman argues</em></a><em>, that â€œ</em>the non-profit campaigning world has overlooked the deep expertise available<em> i</em>n UX design&quot;<em>; in other words, the success of Mamdaniâ€™s campaign was possible because skilled workers chose to donate their expertise, a privilege not readily available to everyÂ team.</em></blockquote><h3>4. Social media engagement and messageÂ clarity</h3><p>If social media was meant for anything it was storytelling. This is exemplified in Mamdaniâ€™s social media campaigning, he didnâ€™t just tell a story, he listened to other peopleâ€™sÂ stories.</p><h4><strong>Near real-time responsiveness</strong></h4><p><a href=""https://www.instagram.com/zohrankmamdani/reel/DQrrenCDtrg/"">Zohran Kwame Mamdani on Instagram: &quot;Thank you, New York City. Last night we made history. Now we get to work. Comment MayorElect to learn about the transition. Comment DonateNow to make a contribution.&quot;</a></p><p><em>Alt text: Video of Mamdani announcing transition plans the day after election victory</em> <em>Video credit: Zohran Mamdani Instagram</em></p><p>Mamdaniâ€™s team developed a reputation for near real-time responsiveness, flooding platforms with multilingual and original content and directly engaging with voters, influencers and critics alike. When he won the mayoral race, influencers joked that Mamdani should â€œgo to bedâ€ as the very next day Mamdani posted a video announcing his plan for the transitional phase.</p><p>Digital experts credited his social media presence with fueling grassroots participation at levels rarely seen in local politics. Mamdani did not simply use social media he was intertwined in its roots through collaboration with influencers he knew would target his voters and his audience, thatâ€™s good user research: <em>know your audience</em>.</p><p>This engagement and real-time communication transcended boundaries and was embraced far beyond its original audience because it told a story and stories have noÂ borders.</p><blockquote><strong><em>Lessons for designers</em></strong><em>: Storytelling as a tool in UX is often overlooked and under-appreciated, yet it is at the center of good UX and UI. Tell aÂ story.</em></blockquote><blockquote><strong><em>However</em></strong><em>, how can we discuss social media political success without acknowledging that</em></blockquote><blockquote><em>the very techniques that made Mamdaniâ€™s campaign successful (rapid iteration, emotional storytelling, influencer partnerships) are the same ones </em><a href=""https://www.stimson.org/2022/social-media-misinformation-and-the-prevention-of-political-instability-and-mass-atrocities/""><em>identified by researchers</em></a><em> as enabling â€œorganized social media misinformation campaignsâ€ that threaten democracy globally.</em></blockquote><blockquote><em>How do we as designers harness the power of emotional connection and rapid iteration without contributing to the erosion of truth and democratic norms?</em></blockquote><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/1008/1*VKRUtjgehtRth1msGLA3uA.png"" /></figure><figure><img alt="""" src=""https://cdn-images-1.medium.com/max/984/1*-tz4fKlRT4hh13dnZ2z2gA.png"" /><figcaption>Two-panel screenshot of Instagram comments showing enthusiastic support for Mamdaniâ€™s campaign from users across the US and internationally, including Philadelphia, London, and Dublin, with comments praising the campaignâ€™s content strategy, authenticity, and comparing it to Obamaâ€™s 2008 campaign. Source: <a href=""https://www.instagram.com/zohrankmamdani/"">https://www.instagram.com/zohrankmamdani/</a></figcaption></figure><h3>5. Clarity as empowerment</h3><p>Other than the consistent and constant social media messaging and presence, the likes of which have never been seen in US political campaigning, Zohran Mamdaniâ€™s message was committed to clarity. On social media and in real life, whether he was explaining voting requirements, or his plans as mayor for the city, he was walking people step-by-step through the message and in multiple languages and settings thereby empowering first-time or previously disengaged voters.</p><blockquote><strong><em>Lessons for designers</em></strong><em>: Mamdaniâ€™s approach exemplified the core UX principle of affordance: making it immediately visible what action is possible and how to takeÂ it.</em></blockquote><blockquote><strong><em>However</em></strong><em>, the question then arises, </em>Why should anyone have to explain the ability and process of voting?<em> Doesnâ€™t this then allow those with the explanation the power to weaponize this knowledge? </em><a href=""https://ask.edgarallan.com/blog/a-ux-perspective-on-the-us-election""><em>Edgar Allanâ€™s UX team notes</em></a><em>, â€œIf there was ever a thing that should be unquestionably clear, understandable and accessible, it is the ability to vote. Unfortunately, the U.S. voting system suffers from a distinct lack of user-centricity.â€</em></blockquote><h3>6. Cultural pain points = empathyÂ mapping</h3><p>One of the first steps in the design thinking process is to empathize. Empathy was the main message throughout Mamdaniâ€™s campaign, it â€œgoes beyond what users explicitly state and manages to unearth hidden motivations, desires, and pain points.â€ (<a href=""https://www.interaction-design.org/literature/article/empathy-map-why-and-how-to-use-it"">Interaction Design Foundation</a>).</p><p><em>By focusing on lived experiences, cultural nuances and specific community needs his campaign resonated with voters in an unprecedented way.</em></p><p>In a historic move not seen before in American politics, Mamdani publicly asked his supporters to stop donating once the campaign reached its financial goals. He posted transparent breakdowns of fundraising progress and, upon reaching the spending cap, communicated directly:</p><p><a href=""https://www.instagram.com/zohrankmamdani/reel/DOOI8_Ijrm5/"">Zohran Kwame Mamdani on Instagram: &quot;I am once again asking you to stop sending us money. But we do need your time. Comment CanvassNow - one word, no spaces - to get a sign up link in your DMs.&quot;</a></p><p><em>Alt text: Video of Mamdani asking voters to stop donating money to his campaign. Video credit: Zohran Mamdani Instagram</em></p><blockquote>â€œWe have enough to win. Pleaseâ€¦do not give more. Redirect your generosity to mutual aid, to neighbors, to other grassroots causes.â€ (ZohranÂ Mamdani)</blockquote><h4><strong>Plain language, clearÂ needs</strong></h4><p>There were no hidden motives or complicated political lingo, just a plain-language presentation of what he needed from his supporters at each moment. Voting instructions were step-by-step. Donation limits were openly discussed. When the campaign reached its fundraising goal, supporters were told explicitly and publicly that there was no need for more underlying the empathetic line that his campaign had been running â€œFor a New York You CanÂ Affordâ€.</p><blockquote><strong><em>Lessons for designers</em></strong><em>: make empathy visible by listening, responding, and adapting your design to usersâ€™ actual lives and constraints.</em></blockquote><blockquote><strong><em>Here again we must consider the power of manipulation and exploitation.</em></strong><em> When genuine empathy certainly bridges gaps, but when performed it can manipulate vulnerable populations. Our responsibility, as designers is to ensure empathy serves usersâ€™ interests, not just campaign goals, to quote </em><a href=""https://uxpamagazine.org/political-design/""><em>Lloyd Hervey writes about Political Design</em></a><em>, designers must consider â€œwhat is possible and what is ethicalâ€¦the trade-offs of who will benefit from a particular solution versus who will be negatively affected.â€</em></blockquote><figure><img alt=""Instagram post by Zohran Mamdani promoting a â€œSavings Calculatorâ€ tool for New York City residents. The left side shows a bright blue and yellow screen asking, â€œAre you a rent-stabilized tenant?â€ with Yes/No options and a rent input field. On the right, the caption explains the calculator helps New Yorkers see how policies affect childcare, rent, and bus fare savings. Source: https://www.instagram.com/p/DPehuVCDji1/"" src=""https://cdn-images-1.medium.com/max/1024/1*UpQ25IdaLunE18QulkkNmg.png"" /><figcaption>Screenshot of the campaignâ€™s affordability agenda calculator, demonstrating the principle of UX affordance by making policy impact immediately tangible and personalized for NYC voters. Source: <a href=""https://www.instagram.com/p/DPehuVCDjt1/"">https://www.instagram.com/p/DPehuVCDjt1/</a></figcaption></figure><h3>7. Multilingual communication = inclusive design</h3><p>Some political opponents criticized Mamdani for â€œcode switchingâ€, shifting languages and communication styles to match his audience. But in UX terms, this is exactly right. Code switching isnâ€™t diluting your message; itâ€™s adapting it for different user contexts.</p><h4><strong>Authentic voices from communities</strong></h4><p><a href=""https://www.instagram.com/zohrankmamdani/reel/DQZrQz4jtFm/"">Zohran Kwame Mamdani on Instagram: &quot;Juntos vamos a construir la ciudad que merecemos! Y con tu ayuda, voy a seguir aprendiendo espaÃ±ol ğŸ˜‰ Â¡Puedes votar temprano hasta el Domingo y el dÃ­a de las elecciones es el Martes 4 de Noviembre! Â¡Comenta con la palabra VOTA y te enviaremos un enlace para ver dÃ³nde votar!&quot;</a></p><p><em>Alt text: Video of Mamdani speaking Spanish with a local Spanish speaking voter. Video credit: Zohran Mamdani Instagram</em></p><p><a href=""https://www.instagram.com/zohrankmamdani/reel/DQhue5vjlgj/"">Zohran Kwame Mamdani on Instagramâ€: &quot;â€Ø£Ù†Ø§ Ø§Ø³Ù…ÙŠ Ø²Ù‡Ø±Ø§Ù† Ù…Ù…Ø¯Ø§Ù† ÙˆØ¹Ù… Ø±Ø´Ù‘Ø­ Ø­Ø§Ù„ÙŠ Ù„Ø£ÙƒÙˆÙ† Ø§Ù„Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ&quot;â€</a></p><p><em>Alt text: Video of Mamdani speaking Arabic. Video credit: Zohran Mamdani Instagram</em></p><p>Mamdaniâ€™s socials are flooded with videos in Arabic, Urdu, Spanish, appealing to all the New York demographics and communities. He did so by enlisting the help of people from those communities, in other words he engaged with more diverse audiences thoughtfully and used locals to help make his message more authentic and relevant. This helped communities feel seen and heard and Mamdani was able to build trust with communities small andÂ large.</p><blockquote><strong><em>Lessons for designers</em></strong><em>: use language fluidity to engage broader, more diverse audiences thoughtfully and do not translate blindly, instead ellicit help from locals who speak the language. S</em></blockquote><blockquote><em>Such help from local communities should go beyond translation and requires including the diverse communioties in the design process itself and not just in the final messaging. Language fluidity is not automatically inclusive and as designers we must be weary of what researchers call â€œ</em>performative diversity<em>â€ which is looking inclusive without transferring actual power to marginalized communities</em></blockquote><h3>Conclusion</h3><h4>Hope through human-centered design</h4><p>Mamdaniâ€™s campaign gave people something special and new (perhaps also dangerous, it remains to be seen):Â Hope.</p><p>He did it by embodying core UX principles: <em>empathy</em>, <em>storytelling</em>, and <em>iteration</em>. His message was always empathetic, his statements clear and direct, and his â€œuser requirementsâ€ (what he needed from his supporters) consistently open and accessible. This was a campaign led by the people, for the people, but more importantly, Mamdani didnâ€™t position himself as someone observing New Yorkers from the outside. He is a New Yorker. He lived their stories alongside them, not aboveÂ them.</p><h4>Remembering the human element and our responsibility as designers.</h4><p>As designers, itâ€™s all too easy to get caught up in technical features or aesthetic appeal. While those things matter, the most meaningful work happens when we remember the element of humanity at the heart of every experience. As the UX world shifts rapidly, perhaps toward â€œZero UIâ€ where interfaces recede and experience comes to the foreground, we should focus on listening deeply, telling better stories, and designing platforms where usersâ€™ stories are welcomed, valued, and allowed to live andÂ breathe.</p><p>But we must also remember our ethical responsibility; feelings give way to manipulation and exploitation, and the same techniques that built hope in Mamdaniâ€™s campaign can and are also used to to spread misinformation, manipulate vulnerable populations, and erode democratic institutions. Our work as designers is never neutral, after all design for everyone is design for no one, and the question is not whether our design has impact, but whether that impact serves democratic values, human dignity, andÂ truth.</p><p>Mamdaniâ€™s campaign was a reminder that empathy, clarity, and authentic connection are what build hope and inspire change. But itâ€™s also a reminder that these tools are powerful, and that with great power comes great responsibility.</p><blockquote>The future of design in democracy depends on our willingness to hold two simultaneous truths: that connection matters deeply, and that not all connection is createdÂ equal.</blockquote><p>Every design decision is a choice. ChooseÂ wisely.</p><h3>References and Additional Readings</h3><h4><strong>Campaign Coverage:</strong></h4><ul><li>Wikipedia. <a href=""https://en.wikipedia.org/wiki/2025_New_York_City_mayoral_election"">â€œ2025 New York City mayoral election.â€</a></li><li>Adweek. <a href=""https://www.adweek.com/agencies/meet-melted-solids-the-scrappy-agency-behind-zohran-mamdanis-primary-winning-campaign/"">â€œMeet Melted Solids, the Scrappy Agency Behind Zohran Mamdaniâ€™s Primary-Winning Campaign.â€</a></li><li>New York Times. <a href=""https://www.nytimes.com/live/2025/11/05/nyregion/nyc-mayor-mamdani"">â€œMamdani, N.Y.C. Mayor-Elect, Names Transition Team of Government Veterans.â€</a> November 6,Â 2025.</li><li>CNN. <a href=""https://www.cnn.com/2025/11/04/politics/video/mamdani-nyc-mayor-democratic-socialist-vrtc"">â€œZohran Mamdani wins NYC mayorâ€™s race in historic upset.â€</a> November 5,Â 2025.</li><li>CBS News. <a href=""https://www.cbsnews.com/newyork/live-updates/nyc-election-results-2025/"">â€œZohran Mamdani claims victory in NYC mayorâ€™s race, promises â€˜relentless improvement.â€™â€</a> November 5,Â 2025.</li><li>New York City Campaign Finance Board. <a href=""https://www.nyccfb.info/vsapps/CandidateSummary.aspx?as_cand_id=2899&amp;as_election_cycle=2025&amp;cand_name=Mamdani"">â€œ2025 Campaign Finance Summary.â€</a></li><li>Mamdani, Z. K. [@zohrankmamdani]. (n.d.). <em>Instagram profile</em>. Instagram. Retrieved November 12, 2025, from <a href=""https://www.instagram.com/zohrankmamdani/"">https://www.instagram.com/zohrankmamdani/</a></li><li>Zohran for NYC. (n.d.). <em>Media kit</em>. Retrieved November 12, 2025, from <a href=""https://www.zohranfornyc.com/media-kit"">https://www.zohranfornyc.com/media-kit</a></li></ul><h4><strong>UX and Political Campaigns:</strong></h4><ul><li>Oâ€™Conner, Brad. <a href=""https://medium.com/design-bootcamp/user-experience-politics-how-ux-can-be-applied-to-political-campaigns-4efe25435846"">â€œUser experience &amp; politics: how UX can be applied to political campaigns.â€</a> Medium, JuneÂ 2021.</li><li>Key Lime Interactive. <a href=""https://info.keylimeinteractive.com/the-ux-of-politics"">â€œThe UX of Politics.â€</a></li><li>Edgar Allan. <a href=""https://ask.edgarallan.com/blog/a-ux-perspective-on-the-us-election"">â€œA UX Perspective on the US Election.â€</a></li><li>Stanford Social Innovation Review. <a href=""https://ssir.org/articles/entry/when_to_use_user_centered_design_for_public_policy"">â€œWhen to Use User-Centered Design for PublicÂ Policy.â€</a></li><li>Stinebrickner-Kauffman, Taren. <a href=""https://medium.com/@TarenSK/progressives-need-a-ux-design-revolution-195aa2c12894"">â€œProgressives need a UX design revolution.â€</a> Medium, NovemberÂ 2018.</li></ul><h4><strong>Design Thinking andÂ Empathy:</strong></h4><ul><li>Nielsen Norman Group. <a href=""https://www.nngroup.com/articles/empathy-mapping/"">â€œEmpathy Mapping: The First Step in Design Thinking.â€</a> JanuaryÂ 2024.</li><li>Interaction Design Foundation. <a href=""https://www.interaction-design.org/literature/article/empathy-map-why-and-how-to-use-it"">â€œEmpathy Mapâ€Šâ€”â€ŠWhy and How to UseÂ It.â€</a></li><li>QED42. <a href=""https://www.qed42.com/insights/how-empathy-works-in-design-thinking"">â€œThe role of empathy mapping in the process of design thinking.â€</a></li><li>Stolzoff, Alex. <a href=""https://medium.com/design-bootcamp/design-thinking-empathy-maps-journey-maps-and-how-they-are-interconnected-b145aafccdd1"">â€œDesign Thinking, Empathy Maps, Journey Maps, and how they are interconnected.â€</a> Medium, MarchÂ 2021.</li></ul><h4><strong>Agile Marketing and SmallÂ Teams:</strong></h4><ul><li>Atlassian. <a href=""https://www.atlassian.com/agile/agile-marketing/agile-marketing-team"">â€œHow to create an agile marketing team.â€</a></li><li>Teamhood. <a href=""https://teamhood.com/agile/what-is-agile-marketing/"">â€œWhat is Agile Marketing: Definition, Framework &amp; Examples.â€</a> JulyÂ 2025.</li></ul><h4><strong>Political Design andÂ Ethics:</strong></h4><ul><li>Hervey, Lloyd. <a href=""https://uxpamagazine.org/political-design/"">â€œPolitical Design.â€</a> UXP Magazine, JuneÂ 2025.</li></ul><h4><strong>Social Media Manipulation and Criticism:</strong></h4><ul><li>University of Oxford. <a href=""https://www.ox.ac.uk/news/2021-01-13-social-media-manipulation-political-actors-industrial-scale-problem-oxford-report"">â€œSocial media manipulation by political actors an industrial scale problem.â€</a> JanuaryÂ 2021.</li><li>Stimson Center. <a href=""https://www.stimson.org/2022/social-media-misinformation-and-the-prevention-of-political-instability-and-mass-atrocities/"">â€œSocial Media Misinformation and the Prevention of Political Instability and Mass Atrocities.â€</a> NovemberÂ 2022.</li><li>Yerlikaya, Turgay, and Seca Toker Aslan. <a href=""https://www.insightturkey.com/articles/social-media-and-fake-news-in-the-post-truth-era-the-manipulation-of-politics-in-the-election-process"">â€œSocial Media and Fake News in the Post-Truth Era: The Manipulation of Politics in the Election Process.â€</a> Insight Turkey, JulyÂ 2020.</li><li>Guess, Andrew, et al. <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC6436681/"">â€œSocial mediaâ€™s contribution to political misperceptions in U.S. Presidential elections.â€</a> PLOSÂ ONE.</li><li>Bonnema, Simone. <a href=""https://www.sciencedirect.com/science/article/pii/S0377221720308249"">â€œThe responsibility of social media in times of societal and political manipulation.â€</a> European Journal of Operational Research, September 2020.</li></ul><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=11f92007e873"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/what-designers-can-learn-from-zohran-mamdanis-historical-campaign-11f92007e873"">What designers can learn from Zohran Mamdani's historical campaign</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/the-evolution-of-youtube-how-every-platform-evolves-into-an-ad-machine-9e6032ff2d20?source=rss----138adf9c44c---4,1762949937,The evolution of Youtube: How every platform evolves into an ad machine,"The evolution of Youtube: How every platform evolves into an ad machine

<h4>A guide to the extinction of user joy in the digitalÂ age.</h4><figure><img alt=""Image of a crab over a phone, symbolizing the evolution of apps into ad machines"" src=""https://cdn-images-1.medium.com/max/1024/1*Yarbt8n6ZoCN7HwRnRAJHg.png"" /><figcaption>An crap shaped ad, emerging from a cellphone.</figcaption></figure><p>I was halfway through doing the dishes while listening to a podcast when an ad cut through and interrupted one of the most interesting bits. My phone was a few meters away in the living room and I rushed over like I had forgotten a burning turkey in the oven to make sure that I got to the phone before the second ad started playing. I tapped that lower-right hand skip button and the tension in my body temporarily melted away as I made my way back to the chore and continued listening to my podcast, ironically about the slow decay of once useful apps, that was so rudely interrupted by a NissanÂ ad.</p><figure><img alt=""Popup for YouTube Premium offering ad free experience"" src=""https://cdn-images-1.medium.com/max/661/0*qVaAxIWg4nrXMgaT.jpg"" /><figcaption><a href=""https://strangershow.com/how-to-buy-youtube-premium/"">Popup for YouTube Premium offering ad free experience</a></figcaption></figure><p>As I pondered how possible it would be to find an ad blocker for my phone, the answer was slapped in my face in the form of a glorious popup! <strong>Try YouTube premium and youâ€™ll be ad free</strong>â€¦ something that only a few years ago was standard had become a premium and I asked myself why? The term I happened to be learning about that day from <a href=""https://doctorow.medium.com/https-pluralistic-net-2024-04-04-teach-me-how-to-shruggie-kagi-caaa88c221f2"">Cory Doctorow was <strong>enshittification</strong></a>, which can be loosely defined as the process by which platforms decay as they shift value away from users and toward themselves and their business customers. In other words, things start out good for us, then get worse as the companies optimize for profit. While we all have a collective <a href=""https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/"">intuitive sense of platforms decaying</a> over the last few years, I wanted to look closer from a design perspective, specifically, at how that decay unfolds through the deliberate, incremental rollout ofÂ ads.</p><p>The key players in this <strong>enshittification</strong> race are the four major tech companies that dominate our digital lives: Google, Meta (Facebook and Instagram), TikTok, and YouTube. But for the sake of this article, Iâ€™m going to focus on one in particular, because itâ€™s where I spend the most time:Â YouTube.</p><p>These companiesâ€™ slow decay into ad infested dystopian nightmares reminded me of a conversation I had with my good friend and cofounder <a href=""https://charliegedeon.medium.com/"">Charlie Gedeon</a>. He told me about this theory, called <a href=""https://en.wikipedia.org/wiki/Carcinisation""><strong>carcinisation</strong></a>, which is the very hilarious scientific process which can be described as â€œ<a href=""https://brill.com/view/journals/ctoz/67/2/article-p79_1.xml"">the many attempts of Nature to evolve [into] a crab</a>â€. In simple terms, there is an evolutionary momentum that has slowly pushed a variety of unrelated species to evolve into the general behaviour pattern and shape of a crab. So given enough time and opportunity, every species will eventually become a crab. I couldnâ€™t ignore the metaphorical parallel: in our technological ecosystem, the biggest species donâ€™t turn into crabs, they turn intoÂ ads.</p><p>Before YouTube, there was TV. The TV was invented in 1939, and the <a href=""https://www.madhive.com/insights/history-of-tv-advertising"">first ads were shown in 1941</a>. In the early 1940s, ads were short, mild interruptions between programs then by the 1980s, they had become pretty much the reason every sitcom, news broadcast, and sports event existed at all. It was simply the packaging for the ad breaks that paid for it. Then streaming arrived and it felt like a breath of fresh air! A new, ad-free subspecies breaking free from its commercial ancestors. Netflix, YouTube, and early Hulu gave us hope of a new evolutionary path: content without interruption. But, it didnâ€™t stay ad free forÂ long.</p><p>So letâ€™s look at YouTube, starting with the first signs of life to crawl out of the primordial soup, we have the humble <a href=""https://www.mediapost.com/publications/article/66159/"">InVideo overlays first launched in 2007</a>, these were thin, semi-transparent banners that floated over the bottom of a playing video, usually small text or a tiny ad image that you could close with a small â€œX.â€ These early ads didnâ€™t stop the video, or call for too much attention. They quietly fed on our attention without killing us, like a parasitic symbiosis. While annoying, they didnâ€™t destabilize the delicate environment of early to mid-2000â€™s YouTube.</p><figure><img alt=""The early dismissible youtube ad banner showing at the bottom 20% of the screen"" src=""https://cdn-images-1.medium.com/max/1024/0*QMeV9fQYXmh-XYNo.png"" /><figcaption><a href=""https://setupad.com/blog/youtube-ad-formats-guide/"">Early dismissible youtube ad banner taking up the bottom 20% of aÂ video.</a></figcaption></figure><p>Then between 2010 and 2018 thereâ€™s an explosion of life, the ads grow legs, lungs, and teethâ€¦ YouTube launched <a href=""https://blog.youtube/news-and-events/trueview-video-ads-give-viewers-choice/"">TrueView ads</a>, those aforementioned and all too familiar skippable pre-rolls that appear before your chosen video. These ads demand visibility, they evolved to study their preyâ€™s habits, tracking which openings held attention longest. At first, there was just one, small but intrusive, a 5-second interaction before you could skip and move on. But as we all know, evolution rewards persistence. Soon, a single ad became two, then a pair before and after your video, and finally in 2012, <a href=""https://blog.youtube/creator-and-artist-stories/mid-roll-ads-updates-explained"">mid-roll ads appeared</a>, splitting your entertainment in bite sizeÂ chunks.</p><figure><img alt=""Showing the skipable after X number of seconds ad at the beginning of a video"" src=""https://cdn-images-1.medium.com/max/1024/0*ZSukJyjEmxwlLrTt.jpg"" /><figcaption><a href=""https://setupad.com/blog/youtube-ad-formats-guide/"">Showing the skipable after X number of seconds ad at the beginning of aÂ video</a></figcaption></figure><p>With each mutation, they became harder and harder to ignore. The variety was overwhelming, displaying banners above, overlays below, and videos within videos. The content creators themselves now, mimicking the copy of the ads. By the end of this period, the once teeming with life content creator ecosystem had turned into a chewed through rotting swamp where every spare patch of attention was colonized with a swarm ofÂ ads.</p><p>Understandably, this environment was not the most pleasant so I, like many others, used an ad-block. To put in perspective how prevalent this problem is, hereâ€™s a quote from Cory Doctorow that really struck me: <a href=""https://youtu.be/P1EKQidRooc?si=W5D9-f7NSy8VVT3I&amp;t=1372"">â€œ51% of web users have installed an ad blocker, it is literally the largest consumer boycott in human history.â€</a> The majority of people, which I imagine probably encompasses people making these decisions in the first place, probably have an ad blocker installed. This was our one tool to try and avoid the onslaught of ads that weâ€™d be subjected to on a daily basis, and while there werenâ€™t as easily accessible tools on mobile, weâ€™d at least have a reprieve on our computersâ€¦ or so weÂ thought.</p><figure><img alt=""YouTube rollout of the ad blocker warning popups, showing that Ad Blockers arenâ€™t allowed on the platform."" src=""https://cdn-images-1.medium.com/max/690/0*zH9j2L6vBUyKB43D.jpeg"" /><figcaption><a href=""https://community.brave.app/t/youtube-showing-popup-for-ad-blockers/511149"">YouTube rollout of the ad blocker warningÂ popups</a></figcaption></figure><p>In late <a href=""https://www.androidauthority.com/youtube-ad-blocker-crackdown-growing-3380809"">May of 2023</a>, YouTube began to mutate again, starting with a small subset of tests where they rolled out banners saying â€œAd Blockers are not allowed on YouTube.â€ An easily dismissable popup asking you to uninstall your Ad Blocker. It was the early signs of a dominant species that was going to make it impossible for you to avoid ads. Eventually, making it an unfeasible arms race between ad-blockers and ad-blocker-blockers (thatâ€™s a mouthful). This persisted to where weâ€™re at now where itâ€™s more of a pain to find a way to circumvent ads then to just sit through the discomfort that weâ€™ve been conditioned toÂ endure.</p><p>This whole process has been a calculated and heavily studied rollout. In some ways it is a masterful example of how to slowly introduce a feature to users that doesnâ€™t actually benefit the majority. At first users feel discomfort, but not enough to abandon the platform. The designers, researchers and tech CEOâ€™s know that theyâ€™re pushing unpleasantness and that they have to go as far as they can without causing too much pain because they understand that itâ€™s a delicate ecosystem of attention and people will find alternatives if pushed too far too quickly. If YouTube had not given notice of its intention to block ads for months prior to the rollout of the full ad-block extinction, what would have happened? I personally think the consequences would have been cataclysmic and in some ways hoped that they would have torn off the bandaid a little more violently to shock us intoÂ action.</p><p>So over the course of 25 years, theyâ€™ve increased the heat and now weâ€™re in a pot of boiling water, but in truth itâ€™s we actually donâ€™t know how much hotter it might get. Many <strong>PAID</strong> platforms now include ads, such as Prime and you have to pay additional fees to exclude them. So what comes next in this grand evolutionary chain? Maybe ads that blend seamlessly into the content, AI-generated sponsorships that mimic the creatorâ€™s voice so perfectly we canâ€™t tell where the video ends and the commercial begins. Maybe theyâ€™ll feel like features instead of intrusions. Either way, the species isnâ€™t going extinct anytime soon. Like crabs, like capitalism, ads always find aÂ way.</p><p>The hope is for the next disruption. YouTube once broke the cable monopoly with creativity, and community before slowly mutating into the very thing it replaced. It would seem, thatâ€™s the pattern of evolution, the old ecosystem collapses under its own weight, and something new crawls out of the primordial muck.</p><p>One can hope that there is a better answer gestating. Maybe itâ€™s decentralized video, maybe itâ€™s a new model of sharing that doesnâ€™t depend on monetized attention, more than likely itâ€™s something we havenâ€™t imagined yet. The godfather of the term, <a href=""https://doctorow.medium.com/"">Cory Doctorow</a>, explores this in his new book <a href=""https://www.goodreads.com/book/show/222615930-enshittification""><em>Enshittification: Why Everything Suddenly Got Worse and What to Do About It</em>Â </a>, with the most important part being that final clause: <strong>what to do aboutÂ it.</strong></p><p>As citizens, we can advocate for antitrust laws, interoperability, and policies that prevent platforms from locking in both users and creators. As users, we can choose to support the smaller, values-driven platforms that still have a soul, ones that remind us the internet doesnâ€™t have to be stinky pile of ads, but a place we actively connect. And lastly as designers, we can embed the values of portability, transparency, user control, and minimal hidden value extraction. Better than hoping for the next better thing is putting our efforts into actually designing it.</p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9e6032ff2d20"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/the-evolution-of-youtube-how-every-platform-evolves-into-an-ad-machine-9e6032ff2d20"">The evolution of Youtube: How every platform evolves into an ad machine</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
rss,uxdesign.cc,https://uxdesign.cc/guiding-the-future-of-ethical-design-796e7cc3c9b1?source=rss----138adf9c44c---4,1762902322,Guiding the future of ethical design,"Guiding the future of ethical design

<h4>How to translate philosophical theory into practical design principles and responsibility.</h4><figure><img alt=""Colorful circular diagram titled â€œEthical Interface Designâ€ with sections: Inclusion, Privacy, Autonomy, Transparency, Well-Being, each linked to ethical theories."" src=""https://cdn-images-1.medium.com/max/1024/1*gm8743DS4GxpcGXJdywN2g.jpeg"" /></figure><p>The following article introduces an evolving academic framework called <em>Ethical Interface Design</em>, which examines how moral philosophy can guide interface design in the era of emerging technologies. The working site, <a href=""https://ethicalinterface.com""><strong>ethicalinterface.com</strong></a>, presents these ideas through a minimalist, text-focused layout that intentionally prioritizes thought over visualsâ€Šâ€”â€Ša meta-commentary on where design itself may be heading. The framework remains in active development, and thoughtful feedback isÂ welcome.</p><p>Society is moving beyond screens into conversational, immersive, and neural experiences, placing designers at the center of the ethical landscape of humanâ€“technology interaction. <a href=""https://ethicalinterface.com/""><em>Ethical Interface Design</em></a> helps designers understand not only the impact of their choices but also the ethical frameworks behind them, exploring:</p><ul><li>How interfaces influence behavior across visual, tactile, conversational, neural, and mixed-reality modalities</li><li>The philosophical roots of <em>Ethical Interface Design</em>â€Šâ€”â€Šinclusion, autonomy, privacy, transparency, and well-being</li><li>The trade-offs between competing moral frameworksâ€Šâ€”â€Šsuch as egalitarianism versus meritocracy, or collectivism versus libertarianismâ€Šâ€”â€Šthat determine how ethical priorities are balanced inÂ design</li><li>Practical guidance for applying ethics to real-world projects</li></ul><p><em>Ethical Interface Design</em> equips designers to make intentional, responsible choices as they shape the digital worldÂ ahead.</p><h3>Interface Modalities</h3><p>Every interface mediates the relationship between humans and machinesâ€Šâ€”â€Štranslating intention into action, and in doing so, shaping how we perceive, decide, and connect. Emerging technologies such as <a href=""https://www.ibm.com/think/topics/large-language-models"">large language models</a> and <a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC6914248/"">neural chips</a> are expanding that relationship, blurring the boundary between user and system. As interfaces grow more adaptive and conversational, the very definition of â€œuser interface designâ€ begins to dissolveâ€Šâ€”â€Šreplaced by fluid exchanges that merge cognition, language, and computation.</p><p>This evolution raises profound questions about agency, inclusion, and moral responsibilityâ€Šâ€”â€Šquestions explored further in the Ethical Foundations and <em>The Five Pillars of Ethical Interface Design</em> section of thisÂ article.</p><h4>From Command to Conversation</h4><p>Early computing relied on text-based <a href=""https://www.w3schools.com/whatis/whatis_cli.asp"">command-line interfaces</a>â€Šâ€”â€Šprecise but exclusive, accessible only to those fluent in code. The 1980s introduced the <a href=""https://www.interaction-design.org/literature/topics/graphical-user-interfaces?srsltid=AfmBOorkkBsRT2lPaE0zQed3OJt5HT3hCRkelHQF4-T-KQ_riqUiSau2"">Graphical User Interface (GUI)</a>, popularized by Xerox PARC and Apple, replacing syntax with icons and windows. This visual paradigm made computing public but also aestheticized controlâ€Šâ€”â€Šwhat you could see, you couldÂ do.</p><p>As technology spread beyond the desktop, new modalities emerged. Touchscreens redefined tactility. Voice assistants reintroduced conversation. Gesture and neural systems now blur the line between intention and execution. Each step expanded access while also raising new ethical questions about consent, surveillance, and cognitive autonomy.</p><h4>Types of Interfaces</h4><p>Interfaces are the boundaries between human intention and digital response. They manifest through the senses and combinations of themâ€Šâ€”â€Šand increasingly through language itself in conversational systems.</p><ul><li><a href=""https://www.nngroup.com/articles/visual-design-in-ux-study-guide/""><strong>Visual Interfaces</strong></a> â†’ Screens, icons, and layouts that communicate through sight. Examples include smartphone apps, operating systems, dashboards, and AI applications that blend visual and conversational interaction.</li><li><a href=""https://www.sciencedirect.com/article/pii/S2666998624001728""><strong>Tactile Interfaces</strong></a> â†’ Touchscreens, trackpads, haptic vibrations, and adaptive textures that make interaction physical. The iPhoneâ€™s multitouch screen (2007) made touch the dominant input for a generation.</li><li><a href=""https://dl.acm.org/doi/10.1016/j.cose.2023.103448""><strong>Voice Interfaces</strong></a> â†’ Spoken interaction with assistants like Alexa, Siri, and Google Assistant. Generative AI extends this to conversational agents voice mode, emphasizing tone, intent, and context over fixed commands.</li><li><a href=""https://www.hci.org.uk/article/exploring-the-role-of-gestural-interaction-in-user-interface-design-challenges-and-opportunities/""><strong>Gesture Interfaces</strong></a> â†’ Motion-based control through cameras and sensors, from the Nintendo Wii (2006) and Microsoft Kinect (2010) to AR/VR hand tracking. They extend interface design into physical space and embodiment.</li><li><a href=""https://pmc.ncbi.nlm.nih.gov/articles/PMC6914248/""><strong>Neural Interfaces</strong></a> â†’ Brainâ€“computer links such as Neuralink or medical prosthetics that translate thought into action. These collapse the boundary between user and system, making ethics inseparable from cognition itself.</li><li><a href=""https://www.mdpi.com/2079-9292/13/3/600""><strong>Mixed Reality Interfaces</strong></a> â†’ Hybrid environments such as virtual and augmented reality that merge visual, tactile, and spatial interaction. Examples include Meta Quest, Apple Vision Pro, and AI-powered immersive designÂ spaces.</li></ul><p>Every modality encodes a worldviewâ€Šâ€”â€Šabout who controls interaction, what is considered intuitive, and where agency resides. <em>Ethical Interface Design</em> asks not only how interfaces function, but what kind of human theyÂ imagine.</p><h3>Ethical Foundations</h3><p>Ethics has always asked how we ought to act. From <a href=""https://plato.stanford.edu/entries/aristotle-ethics/"">Aristotleâ€™s pursuit of virtue</a> to <a href=""https://plato.stanford.edu/entries/kant-moral/"">Kantâ€™s universal duty</a> and <a href=""https://plato.stanford.edu/entries/utilitarianism-history/"">Millâ€™s utilitarian calculus</a>, moral philosophy has sought to balance intention, outcome, and character. In design, these same questions take form in pixels, code, and policies. Every layout, algorithm, and feedback loop implies an answer to an ethical questionâ€Šâ€”â€Šsometimes implicitly, sometimes withÂ intent.</p><p>Yet the foundations of ethics are not absolute. Thinkers like <a href=""https://plato.stanford.edu/entries/nietzsche-moral-political/"">Nietzsche</a>, <a href=""https://plato.stanford.edu/entries/foucault/"">Foucault</a>, and <a href=""https://plato.stanford.edu/entries/derrida/"">Derrida</a> challenged the idea of universal morality, arguing that ethical systems are shaped by culture, power, and interpretation. From this view, ethics is not a fixed code but a living discourseâ€Šâ€”â€Šone that evolves with our technologies and values. What counts as â€œgood designâ€ may therefore reflect not timeless truth, but the shifting moral architectures of anÂ age.</p><h4>Philosophical Frameworks</h4><p><em>Ethical Interface Design</em> draws from a range of philosophical frameworks that form the foundation of <a href=""https://ethicalinterface.com/pillars.html""><em>The Five Pillars of Ethical Interface Design</em></a>. While ethics is contextual, these pillars rest on moral principles widely recognized across contemporary society.</p><p>These principles act as guiding coordinates rather than fixed rules, reflecting a shared yet evolving moral landscape. The <a href=""https://ethicalinterface.com/pillars.html"">Five Pillars</a> reveal how ethical tensions emerge when values intersectâ€Šâ€”â€Šthe goal is not to eliminate these contradictions but to make them visible, allowing designers to act with clarity andÂ intent.</p><p>History shows how one value can override anotherâ€Šâ€”â€Šprivacy may yield to collective well-being during crises, or inclusion may challenge merit-based systems. <em>Ethical Interface Design</em> highlights these trade-offs, guiding designers toward more transparent and deliberate choices.</p><h4>Core Ethical and Philosophical Principles</h4><p>The following list outlines major philosophical frameworks relevant to ethical design. While many other schools of thought exist, these principles form the foundational basis for <a href=""https://ethicalinterface.com/pillars.html""><em>The Five Pillars of Ethical Interface Design</em></a>.</p><ul><li><a href=""https://www.britannica.com/topic/collectivism""><strong>Collectivism</strong></a> â†’ A moral and political philosophy that prioritizes the needs, goals, and well-being of the group over individual interests. It emphasizes cooperation, shared responsibility, and social interdependence as essential to human flourishing.</li><li><a href=""https://plato.stanford.edu/entries/communitarianism/""><strong>Communitarianism</strong></a> â†’ A perspective emphasizing community, shared values, and social responsibility in shaping moral and political life. It critiques excessive individualism in liberalÂ thought.</li><li><a href=""https://plato.stanford.edu/entries/egalitarianism/""><strong>Egalitarianism</strong></a> â†’ The view that all individuals deserve equal moral consideration and that social and economic inequalities require justification. It emphasizes fairness, equal opportunity, and the reduction of arbitrary privilege.</li><li><a href=""https://plato.stanford.edu/entries/kant-moral/""><strong>Kantian Ethics</strong></a> â†’ A deontological moral theory grounded in reason and autonomy. It holds that moral action arises from adherence to universal moral laws derived from rationalÂ duty.</li><li><a href=""https://plato.stanford.edu/entries/liberalism/""><strong>Liberalism</strong></a> â†’ A political and moral philosophy that upholds individual rights, freedom of choice, and consent as the basis of legitimacy. It limits interference by the state or others in personalÂ domains.</li><li><a href=""https://plato.stanford.edu/entries/libertarianism/""><strong>Libertarianism</strong></a> â†’ A philosophy centered on individual liberty and minimal external control. It values personal autonomy, voluntary exchange, and limited government intervention, often resisting collective mandates or welfare-oriented design.</li><li><a href=""https://plato.stanford.edu/entries/meritocracy/""><strong>Meritocracy</strong></a> â†’ The belief that rewards and positions should reflect individual talent, effort, and achievement rather than social status or inherited privilege. It values ability and contribution as the basis for distribution.</li><li><a href=""https://plato.stanford.edu/entries/pragmatism/""><strong>Pragmatism</strong></a> â†’ A philosophical movement that evaluates ideas and actions by their practical effects. It privileges usefulness and results over strict adherence to principles or absoluteÂ truth.</li><li><a href=""https://plato.stanford.edu/entries/utilitarianism/""><strong>Utilitarianism</strong></a> â†’ A consequentialist theory asserting that moral value depends on outcomes, with the best action being the one that maximizes overall happiness or minimizes suffering for the greatestÂ number.</li><li><a href=""https://plato.stanford.edu/entries/ethics-virtue/""><strong>Virtue Ethics</strong></a> â†’ A moral framework emphasizing the cultivation of moral character and the pursuit of virtue. It focuses on traits such as honesty, integrity, and wisdom as the foundation of ethical behavior.</li></ul><h4>Toward an Ethical Interface</h4><p>As we move into an era defined by artificial intelligence, automation, and neural integration, ethics becomes both more complex and more urgent. Interfaces now operate at cognitive and emotional levels once considered private. The goal of <em>Ethical Interface Design</em> is to preserve human dignity within this expanding field of influence.</p><h3>The Five Pillars of <em>Ethical Interface Design</em></h3><p><a href=""https://ethicalinterface.com/pillars.html""><em>The Five Pillars of Ethical Interface Design</em></a> are built on established <a href=""https://ethicalinterface.com/ethics.html"">ethical principles</a> and common and emerging <a href=""https://ethicalinterface.com/modalities.html"">interface modalities</a>. Together, they reveal how moral values manifest across different modes of interactionâ€Šâ€”â€Šand how every ethical choice involves trade-offs that designers must navigate responsibly.</p><p>To learn more, review the principles in detail below. For a concise overview, refer to the <a href=""https://ethicalinterface.com/img/five-pillars-ethical-design-2025.pdf"">summaryÂ table</a>.</p><h4>Inclusion</h4><p>Inclusion ensures that interfaces welcome, represent, and empower people across abilities, cultures, and contexts. It rejects design that privileges one type of user at the expense of others and treats accessibility not as accommodation but as design integrity. An inclusive interface assumes difference as a constant, not an exception.</p><p><strong>Examples Across Modalities</strong></p><ul><li><strong>Visual Interfaces</strong> â†’ Support diverse visual and linguistic literacies through adjustable type scales, high-contrast modes, and culturally inclusive iconography.</li><li><strong>Tactile Interfaces</strong> â†’ Design haptic feedback and physical controls that accommodate varied dexterity and sensory abilities, ensuring equitable interaction.</li><li><strong>Voice Interfaces</strong> â†’ Train recognition systems on global accents, dialects, and speech patterns to prevent bias toward dominant languages.</li><li><strong>Gesture Interfaces</strong> â†’ Calibrate motion detection for diverse ranges of movement, body types, and physical capabilities instead of a single â€œidealâ€ gestureÂ model.</li><li><strong>Neural Interfaces</strong> â†’ Build adaptive systems that account for neurodiversity, cognitive variation, and comfort levels in signal interpretation.</li><li><strong>Mixed Reality Interfaces</strong> â†’ Configure AR and VR environments to support varied sensory sensitivities, spatial perception, and physical comfort acrossÂ users.</li></ul><blockquote><strong>Underlying Philosophy</strong></blockquote><blockquote>Rooted in <a href=""https://plato.stanford.edu/entries/egalitarianism/"">Egalitarianism</a>. The core claim is moral equalityâ€Šâ€”â€Šlike cases should be treated alike unless a relevant difference justifies unequal treatment. In design terms, capability differences, cultural background, and context are relevant inputs to equalize effective opportunity, not reasons toÂ exclude.</blockquote><blockquote><strong>Contrasting Philosophy</strong></blockquote><blockquote><a href=""https://plato.stanford.edu/entries/meritocracy/"">Meritocracy</a> links reward to demonstrated talent, effort, or productivity, appealing to fairness through performance. In design, this logic supports optimizing for â€œpower usersâ€ or â€œhigh-value segmentsâ€ to maximize efficiency andÂ impact.</blockquote><p><strong>Ethical Tension: Equality vs.Â Merit</strong></p><p><strong>Design Focus</strong> â†’ Design for accessibility and difference as defaults while recognizing merit, balancing equality with performance.</p><ul><li>Adopt accessibility guidelines (<a href=""https://www.w3.org/WAI/standards-guidelines/wcag/"">WCAG</a>, <a href=""https://www.w3.org/WAI/standards-guidelines/aria/"">WAI-ARIA</a>) as creative constraints.</li><li>Use participatory methods to include marginalized users in testing and feedback.</li><li>Offer personalizationâ€Šâ€”â€Šcontrast, input method, motion sensitivity, voice settingsâ€Šâ€”â€ŠwithoutÂ stigma.</li><li>Audit datasets, prompts, and imagery for cultural or algorithmic bias.</li><li>Frame inclusivity as an innovation driver that benefits allÂ users.</li><li>Provide â€œpower featuresâ€ as additive layers, not the defaultÂ path.</li><li>Evaluate efficiency metrics for the whole user base, not just the fastest quartile.</li></ul><h4>Autonomy</h4><p>Autonomy protects the userâ€™s capacity to think, choose, and act without manipulation or coercion. In interface design, it means preserving agencyâ€Šâ€”â€Šgiving users real control over what they see, share, andÂ decide.</p><p><strong>Examples Across Modalities</strong></p><ul><li><strong>Visual Interfaces</strong> â†’ Empower users to manage visibility and consent through clear privacy controls, opt-in dialogs, and transparent data-use indicators.</li><li><strong>Tactile Interfaces</strong> â†’ Provide physical controls, such as undo buttons and emergency stops, that let users reverse or interrupt actions on their ownÂ terms.</li><li><strong>Voice Interfaces</strong> â†’ Require explicit verbal control over actions, ensuring conscious intent over automated interpretation.</li><li><strong>Gesture Interfaces</strong> â†’ Design gestures that distinguish deliberate intent from incidental movement, preventing unintended triggers.</li><li><strong>Neural Interfaces</strong> â†’ Secure informed consent and allow opt-out before interpreting or predicting user intent from neuralÂ signals.</li><li><strong>Mixed Reality Interfaces</strong> â†’ Give users control over spatial permissions, tracking boundaries, and data sharing within AR and VR environments.</li></ul><blockquote><strong>Underlying Philosophy</strong></blockquote><blockquote>Grounded in <a href=""https://plato.stanford.edu/entries/kant-moral/"">Kantian Ethics</a>. People must be treated as ends in themselves, not as means to collective goals. Ethical action respects rational self-rule, even when doing so conflicts with collective well-being. Favor transparent choices, meaningful consent, and reversibility over efficiency or massÂ benefit.</blockquote><blockquote><strong>Contrasting Philosophy</strong></blockquote><blockquote><a href=""https://plato.stanford.edu/entries/utilitarianism/"">Utilitarianism</a> values the greatest good for the greatest number. This approach may favor streamlined decisions, the removal of risky options, or persuasive defaults to maximize collective well-being and system efficiency.</blockquote><p><strong>Ethical Tension: Freedom vs.Â Welfare</strong></p><p><strong>Design Focus</strong> â†’ Preserve informed choice while allowing limited, transparent guidance that prevents harm without coercion.</p><ul><li>Treat informed consent as ongoing and contextual.</li><li>Provide granular settings for automation and dataÂ sharing.</li><li>Default to privacy-preserving choices.</li><li>State clearly where automation begins andÂ ends.</li><li>Eliminate dark patterns and manipulative urgencyÂ cues.</li><li>When nudging for welfare, disclose the nudge, show the rationale, and offer a one-tapÂ opt-out.</li><li>Provide escape hatches (undo, exit, manual override).</li></ul><h4>Transparency</h4><p>Transparency concerns the integrity of information shared between humans and systems. It requires honesty, disclosure, and authenticity so that what is shown aligns with what is real. It provides the truthful foundation necessary for understanding, accountability, and rationalÂ choice.</p><p><strong>Examples Across Modalities</strong></p><ul><li><strong>Visual Interfaces</strong> â†’ Present data truthfully through accurate charts, clear sponsorship labels, and visible indicators of AI-generated or manipulated media.</li><li><strong>Tactile Interfaces</strong> â†’ Provide feedback that reflects the true system state, distinguishing between successful actions, errors, and pending responses.</li><li><strong>Voice Interfaces</strong> â†’ Disclose when users are interacting with non-human agents and summarize what information is recorded or retained.</li><li><strong>Gesture Interfaces</strong> â†’ Notify users when motion data is being tracked, interpreted, or stored to maintain awareness of system observation.</li><li><strong>Neural Interfaces</strong> â†’ Distinguish which neural signals can be measured versus which should be, clarifying how thought-related data is interpreted andÂ used.</li><li><strong>Mixed Reality Interfaces</strong> â†’ Display clear boundaries between simulated and real elements, including visibility into what is recorded, shared, or AI-generated within AR/VR environments.</li></ul><blockquote><strong>Underlying Philosophy</strong></blockquote><blockquote>Draws on <a href=""https://plato.stanford.edu/entries/ethics-virtue/"">Virtue Ethics</a>. Honesty and truthfulness appear as reliable presentation, avoidance of deception, and willingness to disclose limits. Interfaces operationalize these traits via faithful visualizations, provenance signals, and candid explanation of uncertainty.</blockquote><blockquote><strong>Contrasting Philosophy</strong></blockquote><blockquote><a href=""https://plato.stanford.edu/entries/pragmatism/"">Pragmatism</a> values what works over what is strictly true. It treats clarity and usefulness as higher goods than full disclosure, accepting that some truths may be simplified or deferred when they hinder progress.</blockquote><p><strong>Ethical Tension: Truth vs.Â Utility</strong></p><p><strong>Design Focus</strong> â†’ Reveal truth and uncertainty clearly and in context, maintaining usability andÂ trust.</p><ul><li>Disclose algorithmic involvement in rankings andÂ outputs.</li><li>Make consent and data flows comprehensible inÂ context.</li><li>Expose uncertainty and known limitations.</li><li>Align copy and feedback with actual system behavior.</li><li>Design clarity as a user benefit, not just compliance.</li><li>Use layered explanations: short, then expandable detailâ€Šâ€”â€Šnever hide conflicts of interest.</li><li>Avoid â€œspinâ€â€Šâ€”â€Šsimplify presentation without sacrificing truth.</li></ul><h4>Privacy</h4><p>Privacy safeguards the boundary between the individual and the system. It upholds user control over information, attention, and identityâ€Šâ€”â€Šdefining the conditions under which data is observed, shared, orÂ stored.</p><p><strong>Examples Across Modalities</strong></p><ul><li><strong>Visual Interfaces</strong> â†’ Provide clear permission settings, visible tracking indicators, and accessible private modes that let users manage visibility and data exposure.</li><li><strong>Tactile Interfaces</strong> â†’ Incorporate hardware shutters, physical switches, and tactile indicators to give users direct control over sensors and device activity.</li><li><strong>Voice Interfaces</strong> â†’ Include audible or visual cues when recording begins, and enable quick, in-flow deletion or redaction of capturedÂ speech.</li><li><strong>Gesture Interfaces</strong> â†’ Capture movement data only upon explicit initiation, ensuring gestures are recorded intentionally rather than passively monitored.</li><li><strong>Neural Interfaces</strong> â†’ Protect sensitive neural data through local processing, encryption, and consent-based access to signal interpretation.</li><li><strong>Mixed Reality Interfaces</strong> â†’ Allow users to define spatial privacy zones and control when spatial mapping, camera feeds, or biometric data areÂ shared.</li></ul><blockquote><strong>Underlying Philosophy</strong></blockquote><blockquote>Informed by <a href=""https://plato.stanford.edu/entries/liberalism/"">Liberalism</a>. Individuals possess rights to personal domain and consent that constrain collective or commercial interests. Privacy functions as a precondition of autonomy by preserving mental space for deliberation, identity formation, andÂ dissent.</blockquote><blockquote><strong>Contrasting Philosophy</strong></blockquote><blockquote><a href=""https://plato.stanford.edu/entries/communitarianism/"">Communitarianism</a> prioritizes common goods and may endorse broader sharing for safety, coordination, or solidarity. Legitimate community aims must be balanced against the standing claim of individuals to control access and use of theirÂ data.</blockquote><p><strong>Ethical Tension: Autonomy vs. Solidarity</strong></p><p><strong>Design Focus</strong> â†’ Protect dignity through consent and control while permitting ethical data sharing for genuine collective benefit.</p><ul><li>Practice data minimization.</li><li>Show whatâ€™s shared, why, and for how longâ€Šâ€”â€ŠwithoutÂ fatigue.</li><li>Make controls accessible, contextual, and reversible.</li><li>Process data on the userâ€™s device whenever possibleâ€Šâ€”â€Šuse cloud storage or computation only when essential and clearly justified.</li><li>Frame privacy as trust that enables participation.</li><li>For â€œcommon goodâ€ uses, require aggregation, anonymization, purpose binding, and expiry byÂ default.</li><li>Provide opt-out mechanisms for any data pooling or sharing when feasibleâ€Šâ€”â€Šdocument non-optional cases.</li></ul><h4>Well-Being</h4><p>Well-being asks whether technology supports human and ecological flourishingâ€Šâ€”â€Špsychological, social, physical, and environmental. It favors sustained clarity, balance, and restoration over compulsive engagement, overuse, or unsustainable resourceÂ demand.</p><p><strong>Examples Across Modalities</strong></p><ul><li><strong>Visual Interfaces</strong> â†’ Design calm visual hierarchies, offer dark or focus modes, and adjust color temperature or brightness over time to reduce eye strain andÂ fatigue.</li><li><strong>Tactile Interfaces</strong> â†’ Use haptic cues to encourage rest, posture shifts, or mindful breaks, supporting physical comfort and recovery.</li><li><strong>Voice Interfaces</strong> â†’ Employ tone and pacing that convey calm support without emotional manipulation or artificial empathy.</li><li><strong>Gesture Interfaces</strong> â†’ Encourage healthy movement through interaction patterns that counter sedentary use and promote active engagement.</li><li><strong>Neural Interfaces</strong> â†’ Adapt cognitive pacing and information density to match user comprehension and prevent overload orÂ fatigue.</li><li><strong>Mixed Reality Interfaces</strong> â†’ Balance immersion with grounding cues, allowing users to pause, recalibrate, or exit experiences to protect mental and physical well-being.</li></ul><blockquote><strong>Underlying Philosophy</strong></blockquote><blockquote>Anchored in <a href=""https://www.britannica.com/topic/collectivism"">Collectivism</a><strong>.</strong> Well-being is measured by the health of the collectiveâ€Šâ€”â€Šhow design supports shared welfare, mutual dependence, and the long-term sustainability of both human and ecological systems. Design choices emphasize cooperation, community benefit, and responsibility for collective outcomes over purely individual gain.</blockquote><blockquote><strong>Contrasting Philosophy</strong></blockquote><blockquote><a href=""https://plato.stanford.edu/entries/libertarianism/"">Libertarianism</a> prioritizes individual freedom and self-determination, often resisting design constraints that guide or limit user behavior for the sake of collective good. From this view, interventions that promote well-beingâ€Šâ€”â€Šsuch as limiting usage or prompting restâ€Šâ€”â€Šcan be seen as paternalistic, infringing on personal autonomy even when intended for protection orÂ benefit.</blockquote><p><strong>Ethical Tension: Welfare vs.Â Freedom</strong></p><p><strong>Design Focus</strong> â†’ Foster flourishing and reduce harm without violating autonomy or moral boundaries.</p><ul><li>Replace engagement KPIs with well-being metrics: satisfaction, balance, trust, recovery.</li><li>Use persuasion for healthy habits, not compulsion.</li><li>Add protective friction: time limits, focus modes, optionalÂ pauses.</li><li>Assess long-term emotional and cognitive effects of tone, color, andÂ loops.</li><li>Test for calm, clarity, and self-perception, not only task completion.</li><li>Offer well-being prompts as configurable aids with clear off switches.</li><li>Decouple core utility from compulsive loops (infinite scroll, variable rewards).</li></ul><h3>Design for theÂ Future</h3><p>Design for the future means translating moral philosophy into tangible choices that shape how people live, work, and connect. <a href=""https://ethicalinterface.com/index.html""><em>Ethical Interface Design</em></a> and the <a href=""https://ethicalinterface.com/pillars.html"">Five Pillars</a> framework were developed by <a href=""https://www.linkedin.com/in/micbuckcreative/"">Michael Buckley</a> to help designers approach emerging technologies with awareness and accountability. The framework offers a structured method for aligning design decisions with ethical intentâ€Šâ€”â€Šbridging creativity, usability, and humanÂ values.</p><h3>Collaborate &amp;Â Connect</h3><p>If youâ€™re interested in exploring <em>Ethical Interface Design</em> furtherâ€Šâ€”â€Šor would like to discuss a speaking engagement, workshop, or collaborationâ€Šâ€”â€Šplease get in touch. Reach out at <a href=""mailto:hello@ethicalinterface.com"">hello@ethicalinterface.com</a></p><h4>Services</h4><ul><li><strong>Speaking &amp; Workshops:</strong> Presentations on <em>Ethical Interface Design</em>, media literacy, and design philosophy.</li><li><strong>Consulting:</strong> Guidance for teams creating transparent, inclusive, and autonomy-driven digital experiences.</li><li><strong>Collaboration:</strong> Academic, research, and publication partnerships on ethics and emerging interface systems.</li></ul><p>Together, we can shape technology that serves humanÂ values.</p><h3>About theÂ Author</h3><p><a href=""https://www.linkedin.com/in/micbuckcreative/"">Michael Buckley</a> is a Professor at <a href=""https://www.shu.edu/profiles/bucklemi.html"">Seton Hall University</a>, where he teaches UX/UI design, web coding, and graphic design. With nearly two decades of experience as a creative director, brand strategist, and UX/UI engineer, his work has been recognized across healthcare, publishing, and technology for its innovation and socialÂ impact.</p><p><strong><em>Donâ€™t miss out! </em></strong><a href=""https://micbuckcreative.medium.com/subscribe""><strong><em>Join my email list</em></strong></a><strong><em> and receive the latestÂ content.</em></strong></p><img alt="""" height=""1"" src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=796e7cc3c9b1"" width=""1"" /><hr /><p><a href=""https://uxdesign.cc/guiding-the-future-of-ethical-design-796e7cc3c9b1"">Guiding the future of ethical design</a> was originally published in <a href=""https://uxdesign.cc"">UX Collective</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>"
